5	이거 좋은 아이디어네요. 아마도 구글의 Word2Vec과 딥러닝이 사용된 것이겠죠? 딥러닝으로 적어놓은 문장에서 어색한 부분을 찾아 내는 것도 충분히 가능할것 같습니다.
15	ICLR2016년 논문인데 session 기반의 상품추천인데 아래와 같이  수정된 RNN 을 사용했는데 기존에 비해 정확도가 20~30% 증가 한다고 합니다. Deep Nets가 추천 시스템에서도 힘을 발휘하네요. 온라인 쇼핑몰과 유사한 사업을 하신다면 눈여겨 볼만합니다. 입력도 전체 아이템을 벡터로 (이번 세션에서 선택된 항목은 1, 나머지 0) 통채로 넣어 주네요. 통큰 Deep Nets입니다.Session-based Recommendations with Recurrent Neural Networkshttp://arxiv.org/abs/1511.06939
5	"모든것에 인공지능을 불어 넣겠다."	1	IAoT 인가요... ^^;
9	http://sebastianraschka.com/Articles/2015_singlelayer_neurons.htmlSung Kim님께서 좋은 글이라고 추천해주셔서 공유하겠습니다.
23	Deep Learning의 거의 모든것이라 할수 있겠습니다! 두고두고 하나씩 볼만 합니다.
20	다른 도구들도 많은데 왜 TensorFlow일까요?아래 Andrej 수업에서도 나오는 것 처럼 1. 전문 개발자 (속칭 구글러)에 의해 처음 부터 개발. (다른 도구들은 대학원생이 대부분 처음 만듬)2. Multi-machine, multi-CPU, multi-GPU! 아마 multi-machine이 지원되는 유일한 도구.3. 우리 모두가 사랑하는 Python로 개발 가능단 하나의 단점은 Pre-trained 데이타 (transfer learning등에 사용할)가 많지 않다는 것인데 이는 사용자들이 급격하게 늘고 있으니 곧 많아 질듯합니다.TensorFlow 의 전문가가 되어 보아요.	2	코드를 보면 원래 gfs에 붙어 있는 파일을 분석하도록 되어있는거 같은데 open source로 풀면서 그쪽 코드는 전부 빠져 있더라구요 google폴더가 사라진 ㅎㅎㅎ	1	텐서플로우도 c++를 지원해주는 줄 알았는데 아닌가보네요. ㅠ	0	caffe도 멀티 gpu지원이 되긴해요 텐서보다 효율은 떨어집니다 100%가용률이 안나오더라구요
24	정말 자세하고 재미있기까지한 Neural Nets 에 대한 설명입니다. 한글 번역이 있는지 모르겠지만 없다면 번역대상 2순위라 생각합니다.(1순위는 TF 홈페이지!)
11	Paul Jang님께서 올려주신 글을 보고 든 생각입니다. https://www.facebook.com/groups/codingeverybody/1175651219142079/?comment_id=1175722882468246&notif_t=like생활코딩 사이트에 수많은 좋은 질문과 답변이 올라 오고 있는데요, TF를 이용해서 자동으로 Stackoverflow 같은 사이트를 만들어 볼수 있을것 같은데 같이 해보실 분들 계신가요?제 생각에는 일단 FB API로 글들을 자동으로 모으로1. 글이 질문인지 아닌지 분류한다.2. 답글이 답변인지 아닌지 분류한다.3. 답변 답글중 질문자가 Like 누른것중 최고 Like받은 것을 답변으로 4. 나머지 답변 답글들은 Like순으로 정렬한다.어떠세요? 같이 하실분들은 하트를 보내 주세요.	0	https://github.com/TensorFlowKR/flowbox 에서 작업 시작합니다. 많은 관심과 커멘트 부탁드립니다.
8	텐서 플로가 caffe에 비해서 사용하기는 참 편리한 데요, pretrained 모델의 성능 차이가 꽤 많이 납니다. "I suspect it's due to the padding algorithms being slightly different"파인튜닝용으로는 아직까지는 caffe가 10% 이상(1%로 승부가 나는 머신러닝에서 두자리수 이상..)  참고하세요~	0	알고리즘이 같다면 error rate의 차이는 어디서 오는 것일까요?
10	박사때 랩친구가 이번주에 공개한 패키지입니다.	1	멋지네요!	3	네, 이 친구는 랩에 첨 들어올때부터 범상치 않았어요. 어셈블리를 다른 언어보다 잘하는 친구였는데요. 1-2년차쯤에는 C++기반 ML팩을 쓸만한걸 공개하더니, 이번에는 이런걸 공개하네요. 워낙 잘하는 친구라 나중에 졸업하고 제대로 큰거 하나 터뜨릴거 같네요.
18	딥러닝에서 텍스트 처리할때 (거의) 기본으로 사용하는 Word2Vec등의 모델을 Python 코드와 함께 완벽하게 알려주는 튜토리얼입니다.https://www.kaggle.com/c/word2vec-nlp-tutorial이걸 보신후 TF에 있는 Word2Vec보시면 바로 이해 되실듯 합니다. https://www.tensorflow.org/versions/r0.7/tutorials/word2vec/index.html	3	TF의 튜토리얼 세션의 번역 강의가 있으니 참고하세요 :) https://codeonweb.com/entry/dcc9ef10-5d8f-47c4-bd6e-27878a9a8b62
7	TensorFlow에서 Pre-trained VGG Net을 활용하는 아주 짧은 코드입니다. 여기 계신 고수님들에겐 별 필요가 없겠지만, 저와 같이 처음 시작하는 사람들에겐 도움이 되지 않을까 해서 올립니다. :) 특히 fine-tuning을 할 때 유용하게 사용될 수 있을 것 같아요. TensorFlow로 구현된 Neural style (https://github.com/anishathalye/neural-style)에서 VGG Net의 각 layer의 feature를 뽑아주는 걸 약간 변형했습니다. MatConvNet 용으로 나온 .mat 파일을 불러와 처리합니다. (use_vgg: http://colorscripter.com/s/DEXXGnh)(vgg.py: http://colorscripter.com/s/JH3pALZ)
7	Taehoon Kim 님이 관리하시는 딥러닝 스터디 자료 + TF 구현입니다. 아주 잘 정리 되었습니다. 
5	오늘 올라온 open, high, low, close and volume 정보만 사용한 주식 정보 예측: (LSTM 모델). 수업의 프로젝트 리포트 정도 수준의 매우 초보적인 논문으로 보입니다만 주식 예측 분야 입문으로 보기 좋을듯.그런데 결과는 비교가 없어서 좋은지 어떤지 모르겠네요. (이분야 일하시는분 계시면 코멘트 부탁드립니다.)http://arxiv.org/pdf/1603.07893v1.pdf
20	마음먹고 DeepLearning Deep 하게 파보실분에게 일독을 권합니다. 지금 나와있는 모든 자료중에 가장 잘 정리된듯 합니다. (양이 좀 많다는 것이 함정)http://www.deeplearningbook.org/제가 보시기 좋게 하나의 PDF로 만들어 두었습니다. 저도 오늘부터 Intro  읽기 시작했습니다. 재미있는거 있으면 이 그룹에 올리겠습니다.https://www.dropbox.com/s/pg5kxk0bm2f7p6m/DeepLearningBook.pdf?dl=0	0	Intro 마지막 부분에 흥미로운 것이 있네요.  딥러닝에사 사용된 뉴런의 갯수와  생물들의 뉴런 갯수인데 2056년이면 우리 인간의 갯수보다 많아 진다는 예측이 나옵니다.	1	딥러닝이 본격 사용되면서 이미지넷 인식의 에러률이 급격하게 떨어진것을 보여 줍니니다. 놀랍네요.
14	https://codeonweb.com/course/7e8c4944-308e-410e-85aa-644624613741딥러닝 관련해서 이런 자료도 있으니 함께 참고해 보시길..	1	텐서플로 튜토리얼 번역부터 시작해서 차근차근 글들을 추가해 보려고 합니다.  재미있게 배우실 수 있게 해 보겠습니다! :)
15	https://gist.github.com/haje01/202ac276bace4b25dd3f한글로 잘 정리해주셨습니다.
6	TensorFlow 본격 들어가시기전 Python과 NumPy 확실히 해두시면 좋습니다.이 두 예제 정도는 쉽게 이해하시고 프로그램에 활용하실수 있으시면 Pass! 가물 가물 하신분들은 아래 링크를 참고 하세요.---------def quicksort(arr):    if len(arr) <= 1:        return arr    pivot = arr[len(arr) / 2]    left = [x for x in arr if x < pivot]    middle = [x for x in arr if x == pivot]    right = [x for x in arr if x > pivot]    return quicksort(left) + middle + quicksort(right)--------import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])y = x + v  # Add v to each row of x using broadcastingprint y  # Prints "[[ 2  2  4]         #          [ 5  5  7]         #          [ 8  8 10]         #          [11 11 13]]"	1	다행히 아래 두 예제를 이해하고 사용하는데는 큰 문제 없을 것 같네요.
28	안녕하세요. 최근에 딥러닝 연구에 관심이 있어 TensorFlow로 여러 모델들을 구현하며 공부해 왔었는데 이렇게 커뮤니티가 생겨서 기쁘네요. 제가 지금까지 구현해 온 모델들은 아래 링크에 공개되어 있습니다. 앞으로 좋은 코드들이 공유되어 많이 배울 수 있으면 좋겠네요 :)1. Deep Convolutional Generative Adversarial Networks (Generative)https://github.com/carpedm20/DCGAN-tensorflow2. End-To-End Memory Network (QA)https://github.com/carpedm20/MemN2N-tensorflow3. Neural Turing Machine (Algorithm Learning)https://github.com/carpedm20/NTM-tensorflow4. Character-Aware Neural Language Models (Language model)https://github.com/carpedm20/lstm-char-cnn-tensorflow5. Deep Visual Analogy-Making (Visual Analogy)https://github.com/carpedm20/visual-analogy-tensorflow6. Neural Variational Inference for Text Processing (QA)https://github.com/carpedm20/variational-text-tensorflow7. Teaching Machines to Read and Comprehend (QA)https://github.com/carpedm20/attentive-reader-tensorflow8. Text-based Games using Deep Reinforcement Learning (Reinforcement Learning (RL)) https://github.com/carpedm20/text-based-game-rl-tensorflow	0	대단하시네요. 코드 귱유 감사합니다.
11	우리 그룹에서 열심히 공부하여 알파고를 꺽는 프로그램을 TensorFlow를 이용하여 구현해 도전해 봅시다. Lua를 사용한 구글 딥마인드와, 구글 TensorFlow를 이용한 우리팀, 누가 이기더라도 구글의 승리가 될것 같지만...	0	하지만 알파고가 유리할때 .. 지나치게 손해보는 수를 용인하는것으로 봐서, 아마도 알파고네이쳐 가 4점을 접었을때 삽질을 좀 하지 않았을까요? 그래서 다소 쉽게 따라잡힌게 아닌가 하는 생각이 듭니다.	1	알파고 네이쳐버전도 프로를 이겼는데... 4점을 접었다는게 불가능해 보여서..
4	안녕하세요, 요즘 TensorFlow열심히 삽질중인 유진호입니다. 조금씩 더 해서 빨리 따라잡아 보겠습니다. ^^
5	TensorFlow를 사용하시고 개발하시는 분들의 모임입니다.	0	반갑습니다. 이런 그룹이 생겨서 좋네요.
16	안녕하세요. 방금 가입한 김용욱입니다.요즘 머신러닝에 대해 관심이 많았는데 이런 커뮤니티가 생겨서 좋습니다.한가지 건의가 있는데 회원 가입 승인을 일부 사람으로 제한을 하는 것입니다. 요즘 페이스북 커뮤니티가 다 그렇듯이 여기도 스패머들이 곧 밀려오기 시작할겁니다. 방금 제가 다른 분을 승인한 걸 보면 멤버 모두가 회원 승인 권한이 있는 것 같은데요. 일부 사람으로 제한하시는 것이 좋을 것 같습니다. 그렇지 않으면 한명이라도 승인을 받으면 다른 스패머를 대량으로 승인할 거에요.	0	아 그거 좋은 아이디어네요 아직은 제가 대부분 아는 분들이니 제가 가입승인 권한을 조정할께요	1	아 이게 관리자만 승인하거나 모두가 승인하거나 둘중 하나네요 당분간은 그대로 뒀다가 스패밍이 시작되면 바꾸지요~	0	맞아요. 놔두면 틀림없이! ㅎㅎ	3	이걸 딥 러닝으로 학습하여 FB api를 이용하여 자동으로 되게 하면 좋을것 같아요. 만들어 보실분 계신가요?
23	https://www.udacity.com/course/deep-learning--ud730TensorFlow를 이용한 딥러닝 온라인 강좌입니다. 저는 이 강좌를 공부하는 분들을 위한 스터디 그룹 지원 방안을 요즘 만들고 있습니다. 관심있는 분들 한번 둘러 보세요. 스터디 그룹 관련 내용은 조만간 공지할께요~	1	초대해주셔서 고마워요~
20	이 커뮤니티는 홍콩과기대의 Sung Kim 교수님께서 만들어 주셨습니다. http://hunkim.github.io/ml/ 에서 정말 좋은 머신러닝 강의를 올려주고 계신 분이기도 하지요. 관심있는 분들의 많은 가입과 홍보도 부탁드립니다~
12	TensorFlow관련 한글 자료가 많은 곳입니다. https://tensorflowkorea.wordpress.com/
3	TensorFlow를 사용하시고 개발하시는 분들의 모임입니다. 일반적인 동향/정보, TensorFlow 코딩등 전반에 대해 이야기 나누어요.
9	TensorFlow 쉬운 예제들 모음
5	TensorFlow/DeepLearning에 대한 최신 연구 결과를 볼수 있는곳! 하루에 4~5씩 나옵니다.
2	게임에 나오는 카드 정보를 보고 코드를 만들어 내는 것입니다. 아직은 잘 안되지만 벤치마크를 만들어두고 같이 해보자는 것이 무섭네요. TensorFlow로 구현해보실분 계신가요?
3	TensorFlow 개발자가 사용법을 알려 줍니다. (프로그래밍법을 바로 보시려면 20분 근처에서 시작하시면 될듯)
32	Keunwoo Choi 님의 char-rnn/word-rnn으로 자동 음악을 만들어 주는 스스템에 대한 논문입니다. 이전 연구에 비해 1) 음악노트의 text입력을 사용하고 2) 기존의 연구보다 훨씬 많은 데이타를 사용했다고 합니다.Word-RNN이 더 잘된다고 합니다.https://arxiv.org/abs/1604.05358TensorFlow에도 char-RNN/word-RNN 구현이 있으니 한번 해보셔도 재미있을것 같습니다.https://github.com/hunkim/word-rnn-tensorflowhttps://github.com/sherjilozair/char-rnn-tensorflow
4	안녕하세요 처음으로 글을 써보네요.다름이 아니라 궁금한점이 있어서 이렇게 올려봅니다.저는 bioinformatics쪽에 deep learning을 적용해보려고 공부중인 대학원생입니다.Tensorflow 초보이고, 예제랑 이것 저것 해보면서 사용할 수 있을지 테스트를 해보고 있습니다. 제가 training하는 데이터의 Y는 10110101 과 같은 bit string으로 정의가 되어 있습니다. (약 1000자리)training을 시키고, 특정 input을 넣었을 때 cost가 저 위에 vector string과 minimization을 시켜야하는데, 이때 cost function은 어떤 것이 적합할까요..?기본적인 cost 함수만을 사용해봐서 아직 감이 안오네요..제가 cost function을 따로 구현을 해야하는 것인지,, 혹시라도 조언을 받을 수 있을까해서 올려봅니다.감사합니다.	0	RNN을 사용해보시는 것은 어떨런지요? X는 어떤 입력인가요?	1	일반적으로 cost function을 직접 정의하는 일이 많지는 않습니다. 정확히 풀고자하는 문제와 데이터를 알려주시면 좋을것같습니다.	1	각각의 bit가 서로 완전 독립적이라면 sum of binary cross entropy를 쓰면 되겠지요? 물론 RNN인 경우는 이렇게 cost를 정의하더라도 bit간의 order가 고려되겠구요. 사실 cost function은 풀고자하는 문제와 아주 밀접한 관련이 있습니다. 이 cost function이 주어진 데이터에 대한 가정을 반영하는 것입니다 (좀더 자세히 얘기하면 supervised learning의 경우 p(y|x)에 대한 가정을 반영하여 cost function을 설계합니다).
23	OpenAI Gym 문서의 예제들 따라 해보는 중인데 재미있네요.  https://gym.openai.com/docs딥러닝이랑 연결해 볼 부분이 많을까요?	1	딥러닝과 연결해볼 부분이 아주 많지요. ㅎㅎ
105	DeepMind 가 향후 연구에는 TensorFlow 를 사용하기로 했다는군요.	5	와우 희소식이네요	1	TF에 더 많은 발전이 있을것 같습니다!!	2	그건 아마도 당연하지 않을까 싶네요... 텐서 플로가 대세가 될....	1	슈스터 박사님 이제는 일부가 아니라 전부가 되겠는데요!
12	안녕하세요. 오늘 Skflow를 이용하여 학습한 모델을 save하고 restore 했을 때, dropout이 오작동하는 버그를 발견해 github에 리포트하였습니다.버그의 원인이 매우 근본적인 데에 있는 것으로 추측되어, 당분간은 이런 상황에서 dropout을 안쓰고 실험하는 수밖에 없어보입니다.	0	skflow를 사용하지 않아도  같은 문제가 있을까요?
2	2-D Tensor(예:x=[[1,2,3],[4,5,6]])와 index tensor(예:y=[1,2])를 주면 [2,6]을 얻는 방법이 뭐가 있을까요? x[y]는 안되네요..tf.slice이용하려고도 해봤는데 잘 안됩니다.	0	index tensor의 형태는 조정가능합니다.	0	index tensor를 one hot encoding하여 [[0, 1, 0], [0, 0, 1]]로 만들고,[[1,2,3],[4,5,6]]*[[0,1,0], [0,0,1]]하면 [[0,2,0],[0,0,6]]이 되고,tf.reduce_sum([[0,2,0],[0,0,6]], reduction_indices=1)을 하면 [2,6]이 되네요어렵네요 ..더 좋은 방법 있으면 알려주시길 바랍니다	2	이렇게 하면 되지 않을까요? 기본적인 아이디어는 idx랑 2-d tensor랑 둘 다 1-d space에 놓고서, 가져 오는 방법입니다.
18	다른분이 공유해주셔서 이제야 알았습니다. Scikitlearn 좋아해서 skflow도 한번 봤는데 왜 이제야 알았는지; 앞으로 더 파워풀 해지겠네요~ㅎhttps://github.com/tensorflow/skflow
25	텐서와 무관하지만, 텐서 디버깅 하시면서 한번 보세요. 그 피우기 어렵다는 행운목의 꽃, 저희 집 행운목이 꽃피는 장면을 17초동안 보여줍니다. 보시는 모두에게 큰 행운이 가득하기를 ...	0	오... 행운목 꽃은 처음 보내요	1	향도 굉장히 강하고 좋죠! ㅎㅎ	0	처음엔 동영상인줄도 몰랐네요..
37	Haimin Lee님이 올려 주신 영상에서 Mike가 소개하는 StackoverFlow 의 TensorFlow 페이지입니다. 질문이 있으면 바로 답을 얻을수 있다고 소개 합니다. 답달기 수월한 초보적인 질문도 아주 많이 올라오는데, 저희 멤버들도 StackoverFlow 에서도 함께 활동하면 좋을듯 합니다. http://stackoverflow.com/questions/tagged/tensorflow?sort=newest
31	[word-rnn 초기 구현] 찾아봐도 Word-RNN의 TF구현이 없는듯 하여, 기존의 char-rnn의 입력 부분만 바꾸어 단어별 RNN을 만들어 보았습니다.https://github.com/hunkim/word-rnn-tensorflow아직 단어 갯수제한이나 문장을 cleanup 하는 등의 기능은 없습니다. 분야에 따라 다르겠지만 시를 만드는 경우 좀더 그럴듯한 결과가 나옵니다."사랑밖에 줄께""적당히 거슬러 눈물""살아 흐느낌이 사이를 자만할까 웃어주리라"	1	"사이를" 을 넣어줄때 을,를 같은 조사포함해서 넣어주도록 구현하셨나요?	1	텐서 플로가 좀 미숙해서 ㅎㅎ rnn돌리던 데이터로 올리신모델로 돌렸는데 그냥 중단되네요~	0	미투! 아윌 래프 위드유아이 러뷰 봇~~^^
77	오늘 NDC 2016에서 발표한 내용입니다. 텐서플로우에 관한 것은 아니지만, Sung Kim님이 추천해주셔서 올려봅니다- 	1	멋진 발표자료네요 ㅎㅎ	0	딥러닝으로 하면 99%정확도도 나올수 있을까요?	1	멋집니다. ~ 직접 봤으면 더 좋았을 그런 발표군요 ^^!!	1	들으러 가고 싶었는데 등록부스를 지키고 있었습니다 자료 감사드려요!	1	두고두고 보겟습니다. 감사합니다. 이런 꿀자료를 ㅋㅋ..	1	발표 좋았습니다 ~ 감사합니다 ㅎ
13	혹 TensorFlow로 구현된 word-rnn 보신적 있으신가요? Torch/Lua 구현은 https://github.com/larspars/word-rnn 에 있는데 TensorFlow는 안 보이네요. 아님 ptb_word_lm.py 등을 참고하여 새로 만들어야 할까요?http://clickotron.com/ 은 100% word-rnn으로 만든 뉴스 사이트 인데, 내용은 좀 그렇지만 제목을 잘 뽑네요. word-rnn으로 재미있는거 많이 만들수 있을것 같아요.
1	Tensorflow를 사용해서 naive bayes 를 구현한 사례는 없을까요?직접 구현해보려고하는데 아직 초보라ㅠ ㅠ도움이 될만한 자료라도 알려주시면 감사하겠습니다.	2	꼭 Tesnorflow를 사용하셔야 하는건가요? 아니면 scikit-learn을 쓰셔도 좋습니다.
93	지난주 목요일, Campus Seoul - 캠퍼스 서울에서 있었던 Google Machine Learning & TensorFlow 관련된 Talk의 동영상을 공유합니다. 참석하지 못하셨던 분들도 full video를 보실 수 있습니다. Enjoy!	2	오오~ 감사합니다. 보고 또 봐야겠습니다!!	2	손상현	1	너무 감사합니다 ^^	1	잘 보겠습니다 감사합니다	1	자료 감사합니다.	1	신청해놓고 못가서 아쉬웠는데....감사드립니다.	2	화면은 보지 않고 음성만 듣고 있는데 처음 소개하시는 분이 유명 앵커이신줄.... 목소리 정말 이쁘시네요. 마이크 시스템이 좋은것인지? ㅋㅋ
32	[텐서플로우, 느리다는 편견을 깨다]딥러닝 라이브러리 중 텐서플로우는 사용하기 쉬우나 성능이 느린 것으로 알려져왔습니다. 그래서 초보자용 라이브러리가 아니냐는 비아냥도 들었었죠. 하지만 그동안 아주 중요한 진전이 있었던 것 같습니다.페이스북 연구원이 라이브러리들의 성능을 비교했는데 CuDNN+Torch가 가장 빠른 반면, 순수한 라이브러리들끼리의 대결에서는 TensorFlow가 Caffe와 Torch를 눌렀다고 하네요. (아래 수정 참고) TensorFlow를 연구하는 구글 연구원이 아닌 Torch를 연구하는 페이스북 연구원이 밝힌 결과라 더 객관적으로 보입니다.(수정) TensorFlow는 자체적으로 CuDNN을 사용하고 있고, 따라서 Caffe와 Torch와는 동등한 비교가 아니라는 지적이 있습니다. 확인 후 수정결과 올리겠습니다.(수정2) TensorFlow의 성능 향상 결과는 mainly CuDNN v2 -> v4의 버전업 적용에 따른 것으로 보입니다. (아래 native Caffe와 native Torch는 CuDNN 사용하지 않음) 따라서 이제 CuDNN v4를 채용한 라이브러리들은 대부분 비슷한 성능을 가지게 되었네요.	0	속도가 느릴뿐더러, 성능도 안좋게(패딩)나오는데 그것도 궁금하네요	0	속도 봤을때  gpu버전에서 cudnn쓴 텐서플로어 아니가요	1	오.. 대단하네요.. 손상현 참고해^^	0	Tensorflow 도 CUDA 썼네요	1	CUDA는 다 쓰지 않았을까요? Caffe, Torch, TensorFlow 모두 같은 조건에서 실험 했을겁니다. 그래야 벤치마킹이니까요	1	Caffe (native)의 의미는 cudnn이 아닌 자체 연산 라이브러리를 사용했다는 의미입니다. 당연히 GPU는 모두 사용하지요. Tensorflow는 cudnn 라이브러리를 이용한 결과입니다. 따라서 순수 라이브러리의 비교 결과가 아닙니다.	0	원문 수정하였습니다. 의견주신 분들 감사합니다.	0	Torch가 다소 좋은 성능을 내는 잘 알려진 이유가 있나요..?
1	안녕하세요 Tensorflow 예제 코드를 보다가 궁금한 부분이 있어서 문의드립니다.optimizer = tf.train.GradientDescentOptimizer(learning_rate)global_step = tf.Variable(0, name='global_step', trainable=False)train_op = optimizer.minimize(loss, global_step=global_step)이 부분에서 global_step이 하는 역할이 무었인지 궁금해서요..API 문서에도 global_step: Optional Variable to increment by one after the variables have been updated.이렇게 나와 있고, 아래 링크에서도 그냥 단순히 count 증가시키는 용도인 것 같은데 맞나요??혹시 어떤 용도로 쓰이는 건지 알수 있나요??	0	문서 상으로는 그런 것 같네요. count = count+1 같은 코드를 간결하게 만들기 위한 용도 같은...	4	optimization 과정을 보면 대개 하나의 mini-batch 를 feed-forward + back-prop (SGD update) 하는 하나의 단위를 1 step 이라고 합니다. TF에서는 global_step 이라는 variable을 통해 이 step 값을 트래킹 하고, optimizer 연산이 한번 실행될 때마다 global_step 을 자동으로 하나 증가시키도록 편리하게 만들어 두었습니다. 따라서 매번 수동으로 step을 관리하지 않아도 되고요.step이 필요한 이유는 여러가지가 있겠지만, 가령 주기적으로 몇 step마다 evaluate / validation / checkpoint 저장 / learning rate decay 를 하기 위해 필요할 것이고, 또한 loss/accuracy 추이의 시간별 추이 그래프로 보기 위해서도 (x축) 필요합니다. 모니터링하고자 하는 loss가 언제 값인지 알기 위해 summary에 add_summary() 할 때 현재 step을 넣어주는데서도 확인할 수 있어요.
9	안녕하세요. 혹시 우분투에 pycharm 설치 해서 tensorflow 사용하시는 방법아시는 분 계신가요? 모든 처음 써보는 프로그램들이라 한참을 헤매고 있습니다. 도움 바랍니다.	0	전 Mac에서 Pycharm인데요, 일단 command line에서 python xx.py로 실행가능하시면 Pycharm 에서 바로 됩니다. (맥의 경우)	1	https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#pip-installation 저는 이것으로 tensorflow 설치하였습니다 ㅎㅎ	1	http://ubuntuhandbook.org/index.php/2015/07/install-pycharm-ubuntu-1404/ Pycharm 설치(community)	0	드디어 성공 했습니다. ^^	0	이제 부터 코딩하는데 속도를 낼 수 있겠네요. 해결 하는 방법은 virtualenv를 실행하고 그 안에서 pycharm 실행 시키면 되더라구요.
28	CNN과 카메라 하나로 자동 운전이 가능한 날이 올까요? NVIDIA 연구자들이 카메라 3대와 운전자의 핸들 조작+알파로 학습한다음 카메라 하나만 입력으로 사용하고 운전대를 어떻게 움직이는지를 예측하여 자동운전 합니다. 속도와 브레이크는 어떻게 하는지 모르겠네요.시뮬레이션과 실제 도로 운전을 했는데 98%정도 자동 운전이 가능했다고 합니다. CNN의 창시자인 Yann이 이 논문에 대해 직접 코멘트를 달았습니다. 우리가 운전하듯이 복잡한 센서 없이 카메라만으로 자동운전 가능할까요?	1	카메라 1대로 하기에는 시야각이 안나오지 않나요? 보복운전도 문제일것 같고요	3	음... CCTV 영상과 차량용 블랙박스 영상을 예전에 조금 만져봤었습니다. 물론 기술적으로 가치 없는 연구는 아니지만.. 차량용 혹은 CCTV 영상은 나이스한 환경뿐 아니라 가혹한 환경도 고려되어야 합니다. 아침 저녁, 그리고 밤 등 시간적으로 바뀌는 빛 환경, 그리고 날씨, 그 와중에 신호등도 정확히 검출해야 하고요. 기존 차량뿐 아니라 동물, 낙석등의 잘 관찰되지 않는 장애물까지요. 특히 밤뿐 아니라 낮에도 발생하는 빛반사의 경우 카메라 한대로는 한계를 나타낼겁니다. 의료 분야와 자율 운전 분야는 이미지넷과 달리, 인식 결과에 따른 책임이란 문제가 따르는 분야가 실제 상용에서는 가혹하리만큼 높은 성능을 요구하고 있습니다. 의료 영상의 경우 99% 정확도도 가치 없다고 평가하시는 분들이 많이 있습니다. 0.1%의 실수를 기계가 책임지게 할 수 없기 때문일거 같습니다. 저도 논문을 재밋게 읽었지만, 업계에서 많이 고생하시는 분들이 고민하시는 문제를 많이 보지 않은 논문이였다고 생각합니다. 물론 딥러닝 분야에서 보면 재밋는 연구지만요 ^^:제가 주제넘게 떠들어봤습니다.	1	사물의 거리를 측정해야 하므로 카메라 두대 또는 한대+거리센서 가 있으면 최소한 현실세계에서 이용가능한 수준의 결과물은 가능할 거 같아요	1	전 개인적으로 이런 end2end 방식에 매우 비관적입니다. 이런 분야는 99.9%도 부족할 때가 많은데, end2end와 같은 self-verification이 힘든 방식은 적절하지 않아보여요. 모빌아이의 샤슈아 교수님도 비슷한 강연을 하셨죠. (https://www.youtube.com/watch?v=GCMXXXmxG-I&feature=youtu.be)	2	뉴럴넷의 인식률과 정확도 문제에서 보통의 답변은 그래도 기계는 운전하면서 스마트폰을 하지도 않고 졸지도 않는다 인것 같습니다컴퓨터가 잘하는 것과 잘못할가능성이 높은것을 잘분리해서 사용할수 있는 환경을 만들어 준다면Self driving이 가능할 것도 같습니다물론 저는 기술적 결함 한계 모두 인정하는 쪽입니다아 end to end 학습에 대해선 위에 최성준님이 적어주신 동영상에서 가능성과 그 대안이 나오는것 같습니다궁극적으로는 가능하겠으나 여전히 많은 어려움이 있고그 이전단계로 알파고와 같은 뉴럴넷+가치판단의 방식이 당장 시작해볼 수있는 형태라고 보고 있습니다	0	
58	tensorboard를 써서 만든 네트워크의 모양을 보는 예제를 만들어보았습니다. CNN: https://github.com/sjchoi86/tensorflow-tutorials/blob/master/notebooks/vis_cnn_mnist.ipynbMLP: https://github.com/sjchoi86/tensorflow-tutorials/blob/master/notebooks/vis_mlp_mnist.ipynbRNN: https://github.com/sjchoi86/tensorflow-tutorials/blob/master/notebooks/vis_rnn_mnsit.ipynb정말 쉬워도 너무 쉽게 만들어놨네요.. 이런 그림들을 논문에서 볼 날이 멀지 않은듯 합니다.	2	Dimension에 따라 굵기를 다르게 준 것도 정말 대박인 것 같아요...	0	이번 0.8에 새로운 기능으로 Tensor의 size가 표시 되어 디버깅시 매우 도움이 됩니다. 그림 정말 멋지네요.
13	TensorFlow를 Keras를 통해 이용하고 계신 분 있으신가요? 실제 어떤 장점이 느껴지시던가요?	1	사용해보지는 않았지만 Keras는 TF와 Theano를 백엔드로 사용할수 있는것 같던데, 그러다 보면 TF의 장점은 따로 살리기 어렵지 않을까요? SKFlow가 더 좋은 선택이 아닐지요?	2	저는 예전에 Keras를 주로 사용했었는데요, Keras는 굉장히 추상화가 잘되어 있어서, 정말 쉽게 아키텍쳐를 설계하고 수정할 수 있는 장점이 있습니다. 같은 아키텍쳐를 Keras와 TF로 짰을 때, 코드 자체의 가독성과 이해도는 Keras 쪽이 많이 더 좋습니다.다만, Keras는 제가 썼을 당시에 버전이 업데이트 될 때마다 기존코드의 하위 호환성 보장이 안되어 그에 맞춰 매번 코드를 수정해야하는 문제가 있었습니다. 그리고 최근에는 TF와 Theano의 백앤드를 동시에 지원하면서, layer를 새로 설계해야하는 일이 이제 매우 어렵게 되었습니다.(특히 RNN계열의 layer 설계는이 매우 힘들거나 불가능)제가 내린 결론은 가벼운 목적으로 딥러닝 아키텍처를 설계할 경우에만 Keras가 강점이 있는 것 같습니다.	1	코딩방법 자체는 텐서보다 직관적이에요 아키텍쳐 자체는 잘짜놓은듯 합니다!
25	얼마 전 최성준씨와 대화가 생각나 글을 남깁니다. 텐서플로우를 그냥 사용하시면 GPU 메모리를 한번에 다 잡고 시작해서 여럿이 GPU를 공유하실 때는 난감하실 때가 있는데요. 간단한 옵션 설정으로 제한적으로 잡을 수 있습니다. http://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory# Assume that you have 12GB of GPU memory and want to allocate ~4GB:gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))GPU 옵션 설정으로 제한적으로 잡을 수 있게 되어 있네요. 이제 짬을 내 성준씨와 김교수님 자료를 바탕으로 텐서플로우 구경을 시작해서.. 쓸데없을지 모르지만 정보 공유합니다.	0	오 이거 진짜 필요했던 정보인데 감사합니다!	0	유용한 정보 감사합니다~	3	한가지 첨언하자면, 여기서 memory fraction의 기준이 현재 사용 가능한 메모리입니다. 예를 들어 현재 12GB가 남아 있고 6GB씩 두개의 프로세스를 돌리고 싶으면 첫 프로세스는 fraction 0.5를 주고 다음 프로세스는 fraction을 1로 줘야 합니다.
2	혹시나 하는 생각에 질문 드립니다tensorflow와matplotlib를 import 시킬 경우에 에러코드 139를 표시하는데 이것에 대한 해결 방법을 아시는 분이 계신가요?잘 되던 녀석이 갑자기 import에서 죽어버리니 당황 스럽네요..os는 우분투 16.04 lts이고 interpreter는 2.7.11입니다	0	에러메시지가 작아서 잘 안보이는데 메시지 올려 주시면 좋을것 같아요.	1	저도 처음 보는 에러인데, 메모리가 충분하신지요? 메모리 139는 메모리 관련에러라고 합니다.	1	"attempt to access a virtual address which is not in your address space", which would support a memory allocation error, which could happen easily if you are on 32-bit system with low amount of RAM, and other things are already in memory." http://stackoverflow.com/questions/23704040/	0	matplotlib import하는 라인을 주석 처리 하면 아무문제 없이 실행 됩니다.	1	자문자답 TensorFlow를 0.7로 다운그레이드 하니 해결되었습니다.import 할때 tensorflow를 맨위에 import 하고 다른 라이브러리를 차례대로 import 하세요 안그러면 역시나 139 문제가 나오더군요..혹시나 원인을 아시는 분은 도움을 주시기 바랍니다	1	비슷한 문제로 저도 exit code 139 뜨면서 import tensorflow 에서 죽었는데, 그 위에 from sklearn 해주니 돌더군요. skflow 를 사용하지 않는 코드에서도요.skflow 가 추가되면서 초기화 부분이 뭐가 꼬였던지 한것 같습니다.시간이 지나 해결되기를 기대하면서...
76	이제 영어의 문법도 딥러닝으로 고쳐 줍니다. AESW라는 100만 영어 문장의 문법 수정 자료를 시퀀스-시퀀스로 학습니다. (이런 공개된 데이타가 있다는 것도 멋지네요.) 특이점은 word/char embading을 사용하지 않고 CNN을 사용한다는 것입니다.F1이 66% 정도 나오는데 노이즈가 많을수 밖에 없는 이런 문법수정 데이타에서 상당한 결과라 생각됩니다. 앞으로 영어문법 완벽하게 고쳐주는 로봇이 나올날이 멀지 않은것 같습니다.https://arxiv.org/abs/1604.04677	1	와우 엄청나네요. 데이터가 있단 것도 멋집니다	1	word2vec 이랑 비슷하네요.
29	이해하는 것들을 정리하며 텐서플로우를 공부하고 있습니다. 간략히 텐서플로우의 기본 구조를 적어봤으니 아직 텐서플로우 코딩을 시작하지 않으신 분들은 참고해주세요 ^^ 내용에 대해 고수님들의 피드백도 기다리겠습니다!	2	오오~ 글이 좋아 번역하시는 분들이 나올것 같아요.
18	지난 4월 21일에 열린 구글 텐서플로우 강의 내용이아주 상세하게 기사로 나왔네요. 아직 안 읽어보신 분들 추천드립니다^^텐서플로우 이용팁과 구글이 진행하고 있는 프로젝트 내용,그리고 지원하는 엔비디아 GPU 등 전반적인 참석자 Q&A들이 잘 정리되어 있습니다.
55	Node로 간단하게 해보는 Wit과 Facebook 메신저의 연동입니다. FB, Bot, serve로 나누어 테스트하기 쉽게 만들어 보았습니다.  https://github.com/hunkim/Wit-FacebookWit은 앞단에서 NLP를 담당해서 context를 뽑아 내고 뒷단에서 Node js모듈이 답을 만들어 주는 형식입니다. 상당한 메뉴얼 작업이라 하겠습니다. 추후로는 TensorFlow QA 모델을 뒷단에 넣으면 정말 멋진 bot이 탄생할것 같습니다.저도 처음해보는 것이라 설명과 코드에 오류가 있을수 있는데, comment와  PR환영합니다.	0	tensorflow는 아니지만 JAVA로 인공신경망 구현한거에대해서 질문이있는데 받아주실수있나요 ?	1	좋은 예제 감사드리고 승인 감사드립니다..^^
39	CNN을 Text Classification에 활용한 예가 있어 수집하였습니다.샘플 예제가 잘 되어있어 따라 해보면 재믿겠습니다.	1	감사합니다.
10	이 예제들도 아마 전에 공유된 적이 있겠지요? 혹시 안되었을까봐 공유해봅니다. implementation 깃헙에 흡수해버려요ㅎㅎ	0	요즘 하는 작업이 pure python(+numpy, scipy), scikit, tensor flow로 머신러닝 알고리즘 예시를  만드는 일인데... 의외로 tensor flow는 deep learning 말고는 많지는 않군요. 예제를 뿌려주셔서 감사.	0	아나콘다를 미신다고 하지 않으셨습니까... 그나저나 작업 끝나시면 제가 줍할게요~	0	제 대부분의 코드가 이 튜토리얼을 따라한거에요. ㅎㅎㅎ
43	Python Flask 로 간단하게 해보는 TF serving 예제. TensorFlow Serving 이 gRPC를 사용해서 성능은 좋다고 하는데 상당히 복잡한 면이 있는데, Python Flask 와 TF의 restore 를 이용하여 쉽게 RestAPI로 서비스 하는 데모입니다.JS로 직접 숫자를 입력받는 모듈도 있어 재미있는 것을 만들어 볼수 있을것 같습니다.깃허브: https://github.com/sugyan/tensorflow-mnist데모: https://tensorflow-mnist.herokuapp.com/	1	컨볼셔널 정확도가 상당하네여
51	혹 참여하신 다른 분들도 후기 많이 올려 주세요.
33	안녕하세요?자연어처리(NLP) 스터디그룹 바벨피쉬(https://www.facebook.com/groups/babelPish/)의 송치성입니다. 지난 주 RNN(Recurrent Neural Net)을 이용한 악평생성기에 대한 발표를 했는데요. 혹시 자연어처리에 관심있으신분 계실까봐 여기에도 공유합니다! WildML의 튜토리얼을 보고 따라하느라 Theano로 모델링되었는데,, TensorFlow로도 제작해서 튜닝도 해보고 싶네요 ㅎㅎ----발표자료 : http://www.slideshare.net/shuraba1/bad-comment-generator-using-rnn실습코드 : http://nbviewer.jupyter.org/github/daydrill/BadCmtGenerator/blob/master/bad_cmt_generator_code.ipynb	2	"TensorFlow로도 제작해서 튜닝" 기대 됩니다!	1	Ppt 예쁘네요!
86	Google Brain팀에서 TensorFlow를 개발하고 한국어 음성인식도 개발했던 Mike Schuster씨와 이곳 TensorFlow KR 커뮤니티 운영자이신 김택수 김태훈 님과 함께 즐거운 시간을 보내고 있습니다~	2	거물들과 노는구나. ㅎ Mike Schuster박사님께 강연 잘 들었다고 전해주삼~ 제일 앞자리에서 열심히 들었다고...	1	와...	1	보기 좋습니다.
22	Hi everybody,My teammates and I have been working on a very first tutorial based on TensorFlow. Through this project, our aim is to help people discover and try their hands at ML by solving an image recognition exercise. We’ve just released a first version and we would like to take it to the next level, so we are looking for feedback from Machine Learning enthusiasts.Here is the link to discover the tutorial: https://goo.gl/1zCrDFThank you very much and I hope you’ll like it! :)Maria﻿
30	2015년 imagenet의 Top5예측 에러율 3%대로 떨어뜨려 사람들을 깜짝 놀라게 했던 ResNet의 TF구현입니다.https://github.com/ppwwyyxx/tensorpack/tree/master/examples/ResNet	4	Iteration 30000 넘어가는 부분에서 에러가 확 떨어지는데 왜 그런걸까요
30	TensorFlow training 모델 save/restore 예제가 추가 되었습니다.  추가로 training을 할때 이전 모델을 불러 올수 있어 매우 유용합니다. https://github.com/nlintz/TensorFlow-Tutorials/blob/master/10_save_restore_net.py이제 대략 남은 것은 char/word RNN, TensorFlow Serving, 분산 TensorFlow의 매우 매우 쉬운 예제들인데 혹 도와 주실분 계신가요?	0	남은 것 모두 기대됩니다~!! 도움 되고 싶지만 아직 TF 완전 초보라 아쉽네요.	0	혹시 분산 TensorFlow 예제 돌리는데 성공 하셨나요?
13	혹시 참석하시는 분 계시나요?	1	저 갑니다~ 가능할지 모르겠지만 여기 그룹분들 인사하면 좋겠네요~ 그러고보니 혹시 스사모에서 1등 상품 받으신분 아니신가요?ㅎㅎ	0	다녀와서 후기 남겨주시길...	0	기숙학생이라.. 아쉽네요	0	후기 남겨주시면 감사하겠습니다.^^	0	가고싶은데 신청 마감이더군요 ㅠㅠ	0	저 어제 참석했었는데, 생각만큼은 아니었지만 그래도 나름 유익한 시간이었습니다~	1	내용은 무난했고요, 질답시간에 궁금했던 것들이 몇가지 해소되어서 좋았습니다.
33	제가 진행중인 수업( hunkim.github.io/ml/) 의 종강 주제인 RNN 을 준비하면서 예제를 만드는 중인데요. Karpathy's RNN슬라이드가 쉬워 이를 TF 만들어 보았는데 혹시 잘 되었는지 한번 봐주시겠습니까?TF RNN쪽은 API doc이 없어서 TF 예제/코드를 보고 해야해서 잘되었는지 모르겠습니다. batch도 하나 밖에 없어 state 를 보관할 필요도 없을것 같습니다만.  의견 있으시면 부탁드립니다.	3	벌써 종강이라니 ㅠ 수고많으십니다 감사합니다 ^^	1	교수님 강의로 얼렁 배워서 도움을 좀 드려야겠네요.ㅎㅎ
51	깃헙에  흑백사진을 컬러로 바꿔주는 걸 tensorflow로 바꾼 프로젝트가 있습니다. 정리해 보았습니다.	1	감사합니다. 재미있게 읽었습니다. 혹시 github URL 여기 추가 해주실수 있으신지요? https://github.com/TensorFlowKR/awesome_tensorflow_implementations
16	열기가 후끈후끈 하네요. 열기로 인해서 다운 되겠네요(유머)	2	나도 거기
81	1,000! 가입해주시고 활동회주시는 1,000 명의 회원님들에게 감사드리며 여러분들의 귀한 이름으로 word colud를 만들어 보았습니다. 다시 한번 감사드리며 자주 뵙도록 하겠습니다.	2	축하합니다	2	축하드려요~ 가까스로 들어갔네요 ㅋ	2	제 이름도 껴있겠죵	1	수고가 많습니다. 감사합니다.
30	여러 종류의 넷트웍에다, Belief Trackers, DB까지 붙여서 만드는 특정 task를 수행하는 봇 논문. 데이타 베이스 쿼리 까지 연결시키고 결과를 다시 넷트웍의 입력으로 사용하는 것이 재미있네요.https://arxiv.org/abs/1604.04562정확도도 상당하고 논문에 붙어 있는 대화 예제도 훌륭합니다. Human : hello Machine : what cuisine would you like ? Human : afghan Machine : i am sorry , there are no afghan restaurants . would you like something else ? Human : korean Machine : little seoul serves korean food , it is located at 108 regent street city centre . Human : is it expensive? Machine : little seoul serves korean food and is in the expensive price range . Human : what area is that Machine : little seoul is located in the centre area of town . would you like their number ? Human : yes Machine : the telephone number is 01223 308681 . is there anything else i can help you with today ? Human : no goodbye Machine : thank you for using the cambridge restaurant system , goodbye .그림과 대화에 한국 식당이 나오는 것으로 봐서 저자중 한국분이 있는 것일까요?	1	이런 시스템에다 DB를 붙이지 말고 구글을 붙이면 어떻게 될까요?	1	좋은 논문 링크 감사합니다~ 자연어처리 전통적 관점에서 googling (혹은 정보검색)의 성능이 50%미만으로 생각이 있어, 더욱 정확한 답을 위해 DB를 붙였으리라 생각됩니다.	0	염화음	1	요즘 인매모리 처리가 많아서요
20	캠퍼스서울에서 텐서플로우 에 관해 이야기 하는데 벌써 모집인원이 다 차버렸네요! 텐서플로우의 개발과정과 향후 방향성에 대해 집중적으로 이야기할 예정이라니 개인적으로 흥미가 있었는데, 혹시 가시는 분 계신다면 모임 끝나고 내용 공유 부탁드립니다!	1	참가신청 해놓긴 했는데 시간이 될지 모르겠네요 ㅜㅜ 갔다오게 되면 내용 공유드리겠습니다~	1	혹시 생중계 지원 되나요? ^^;
110	몇시간 전에 올라온 스텐포드 CS224D 수업의 TF Tutorial 비디오 입니다. TF 튜토리얼중 최고입니다. 발음도 좋고 말도 잘하고 내용도 매우 충실 합니다. 강추 합니다. 비디오: https://www.youtube.com/watch?v=L8Y2_Cq2X5s슬라이드: http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf
7	TensorFlow (TF), 딥러닝의 모든 이야기 나누어요.TF 구현 모음: https://github.com/TensorFlowKR/awesome_tensorflow_implementations
21	Hyeongdo Lee 이 소개해주신 First Contact With TensorFlow 결론 부분에 나오는 이야기 입니다. 충분히 공감가고 그래서 지금 TensorFlow를 시작하시는 것이 매우 도움이 될듯합니다.
5	TF를 가지고 CudNN을 해보다가 알게된 것입니다.실행 중에 이런 에러를 보았습니다."could not set cudnn filter d\escriptor: CUDNN_STATUS_BAD_PARAM"무엇이 잘못되는지 알아보니, TF 0.8rc는 cuDNN v5바이너리 호환이 안되네요. CudNN v4를 설치하니 문제 해결.^^
7	Hyeongdo Lee 이 소개해주신 First Contact With TensorFlow보고 있는데 Tensor Serving 그림 귀엽게 소개하네요.혹 Tensor Serving으로 서비스 하시는분 계신가요? 설치나 운영 경험담 부탁드립니다.
4	가입 승인 감사드립니다. 요즘 python으로 라즈베리파이 3에다 뻘짓거리를 하고 있는 온실 환경제어/양액기 양액 제어 개발합니다. ^^... 잘 부탁드립니다.	0	환영합니다!	0	이문환 차장님. 여기서도 뵈니 반갑니다^^	0	정상용 잘 지내시죠? ^^
2	가입승인 감사드립니다.공부해야될 양이 꽤 많아보이네요^^;
23	아직 들여다 보지는 않았는데 책이 나왔다고 합니다.	1	전 오늘 구매해서 제본을 하는중인데... 언제볼까요 ㅎㅎ	0	저도 킨들 버전 구매. 곧 읽어 보고 후기 올려봅시다. ㅋㅋ 가격이 저렴하네요.
9	요새 다들 TF 환경구축에고생하시는거같은데개발환경뭐쓰시나요??갑자기궁금해지네요~ㅋㅋ리눅스?맥?윈+Docker???	2	이거 가지고 Poll한번 만들어 봐도 재미있겠습니다. 하나 만들어 주시겠습니까? 참고로 저는 제 로컬 맥 + AWS + Google Cloud (with $300 gift) 입니다.	1	저희는 실제 프로덕션은 리눅스 개발은 맥입니다.	3	저는 windows에서 docker를 씁니다.	3	전 맥북에서 CPU 버전과 aws에서 CPU 버전, 그리고 서버에서 GPU 바젼을 사용중입니다. ㅎㅎ	1	저는 현재 맥북에서 CPU기반으로 돌려보고 로컬은 리눅스에서 도커로 해보려합니다.위치 제약을 줄이려고 클라우드를 사용해보고 싶어요.
18	우왓 가입 받아 주셔서 고맙습니다.첫 가입글 투척합니다. 딥러닝 으로 jazz 를 풀어낸 깃헙 프로젝트가 있네요. 게다가 한국인 프로젝트네요. 다들 github 스타 주셔도 좋을 거 같습니다.
5	TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function이런 에러 보신적 있거나, 해결 방법을 아시는 분 계신가요? GPU가 있는 서버에 텐서플로우를 bazel을 이용해서 설치를 했습니다. 다 잘되다가 sudo pip install scikit-image를 했더니 그 뒤부턴 위와 같은 에러가 계속 발생합니다..	0	I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so.7.0 locallyTraceback (most recent call last):  File "convolutional.py", line 34, in <module>    import tensorflow as tf  File "/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py", line 23, in <module>    from tensorflow.python import *  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py", line 62, in <module>    import tensorflow.contrib as contrib  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py", line 27, in <module>    from tensorflow.contrib import learn  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/__init__.py", line 20, in <module>    from tensorflow.contrib.learn.python.learn import *  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/__init__.py", line 20, in <module>    from tensorflow.contrib.learn.python.learn import *  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py", line 22, in <module>    from tensorflow.contrib.learn.python.learn.io import *  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/__init__.py", line 20, in <module>    from tensorflow.contrib.learn.python.learn.io.dask_io import *  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/dask_io.py", line 23, in <module>    import dask.dataframe as dd  File "/usr/local/lib/python2.7/dist-packages/dask/dataframe/__init__.py", line 1, in <module>    from .core import (DataFrame, Series, Index, _Frame, map_partitions,  File "/usr/local/lib/python2.7/dist-packages/dask/dataframe/core.py", line 1234, in <module>    class Index(Series):  File "/usr/local/lib/python2.7/dist-packages/dask/dataframe/core.py", line 1266, in Index    @derived_from(pd.Index)  File "/usr/local/lib/python2.7/dist-packages/dask/utils.py", line 526, in wrapper    original_args = getargspec(original_method).args  File "/usr/local/lib/python2.7/dist-packages/dask/compatibility.py", line 190, in getargspec    return _getargspec(func)  File "/usr/local/lib/python2.7/dist-packages/dask/compatibility.py", line 56, in _getargspec    return inspect.getargspec(func)  File "/usr/lib/python2.7/inspect.py", line 816, in getargspec    raise TypeError('{!r} is not a Python function'.format(func))TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function전체 에러는 위와 같습니다.	1	자답입니다. /usr/local/lib/python2.7/dist-package/dask를 지우니까 잘 돌아갑니다..
4	안녕하세요 처음으로 도움 요청 드립니다.혹시 Tensorflow/models/image/mnist 안의 convolutional.py 를 python convolutional.py 동작 하니 Extracting data/train-images-idx3-ubyte.gzTraceback (most recent call last):  File "convolutional.py", line 270, in <module>    tf.app.run()  File "/home/cwjun/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py", line 11, in run    sys.exit(main(sys.argv))  File "convolutional.py", line 107, in main    train_data = extract_data(train_data_filename, 60000)  File "convolutional.py", line 53, in extract_data    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)  File "/home/cwjun/anaconda/lib/python2.7/gzip.py", line 268, in read    self._read(readsize)  File "/home/cwjun/anaconda/lib/python2.7/gzip.py", line 315, in _read    self._read_eof()  File "/home/cwjun/anaconda/lib/python2.7/gzip.py", line 354, in _read_eof    hex(self.crc)))IOError: CRC check failed 0xafedbd81 != 0x28ab034bL이렇게 CRC에러가 발생 하는데 혹시 아시는 분 있나요 .. 설치하고 테스트가 엄청 어렵네요 .. 너무 초보라 ㅠㅠ	1	혹 간단한 https://github.com/nlintz/TensorFlow-Tutorials 예제들을 한번 먼저 돌려 보시는 것도 좋을듯 합니다.	1	아마 공간이 부족하거나 권한등의 이유로 gzip파일이 다운이 잘 안된것이 아닌가 생각됩니다.	0	마음 가다듬고 다시 해봐야 겠네요 .. ㅠㅠ	1	그리고 저기 공유 해주시 튜토리얼에서요 import input_data 해서 MNIST_data/ 를 가져 오는데요 . 어디에 존재 해야 하는건가요 .. 해당 input_data 가 ^^ 초보라 파이선 텐설 둘다 ^^	1	https://github.com/nlintz/TensorFlow-Tutorials/blob/master/input_data.py
26	슬라이드 한장으로 셜명하는 성공적인 딥뉴럴넷 구축방법http://cs224d.stanford.edu/syllabus.html	1	2번을 해봐야겠네요!
21	본인의 TF 프로젝트를 Travis로 지속적으로 테스트 하는 방법.
62	안녕하세요. 제가 최근에 딥러닝 실습에서 tensorflow를 강의하는 기회가 있었는데, 이를 위해 통합 딥러닝 개발환경 docker image를 만들었습니다.https://hub.docker.com/r/imcomking/ttskc/위 이미지에는 Tensorflow, Theano, Scikit Learn, Keras, Caffe 등의 주요 라이브러리가 설치되어 있고 어느정도 수준까지 테스트 되었습니다. 그밖에 IPython, ssh-server 등 유용한 라이브러리들도 모두 설치되어있어, 혹시 통합 딥러닝 개발 환경이 필요하시다면 위의 이미지를 docker pull imcomking/ttskc 로 받으셔서 활용하시면 좋을 것 같습니다~	1	감사합니다 안그래도 시작해보려고 했는데 큰 도움이 될거같아요!	1	정말 좋네요. 감사합니다. 혹 강의내용도 조금씩 저희들에게 알려주세요. ^^	0	이런 질문 드리기가 좀 그렇데요... docker pull시에 x509문제가 발생이 되어 방법을 조심스럽게 여쭤봅니다. docker에 익숙치 않아 발생한것 같습니다.ㅠㅠ	1	오늘강의잘들었습니다 수고하셨습니다!	0	저도 들었는데... 쉽지 않아서..ㅠㅠ.근데 주피터에서는 GPU 쉽게 돌리나요? 우분투, 주피터 어떤게 좋나요??	1	오늘 마지막에 질문드린(실은  강의내내  RL 질문드린) 모두의연구소 김승일입니다. 오늘 잘 들었습니다!!! 많은 도움이 되었어요 ^^	0	죄송하지만.. Dockerfile 링크도 공개하실 수 있을까요? ^^	1	ㅋ~ 저도 오늘 강의 잘들었습니다. 수고 많으셨습니다~ ^^	0	안녕하세요. 강의 잘들었습니다. 올려주신 딥러닝 환경설정은 cpu 환경인거 같은데, gpu  환경일 때 딥러닝 환경설정도 알려주실 수 있으신가요? docker 에서 cuda 설치부분이 없는 것 같아서요. 감사합니다.
36	제가 여러 번 해보고 된 방법을 정리해보았습니다.	1	구축 후기 감사합니다.^^	1	쿠다 설치할때 --no-opengl-libs....	1	좋은 정보입니다.^^
47	잘 정리된 깊고 좋은 글입니다.
44	2분만에 논문 하나 설명을 시도하는 비디오인데, 전체 동향을 한번 쭉 보시는데 도움이 되실듯. 오늘 기준 총 123개의 비디오. 대단하네요.
18	TensorBoard가 제대로 작동하지 않는 경우 참고하시면 좋을 것 같습니다 (잘못된 부분이나 애매한 부분이 있으면 댓글 부탁드립니다).	1	저도 같은 문제를 겪고 있어서 따라해봤는데 3.5.1 의 경로에 있는 tensorboard 를 붙여넣기하니깐 안되더군요 그래서 검색해본 결과 컴파일해서 생성된 폴더 안에tensorflow/tensorflow/tensorboard 가 아니라bazel-bin/tensorflow/tensorboard/ 폴더를 복사해서 쓰니깐 동작했습니다.혹시 저처럼 안되시는분은 참고하셔도 될 듯 합니다.(환경은 macOS, anaconda 사용)
13	이런 사이트도 있네요.아직 공부 시작도 못했지만...자료 수집 차원에서... 공유합니다.	1	시작만 잘하는 사람도 있어요 ㅋㅋㅋ
23	저와 같이 TensorFlow 초보자 (정말 초보자) 를 위한 설치 및 실행 tutorial입니다. 현재 60일동안 USD300만큼의 credit을 무료로 사용할 수 있는 Google cloud를 이용했습니다.	0	파일좀 다시올려주세요.	1	감사합니당 !!
9	안녕하셔요. 쿠다 깔다가 우분투 세 번 날려먹은 촙촙촙오 꼬꼬마입니다.쿠다랑 cuDNN 다 잘 설치하고 카피해넣고 bashrc 도 잘 에딧해주었는데 왜 cuDNN만 로드가 안될까요? 무슨 문제가 있을 수 있을지 추정 부탁드리겠습니다ㅠ 어떤 댓글이든 다 큰 도움이 될 거라 믿습니다ㅠㅠp.s. 혹시 아나콘다에서 tensorflow 임포트 하시는 분 있으신가요? 세번째 날려먹을 때 아나콘다에서 임포트 성공했었는데... 지금은 기본에서만 임포트되네용. 촙촙촙오 도와주세요. 이 관문 지나면 저도 쭉쭉쭉 기여할게요ㅠㅠ	0	libcudnn.so의 파일 퍼미션 한번 확인해보세요~	0	저도 그게 의심스러워서 chmod 돌다리도 두들겨가며 했는데..ㅠ 다시 확인해보겠습니다 감사합니다!	0	제가 진행중인 강의의 마지막이 aws에서 tf gpu 버전 돌려 보기인데 테리님 어떻게 하는지 알아내시면 강의 도와주실래요? 전 gpu 시작도 안해봐서. :-)	0	Sung Kim // 저는 꼬꼬마라...ㅜ Sungjoon Choi Samuel님이 aws 상의 주피터 환경에서 진행 중이시니 가능하지 않을까요?	0	Sung-Un Park // 그걸 꼼꼼히 다시 해봤는데...ㅠ 일단 제가 방금 퇴근한지라 낼 다시 퍼미션 잘 바껴있나 확인해보려고요 감사합니다!	1	개인적으로는 anaconda 를 아얘 사용하지 않고 apt-get install python-numpy 등으로 설치하면 환경변수가 안꼬여서 편하더라고요..	0	docker 사용이 환경구성에는 좀 나은 방법 아닌가요?	0	cuda 를 run 파일이 아니라 apt-get으로 설치 하셨다면 ld.conf.d 에 면저 전역 변수가 잡혀 있어서 그럴수 있습니다그리고 libcudnn.so.5 이면 cudnn-7.0 같은데 아직 tensirflow가 이버젼을 지원 했던지 외부라 정확히 기억이 안나네요 ㅎㅎ	0	저도 아나콘다 사용하지 않고.. 그냥 필요한걸 하나씩 설치해서 사용한 상태라.. 도움이 못 되는군요. ^^;	1	아나콘다의 콘다사용하시면 파이썬 라이브러리 설정은 매우편리하게하실수있어요 ㅜㅜ 우리콘다 아껴주세요.	0	https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#anaconda-installation	0	pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl easyinstall 에러나시는건 ignore install 옵션으로 해결하시고. 그리고 인터넷 주소 넣지 말고인터넷에서 직접 파일을 받아서 home에 두고 하는게 더 잘 되는 듯 합니당저기서는 콘다 virtualenv 상태로 하라는데저는 그냥 ignore 옵션만 주니까 잘 해결되었습니다cuda의 경우는 deb으로 설치하지 말고 run 파일 받아서 설치하는데 nouveau 꺼야하고... nouveau 블랙리스트 먹여야하고 opengl은 설치하면 안된다더라고요opengl 설치하니 자꾸 검은 화면이 ㅠㅠ아 그리로 permission denied 에러 나는건chown -R 계정명 /home/계정명/anaconda2 로 해결했어요	3	으하하 감사합니다. 되었습니다. 문제는 제가 cuDNN v5 Library for Linux를 받지않고 cuDNN v5 Library for Linux[ARM64]를 받아서였습니다;;; 멍청해서 죄송합니다ㅜ 암튼 이제 활발한 기여하도록 하겠습니다 ^^
42	정말 쉽게 개념을 잡아주는 Q-Learning 비디오:https://www.youtube.com/watch?v=3T5eCou2erg&feature=youtu.be비디오 보신다음 TF를 이용해서 이런 자동 게임플레이어 만들어 보아요.  https://github.com/DeepLearningProjects/DeepLearningFlappyBird	1	TF에서 Q 러닝 구현할 때는 어떻게 할지 궁금하네요.
37	지난 4월 5일부터 일주일 동안 가장 많은 '좋아요'를 받은 글을 올려주신 분을 매일 한분씩 선정해서 TensorFlow 티셔츠를 보내 드리기로 했었는데요~ 생각보다 많지는 않아서 단순한 가입 인사를 올려주신 분들 등은 제외하고, 해당 기간 동안 유용한 정보를 올려주신 분들께 모두 티셔츠를 보내 드리기로 했습니다. :-)Sung Kim님은 이미 받으셨으니 제외하고요. :-)곽동현 , 변상준 , 김택수 , 서형석 , Alan Kim 님은 제게 메시지로 이름, 주소, 전화번호(안적으면 택배를 안 받아 주더군요), 티셔츠 사이즈(M, L, XL 중 하나) 를 이번주 내로 보내 주시면 다음주에 보내 드리도록 하겠습니다. 앞으로도 좋은 정보 많이 올려 주시기를~이름:주소:전화번호:티셔츠 사이즈(M,L,XL):	0	부럽네요.. ㅎㅎ 저도 공부하면서 유용한 정보를 올릴 수 있기를..	0	앗! 감사합니다	0	오오오 감사합니다!!	2	좋겠습니다! 받으신분들은 인증+착용샷 필수지요? ㅋㅋ	0	감사합니다~ㅎㅎㅎㅋㅋ	0	ㅎㅎ 감사합니다!	0	저도 입어 보고 싶네요^^	0	분발해야겠군요.	0	ㅠㅠ 이쁜티셔츠
24	[AWS EC2에 GPU활용하기2]  엄청 쉬운 방법.1. Cuda 7.5 설치: http://tleyden.github.io/blog/2015/11/22/cuda-7-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/ (이게 됩니다. CUDA 웹이지 보고 따라해본것이 함정. 위 페이지 따라하시면 한번에 OK)2.  ~/.profile 에 두줄 추가후 source .profileexport PATH=/usr/local/cuda/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH3. TF whl설치:sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl끝!Google cloud도 마찬가지 겠지요?제가 사용한 16개의 명령.   1  wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.5-18_amd64.deb    2  sudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb    3  sudo apt-get update    4  sudo apt-get upgrade -y    5  sudo apt-get install -y opencl-headers build-essential protobuf-compiler     libprotoc-dev libboost-all-dev libleveldb-dev hdf5-tools libhdf5-serial-dev     libopencv-core-dev  libopencv-highgui-dev libsnappy-dev libsnappy1     libatlas-base-dev cmake libstdc++6-4.8-dbg libgoogle-glog0 libgoogle-glog-dev     libgflags-dev liblmdb-dev git python-pip gfortran    6  sudo apt-get clean    7  sudo apt-get install -y linux-image-extra-`uname -r` linux-headers-`uname -r` linux-image-`uname -r`    8  sudo apt-get install -y cuda    9  nvidia-smi   10  sudo apt-get install python-pip python-dev   11  sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl   12  git clone https://github.com/nlintz/TensorFlow-Tutorials   13  cd TensorFlow-Tutorials/   14  vi ~/.profile  # add PATH, LD PATH   15  source ~/.profile   16  python 7_lstm.py	0	Gpu 메모리가 얼마인가요? 980ti수준 이상은 되는지	1	함 시도해야겠네요
5	Terry Tae-woong Um 포스팅 보고 AWS에서 저도 해보는 중인데, 다음 GPU가 동작 하는 것인가요?"I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)"이렇게 나오는데, 앞에 보니 에러들이 많네요.I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /usr/local/cuda/lib64:TF가 cuda 7.5로 컴파일 되어 있는듯 한데, 혹 cuda 7.5를 AWS EC2에 설치해보신분 계신가요?	1	CUDA 7.5 가 커널 모듈 호환성 이슈가 있습니다. 텐서플로 쓰시려면 CUDA 7.0으로 하시면 될거에요. (3월 중순에 시도해본 것 기준입니다.)	0	TF 0.8 을 다운 받았더니 ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory.  7.5를 찾고 있는것 같아요.
26	[AWS EC2에 GPU활용하기] g2.8xlarg, g2.2xlarge 와 저의 Maci7 16G 성능비교 (그림 참조). 간단한 작업이라 그런지 g2.8xlarg 와 g2.2xlarg는 큰 차이가 없었고, 제 Mac보다는 2~3배 정도 빠른듯 보입니다.AWS AMI 를 public으로 만들어 두어습니다: ami-4bf6002b아래는 간략 설치 설명0. TF whl 설치파일은 CUDA 7.5를 요구.ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory그런데 CUDA 7.5는 AWS EC2 Ubuntu와는 뭔가가 안맞음. (한시간동안 시도후 포기 - 다른 방법을 찾았습니다. 다음 포스트 참조)1. 우선 CUDA 7.0 을 설치 (김정주님의 가이드 그대로 따라함. 6.x를 7.0으로 바꿈. https://gist.github.com/haje01/f13053738853f39ce5a2 참조)http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/2. cuDNN (개발자 가입후) 설치: https://developer.nvidia.com/cudnn3. 바젤 설치: http://bazel.io/docs/install.html4. 자잘한것들 pip/apt-get등으로 시키는 대로 설치: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installing-from-sources5.Tensorflow 소스 다운후 ./configure...마지막 질문 주의!your build time and binary size. [Default is: "3.5,5.2"]: 3.0 # 꼭 3.0 선택http://stackoverflow.com/questions/33651810 참고 6. 바젤로 한참 컴파일후, whl파일 만들고, 설치완료! https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installing-from-sources7. 이전에 TF 를 설치하였으면 먼저 sudo pip uninstall tensorflow 한후 설치.
1	혹시 도커 관련 질문을 해도 될까요?  저번주까지 만 해도 잘되던 도커가 갑자리 이렇게 됬습니다. 구글링해서 가능한 해결책들 1.백신 끄기, 2 가상화enable 확인 3. 파일 복사 붙여넣기등을 해봤는데 안되서 버츄얼박스 및 나머지 관련 파일들을 지우고 다시다운 받아서 깔았지만 이런 에러가 뜹니다. 혹시 윈도우서 사용하시는분들중 이런 에러를 만나서 해결해보신분 있으신가요?그리고 이후 텐서플로우 설치에 대한 것도 잘 이해가 안가서 그러는데 도커가 보면 버츄얼 머신을 사용하는데 그렇다면 리눅스에서처럼 윈도우에서도 텐서플로우 GPU를 사용 가능한가요. 물론 현재 TF지원 GPU가 집에 없어서 확인은 못하지만 궁금하네요.
19	이런 것도 있네요 :-)	2	Sung Kim 님 너무 바쁘실듯 :-)
32	TF 8.0의 개선사항. 가장 큰것인 distributed 말고도 TensorBoard에도 shape info등이 추가 되며 좋은 기능이 추가 되었네요. 아래 Contributors 이름도 한번 읽어 주세요. :-)https://github.com/tensorflow/tensorflow/releases/tag/v0.8.0rc0	0	You've contributed here, awesome!!
48	분산처리를 지원하는 TensorFlow 새버전이 나왔네요~	1	우와.. ㄷㄷㄷ	3	보자마자 바로: sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0rc0-py2-none-any.whl따라해보세요. ㅋㅋ	1	오오! 드디어 분산 처리가 되는군요!!	1	sudo pip install --upgrade로 할 때 잘 안되시면 tensorflow github에서 .whl 파일을 받고 설치하시면 될 것 같네요
5	어떤 친절하신 고수님이 GPU 연동이 되는 텐서플로우 설치하는 법에 관련한 instruction을 만들어주실 의향 없으신가요? ㅠㅠ 현재 연구실 서버를 두 번이나 날려먹어서 쉽사리 시도하기 어렵네요.. 제가 날려 먹은 순서는 (http://enginius.tistory.com/628)에 있습니다.. 먼저 서버에 xubuntu를 설치하고, 쿠다 7.0을 설치했습니다. GPU는 Titan X가 두 개 있습니다. 여기에 python3를 설치하고, pip3로 GPU 지원이 되는 tensorflow를 설치했습니다. TF를 소스로 설치를 하지 않았더니 cuda 7.5를 필요로 해서 symbolic link로 7.0을 7.5와 연결했더니 잘 되더라구요. 간단한 cnn으로 MNIST 학습에는 성공을 했습니다. (99.4%!) 여기에 JupyterHub까지 설치를 해서 웹으로 TF를 돌리는 것 까진 했습니다. 문제는 그 다음에 여러 다른 패키지들, PIL, Scipy등을 설치하기 위해서 이것저것 구글링으로 찾은 아래 명령어를 선언한 다음이었습니다. ____________________________________________sudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose -ysudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev \libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev(왠지 위에 커맨드가 문제인듯.. 하지말자. )sudo apt-get install gfortran libopenblas-dev liblapack-dev -y(이거 하니까 밑에 sudo pip3 install scipy 가 되는듯..? 아직 안끝났다..)sudo pip3 install scipy(takes a lot of time, but... 오 되었다!)sudo apt-get install libfreetype6-dev libxft-dev -ysudo pip3 install matplotlibsudo apt-get install libjpeg-dev -ysudo pip3 install pillowsudo apt-get install python3-pandas -ysudo pip3 install -U scikit-image____________________________________________위의 명령어를 다 실행을 했더니, 에러가 없이 다 설치가 되어서 이제 진짜 이것저것 해보려고 import tensorflow as tf를 했는데, 에러가 딱!..ㅠㅠㅠ 그리고 고쳐지지 않더라구요. numpy 관련해서 몬가 에러가 난 것 같습니다. 분명 위의 명령어 어딘가에서 문제를 일으킨 것이지요... 그래서 혹시 제가 무엇을 잘못했는지, 혹은 제대로 다른 패키지들을 설치하는 방법에 대해서 알려주시면 감사하겠습니다! 참고로 위의 명령어를 CPU 버젼의 TF를 설치하고 하면, 아무런 문제가 없이 잘 돌아갑니다. (현재 EC2에는 위의 방식으로 설치가 되어있습니다.)	1	https://gist.github.com/haje01/f13053738853f39ce5a2 보셨나요?	0	파이션이 워낙 버젼을 많이 타서 여러 종류의 버젼이나 다양한 프레임워크를 쓰실려면 도커를 쓰시기를...아니면 virtualenv나 nvidia 도 도커를 사용해서 관리하기를 권장 하고 있습니다	0	뭐라도 도와 드리고 싶은데 거의 해보신 과정을 저도 반복하였을 뿐이라 힘내시라고 응원만 합니다.드라이버 깔다 날리고, 컴파일하다 날리고, 도커깔다 날리고... ㅠ ㅠ	0	virtualenv쓰는게 확실히 편하더라고요..
13	TensorFlow Serve 와 (아마) 분산환경에서 사용되는 GRPC 관련 lib+howto 입니다. http://www.grpc.io/점점 공부할것이 많아 집니다. :-)	1	grpc는 첨에는 rpc의 끝판왕으로 보였는데.. 작년에 평가할 때는 java support 가 좀 약한 것 같더라구요..  실제 도는 샘플을 볼때까지 좀 시간이 걸렸습니다.   그리고 개별 call의 성능은 thrift 보다 3배정도 느려요.. 지금은 어떤지 모르겠네요.
12	Word2vec 해보신분들에게 질문 드립니다. 제가 개념을 이해하기 위해 TF tutorial에 있는 것을 이용하여 정말 간단하게 구현해 보았는데, 제대로 돌아가는지 모르겠습니다. cost는 줄어 들긴합니다. tsne가 부담스러워 embeding 도 2차원으로 해서 바로 그림을 그리니, cat과 dog이 비슷한 위치이긴 한데 이것이 잘 되는 것인지 잘 모르겠습니다. (우선 sample수도 너무 부족합니다만.)혹시 embeding weights를 디버깅/verification 하는 좋은 방법이 있을까요? 코드는 50줄 정도 밖에 안되는데 한번 봐주세요. 미리 감사드립니다.https://github.com/DeepLearningProjects/TensorFlow-Tutorials/blob/word2vec/8_word2vec.py	1	샘플수가 작을 때 정량적으로 정확도 여부를 가늠할 방법은 (굉장히 부정확한) n-gram corpus간의 similarity 와 비교하는 정도인데요, skip-gram을 사용하셨고 샘플수가 적으면 원리상 두 값이 거의 같을거라 디버깅하는 의미가 적을 것 같습니다.	3	저도 잘은 모르지만,, 학습하는 차원(임베딩)이 2차원이면 너무 적지않나요? (코퍼스도 작은데..) 차원수를 조금 늘려서 학습하신 뒤에 tsne해보시는건 어떨까요? 잘알지는 모르지만 돌려보기는 했었는데, 코드 공유드립니다.http://nbviewer.jupyter.org/github/babelPish/nlp/blob/master/part5/studybreak_zip/babel_zip.ipynb(tensorflow는 모르겟지만,, gensim으로 모델링한거에 scikit-learn으로 tsne 적용해보니 쉽게 되더라구요. )	1	word2vec 의 학습과정은 TF tutorial 에 나오는 것처럼 학습을 하면서 몇몇 단어들에 대해 유사한 단어들을 계속 확인하는 게 직관적으로 잘 보이는 것 같아요.	1	Skip-gram과 cbow 등 알고리즘에 따라 syntactic/semantic 측면 성능이 차이가 난다고 알고 있습니다. skipgram은 cbow에 비해 semantic 성능이 많이 높습니다. 그리고 임베딩 차원이 너무 적은 경우 잘 안된다고 들었던 기억이 납니다. Verification은 구글의 word2vec에 코드가 포함되어 있습니다.（c언어）.작은 데이터를 말씀하셨는데, 데이터가 일정 이상 되어야 좋은 성능이 나오는 것으로 알고 있습니다. 도움이 되었으면 좋겠습니다.	1	코드를 보았습니다. 샘플수가 적어서 검증이 쉽지 않겠어요. word2vec에 대해서 관심을 가지게 되었네요.
33	Soonson Kwon 님이 아침부터 전해주신 기쁜소식, 0.8. 분산 환경에서 돌리는 방법을 본인들의 "Inception Architecture" 코드공개와 함게 설명합니다. 오늘 한번 해봐야겠습니다.https://github.com/tensorflow/models/tree/master/inception
41	텐서 플로우 강의를 하면서 수업에 사용하는 쥬피터 노트북 자료들을 깃헙에 올리고 있습니다. 수업을 시작한지 이 주가 되어서 아직은 Week2까지 있지만, Week6까지 늘어날 예정입니다. :) 	0	와 목차만 봤을때 스탠포드 cs231 수업에 버금가네요~공개해주어서 감사합니다 저도 짬을 내어 꼭 따라해보겠습니다	0	공유해주셔서 감사합니다.
2	Thank you for allowing me to join your group :)
37	대단하네요. 저렇게 만든다음 코드를 바로 만들어 주면 좋을텐데요.	2	코드도 있네요. https://github.com/tensorflow/playground
33	우리 멤버들은 다 아시는 내용이지만 Deep forwardnet의 완결인 이번 비디오 주위 입문 하시는 분들에게 소개/공유 부탁드립니다.	1	좋은 강의 너무 감사드립니다. 주말에 날잡아서 다 봐버렸네요.ㅋㅋ	0	감사합니다!	0	감사합니다!!! ㅎ
39	간단한거 하나랑 오타를 수정했더니 2개의 commit으로 TF "Contributors" 로 (오늘 현재) 65번째 이름이 올라갑니다. 코드 열심히 봐서 여름까지 10개 정도 그리고 좀더 의미 있는 commit을 목표로 해봐야겠습니다.정말 active한 프로젝트 답게 PR올리면 바로 바로 답을 달아 주고 merge해줍니다. 여러분들도 코드 보시고 PR 많이 보내보시길.	0	축하드려요	0	정말 재미있어 보여요~ ^^b
36	TensorFlow 관련 강의가 있습니다~https://www.facebook.com/CampusSeoul/photos/a.1065463440136426.1073741828.1057127864303317/1291267280889373/?type=3&theater	0	탱큐~ 참석할께
4	TensorFlow (TF), 딥러닝의 모든 이야기 나누어요.TF 구현 모음: https://github.com/TensorFlowKR/Tensorflow_implementation
28	http://enginius.tistory.com/627 좋은내용을 공유합니다.	2	ㅎㅎ 이미지 정말 잘 맞네요. 제가 처음 몇줄 안되는 TF코드 보면서 혼돈의 카오스 였는데. ㅋㅋ	1	제가 원하던 내용인데,  집에세 해봐야겠네요.  감사합니다(__	2	제 블로그군요. ㅋㅋ 공유 감사합니다. :) 6주 수업 내용을 https://github.com/sjchoi86/tensorflow101 에 올릴 예정입니다. 지금은 1,2주 내용이 있습니다.
52	저희 운영진중 한분이신 김택수님주도로 TensorFlow로 구현된 많은 Deep learning 알고리즘을 정리하고 있습니다. 일부 구현은 입력부분만 바꾸시면 현업에도 바로 적용가능합니다.https://github.com/TensorFlowKR/Tensorflow_implementation혹 다른 TF 구현 보시면 저희들에게 pull-request 바로 보내 주세요.
1	TensorFlow (TF) 를 사용하시고 개발하시는 분들의 모임입니다. 일반적인 동향/정보, TF 코딩등 전반에 대해 이야기 나누어요.TF 구현 모음: https://github.com/TensorFlowKR/Tensorflow_implementation
50	저의 첫 TF pull request가 (nice)와 함께 merge되었습니다. 아주 사소한 것이지만 기분 좋네요. 다른거 pull request할만한거 있는지 같이 찾아 보아요.https://github.com/tensorflow/tensorflow/pull/1838	1	멋지세요!	1	멋지십니다 저도 참여해봐야겠어요
18	아주 간단한 저의 첫 TF Pull request. 기능적인 부분보다는 readability와 스타일이라 어찌될지 모르지만 관심있으시면 보시고 아래 pull request 링크에 의견 달아 주세요.https://github.com/tensorflow/tensorflow/pull/1838
8	안녕하세요!저는 실무교육기관 '패스트캠퍼스'에서 데이터 사이언스 교육과정을 기획하고 있는 김미림입니다.사용자 행위데이터를 관찰, 추적 후 대규모 모델링을 통해 이용자의 행위를 예측하기 위해서 딥러닝을 활용하는 방향으로 강의를 기획중인데, 실제로 국내에서 도입중인 기업사례와 가르쳐 주실 실력있는 강사님을 애타게 찾고 있습니다.혹시 주변에 좋은 분 있으시면 추천 부탁드립니다!페메로 연락주세요.^^ 감사합니다.	0	"사용자 행위데이터를 관찰" 데이타가 모인것이 좀 있나요?	2	http://courses.media.mit.edu/2004fall/mas622j/04.projects/home/ 조금 오래되긴 했지만, 이런 데이터셋이 있긴 합니다. 제 첫 논문이 DBN을 활용해 예측하는 것이었습니다. ㅎㅎ (http://cpslab.snu.ac.kr/publications/papers/2013_RO-MAN_behaviorDL.pdf)
12	Tensorflow 구현체 큐레이션 페이지를 하나 만드는건 어떨까요? 텐서플로로 각종 논문이나 프로젝트들 구현하는 분들이 많은데, 한곳에 모아 놓으면 좋겠다는 생각을 예전부터 하고 있습니다. Torch의 경우 비슷한 페이지가 있는 것 같던데 텐서플로도 있으면 좋겠습니다	3	좋은 생각이십니다. 어떻게 시작하면 좋을까요? Jiho Bak 님이 만드신 https://github.com/TensorFlowKR ORG에 project 하나 만들어 달라고 하고 같이 해볼까요?	1	Model zoo가 따로없나요?
7	The alpha release of Cloud Machine Learning, a framework for building and training custom models to be used in intelligent applications.  http://googleresearch.blogspot.kr/2016/03/machine-learning-in-cloud-with.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed:+blogspot/gJZg+(Official+Google+Research+Blog)
20	개별사용자의 글쓰기 패턴 (또는 리뷰점수, 분류등)에 맞게 문장을 만들어내는 char-level RNN논문입니다. 우선 그림 1을 보면 만들어진 review가 상당히 훌륭합니다.그림 2가 간단히 넷트웍의 구조인데 일반적인 char-RNN입력에 추가 정보 (글쓴이, 리뷰점수, 분류등)를 입력으로 넣어준 간단한 구조입니다.Theano로 구현했다고 하는데, 첫번째 저자의 git repos에는 아직 올라오지 않은듯 합니다. https://github.com/zackchase이런 넷트웍 TF로 공부삼아 같이 구현해보면 재미있을듯 합니다.전반적인 배경과 LSTM등의 소개를 잘 정리한 잘 쓰여진 논문인듯 합니다.http://arxiv.org/abs/1511.03683
50	오렐리에서 올해말에 나올 예정이라는 TF를 이용한 딥러닝 책에 사용될 예제들 만들고 있는 깃 허브입니다. (쓸데 없이 너무 def를 남용하여 전체 뉴럴 넷트웍의 흐름을 보기 어렵게 코딩한 스타일이 조금 마음에 들지 않지만) TF 를 이해 하시는데 도움 되실듯해서 공유 합니다.책은 작성중인데 pre-order로 작성중인 부분까지 볼수 있습니다.https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book
8	페이스북이 딥러닝 이미지 테깅을 이용하여 좋은 일을 하네요. 시각장애인들을 위해 이미지에 뭐가 있는지 읽어 줍니다.
21	CNN 구성으로 text classification등에 좋은 성능을 내고 있는데 각종 세팅을 어떻게 하면 좋을지 여러기지 옵션을 사용해 실험해본 논문입니다. GPU많이 사용했을듯 합니다.결론은 다소 뻔합니다. Dropout 은 0.5이하, Relu와 tanh좋고, 2 norm regularation은 조금 사용하는것이 좋고,  wordvec좋다는 이야기.CNN 으로 text관련 튜닝하실때 (5장) 한번 보시면 좋을것 같네요.https://arxiv.org/abs/1510.03820
1	가입 승인 감사합니다.
22	TensoeFlow의 가장 큰 장점중 하나가 바로 그래프와 데이타 (W, 학습과정등)을 비쥬얼하게 보여주는 TensorBoard인데요, 코드 보시다 보면 이런거 많이 보실 것입니다. # Summaries for loss and accuracy        loss_summary = tf.scalar_summary("loss", cnn.loss)        acc_summary = tf.scalar_summary("accuracy", cnn.accuracy)        # Train Summaries        train_summary_op = tf.merge_summary([loss_summary, acc_summary, grad_summaries_merged])        train_summary_dir = os.path.join(out_dir, "summaries", "train")        train_summary_writer = tf.train.SummaryWriter(train_summary_dir, sess.graph_def)        # Dev summaries        dev_summary_op = tf.merge_summary([loss_summary, acc_summary])        dev_summary_dir = os.path.join(out_dir, "summaries", "dev")        dev_summary_writer = tf.train.SummaryWriter(dev_summary_dir, sess.graph_def)이에 대한 간략 설명 슬리이드: http://www.slideshare.net/hunkim/tensor-board와 설명 비디오: https://www.youtube.com/watch?v=eDKxY5Z5dVQ 만들어 보았습니다.
1	Sung Kim 가입승인 고맙습니다!
18	WordVec 과 Paragraph vector를 구글러 (Paragraph vector를 제안한) Le 가 15분 만에 설명하는 비디오. Word2vec의 W를 학습하는 과정을 softmax classifier 로 쉽게 표현하네요 (그림 1). 여기에다 paragraph id (그림 2)를 추가하여 paragraph vector (P)를 학습하게 됩니다.Text classification에서 좋은 성능이 나오고 (그림 3), 구글 검색결과 ranking에도 좋은 성능을 보여 줍니다 (그림 4).비디오: http://techtalks.tv/beta/talks/distributed-representations-of-sentences-and-documents/60988/논문: http://arxiv.org/abs/1405.4053일부구현: https://github.com/dennybritz/tf-models (비슷한 모델을 비교하는 것인데, 리스트는 있는데 코드는 다 구현되었는지는 확실하지 않음)	0	혹시 Paragraph vector 를 사용해보신분 계신가요?	1	감사합니다. 업무에 많은 도움이 될것 같습니다~	1	서비스활용사례를 알고있긴하나 사업비밀일것같네요	1	최근의 연구에서 사용했는데 꽤 잘 되기는 하나 word2vec만큼은 아닙니다. 당연한 얘기지만요 ㅎㅎ
55	TensorFlow 티셔츠를 받을 수 있는 절호(?)의 기회!매일매일 가장 많은 '좋아요'를 받은 글을 올려주신 분들을 한분씩 선정해서 TensorFlow 티셔츠를 보내 드리도록 하겠습니다~ 오늘부터 일주일 동안 진행하며 머신러닝/딥러닝/TensorFlow에 관련된 유용한 글을 올려주신 분들 중에서 선정합니다.자 그럼.. 많은 분들의 참여 기대하겠습니다! :-)	2	어제/오늘 보니 받으실 분들이 몇분 보이는것 같습니다. :-)
29	DeepLearning은 역시 초기값이 중요하다는 것을 보여주는 유명한 논문.ReLu의 경우 초기값의 범위에 따라 학습 결과가 많이 차이나고 1.4 근처가 좋다는...http://arxiv.org/abs/1511.06422
26	중국의 4행시를 자동으로 만들어 내는 Deeplearning 시스템이 나왔습니다. https://arxiv.org/abs/1604.01537그림 1처럼 3개의 모듈 (단어->한문장, 한문장->한문장, 두문장->한문장)을 각각 설계하고 학습시킨 다음 시를 생성합니다.결과가 아주 인상적입니다. 사람이 쓴 시와 비슷하게 나옵니다. (1-5점 사이 평가, 그림2)각 모듈은 아래에서 사용된 넷트웍 디자인이 사용되었다고 합니다.재미있네요.Dzmitry Bahdanau, KyungHyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings  of the 2015 International Conference on  Learning Representations, San Diego, CA.	1	엄청나게 쏟아져 나오네요	0	홍정모 arxiv에 딥러닝 관련 하루에 4~5개씩 논문이 올라오는데 이중 70% 이상에 중국 저자들이 있습니다. 엄청나게 나오고 또 중국 논문 엄청나네요.
3	혹시 여기계신분들중에 혹시 CentOS7에서 탠서플로우를 GPU기반으로 cuda 사용하도록 설치에 성공하신 분이 있으신지요? 노하우 공유 부탁드려요~	3	전 해본적은 없는데 ubuntu https://gist.github.com/haje01/f13053738853f39ce5a2 보면 GPU 설정 부분이 나오는데 비슷하게 할수 있나요?CentOS7에서는 따로 TF를 컴파일 해야 하죠?	1	오!!! 감사합니다.~^^	0	인스톨 가이드를 포스팅 했습니다. 참고하세요~
9	안녕하세요.TensorFlow를 이용한 Pretrained CNN Model에 대한 글을 연구실 내 위키에 쓴적이 있는데 이를 다시 정리해서 올려봅니다.----------1. Convert Caffe to TF아직까지는 tensorflow로 공개된 pretrained model은 많지 않다. 따라서 tf를 활용하기 위해서 일차적으로 caffe 로 공개된 모델을 tf로 변환해주는 오픈소스 프로젝트를 고려해볼 수 있다. 그러나 이 경우, caffe와 tf를 모두 설치해야하는 번거로움이 있고, 두 플랫폼에 대한 기본적인 이해를 필요로 한다. 이 오픈소스에 대한 링크는 다음과 같다.(https://github.com/ethereon/caffe-tensorflow)이 방법을 사용하면, 2015년 이미지넷 대회에서 1등하여 공개된 Deep Residual Network의 caffe 모델도 변환해서 쓸 수가 있다. (https://github.com/KaimingHe/deep-residual-networks)2. VGG16위의 방법으로 caffe에 구현된 VGG16를 tf로 변환해놓은 오픈소스 링크가 있다. 위 링크에서는 caffe 설치를 안하고도 사용할 수 있는 tf 버젼 모델을 토렌트로 공유하고 있다. 그러나 seed가 매우 없어서 다운받기는 데 1주일이 소모되었다. (https://github.com/ry/tensorflow-vgg16)3. Inception 2015구글의 연구팀에서 2015년 12월에 학습시킨 인셉션 네트워크는 텐서플로우 공식 예제에서 사용되고 있으며, 그 모델 또한 공개되어있다. (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image)결론적으로 3번의 방법을 활용하는 것이 가장 쉽고 빠르게 해볼 수 있는 방법이다. 그러나 이 모델을 로딩해서 classification을 해보는 것은 쉽게 따라할 수 있지만, 중간 layer에서의 feature를 추출하는 것은 아직까지 매우 복잡한 과정을 거쳐야한다. 이 과정은 추후 논의 할 예정이다.	0	좋은글 감사합니다. 이 모델이 이미지 넷의 경우 레벨이 1000 개로 정해져 있는데 혹시 이를 백만개 (대략 우리가 사용하는 단어) 정도로 확장하고 생활속의 이미지랑 레이블 입력 받아 세상의 모든 이미지 인식 가능할까요?
20	http://cs224d.stanford.edu/ 수업 2016년 프로젝트 아이디어를 추천해주는 슬라이드입니다. 대략적인 NLP+Deeplearning의 동향과 참고 논문/자료를 볼수 있네요.•  Summariza2on•  NER, like PSet 2 but with larger dataNatural Language Processing (almost) from Scratch, Ronan Collobert, Jason Weston, Leon BoMou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa, http://arxiv.org/abs/1103.0398•  Simple ques2on answering,A Neural Network for Factoid Ques2on Answering over Paragraphs, Mohit Iyyer, Jordan Boyd-Graber,Leonardo Claudino, Richard Socher and Hal Daumé III (EMNLP 2014)•  Image to text mapping or genera2on,Grounded Composi2onal Seman2cs for Finding and Describing Images with Sentences, Richard Socher, AndrejKarpathy, Quoc V. Le, Christopher D. Manning, Andrew Y. Ng. (TACL 2014)orDeep Visual-Seman2c Alignments for Genera2ng Image Descrip2ons, Andrej Karpathy, Li Fei-Fei•  En2ty level sen2ment•  Use DL to solve an NLP challenge on kaggle,Develop a scoring algorithm for student-wriMen short-answer responses, https://www.kaggle.com/c/asap-sas
5	안녕하세요.전자회사에서 HMI 특히 차량용 제스쳐 인식 선행개발하고 있습니다.현재는 적외선 센서를 사용하고 있으며 향후 TOF 카메라를 이용할 예정입니다.잘 부탁 드립니다.	1	좋은 연구 하시네요. 기회되면 하시는일 자세히 소개해 주셔도 매우 좋을것 같습니다.
4	RNN을 활용한 (한국어 중심) NLP를 연구중인 대학원생입니다. 텐서플로우 api가 쓰기 쉬워보여 우선 이걸로 구현중입니다. 앞으로도 잘 부탁드립니다.	0	반갑습니다. 혹시 어떤 연구를 하시는지 조금더 소개 해주실수 있으신지요?
38	500! 3/26일 시작한 저희 그룹이 500명의 회원을 돌파하였습니다. 감사합니다. 기념으로 여러분들의 사진들을 모아 500숫자 사진을 만들어 보았습니다. (본인의 사진을 찾아 tag해주세요. :-) )	1	ㅎㅎㅎㅎ 교수님 대단하세요! ㅎㅎ	1	다운로드해서 확대해도 작은데 다행히 배경이 파란색이라 쉽게 찾았습니다	1	아하하 저도 쉽게 찾았습니다.
1	승인 감사합니다(__	0	감사합니다. 많은 활동 부탁드립니다.
15	유명한 수업인데 올해 3월 말에 시작한 수업 비디오가 올라오고 있습니다. 작년 비디오 몇개 보았는데, 강사님이신 Richard Socher 가 올해 훨씬 더 잘 가르치시는 것 같습니다.2006년 논문도 소개되고 (MetaMind) 데모도 보여주네요.Richard 최근 Salesforce 에 팔린 MetaMind의 Founder & CEO 입니다.
19	딥러닝을 이용한 QA시스템에 대해 잘 설명해주는 슬라이드입니다. Word embading도 잘 설명해줍니다. 간단한 모델에서 시작하여 더 발전된 모델을 보여주고 소스코드도 공개 합니다.http://cs.umd.edu/~miyyer/data/deepqa.pdf	1	문자열을 어떻게 넷트웍에 입력할까에 대한 정답은 아직 없는가 봅니다. 서형석 님 혹시 이분야 경험 있으신가요?
6	김정주 님의 텐서플로우 시작하기, 간단하게 잘 설명해주셨습니다. 
1	가입승인 감사합니다.~^^	1	감사합니다. 앞으로 저희 그룹에서 자주 뵈어요.	0	넵!!! 감사합니다.
16	"사람처럼 생각하는 기계 만들기"라는 흥미로운 제목의 논문이 올라왔습니다. 논문이 좀 길고 복잡한데 대락 주장하는 바는 요약에 있는 것 처럼, 지금처럼 패턴을 인식하는 것을 넘어서서 1) 원인 분석모델 (어떤 현상의 설명과 이해를 위해), 2) 물리와 철학등의 기본 상식 (학습내용을 더 풍성하게 하기 위해), 3) 배운 지식을 다른고 새로운 곳에 적용하는 기술 (일종의 transfer learning) 을 해야 한다고 방향을 제시 합니다.기존 기술들을 소개하고 단점에 대해 이야기 합니다. 알파고 이야기도 뒷부분에 나옵니다. 재미있는 토론을 위한 주제를 던져 주는것 같습니다.
25	다른 사람들이 다 안된다고 할때 한 우울을 열심히 파셨던 DeepLearning의 대부 Hinton교수님이 나오는 뉴스. 이런분을 볼수 있다는 것이 영광인것 같습니다. 64세라고 하는데 오래 오래 건강하셔서 Breakthrough 더 많이 만들어 주시면 좋겠습니다.
28	저희 커뮤니티 분들은 다 아시는 내용이지만 혹 주위에 DeepLearning 입문 하시려는 분들이 있으면 많이 소개해주시기 부탁드립니다.
40	챡용샷 입니다. 외출용으로도 손색이 없는듯 합니다. 올 여름 IT계의 패션을 주도할 아이템이 아닐지 조심스레 예측해봅니다. :-)	0	가, 가격이!!	0	어떻게 하면 구매가 가능한가요?	0	멋지네요! ㅎㅎ	0	멋지네요..! 구매는 가능한가요?
52	누가 만든것인지 이름은 없는데 제가 본 튜토리얼 슬라이드중 최고인것 같습니다. 꼭 소장하고 두고 두고 봐도 좋을것 같아요.	2	Sung Kim TensorFlow Tutorial given by Chung-Cheng Chiu라고 아래에 적혀있는데 그 분의 발표가 아닐까요?
29	물건너 구글 코리아에서 도착한 따끈따끈한 TensorFlow T-shirts! 잘 입겠습니다.(곧 여러분들도 받으실 기회가 있을 것으로 생각합니다. 아주 곧!)	1	헉 ㅎ갖구싶네여 ㅋㅋ	1	미리 손들고 싶습니다 ㅋㅋ	1	멋져요 ~!!	1	저도 갖고 싶습니다.	1	저도 손 들어 봅니다	1	손 ^^	1	저도 좀 ㅠㅠ	1	저도 가지고 싶습니다	1	우왕.. 멋있네용..ㅎㅎㅎㅎ
14	지난 3월 23일 CGP NEXT 2016년 Jeff Dean 의 구글 Deep Learning @Google에 대해 이야기하는데 VisionAPI의 재미있는 데모, 스피치 API (한글포함?), TensorFlow (작년 11월에 발표후 5개월간 github 에서 ML 최고 인기 프로젝트, 800여개의 TF관련 프로젝트가 이미 github 에 있다고), TF를 이용한 Cloud Machine Learning Product 데모를 보여 줍니다. 간단한 DeepLearning의 구조와 TF tutorial을 하면서 --cloud 옵션으로  구글 클라우드에서 돌리는 놀라운 방법을 보여 줍니다.이제 데이타와 알고리즘만 있으면 뭐든 다 돌려볼수 있을듯합니다.https://youtu.be/HgWHeT_OwHc?t=1h59m17sCloud Machine Learning 정보는 여기 https://cloud.google.com/ml/.
7	우앙.. 좋은 그룹이네요...! 저도 텐서플로우 god 시작했습니다. 저도 공부하며 틈틈이 자료 남겨보도록 하겠습니다! 이런 소수 커뮤니티 좋아요~	0	반갑습니다. 블로그 잘 보고 있습니다. 많은 활약을 기대합니다.	1	god Terry Tae-woong Um님이네요	1	god난이일 뿐입니다...	0	웰컴! ㅋㅋㅋ
6	MNIST 로 학습한 다음 아래 그림과 같이 연속해서 적은 숫자를 판별합니다. TF로 만들어진 코드입니다. 재미있네요. 	1	좋은 자료 감사합니다. ㅎㅎ 방금 돌려봤는데, 잘 되는군요! 코드도 직관적이구요.
6	참 멋진 Tutorial입니다. TF가 Theano 모델을 보고 만들어 비슷하다던데 혹시 이 Tutorial을 TF용으로 만들어 주실분 계신가요?	3	가까운 미래에 제가 한번...;;
4	http://blog.kubernetes.io/2016/03/scaling-neural-network-image-classification-using-Kubernetes-with-TensorFlow-Serving.html공유하겠습니다. ㅎㅎ
9	뒷북일수 있으나 터미네이터 영화에 이런 대사가 나오나요?TERMINATOR: My CPU is a neural-net processor... a learning computer. But Skynet presets the switch to "read-only" when we are sent out alone. 1991년 대단한 예지력이네요. 그럼 구글의 TF가 나중에 스카이넷이 될 가능성이? :-)http://pages.cs.wisc.edu/~jerryzhu/cs540/handouts/neural.pdf	2	미국에서 T2 개봉할 때 봤는데, 저 대사는 정확하게 기억하고 있습니다. 그 때는 한창 뉴럴넷이 인기있을 때였죠. 우리학교 (USC) 캠퍼스 내에 뉴로사이언스 빌딩도 크게 짔고 그 책임자로는 당시 그 분야의 대가로 일컬어지던 마이클 아비브 교수가 있었고...참 옛날 얘기입니다..
25	대단한 것들이 많이 있습니다.	0	첫 논문이 그래픽스 논문이네요.
29	원래는 Sung Kim 교수님께서 convolution 자체에 대한 블로그 글에 대해 독려의 말씀 주셔서 글을 시작했는데요, 어쩌다보니 CNN만 설명하다가 끝나버렸네요 >.< 다음 글에서 convolution 자체에 대해 다양한 이해들을 한번 시도해보도록 할게요~ 즐겁게 읽어주세요!
6	안녕하세요End-To-End Memory Networks 논문 관련 질문드립니다 (http://arxiv.org/abs/1503.08895)사진에 있는 설명에서Input memory representation은 sentence와 question의 유사도를 표현하고Output memory representation은 input memory representation에서 구한 P(sentence,question)와 sentence 사이의 유사도를 동시에 표현하는 것이라 이해했습니다그런데 Generating 단계에서 output 단계에서 구한 o와 question의 embedding matrix u를 더해주는데 이것의 의미를 잘 모르겠습니다.설명해주실 수 있을까요?	1	저도 저 u와 o를 더하는 의미는 잘모르겠더라구요...아그리고  p는 스칼라라 p와 sentence의 유사도를 구하는게 아니라sentence가 q와 얼마나 비슷한지에 따라 p로 가중치를 줘서 재배열해 주는게 아닐까요?
73	[6/18 첫 오프모임 홍보 #1]2016년 6월 18일 11:50AM 부터 7:00PM 까지 Google Seoul office (역삼역 2번 출구 강남 파이낸스 센터 22층)에서 모임을 가집니다. 장소 관계로 140명 선착순 (6/2일 오전 10시부터) 등록을 받습니다. 자세한 사항은 내일 더 알려드리겠습니다.자리가 너무 한정된 관계로 No-show 방지를 위해 등록비 *1만원* 을 받을 예정입니다. 이 등록비 전액은 기부하려고 합니다.이에 어떤 단체에 기부할지 회원님들에게 여쭈어 봅니다. 저희 운영진이 알고 있는 단체는 유니세프, 엠네스티, 굿네이버스 정도인데, 내일 5/31일 11:59PM까지 지원하고 싶거나 알고 있는 좋은 단체를 이 글의 댓글로 알려주시면 6/1일부터 일주일간 회원들의 최다 투표로 결정된 두 곳을 지원하도록 하겠습니다. 좋은 단체를 많이 알려 주세요.	0	일단 페이스북에서 신청할께요^^	2	기부한 단체로 카리타스는 어떨까요? 가난한 곳에 관심과 봉사하는 단체로 기부금은 전액 해외원조에 사용됩니다.	1	http://landliberty.org/xe/	1	전 그날 수업이 있어서요.. 뒷풀이 때는 참석하겠습니다.	12	해당 금액이 기부가 아니라 후원으로도 사용될 수 있다면 파이콘 APAC 2016 후원은 어떨까 싶습니다 :) https://www.pycon.kr/2016apac/about/sponsorship/	4	혹시 촬영예정은 없으신가요?ㅜㅜ icml참석으로 인해서 못오시는분도 좀 되실듯..	2	후원보다는 해외원조쪽이 훨씬 좋은것 같네요!!
2	Deep API Learning http://arxiv.org/pdf/1605.08535v1.pdf
2	안녕하세요. 산업 공학을 전공하고 있는 대학원생입니다.저는 TF 를 이용해 MLP의 variant를 훈련시키려고 합니다. 다만 문제는 트레이닝 데이터셋의 크기입니다. 모두 bmp로 이루어져 있고 55GB 사이즈입니다. 그래서 이 데이터로 모델을 훈련시키려면 hdf5 같은 db(?)로 전환이 필요하다고 생각이 듭니다. 문제는 어떻게 변환을 해야하는지, 가능하다면 bmp 이미지를 array 로 변환해서 저장하고 싶습니다, 또  db로 변환 후 데이터의 레이블링을 어떻게 야하는지 (현재는 이미지의 이름으로 레이블링이 되어있습니다.), 그다음에 tf에서는 어떻게 사용해야하는지 전혀 감이 잡히지 않습니다.관련해서 도움 받을수 있을까요? 미리 감사드립니다.	2	BMP를 읽어서 numpy npy나 hdf5 로 변환하세요. 하나의 큰 파일보다는 여러개로 나눠서 저장하시고, 라벨은 복잡하지 않다면 디렉토리 같은거로 구분하는게 어떨까요. 어차피 저정도 사이즈면 GPU에 다 올리지 못하니 mini batch 로 학습하셔야할거고, 그러면 파일로 나눈 다음에 그때그때 학습이 필요할 때 불러오시면 될 것 같습니다.
2	아래 사이트의 Auto Encoder sample 을 돌력 보고 있는데 error 가 발생을 하는데 이유를 아시는 분은 도움을 부탁합니다.https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/autoencoder.py>>> cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))>>> optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)Traceback (most recent call last):  File "<stdin>", line 1, in <module>TypeError: __init__() takes at least 3 arguments (2 given)	0	decay 를 default 값으로 설정하면 에러가 발생을 하지 않는군요.optimizer = tf.train.RMSPropOptimizer(learning_rate, 0.9).minimize(cost)
40	지난 5월25일 Nvidia 세미나 오후에 DIGISTS라는 딥러닝 개발 소프트웨어로 amazon 과 연결하여 hand-on 을 할 수 있었습니다. 그 내용을 소개합니다...Kaggle에서 이미 끝난 contest 이지만, 이 고래 사진을 보고 고래번호(고래ID)를 알아맞추는 문제입니다. 사람 얼굴을 보고 이름을 맞추는 것과 같습니다. 그런데. 각 ID별로 테스트 데이터가 1개에서 부터 30여개까지 그리 많지 않아서 CNN을 써서 돌리면 정확도가 2%에 지나지 않습니다. 그러나 1등팀은 95%까지 맞추었는데. 비밀은 고래의 머리와 꼬리 방향을 일치시키고, 고래의 코와 여러가지 포인트를 중심으로 이것이 right whale인지를 정리는 하는 겁니다. (마치 사람얼굴을 인식하는 것과 유사한 방식으로)그리고 파도나 숨을 쉴때 나오는 하얀 물보라 같은 것을 제외시켜야 하는 것이었습니다. 딥러닝에서도 예외가 아니게 데이터 작업은 항상 까다로운 것이었습니다. deep learning을 쓴다해서 무조건 인식율이 올라가는 것이 아니라, 데이터 속성을 잘 파악해서 그 데이터를 잘 manipulation 하고, 그에 따른 알고리즘을 적용해야 한다는 아주 평범한 진리를 알게하는 실습이었습니다.	2	"그 데이터를 잘 manipulation 하고, 그에 따른 알고리즘을 적용" 정말 중요한 포인트 같아요.	0	2등팀이었나 그 팀에서 블로그에 작성한 포스트를 봤는데, 데이터 manipulation (detection box를 씌우는 등등)은 수동으로 하지않았나요? 비슷한 작업을 할 일이 있었는데 annotation을 만들다 너무 힘들어서 때려쳤던 기억이 있네요 ㅠㅠ	1	네. 주최측에서 수동으로 하는 걸 인정해주었다고 합니다.
39	엔비디아 딥러닝 데이 오전 세션 간략 요약입니다. 페이스북 문서가 그룹 타임라인에 잘 보이지 않는다는 말씀이 있어 포스트로 다시 올립니다.(오프닝 영상) - 엔비디아 무인자동차 등, 딥러닝으로 실현되고 있는 일들. (환영사) 이용덕, 엔비디아 코리아 지사장 - 전기자동차 레이스 Formula E가 올해 최초로 무인 레이스를 주최하며, “소프트웨어 코딩 레이스”가 될 것. 엔비디아도 참여. - DGX-1: 세계 최초의 딥러닝 슈퍼컴퓨터, 250개의 CPU 서버. (세션1) “GPUs for Data Science” – Jerry Chen, 스타트업 에코시스템 개발 책임자 - 데이터 사이언스에 있어 초기이고 중요한 시기. - 무어의 법칙이 죽어가고 있다는 말이 있고 이는 순차 프로세싱 및 알고리즘에 대해서는 사실이지만, 병렬 프로세싱은 여전히 지속적인 속도로 발전 중(면적 당 트랜지스터 개수 기준). 이는 “새로운 패러다임, 새로운 무어의 법칙”. - CPU 중심 시대에서 GPU 중심 시대로 옮겨오면서 가격 및 기술 장벽이 낮춰지고, 이는 혁신을 “민주화” 시키는 결과. - DGX-1은 연구에 최적. - 스타트업과 개발 커뮤니티 협력 노력, 기술 접근성 향상 노력을 강조. - 엔비디아의 스타트업 액셀러레이션 프로그램: http://nvidia.com/inception (세션2) “NVIDIA’s Deep Learning Platform” – Leo Tam, 솔루션 아키텍쳐 산하 딥러닝 커뮤니티 매니저 - DL SDK들에 대한 설명. - 성능, 산업협력, 기술접근성이 엔비디아 DL SDK의 가치. - DIGITS(Interactive Deep Learning GPU Training System): 프로세싱/설정관리/모니터링/시각화용 웹앱. 오픈소스. http://developer.nvidia.com/digits - LTSM: RNN 가속 유닛 - NCCL(니클): 다중 노드 트레이닝을 위한 GPU간 통신. - FP16(Floating Point 16): 부동소수점 연산의 정확도를 16비트(1bit sign + 5bit exponent + 10 bit fraction)으로 제한하여 전력 및 메모리에서 효율 향상(구글의 TPU와 비슷한듯). TX1에서 네이티브 지원. 사용법은 http://leotam.github.io 참고. - GPU Inference Engine: 런타임 추론 최적화 엔진. http://developer.nvidia.com/gpu-inference-engine (세션3) “NVIDIA’s Autonomous Driving Platform” – Pradeep Gupta, 리드 HPC & 딥러닝 솔루션즈 아키텍트 - NVIDIA Drive™: NVIDIA PX, CX, 개발 Kit 등 자동주행 솔루션. - NVIDIA PX: 자율 주행 자동차 개발 플랫폼. 세계 최초의 자율주행용 슈퍼컴퓨터. 150대의 맥북 프로에 상당하는 연산력, 70Gb/초에 이르는 입출력. (기타 안내) - NVIDA Deep Learning Contest 주제 발표: 6월 9일 공지 예정(http://www.nvidiakoreaspc.com/contest/deeplearning.html), 지정 주제(딥러닝을 통한 이미지 분류) 및 자유 주제(GPU 가속 통한 딥러닝 연구 결과 포스터 제출, 자유분야).- Hands-on 로드쇼: 6.30 대전 시티호텔을 시작으로 대구, 부산에서 딥러닝 체험행사 진행 예정. 추후 http://nvidiaevent.co.kr에 공지 예정.	1	소식 감사합니다.
173	[Deep API Learning 논문 FSE 2016 Accept!] 저희 연구실 Gu학생 주도로 Microsoft Research Asia와 공동으로 연구한 Deep API Learning 논문이 소프트웨어 공학 최고 학회인 FSE 2016에 accept 되었습니다.RNN Encoder-Decoder 모델을 사용하여 "자연어"를 입력하면 이를 구현하는데 필요한 "API의 sequence" 를 생성해냅니다. 생성된 sequence 가 컴파일 되거나 바로 실행되는것은 아니지만, 사용 가능한 코드 생성의 첫 스텝이라 하겠습니다. 이전에도 API sequence를 생성하는 연구가 있었지만 BLEU가 20%대였는데 Deep Learning의 사용으로 68%까지 올렸습니다. 아마도 Deep Learning으로 코드 일부를 생성시키는 메이저 소프트웨어 공학회 첫 논문이 아닐까 싶습니다.구현은 TensorFlow가 안정화되기 전에 시작한 일이라 GroundHog/Theano 로 하였는데 후속 연구등에는 TensorFlow를 사용할 예정입니다. :-)Pre-print는 아래에서 보실수 있습니다. http://arxiv.org/abs/1605.08535 매우 초보적인 Deep Learning이 사용이라 아직 부족하고 개선해야 할 점이 많이 있습니다. 보시고 의견있으시면 알려 주시면 감사하겠습니다.	1	아이디어가 엄청 재미있네요 ㅎㅎ 재미있게 읽겠습니다.	1	우와..	0	우와..2	0	Mun Kim, Anna Jung 우와할 수준은 아닙니다. 그냥 first step 입니다.	1	코드를 만들어내나요? 굉장해보입니다!	0	축하드립니다!	1	최초 DL 코딩봇이 교수님 랩에서 나오겠습니다. 기대됩니다.^^	0	우와 멋지세요~^^	0		0	축하드립니다~!	0	오 축하드립니다!!	0	축하드립니다! :)	0	축하합니다.	0	축하드립니다^^	0	꿈에서나 생각해봄직한 코드 생성이 실현되나봅니다! 첫단추를 잘꿰신것같습니다! 축하드립니다!	0	정말 멋집니다! 프로그래머가 요구사항을 중얼거리면서 코딩하면 옆에 추천API 목록 같은게 뜰 수도 있겠네요ㅎㅎ	2	요구사항 JSON 형식으로 입력하면 Client 언어 별로 API Code Generation 해주는 Swagger랑 비슷한 것 같네요	0	권수정
32	엔비디아 딥러닝 데이 행사에 오신 분 계신가요?저는 사전등록을 놓쳐서 직접 체험은 못하고 참관만 하게 되었지만, 후기 공유하겠습니다.	2	저는 곧 도착합니다. 그럼 체험 후기는 제가 ㅎㅎ	0	저도지금와있습니다!	0	반갑습니다! 제가 자리라도 맡아놓을 걸 그랬네요. 혹시 오후 세션 때 옆자리 빌려주실 분이 계실까요?	0	어.... 저는 오른쪽 중간쯤에.... ㅋ. 엔터프라이즈 신청해서 왔어요 ㅎ	0	저도 오전만 듣고 내러가유	1	소감 어떠신가요..? 너무 기본이야기만 하는듯한 느낌 ㅜ	1	제가 들었습니다. 제 페북 담벼락에 올렸어요	2	저도 참석했어요. DIGITS 실습했네요^^	3	핸즈온 실습은 정말 짱이었어요.	0	누구세요? 이것도 켑쳐...	0	후기 올려주셨나요? 기다리고 있습니다!
31	구글이 올 초쯤 올린 프로젝트인데, 생각보다 잘 알려져있지 않아서 소개해봅니다! Tensorflow를 Fluent하게 사용할 수 있도록 래핑한 프레임워크로서, Inception같은 복잡한 구조도 심플하게 구현할 수 있고 다양한 헬퍼 클래스가 존재합니다.단점이라면 구글 프로젝트 치고는 문서화나 커뮤니티가 좀 빈약하네요...
74	제가 만든 텐서플로우 튜토리얼 슬라이드입니다. 잉여력이 된다면 음성까지 입히고 싶은데...ㅠ 그건 제 마음먹기에 달린 듯 합니다 >.< 튜토리얼엔 뉴럴네트워크와 컨볼루셔널 뉴럴네트워크에 대한 간단한 설명도 포함되어 있고, 예제도 포함되어있습니다. 텐서플로우를 처음 시작하시는 분께 좋은 자료가 되길...! (그리고 좋은 튜토리얼 만들어준 최성준님께도 고맙단 말 전하고 싶습니다!)	2	오오 감사합니다.
0	여기도 일베충이 있네요."민주화" 란 단어를 쓰는 양반...심지어 그 사람 댓글에 그 사람을 일베라 썼는데 삭제 되었네요.일단 이 글은 캡쳐...	2	제 글에 댓글을 남기신 것으로 보아 혹시 저를 지칭하신 거라면, 해당 표현은 발표자가 사용한 표현 그대로(democratize)를 문맥상 중요하다 판단하여 직역한 것이며, 따라서 따옴표 안에 가두어 적은 바 았습니다. 해당 어휘는 NVIDIA에서 공식적으로 사용하는 표현입니다. (참고: http://images.nvidia.com/content/pdf/tesla/accelerated-computing-and-democratization-of-supercomputer-whitepaper.pdf)아울러 저는 언급하신 사이트와 일체의 관계가 없으며, 페이스북 상에서 누구의 댓글도 삭제한 사실이 없습니다. 말씀하신 댓글은 해당 글에 그대로 남아있는 것 같습니다. 오해 없이 건전하고 생산적인 정보 공유의 장이 되기를 바랍니다.
23	TensorFlow 위에서 돌아가는 모듈로 고속을 지원하기 위해 상위 레벨 API를 제공합니다.특징은 1. Easy-to-use and understand high-level API for implementing deep neural networks, with tutorial and examples.2. Fast prototyping through highly modular built-in neural network layers, regularizers, optimizers, metrics...3. Full transparency over Tensorflow. All functions are built over tensors and can be used independently of TFLearn.4. Powerful helper functions to train any TensorFlow graph, with support of multiple inputs, outputs and optimizers.5. Easy and beautiful graph visualization, with details about weights, gradients, activations and more...6. Effortless device placement for using multiple CPU/GPU.
13	텐서플로우 관련 자료창고입니다.
33	https://github.com/nlintz/TensorFlow-Tutorials/issues/38제가 기여하고 있는 쉬운 TensorFlow tutorial 예제들인데요, 혹시 LSTM으로 time-series 입력/출력 예제를 만들어 보실 분이 계신가요?이 이슈를 올려주신 분이 sin 값을 입력으로 하면 어떨까 건의주셨는데 좋은 아이디어 같습니다. 구현하실수 있으신분 있으시면 PR 부탁드립니다.
117	TensorFlow 하는데 아마 이 책도 많이 도움이 될듯 합니다. 저희 첫 모임인 6월 18일 (자세한 내용및 접수는 곧 합니다. 일단 18일 오전 11:30분부터 저녁 7시까지 달력에 표시!) 이 책을 가져오시면 번역자 (Lucy Park) 사인도 받으실수 있으실 것으로 예상됩니다.  :-)	2	감사합니다~	0	감사합니다. 목차만봐도 좋네요	0	장소 및 시간도 기다릴께요^^	0	좋은책이네요 공부하는데 도움이 될거 같습니다^^	0	좋은 책 추천 감사합니다 :)	0	책 준비해서 가게습니다.	1	우왕...... 감사합니다 교수님 ^^	0	심상현	0	감사합니다.	0	감사합니다	0	쩝 ...	1	6월 18일에 모임이 있나요...	0	엄청 모이겠군요.	1	딥러닝 한다가 이제 텐서플로우한다가 되는 건가요 ㅎㅎ
37	앞에 15분 정도 Andrew Ng 교수님과 문답인데 기억 남는것 2가지:1. 인공지능 시대 자녀교육 어떻게? Teach how to learn. 새로운 것을 학습할수 있는 능력을 길러주면 이것 저것 해가며 살아 남을것2. 딥러닝의 약점? 엄청난 label데이타가 필요한거. 새로운 학습방법으로 적은 양의 데이터로도 충분한 학습이될수 있는 새로운 방법이 나올듯.	1	여기서 얘기하는 '적다less amount'는게 지금에 비해 적은 것이지 절대적으로 적다는 의미는 아니겠지요? ... ?
57	TensorFlow 관련 자료 저도 하나 올려드립니다.지난 3월에 회사에서 발표하기 위해 작성했던 자료라 최근 자료는 아닙니다.	0	한글에다 그림 자료가 많아서 이해하기 편하네요 감사합니다!	0	재미있게 읽었습니다. 감사합니다.	0	깊이가 다른 좋은 자료 공유 감사합니다!!
83	전직 Software Engineer이자 현재는 Data Science를 배우는 늦깍이 대학원생입니다. 먼저 이 그룹에서 TF에 관한 많은 정보를 얻게 되었음을 감사드립니다. 여러 대가들의 지식나눔에 동참하여 부족하지만 white paper와 source code 분석을 통해 얻은 얕은 지식을 공유하고자 합니다. http://www.slideshare.net/ChoHyunghun/tensorflow-internalTF를 이해하는데 조금이라도 도움이 되길 바랍니다.	1	감사합니다	1	좋은 자료 감사합니다.	1	요새 한창 텐서플로우 짜고 있는데 좋은 자료 감사합니다 ㅎ	1	정말 잘 정리해 주셨네요 감사합니다!	1	좋은 자료 감사합니다 ㅎㅎ	1	감사합니다 ^^
1	가닙승인을 해주셔서 감사합니다. 현재 학부생으로써 인공지능에 관심을 가지고 돌아다니고 있습니다. 잘 부탁드립니다.
1	감사합니다. 불러주시면 더 고맙겠습니다.
8	# tensorflow.basic아직 공부가 부족한 상태에서도, 이런 의문은 가져야되지 않는가 싶어 글을 올립니다.먼저 아래 소스코드를 보겠습니다.```import tensorflow as tfa = tf.placeholder("float")b = tf.placeholder("float")y = tf.mul(a, b)sess = tf.Session()print sess.run(y, feed_dict={a: 3, b: 3})```[질문]대부분 많은 source library가 데이터 전처리를 위해 numpy, scipy, sklearning 패키지를 이용하여 구현되어 있습니다.이때, 굳이 기 사용되고 있는 data preprocessing code를 tensorflow로 재작업하는 것이 이득이 있는가하는 것입니다.정말 이득이 있는 지 확인이 되었는지요?- 속도가 빠르다?- 어짜피 tensorflow instance화 해야한다?또는, 기 정의된 변수 a, b가 tensorflow object이기 때문에 어쩔 수 없다?다시 말해, 위의 예에서는 y = tf.mul(a, b)를 굳이 tensorflow 모듈의 메소드로 할 이유가 정말 있는 것인지 의문입니다.전처리는 sklearn 등으로 수행하고, 실제 modeling 및 parameter optimization and prediction만 tensorflow로 하는 예가 거의 없어서의문이 들었습니다.	2	데이터 처리는 numpy등으로 가능하지만 모델은 tf로 해야 학습이 됩니다. (Chain-rule이 적용됩니다)	1	가능한 것은 알지만, 교수님의 많은 예에서, 데이터 전처리를 tf에만 의존하는 것 같아서, 왜 그럴까? 무슨 이유가 있을까? 속도가 빨라서 그런가? 등에 대해 의문점이 있습니다.	0	이런 질문의 배경에는 sas로 데이터분석을 출발했다가, 빅데이터를 위해 R을 공부하고 이것으로 프로젝트를 진행하다가, deeplearning 때문에 python을 공부하면서, basic으로 sklearn으로 ML을 학습했던 저와 같은 기존 분석가 입장에서는 기존의 수많은 탐색적 data 분서과, 전처리 라이브러리를 희생하지 않고, 공존하는 방법을 생각해보지 않을 수 없기 때문입니다.	1	Session.run()의 파라미터를 보니, fetch_dict에서 dictionary의 element는 graph element 만을 mapping할 수 있네요. 조금 감이 잡히긴 합니다.	2	사람들이 구글에 낚인 거죠. 알면서도 어설프게 아는 고객이 들이대면 써야 하는게 현실이죠. 알파고 만세~!	1	퍼포먼스 부분과 기존 시스템의 재활용성 부분에서 권오성님의 의견에 한 표 드립니다. 단 개념을 이해하기 위한 강의자료에는 여러 라이브러리가 포함되는 것보단 지금 코드가 저한테는 훨씬 이해가 쉬운 것 같아요	0	전처리는 그대로 하셔도 될거라 생각합니다어차피 모델에 들어가는 것은 잘 정리된 데이터마트이고 위에 있는 코드는 텐서플로를 이용한 전처리가 아니라네트워크를 구성하기 위해 필요한 아키텍쳐를 스스로 구현하는 과정이라고 생각합니다나중에 저렇게 짜놓은 코드에다른 라이브러리로 만들어놓은 feature들을 feed 시키는 거니까요위에 tf.mul 은 첫 댓글에 교수님께서 써두셨듯 데이터전처리가 아니라 모델의 아키텍쳐를 구성하는 부분이라는 의견입니다	1	위에 교수님 말씀대로 저 코드는 Tensorflow 내에서 수행될 연산인데요, 말씀 대로 가공은 scipy나 pandas로 하고 피쳐정리가 끝나면 분석할 데이터와 연산식들은 TF로 넘겨야 TF를 통해 GPU나 분선환경의 다른 머신으로 위 식이 흘러들어가겠죠~	1	tensorflow 로만 작성되면 한가지만 공부하면 되는데 다른 서드파티 라이브러리를 쓰게 되면 그것까지도 모두 알아야겠죠. 그러기에 샘플코드는 tensorflow 로만 작성하는...	0	감사합니다~~
2	[질문] cifar10 예제로 샘플을 구성해보려고 분석을 하고 있습니다.예제에서는 준비된 32*32 칼라 이미지셋을 binary로 labeling된 데이터를 준비해놓아서 그대로 사용을 하면 되는데...저는 gray 8bit bmp이미지를 처리 가능하도록 binary로 labeling하고 싶습니다. 데이터 변환에 관련된 샘플 소스를 참고할 수 있는 곳이 있을까요?	1	32*32 rgb이미지를 처리하기위한 이미학습된  모델에 32*32 gray 이미지를 넣어서 레이블을 예측해보신다는 말씀이신가요?	1	제생각에는 억지러 변환해서 넣어도 잘 안될것같습니다. CNN에서는 rgb각각을 연결하는 weight가 다르기때문에 도메인이 달라지면 다시학습 시키는게 맞을것 같습니다.	1	cifar10 예제용 binary 쓰시는게 아니라 직접 binary 만든다음에 쓰신다는 거죠?? binary 구조가 label + R + G + B 이형태로 되어 있으니깐 label + raw data 이렇게 구축하시고 내부 소스 가져오는 부분을 RGB 대신 1개 채널로 바꾸면 되지 않을까요
0	감사합니다
4	[질문] classification 말고 fitting 관련된 예제좀 없을까요?scikit-learn이랑, matlab에 있는 boston house price dataset를 가져다가 TensorFlow ANN 코드 짜보려고 했는데 잘 안되네요;;classification을 위한 ANN이나 fitting을 위한이나 ANN 이론은 거의 동일한데 코드의 미묘한 차이점을 찾지 못해서 난관에 부딪혔습니다 ㅠㅠ
4	tf 로 cnn structured prediction net 을 만들고 있습니다.일반 cnn과의 차이점은 final output 이 이미지 크기만큼의 one hot vector집합이라는 것입니다.따라서, softmax loss 를 계산하기 위해 w x h 번 연산을 해야할 필요가 있는데,tf의 softmax cross entropy 함수는 m x classNo 의 입력만을 받더군요.[m x h x w x classNo] 로 이루어진 tensor 의 softmax 를 vectorization 할 수 있는 방법이 있을까요?써놓고 보니 tf.exp, tf.reduce_mean 등으로 직접 계산하는방법도 있겠군요...	2	저도 확신은없지만 tf.transpose로 m h w n 텐서를 h w m n 모양으로 변경하고, tf.unpack을 반복해서 m x class no 의 텐서들의 리스트로 변환후 적용하는 방법도있을것같습니다.
22	이제 드디어 서울대 인지과학연구소가 주최하고 (사)한국인지과학산업협회가 주관하는 국내최고의 딥러닝실습 튜토리알을 연구원의 메카 대전카이스트에서 6월 9-10일에 체험하실수 있습니다	0	심상현
8	#tensorflow드뎌 GPU를 샀습니다. 욕심내지 않고 gtx960 4GB.온전히 gtx는 floating point 연산에만 사용하고, 디스플레이 출력은 onboard vga에만 맞겨서 gpu 처리 속도를 올리는 설정 방법이 있을까요? ubunto에서의 설정법에 대한 문의입니다.	0	설정법에 대한 답변은 아니지만, 혹시 얼마에 주고 사셨는지 알 수 있을까요?	2	http://nvidia.custhelp.com/app/answers/detail/a_id/3029/~/using-cuda-and-x이 글이 답변인 듯 하네요.
1	[스터디원 모집] 의사결정RL : 파트4 (+강화학습/신경경제학)* 2주에 한번 월요일, 저녁 7시~10시, 강남, 회비 없음(무료공간을 못구하면 공간이용비는 걷을 수 있습니다)* 이벤트 링크 - https://www.facebook.com/events/1597748890535659/안녕하세요. 눈팅회원입니다. tensorflow로 강화학습  실습을 할 예정이라, 관련된 스터디라고 생각되어 이곳에도 글 남깁니다.* 이 스터디는 싸이그래머와 싸이지먼트가 함께 합니다.머신러닝의 강화학습과 인간의 의사결정 심리를 함께 공부하는 의사결정RL. 어느새 파트4로 넘어갑니다. 파트4에서는 새롭게 '신경경제학'이 추가되었습니다. '보상'에 '뇌'가 어떻게 반응하고 결정을 내리는지를 연구하는 뇌과학 + 심리학 + 경제학 분야입니다.그리고 파트3에 이어서 파트4에서도 '강화학습 기초'와 '딥러닝 강화학습' 부분이 이어집니다.전공자/실무자 모임이 아닌, 관심있는 누구나 함께 하실 수 있는 취미 스터디입니다. 참여를 원하시면 이벤트에 '참석'을 누르시거나, 댓글을 다시거나, 해당 장소로 바로 찾아오시면 됩니다.	0	* (U-RL) 강화학습 기초 - https://www.udacity.com/course/reinforcement-learning--ud600	0	* (D-RL) CS 294: Deep Reinforcement Learning, Fall 2015 - http://rll.berkeley.edu/deeprlcourse/	0	http://www.amazon.com/Neuroeconomics-Second-Decision-Making-Brain/dp/0124160085
3	안녕하세요. 육아 헬스케어 부분 최고를 목표로 하는 베이비 타임에서 서버 개발자분을 포함하여 개발자분들/그로스 해커분을 모십니다. 자세한 문의는 메시지 혹은 jaehwa.jung@simfler.com 이메일로 부탁드리겠습니다. ^^
2	https://github.com/aymericdamien/TensorFlow-Examples 사이트에  있는 코드를 보다가 질문을 올립니다. 초보적인 사항인지는 모르겠는데 잘 모르는 부분이라서 질문을 올립니다.AlexNet 샘플코드에서 아래 함수를 사용법을 모르겠습니다.메뉴얼을 보면 local response normalization 이 4차원째의 벡터를 정규화를 한다고 나와있는데 4차원째가 색상채널인 것 같은데 이것을 정규화를 하는 것인지 다른 부분을 정규화하는 것인지 궁금합니다.def norm(name, l_input, lsize=4):    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)_X = tf.reshape(_X, shape=[-1, 28, 28, 1])conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'])pool1 = max_pool('pool1', conv1, k=2)norm1 = norm('norm1', pool1, lsize=4)weights = {    'wc1': tf.Variable(tf.random_normal([3, 3, 1, 64])),    'wc2': tf.Variable(tf.random_normal([3, 3, 64, 128])),    'wc3': tf.Variable(tf.random_normal([3, 3, 128, 256])),    'wd1': tf.Variable(tf.random_normal([4*4*256, 1024])),    'wd2': tf.Variable(tf.random_normal([1024, 1024])),    'out': tf.Variable(tf.random_normal([1024, 10]))}	0	이런 경우는 API 설명을 보시면 편합니다. 4차원 째가 맞고, depth_radius가 정의되있지 않으니, 바로 인접한 element를 가지고 정규화하는 것 같습니다.https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#local_response_normalization
7	[질문] TensorFlow Bazel로 빌드 TF : CPU onlyUbuntu : 14.04gcc : 4.8Bazel : 0.2.3TF 공식 홈페이지에서 bazel 설치 쭉따라하고 bazel build -c opt //tensorflow/tools/pip_package:build_pip_package이 부분 까지 했습니다. (완벽하게 실행되었는지는 모르겠는데 10에 걸쳐 끝나고)https://www.tensorflow.org/versions/r0.8/how_tos/image_retraining/index.html여기 예제 실행해보려고 bazel build tensorflow/examples/image_retraining:retrain이 명령어 입력하니 빌드가 되는 것 같더니.. 아래와 같은 에러가 뜨더군요...bazel 몇번이나 깔았다지우고 시간 다 날려먹었는데 혹시 도움 주실 수 있는분 있나요...	1	선생님sudo apt-get install g++를 한번해보시겠어요?저도 비슷한 문제가 있었는데... gcc 4.8 인가 몇 버젼때문에 문제가 있었던 것으로 기억합니다.	0	https://github.com/tensorflow/tensorflow/issues/1530이런 글이 검색되네요
43	구글 IO 2016, 125개의 비디오 리스트 입니다. ML/DL에 관한 내용도 좀있는데 혹시 보신분있으시면 후기 같이 올려 보아요.	4	마운틴 뷰 가서 거의 모든 ML세션을 들었는데요 (하나는 줄이 길어서 짤렸고 ㅠ_ㅠ), 대체적으로 소개 한 20분 한 후 앉아서 좌담회 비슷하게 진행하고 질답 받는 식이었습니다. ML을 직접 다룬다기 보다는 비전 제시 성격의 세션이 좀 많았고요, 구체적인 부분을 이야기하는 대신 딥러닝 기반의 (이제 프리뷰고 공개 예정인) Vision API / Speech API 의 소개 및 시연, 실습이 주 주제였습니다. 저 두가지 API+기계번역 관련 이슈가 좀 어마무시하긴 했습니다... ML할 때 저 분야들에 대한 의욕은 확 꺾일 정도?의 데이터 스케일+계산 스케일+성능이었습니다.. 질답 부분에서는 텐서플로 그래프의 최적화 관련한 부분들이 좀 기억에 남습니다. (처음 모델 설계할 때 graph centrality를 어떤 measure를 가져와서 어떻게 잰 후 적당한 크기의 레이어 번들 사이즈 / 뎁스를 결정하는가 같은 실제로 큰 시스템을 만들어 볼 때 고민하게 되는 것들에 대한 질문과 답변들이 가끔 있었습니다.)
100	오늘 아침, 우리나라 소프트웨어 엔지니어들에게 좋은 말씀이 하나 있네요.구글의 Peter Norvig (Google Researcher)가 이야기 한 내용입니다.SW 엔지니어가 AI로 경력을 바꾸려면 뭘 해야 하는지에 대한 질문에 대해서...이미 SW엔지니어는 복잡한 시스템을 만드는 것이므로 경력을 바꾸는 것이 아니라AI라는 새로운 방법으로 같은 것을 하는 것이다 라고 답을 했습니다.거꾸로 이야기한다면, 모든 SW 엔지니어들은 AI를 해야하고 할 수 밖에 없다는 말입니다. 저두 같은 생각입니다.우리나라에서는 AI는 어느 특정 전문 집단(전공교수들)이 하는 것이라고 생각하는 것 자체가 잘못된 생각입니다. SW를 할줄 알면 조금만 노력하면 누구나 다 할 수 있고, 누구나 AI의 멋진 기능들을 다 활용할 수 있습니다. 이점이 구글이 가려고 하는 점이고, 또한 저의 생각입니다.	6	공감됩니다.	2	알고리즘이나 자료구조처럼 필수가 되지 않을까요?	3	개발자로서 공감합니다. 기존에 수많은 if then else 로 문제를 해결해 왔다면 이제는 기계학습이란 새로운 접근법으로 문제를 해결하는 거죠.하지만 초기 진입시 수많은 새로운 개념들로 멘붕을 여러번 경험하지만... 머 그래도 극복은 되네요....
34	이미지 관련으로 검색하던 중, 재미있는 코드가 나와서 공유합니다.텐서플로우 예제로 R의 shiny와 결합하여 간단히 UI측면을 결합해서 선택한 사진을 Text화로 나오는 프로그램인데요, R을 모르셔도 따라서 설치하면 30분 이내에 구현이 가능하니까 참고하세요.	0	이런 자료는 어떻게 알게되신건가요?평소에 자주 가보시는 페이지이신지? 아님 검색으나, 특정 site의 RSS로 부터 알게되신건지? 암튼, 정말 재미있는 코드네요.. 감사합니다.
18	convolution과 deconvolution을 결합해서 만든 convolutional auto-encoder(cae)입니다. deconvolution에 대한 감을 잡기에 좋은 예제인듯합니다. :) 성능이 잘 안나오는데 동일한 코드를 서버의 GPU버젼으로 돌리면 잘나오는데, CPU버젼에서는 잘 안나오네요. 이상합니다. ㅋㅋ 	2	Thanks to 차건호 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ	1	역시... 천재는 뭘해도 금방이다...!	0	좋은 정보를 주셔서 감사합니다..^^ 기본적인 질문인지 모르겠는데    Logistic Regression 예제에서 각 epoch 에서 처음 batch만 순차적으로 sampling 하는 이유가 궁금합니다.
5	안녕하세요, 한가지 질문이 있어서 고민을 하다가 여쭈어봅니다.텐서플로우 상에 있는 Cifar-10를 학습을 시키고,학습을 시킨 모델을 활용하여 간단한 영상 분류기를 해보려고 하는데 몇가지 방향성을 여쭙고자 질문 드립니다.관련 조언이나 방향성만 맞게 주시면 감사하겠습니다.1. 일반적인 이미지 데이터 (강이지, 고양이 등등)을 받아 cifar10으로 학습시킨 모델링으로 입력 (이미지 전처리 및 모델 입력)2. 모델링에서 분류된 이미지의 범주를 분류 EX)인터넷에서 받은 무작위의 100개의 이미지를 삽입-> cifar10으로 학습된 모델이 각 이미지를 분류-> 분류된 이미지를 각각의 폴더에 분류 (1. 개, 2. 고양이)완성된 코드는 공유드리겠습니다.감사합니다.
7	안녕하세요.학부 2학년입니다.먼저, 항상 좋은 정보 공유해주시는 분들에게 감사하다는 말 전하고싶습니다.본론으로김홍배님이 방금 올리신 글을 보고서, ai가 앞으로 필수로 배워야 할중요한 것처럼 느껴졌습니다.그래서 공부해볼려고하는데, ㅋㅋ찾아보니너무 막막하고 어렵네요. 혹시 어떻게 가닥을 잡아가야 할지실마리라도 주시면 감사하겠습니다.	10	http://qna.iamprogrammer.io/t/topic/213/4 참고해보세요.	0	논점과 맞지않는 댓글이지만 송곡고등학교 재학하시는중인가요?	1	미국에서도 Andrew Ng교수의 비디오강의는 인기가 많아요,https://class.coursera.org/ml-003/lecture	3	이건 요새 제가 보는거... 이해가 쏙쏙됩니다 ㅎㅎ http://hunkim.github.io/ml/
3	안녕하세요. tensor flow 이용해서 image segmentation 을 해보고 싶은데 혹시 참고할만한 튜토리얼 문서 알고계신분 있으실까요?데이터셋은 MRI 뇌영상 이미지고 수작업한이미지가 10개정도 있습니다.해당하는 부분만 1로 그외는 0으로 표기되는 mask image 를 생성하고싶습니다. Tensorflow가 이런 작업에 적합한지도 궁금합니다.전문가분들의 고견 부탁드립니다. 감사합니다.	1	http://arxiv.org/pdf/1509.00083.pdf혹시 이런게 맞나요?	1	Semantic segmentation이 근접한데요아직 tf 예제는 본적이 없습니다Caffe matconvnet은 있고요그러나 데이터가 너무작네요보통 수천장은 되어야...	0	두분 감사드립니다. Tensorflow Semantic Segmentation 으로 검색하니 몇가지 나오는것들이 있기는 하네요. 한번 제가 따라해볼 수준이 되는지 도전해보아야겠네요. +_+
7	[질문]안녕하세요 :]https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/multilayer_perceptron.py위 예제와 관련해서 궁금한 점이 있습니다.81~84라인에서 accuracy를 측정하고 있는데, 각각의 test image들이 어떤 클래스로 분류 되었는지는 어떻게 확인할 수 있나요?	0	tf.argmax(pred, 1) 이 부분이 클래스 번호를 구하는 부분인 것 같습니다. 클래스 번호가 어떤 이미지를 의미하는지는 데이터에 관한 정보를 찾아보셔야 될 것 같습니다.	0	pred가 test images에 대한 1x10짜리 분류 결과입니다. one-hot vector이기때문에 tf.argmax()한 값이 숫자를 분류한 클래스와 같다고 보시면 됩니다.	0	답변 감사합니다.single_img = test_xs[7] print sess.run(tf.argmax(pred,1), feed_dict={x: [single_img]})이렇게 하면 클래스 번호가 나오긴 합니다. 코드에서 7은 의미가 없는 랜덤 넘버라고 생각하시면 됩니다.근데,위의 코드로 test examples의 클래스 결과 값들을 뽑고 실제 test set의 정답과 비교해서 accuracy 구해보니 예제 코드 (81~84라인)에 있는 accuracy와 다릅니다.	0	Accuracy값이 어느정도 나오나요? 예제에서 제시하는 값과 많이 다른가요?	1	Daewon Lee 전태균 정말 감사합니다!
1	[질문]https://www.tensorflow.org/versions/r0.8/how_tos/image_retraining/index.html이 예제 따라서 한번 해보려고하는데 명령어 : bazel build tensorflow/examples/image_retraining:retrain이 부분을 치면 아래와같은 에러가 나네요...ERROR: /home/hadoop/tensorflow/tensorflow/BUILD:46:1: error loading package 'tensorflow/python': Extension file not found. Unable to load package for '//google/protobuf:protobuf.bzl': BUILD file not found on package path and referenced by '//tensorflow:tensorflow_py'.	0	stackoverflow 에 답변있습니다.	1	http://stackoverflow.com/questions/36070588/distributed-tensorflow-fails-with-build-file-not-found-on-package
1	FIRST CONTACT WITH TENSORFLOW 을 보고 있는데 기본적인 내용이지만 이해가 되지 않아서 질문을 올립니다.Convolution Network 을 설명하는 예제에서 아래와 같은 코드가 있습니다.x_image 가 28x28 이라서 h_conv1 은 24x24 이고 h_pool1 은 12x12 가 됩니다.그러면 h_conv2 는 8x8 이고 h_pool2 은 4x4 가 되는 것 같은데책에서는 h_pool2 가 7x7 인 것으로 설명을 하고 있습니다.(he resulting output of the convolution has a dimension of 7×7 as we are applying the 5×5 window to a 12×12 space with a stride size of 1. The next step will be to add a fully connected layer to 7×7 output, which will then be fed to the final softmax layer like we did in the previous chapter.)제가 잘 못 이해하는 것인지 모르겠지만 조언을 부탁합니다.----------------------------------------------------------------------def weight_variable(shape):initial = tf.truncated_normal(shape, stddev=0.1)return tf.Variable(initial)def bias_variable(shape):initial = tf.constant(0.1, shape=shape)return tf.Variable(initial)def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)----------------------------------------------------------------------	3	padding이 same이면 입력과 같은 출력을 보냅니다. 즉 conv1은 28x28. 그 다음 풀링이 절반으로 줄입니다. 14x14죠. Conv2는 14x14. 다시 풀링해서 7x7.코드에서 print conv1 명령으로 차원을 볼 수 있습니다.
34	이제 딥러닝 전용 보드가 나오는 건가요?	0	헐! 좋군요!	0	딥러닝머신을 팔지도....
0	How can I change cost function in theano to my own cost function??
1	[질문] Pycharm  / Docker안녕하세요 윈도우 10에서 Docker(우분투 14.04) 와 jupyter notebook 을 이용해서 텐서플로우를 돌리고 있습니다.파이참으로 텐서플로우를 이용하고 싶어서 설치까지는 했는데Startup Error: Unable to detect graphics environment라는 에러가 뜨면서 실행이 정상적으로 되지 않네요.해당 에러를 구글에 검색했지만 Display 변수를 설정해주라는 답변 외에는 아직 도움을 얻지 못했습니다.윈도우 도커 환경에서 VI 외에 다른 IDE를 사용하시는 분들 계신가요?
20	알파고때 사용된게 TPU 였다고 합니다. 데이터 센터에는 1년전부터 사용하고있었다고 합니다. 주요 특징은,TPU is tailored to machine learning applications, allowing the chip to be more tolerant of reduced computational precision, which means it requires fewer transistors per operation. Because of this, we can squeeze more operations per second into the silicon, use more sophisticated and powerful machine learning models and apply these models more quickly,	2	딥러닝에 맞게 computation precision을 확 낮춰서 연산 속도를 높였군요.
112	방금 구글 i/o 2016에서 Tensorflow 전용 프로세싱 유닛을 발표했습니다. Tensor Processing Unit이라고 부른다네요.머신러닝에 특화시킨 프로세서로 동일 전력 기준으로 기존 프로세서들보다 order of magnitude 가 빠르다고 합니다.	1	잉 구글 클라우드?	1	좋은 소식이네요. 언제부터 구글 클라우드에서도 지원 되나요?	0	와..
20	의료분야에 종사하시는 분들에게 도움이 될 강의자료입니다.Machine learning in medical imaging
24	http://m.news.naver.com/read.nhn?oid=028&aid=0002318599&sid1=105&mode=LSD연구내용보다 연구에 머신러닝을 적용했다는 것이 흥미롭네요.
7	https://github.com/garion9013/impl-pruning-TF다들 아시는 Iterative Pruning 논문 (Learning both Weights and Connections for Efficient Neural Network. Song et al. NIPS '15)을 TensorFlow 0.8.0에 구현해 보았습니다. 본래는 라이브러리화가 목표였습니다만, 일단은 소정의 성과를 거뒀다 싶어 우선 공개합니다. 또한, 저는 TF의 성능(Latency)에 관심이 있기 때문에, 논문의 정확한 재현보다는 weight를 얼만큼 날렸을 때, TF 실행 시 Latency 및 압축율이 어느정도 되는지를 확인해보고자 하였습니다. 일단, 결과만 말씀드리자면, 현재 상태에서는 accuracy loss 및 모델의 압축율은 준수하게 나오지만, Sparse matrix를 사용함으로써 나오는 성능 이득은 미미하거나, 오히려 안좋습니다. 이는 baseline으로 사용한 모델 사이즈가 너무 작고 (13MB), TF에서 지원이 부족하여 생기는 결과라고 생각됩니다.즉, TensorFlow에서 아직 SparseTensor 및 SparseVariable에 대한 지원이 부족해서 operation을 우회적으로 구현한 점. 또 TF 자체적으로 Sparse matrix에 널리 쓰이는 CSR 포맷을 사용하지 않기 때문에 완벽한 성능이 나오지는 않습니다. 이 밖에도 이 코드에서 사용한 방식을 그대로 다른 모델에 적용하기에는 몇 가지 문제점이 있습니다. (README 참고) 하지만, TF에 이 테크닉을 적용했을 때 어느 정도의 성능 트랜드는 재현해 볼 수 있었습니다.재미있는건, 작은 MNIST 모델이라서 그런지 FC layer의 90%를 그냥 없애버려도 accuracy loss가 그닥 없다는 겁니다. 모델 사이즈는 6.5배 가까이 줄었구요. Optimizer로 수렴해서 찾은 model이 과연 정말 최선인가? 하는 생각이 들더라구요. 또한, protobuf가 인상적으로 serialize를 잘해주는구나 하는 결론을 얻었습니다. (saver의 protobuf를 통한 저장만 하더라도, Non-zero element들을 손으로 계산한 용량에 비해 거의 2배가량의 압축율)혼자서 나름 문서화 및 주석을 달아놓긴 했는데, 많이 부족합니다. 지적이나 질문 환영합니다. 이 다음으로는 더 큰 모델에 대해서, 또 Nvidia 사의 Tegra TK1에서 같은 실험을 해보려고 하고 있습니다. 그런데 TK1 보드에 TensorFlow 까는게 쉽지 않아 보이네요ㅎㅎ 혹시 이 그룹에 TK1 보드 같은 모바일향 보드에 설치해보신 분이 계실까요?
2	[질문] 텐서플로우로 트레이닝된 모델을 로드하여(graph.get_operation_by_name 이용)콘솔입력에 대해 루프를 돌면서 테스팅을 하고 있습니다.입력은 백터화 해서 numpy array로 들어갑니다.while True:     print (sess.run(predict))아래와 같이 하게되면  몇 번 입력 후에는 이 로직이 죽게 되는데요. 아래와 같은 에러를 줍니다.TypeError: Fetch argument array has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)run 이후 다시 초기화를 한다던가..이런 작업이 필요한지 session.run을 반복적으로 할 경우는 안된다거나  이런 케이스가 있을가요?	0	위 코드에 인덴트가 안들어가네요;;	0	보통 미니배치를 하게되면 sess.run()을 수백, 수천번 반복하게 되는 데 문제가 생겼던 적은 없었습니다.혹시 콘솔 입력 중에서 잘못된 입력이 들어갔을 확률은 없나요? 같은 입력에 대해서만 반복했을 때도, 중간에 저런 에러가 발생하나요?	0	에러 메시지만 봐서는 초기화 문제가 아니라 numpy array를 직접 연산에 넣으려고 해서 문제인것 같은데요. tf.constant 등으로 감싸서 Tensor를 생성하지 않고 직접 numpy array를 수식에 넣는 부분이 없는지 확인하셔야 할것 같습니다. 초기화는 Variable에만 해당하는 거라 이 에러랑은 무관할 것 같네요. 근데 batch가 몇번 도는 중간에 에러가 나는건가요?	1	자문자답입니다. ㅎㅎ  한번  sess.run을 한 후 저장해놓은 operation들을 다시 불러와서  해결하였습니다. 아마 세션 런 후  operation들을 잃어버리는 것 같아 보입니다.
42	석박사과정을 준비하는 학생을 대상으로 주로 CNN(영상처리)을 중심으로 응용주제별로 최신 연구내용을 전반에 걸쳐 심도있게 설명하는 강의 내용입니다.대학 고년차 이상의 학생들은 물론딥러닝 입문자들에게 많은 도움이 되는 내용인 듯해서올려봅니다.CNN의 기초부터 캡셔닝, super resolution,Optical flow,  visual question answeringBiomedical imaging,  3D computer vision 등http://www.cs.ucf.edu/~bgong/CAP6412.html	1	좋은 자료 감사합니다.	1	심상현	1	좋은 자료.. 감사합니다.	1	대박이네요... 강의 동영상은 따로 없능건가요?
77	Junhyun Cho 님의 상세한 설명. 따라만 하면 바로 TF 를 돌릴수 있습니다!	1	아주 좋은 정보입니다.	2	그런데 아주 혹시라도  설치 후 우분투에서 로그인이 무한대로 반복하는 것을 겪으신 분이 계실까 하여... 이것 저것 찾아서 해보고 있는 중에 링크 하나 공유드려여.. http://m.blog.naver.com/mapirus7777/150162559481 하핫..ㅜㅜ 참 저란 사람은 모든것이 쉬이 되는 것이 없군여 ㅜㅜ 하핫..ㅎㅎ^^;; 모두들 화팅여~	0	안녕하세요오늘 첨부해주신 자료대로 하다가 보니Ubuntu 16.04로 설치를 했네요.Cuda 7.5가 지원이 안된다고 하는데 Ubuntu 16.04에서도Cuda 7.5를 설치 할 수 있는 방법이 없나요?	0	이 포스트를 따라해보니 (저는 cpu only이고 다 똑같이 따라했습니다.)1. pycharm 에서 import tensorflow as tf 할 때 tensorflow에 빨간줄이 뜹니다.2. 콘솔에서 tensorboard를 실행시키니 사진과 같이 나옵니다... 아무것도 나타나지 않아요. (이전에 잘 나왔던 event log파일로했는데도요) - 포스트를 따라하면서 anaconda로 tensorflow를 깔게되었고 실행할 때 source activate tensorflow 명령하고 실행시켰습니다.
5	GPU 메모리 부족으로 인한 에러를 잡을 수 있는 좋은 방법 있을까요?Test error를 계산하려고 accuracy = sess.run(accuracy, feed_dict={x: testX[1:9000,:], y: testY[1:9000,:]}) 를 넣었더니 데이터개수 8000 까지는 메모리가 괜찮고 9000부터 에러가 나네요ㅠㅠㅠㅠ 에러를 발생시키기 전에 적당한 최대치를 먼저 아는 방법 없을까요? (그냥 다들 쪼개서 계산한 후 합하시나요?)	0	그룹 내에 곽동현 님이 올려주신 GPU 메모리를 점진적으로 늘려가며 할당하는 방법에 관한 글을 봤습니다. 18시간쯤 전에 올라온 글인데 도움이 될지도 모르겠네요 :D	0	시용하시는 데이터가 어떤데이터인지모르겠지만, 적당한 테스트배치사이즈를 정하고 iteratively 계산하는게 일반적입니다.	1	선로이, Hyo-Eun Kim // 감사합니다. 뭔가 더 산뜻한 방법을 제공해줄 줄 알았는데..ㅠ (곽동현님이 알려주신 방법은 GPU리소스의 한계벽(?)을 바꾸는 방법으로 이해하고 있습니다>.<)	0	최대치*n번 inference 대비 적당치*m번 (m>n) inference 가 느리긴하겠지만 테스트를 매 train iteration마다 할정도로 빈번하게 하지않는 이상 굳이 최대치를 찾아야할 필요가없다고 생각하는데, 혹시 다른이유가 있습니까?	0	Hyo-Eun Kim // 아니요 이유가 없습니다 ㅎㅎㅎ 그냥 이런 것도 자동으로 신경써주는 함수가 있었으면 좋겠어서요 ㅎㅎ 메모리 에러가 날 것 같으면 자동으로 쪼개서 accuracy를 evaluate해주는...	0	위에하신것처럼 testX가 시스템메모리에 다 올라가는경우라면 유용할듯하네요~ 하지만 시스템메모리는 모든 프로세스가 나눠써야하는 귀한(?)자원이라 영상데이터처럼 하나하나 용량이 큰 데이터들은 애초에 testX부터 적당히 쪼개줄필요가 있습니다. feed dict대신 data queue 를 정의해서 쓰면 자동적으로 처리할수있게 만들수는있긴합니다. (그래도 있으면 좋을것 같네요~)
15	StackoverFlow tensorflow 테그의 답을 가장 많이 달아 주시는 분인데 오늘은 질문을 올려 주셨네요. 구글 브레인팀 직원의 질문. 혹시 답을 아시는 분은 망설이지 말고 http://stackoverflow.com/questions/37281928 로 답 달아 주세요.	0	이런 것 너무 좋아라하는데...저의 코딩 실력으로는 그림의 떡~^^ 그렇치만 보는 것 만으로도 흐뭇합니다.	0	쉬운게 아니네요
155	드디어 6월 18일 TF-KR 첫 모임을 가지려고 합니다. 즐거운 모임이 되기 위해 여러분들의 참여가 필요합니다. 우선 이 모임때 발표해주실 분들을 찾고 있습니다. http://goo.gl/forms/vxhMaOQufd본인이 지원하시거나 주위에 좋은 분이 있으시면 추천해 주시면 됩니다. 섭외와 준비 관계로 5월 15일까지 지원과 추천을 받겠습니다.이 지원/추천 페이지도 많이 홍보및 공유하여 주시기 부탁드립니다. 그럼 6/18일 즐겁게 뵙도록 하겠습니다.	2	메이저 학회인 ICML 2016 이번에 뉴욕에서 개최되는데, 6/18 출국해야 갈수 있습니다. ML전문가들께서 가시는 분들이 많을것 같은데, 혹시 한주전이나 2주 후로 일정조정이 가능할까요? 꼭 참석하고 싶어서 의견드립니다~	1	전 발표자는 아니지만 참관을 할께요	1	전 김교수님 얼굴보러 가고 싶습니다.	0	유미 여기 신청해보세요
11	[질문] 텐서플로우에서 MLP를 돌려보고 있는데요, optimizer로 GradientDescentOptimizer 를 썼을 땐 첫 accuracy가 10%보다 작게 시작해 성능개선도 시원찮던데요, AdamOptimizer를 쓰니까 첫번째부터 90% 이상을 뽝 찍더니 거의 100%까지 성능이 올라가더라고요.  왜 이렇게 차이가 심하나요?? GradientDescent도 regularization 잘 해주고 충분히 오래 트레이닝 시키면 언젠간 90% 이상까지 올라가는건가요? 초반 업데이트의 차이?? (AdamOptimizer 논문을 읽어봐야겠네요...)	5	모멘텀 적용 방식에 따라서 스텝사이즈가 수백배까지 달라질 수 있기 때문에 발생하는 현상입니다. 옵티마이저 튜닝은 사실상 필수.. http://m.imgur.com/a/Hqolp	0	모멘텀 만으로 설명하기엔 몇번 후도 아니고, 딱 첫번째부터 90% 이상을 찍는게 신기해서요. 제가 아주 옛날 수업에서 들었던 conjugate gradient (너무 구닥다리인가ㅠ) 이런 것도 한번에 이렇게 정확히는 못갈텐데... 논문을 읽어봐야겠네요. 바쁜거 끝나고..ㅠㅠㅠㅠ	1	첫 배치가 아니라 첫 에폭 말씀이시죠? 데이터에 따라 배치들의 분포가 충분히 균질하면 가능한 시나리오 같습니다 @.@	0	아... 그렇겠네요! 오 감사합니다!	0	저도 비슷한 경험이 있습니다. 저는 어떤 동역학 모델에 대해 무작위로 동역학 모델의 파라미터를 생성한 후 수행한 시뮬레이션 데이터를 학습에 이용하고 있는데요, AdamOptimizer가 TensorFlow에서 제공하는 여타 Optimizer보다 대개 훨씬 빠른 학습 속도를 보여주었습니다.	0	수렴속도보단 마지막 loss도달지점이 중요한게 아닐까요보통 lr과 loss가 0.1이하 안정화되고나서도 작게 진동하며 하루이틀천천히 떨어지는 경우가 많았습니다
57	안녕하세요. TensorFlow 사용 시 gpu memory를 일부만 할당하는 옵션 [ per_process_gpu_memory_fraction=0.1 ]은 다들 아실텐데요, 그이외에 유용한 옵션인 allow_growth 옵션을 알게되어 소개드립니다.sess=tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))이 옵션을 사용하면, session에서 필요로하는 메모리를 최소한으로 할당한 후 필요할 때마다 점진적으로 늘려가면서 메모리를 추가할당하게 됩니다. 이를 통해 내 모델이 필요로하는 메모리를 쉽게 알아낼 수 있고, 동시에 여러사람이 1대의 gpu를 사용하는 환경에서 매우 유용합니다.	1	와 이게 있었네요. 감사합니다.	1	꼭 필요한 설정이었는데 없어서 이상하다고 생각했는데 제가 못찾았었던거군요. 감사합니다.	1	좋은 정보 감사드립니다!	0	감사합니다. 한번 써봤는데, 할당된 메모리 양이 로그로 보여지는 것 같진 않네요. 혹시 이를 확인할 수 있는 방법이 있을까요?
32	http://playground.tensorflow.org	0	와 대단하네요 해봤는데 시각적으로 보이니깐 확 느낌이 오네요	0	볼때마다 대단한거 같아요
111	구글이 어제 Research Blog를 통해 공개한 TensorFlow 기반 자연어 처리 SyntaxNet에 대해, 원문 글을 한글화 번역 및 조금 다듬어보았습니다. 실제적으로 코드 수행 등등에 대한 부분도 추후 공유하도록 하겠습니다. 	0	번역 감사합니다.	0	감사합니다.	0	재.....재유야!?	0	저도 감사해요^^	0	번역이 너무 좋아요 술술 익혀요^^	0	학습데이터까지 제공하다니... 아두이노에도 넣을 수있는거 아님?	0	이번에 영어학습 플랫폼개발을 하면서 NLTK와 Stanford parser를 이용했는데 구글에서 정확도가 높은 알고리즘을 발표해서 좀더 나은 방향으로 접근할 수 있게되었습니다. 그리고, 번역이 어려웠었는데 이렇게 번역을 해주셔서 정말 감사합니다.
17	개인노트북으로 텐서플로우를 돌리니깐 진짜 발열이 장난이 아니네요ㅜㅜ다른분들은 어떤 환경에서 돌리고 계신가요?계속 이걸 하려면 새로 PC를 하나 맞춰야 할것 같다는 생각이 많이 들어요ㅜㅜ	4	저도 노트북. TF돌리면 다른 작업은 불가합니다. ㅠㅠ 그래서 간단한것은 여기서 돌리고 조금 복잡해지면 AWS/ Google Clould로 바로 보냅니다. :-)	1	GPU를 사용하지 않으면 부하가 많이 걸려요. 그래서 CPU + GPU환경이 좋겠지요.	1	노트북은 어떤거 쓰시나요?	4	구글 클라우드 플랫폼의 머신러닝 서비스도 한번 살펴보세요.https://cloud.google.com/ml/	1	GPU 필수입니다. 10분이면 끝날 학습이 10시간 이상 걸려요.
40	텐서플로우 강의를 듣다가 어설프게 배운 Character RNN을 갖고 한글을 음소 단위로 분리해서 기존 Character RNN 구현 코드에 올려봤습니다. RNN구조는 영문 RNN에서 RNN Size가 1024로 늘어난것 외에 딱히 변경된 부분이 없습니다. 한글 글자가 조합 될 수 있는 형태로 만들어지고 단어가 되는게 만들어 놓고도 참 신기하네요.다음은 96000 Iter.에서 셈플링 된 예제 일부 입니다. 더 돌리면 멋진게 나올듯 한데 장비가 안따라 주네요;----------------------------------------------------------------------노인은 잡히고 재갈처럼 세상의 관심을 삶을 시작하여 박육중의 내쪽도 미적지고 무엇일까요? 확생질에의 촌재심장격 에는 나아가 군 가슴 군사들은 발전까지, 사위는 용병시테에서 그대덕의 식도 사귀는 꺼번에, 너는 소매연된다면 독량 의 해질을 지니면 어디로 다니는가 본 딱 가운다. 이미 죄 처해줬다. 정말 여섯 결과가 일으키였어요.노기는 내가 만가든 자의 앞광경을 '이기 켜!] 물에 정말이라----------------------------------------------------------------------좋은 강의와 디버깅과 서버 리소스 랜탈(?) 등등 이래저래 많은도움 주신 최성준 강사님께 감사드립니다.	2	해독은 안되도 strong feel이 있습니다. ^^ 세태를 한탄하는 도담 같아요 화이팅입니다! 저도 꼭 한 번 해보고 싶네요	1	오우, 멋지군여 ! 한글 CharRNN은 처음 보네요. 카파시는 2MB 정도의 텍스트를 권장하던데, 실제 피딩된 텍스트 데이터파일 크기가 어느 정도인지, 주로 어떤 텍스트였는지 궁금합니다. 리눅스 커널소스가 엄청 커서 약 475MB 정도지만, 영문 킹제임스 바이블은 4.5MB 정도 되는걸로 압니다만.	1	멋집니다.	0	설명을 듣고 다시 코드를 보니 이해가 잘 되더군요! ㅎㅎ 멋진 코드 감사합니다.
4	맥북에어 anaconda상에서 tensorflow를 사용하고 있는데요. 김성훈교수님 강의자료에 있는 char-rnn 관련 코드만 유독 에러가 생겨 돌아가질 않는데요... 혹시 다른분들도 그러시나요?? 혹시 맥북에서 anaconda말고 다른 환경쓰시고 계신 분들 추천좀 부탁드립니다.	1	혹시 에러메시지가 어떻게 나오나요? 혹 다른분 돌려보신분 계신가요?	1	혹시 문제가 해결되었나요?	0	간단한 RNN코드로 교수님께서 올려주신 "hello RNN" 예제에서ValueError: Variable RNN/BasicRNNCell/Linear/Matrix already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:다음과 같은 에러가 발생해서 교수님께서수정해주신 아래 코드도 실행해보았을때,정상적으로 실행이 되더라구요-----------------------------------------------------------------------------------import tensorflow as tffrom tensorflow.models.rnn import rnn, rnn_cellimport numpy as npchar_rdic = ['h','e','l','o']  # id -> charchar_dic = {w: i for i, w in enumerate(char_rdic)}  # char -> idsample = [char_dic[c] for c in "hello"] # to indexx_data = np.array([ [1,0,0,0],  # h                    [0,1,0,0],  # e                    [0,0,1,0],  # l                    [0,0,1,0]],  # l                     dtype='f')# x_data = tf.one_hot(sample[:-1], len(char_dic), 1.0, 0.0, -1)# Configurationchar_vocab_size = len(char_dic)rnn_size = 4 #char_vocab_size  # 1 hot coding (one of 4)time_step_size = 4  # 'hell' -> predict 'ello'batch_size = 1      # one sample# RNN modelrnn_cell = rnn_cell.BasicRNNCell(rnn_size)state = tf.zeros([batch_size, rnn_cell.state_size])X_split = tf.split(0, time_step_size, x_data)outputs, state = rnn.rnn(rnn_cell, X_split, state)#outputs, state = tf.nn.seq2seq.rnn_decoder ( X_split, state, rnn_cell)print (state)print (outputs)# logits: list of 2D Tensors of shape [batch_size x num_decoder_symbols].# targets: list of 1D batch-sized int32 Tensors of the same length as logits.# weights: list of 1D batch-sized float-Tensors of the same length as logits.logits = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])targets = tf.reshape(sample[1:], [-1])weights = tf.ones([time_step_size * batch_size])loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [targets], [weights])cost = tf.reduce_sum(loss) / batch_sizetrain_op = tf.train.RMSPropOptimizer(0.01, 0.9).minimize(cost)# Launch the graph in a sessionwith tf.Session() as sess:    # you need to initialize all variables    tf.initialize_all_variables().run()    for i in range(100):        sess.run(train_op)        result = sess.run(tf.arg_max(logits, 1))        print (result, [char_rdic[t] for t in result])﻿----------------------------------------------------------------------------------그런데 Mac  anacoda환경에서 돌리면 같은 증상인지 모르겠지만,한번 실행시키고 다시 실행시키면 에러메세지가 뜨고,한번 수행하고 다시 재수행할때anaconda spyder를 다시 실행시켜야 정상동작을 하는데 혹시 저와 같은 환경을 쓰시는 다른 분들도 같은 증상입니까? 교수님께서는 Mac에서 어떤 환경을 구축하셔서 사용하고 계신지요?	3	아나콘다의 문제는 아닌 것 같습니다. rnn의 경우 nn_cell = rnn_cell.BasicRNNCell(rnn_size)를 한번 부를 때마다 내부적으로 메모리를 잡는데, 해당 구문을 다시 call할 경우에 위에 에러 메세지와 같이 이전에 할당해놓은 메모리와 충돌이 납니다. cell별 수행이 아니라, reset하고, 다시 run을 하면 잘되는게 맞는 것 같습니다.
39	구글에서 TensorFlow 기반 자연어 처리 코드인 SyntaxNet를 공개했습니다. POS Tagging (형태소분석)에 사용되었네요.  핵심 아이디어는 단어간 transition dependency parsing 입니다. Beam searching이란걸 이용하는군요. 자세한 내용은 아래 링크를 참조해보세요. 시간날때 집중해서 읽어봐야겠습니다.Google blog: http://googleresearch.blogspot.kr/2016/05/announcing-syntaxnet-worlds-most.htmlarXiv paper: http://arxiv.org/abs/1603.06042Github link: https://github.com/tensorflow/models/tree/master/syntaxnet	1	정보가 매일 매일 쏟아지는 군요~	0	POS 테그를 좀더 정확하게 할수 있는것 같은데 이것으로 할수 있는 일들이 뭐가 있을까요? 요즈음은 그냥 txt를 딥러닝의 입력으로 사용하는경우가 많은것 같은데 이 POS테그가 유용할까요? NLP전문가님들 알려주세요.
40	텐서플로의 강력한 도전자가 등장하였습니다!	0	심상현	1	서로 앞다투어 이렇게 오픈소스로 경쟁하는 모습 보시 좋습니다. dsstne 사용해보신분들 후기 기다립니다.
9	https://www.facebook.com/100001173798815/videos/970806819635102/
24	발표자 추천/지원이 내일 5/15일 까지 입니다. 지원을 망설이고 계신분이나 주위에 좋은 분이 있으시면 망설이지말고 추천/지원 부탁드립니다.
22	아마존에서 공개한 오픈소스 딥러닝 툴입니다. NetCDF포맷을 사용하고 있고 여타 다른 딥러닝 툴 처럼 input, hidden layer, output이 기본입니다.tensorflow랑 비교해 볼 수가 있을까요?
27	안녕하세요. 항상 눈팅만하다가... 유용한 자료를 발견해서 공유드립니다.전 CNN을 가지고 공장 설비의 무수한 제어 및 센서 계측 실적 데이터에서 결과를 예측하는걸 연구하고 있습니다.( 이제 겨우 MNIST 예제 돌리며 원리를 공부하고 있습니다)실적 데이터가 이미지가 아니라 CNN을 바로 적용하는건 무리가 있겠지만 NLP에도 적용하는 연구가 진행되고 있으니... 희망을 가지고...암튼 첨부된 싸이트 자료에 데이터 준비부터 전처리, 파라미터 설정등 연구할때 무엇을 건드리면서 해야 하는지 깊은 감동을 주고 있습니다.싸이트 안에 링크된 ppt 슬라이드 또한 저에게 많은 깨달음을 주었고요...하여 저같은 초짜들에게 공유합니다.감사합니다.	1	좋은 자료 공유 감사드립니다! 혹시 실적 예측이 Regression류의 문제라면 특징추출과 분류에 적합한 CNN보다는 Linear나 Logistic Regression이 좀 더 적합하지 않을까요?
38	프랑스 소니 CSL팀에서 재밌는걸 꾸준히 하고 있었네요. RNN을 이용하여 Machine Translation 하는 것과 같이 Markov matrix를 학습해서 음악을 다른 스타일로 편곡하는데 적용했네요.음악 장르별로 이퀄라이져 제공하는 것 처럼 선호 음악 스타일 별로 편곡해서 제공해주는 뮤직 스타트업도 생기면 재밌겠군요 :) 공부하시면서 좋은 음악 듣고 가세요!http://www.yonhapnews.co.kr/local/0899000000.html?cid=MYH20160511017400797	1	오 뉴럴 아티스트를 보고 음악쪽에도 이런게 생기면 재밌겠다라고 생각만 하고있었는데 역시 연구가 되고있기는 하네요. 혹시 관련 논문들은 볼 수 없을까요?	1	오오... 신기하네요
12	"딥러닝은 결국 머신러닝 기반에서 시작이 되었고, 궁금한 점은 이러한 학습을 하는데 있어서 일반적인 데이터 형태가 어떠한지 궁금합니다.입력되는 유한개의 X 값들의 결과값이 항상 하나의 출력값인 Y 형태로 되는지 궁금합니다.또한 이 때, 학습이 될 경우가 하나의 row에 모든 정보가 포함이 되어야 하는가요? 예를 들면 Sequential Data와 같은 형태가 되어야 분석이 가능한지 궁금합니다."	0	방법에따라 데이터의 형태가 다른데, 머신러닝의 기초인 회귀분석의 경우만 예를 들자면 단일x, 단일y(단순선형회귀) 또는 다중x, 단일y(다중선형회귀)가 가능하구요. y가 실수형이아니라 범주형이라면 로지스틱회귀도 가능하고...ann의 경우엔 다중x 다중y를 학습시키는게 가능하고..결론을 내 보자면 데이터의 종류에 따라 학습방법이 다양하기때문에진짜 고민해야하는건 데이터의 형태가아니라 어떤 방법을 왜 사용할것인가 하는 문제인곳같습니다.	1	Supervised learning 의 label 도 멀티가 가능합니다. 일반적이진 않은듯 하지만 CNN도 논문들 중에 multilabel CNN이 되도록 변형하는 방법에 관한 논문들이 있었구요. multilabel supervised learning 에 특화된 예를 들어 BP-MLL 같은 Neural Network 모델도 있더군요. 막 공부하고 있는 newbie라 아직 저도 잘은모르는데요. 논문들 위주로 보다 보니 그런것들이 있었습니다.
109	TensorFlow 튜토리얼들 (코드와 발표 자료) 코드: https://github.com/sjchoi86/Tensorflow-101발표자료: https://github.com/sjchoi86/Deep-Learning-1016주의 수업이 모두 끝나가니 생각보다 많은 자료가 모인 것 같아 공유합니다.	1	고퀄리티 자료 감사합니다.	1	고퀄리티 자료 감사합니다.+1	2	고퀄리티 자료 감사합니다.+2	0	좋은 정보를 공유해 주셔서 감사합니다....^^	0	잘 볼게!! 고마워!	0	To Sungjoon Choi Samuel MNIST In [4] 에 plt.show() 빠진 것 같은데요...^^ 좋은 자료를 잘 보고 있습니다.
20	"모두를 위한 딥러닝 강좌 시즌 1에서 lec 01의 설명중 tensor 가 정확히 이해가 안되는 부분이 있어서요. lab01 에서는 노드와 엣지로 구성된 그래프(Tensor Data Graph)가 있고 이 그래프가 떠다니는 것(?)을 tensor 라고 하셨는데요. 이 떠다닌다는 것이 무슨 뜻인가요?"	11	처음에 tensorflow라고 이름을  지은 이유를  설명하다 보니 이것이 오히려 혼란을 불러일으킨 듯 합니다.  일반적으로 많이 다루는 이미지 데이터를 보면 2차원 (gray)또는 3차원(rgb)의 다차원 데이터인데  이것을 일반적으로 텐서라 하고 node에서 정의된 연산과정을 거쳐 엣지(노드간을 연결줄)로 미리 정의된 흐름(flow)에 따라 다음 연산과정으로 전달되는 과정이라고 이해하시면 됩니다.
103	얼마전에  김교수님이 올려주셨던"중학생도 알아듣는 Tensorflow입문"을번역하고 classifier architecture추가와이해하기 좋도록 관련 수식까지 함께 넣은 자료입니다.어느 자료보다 쉽게 이해하실 수 있습니다.https://www.slideshare.net/mobile/ssuser06e0c5/mnist-for-ml-beginners	3	감사합니다. like^100 하고 싶습니다.	1		3	이걸보고 이해가 안되면 중학생도 안되는건가 하는 불안감은 있지만 자료 감사합니다! XD	1	잘보겠습니다 감사합니다^^	1	감사합니다 잘보고 배우겠습니다	1	자료 감사합니다
3	가입 승인 감사합니다
16	어제 윈도우 bash에 텐서플로우 설치해 보았던 사람입니다.오늘 학교 마치자 마자 파티션 나눠서 윈도우를 본컴에 깔고, GPU-enabled 버전 설치를 시도해 보았습니다만..여타 라이브러리들은 정상적으로 설치가 되었습니다.다만 nvidia 드라이버가 정상적으로 설치되지 않네요ㅠㅠ 내일 다시한번 시도해 보아야 할 것 같습니다아쉬운 소식 전해드려서 괜사리 마음이 무겁네요ㅠㅠ	1	https://github.com/Microsoft/BashOnWindows/issues/49아마 이게 문제같습니다만.. 해결방법들 총동원해보아야겠군요	1	응원드립니다. 화이팅~~~	1	응원드립니다.
0	tensorboard 관련 질문입니다.예전에 실행시킨적 있었는데 지금 다시 해보려니 Segmentation fault 오류가 나네요0.8로 업그레이드 시켜서 그런지... 혹시 제가 어떤 부분이 틀렸는지 아니면 방법 아시는분 계신가요..?	0	Segmentation fault 는 못보았는데 혹 이전 버전의 파일이 logdir에 남아 있나요? 삭제한다음 한번 해보세요.	5	지금 릴리즈된 0.8.0 버전에서 발생하는 버그입니다. 릴리즈되고 나서 몇일후에 고쳐졌구요 nightly build 로 설치하시면 문제 안생길거에요~https://github.com/tensorflow/tensorflow/issues/1373
15	유용한 컨퍼런스가 있어 공유드립니다 :)'AI / Data Developer Conference - 기술 스타트업의 최신 기술과 사업을 만나다' 에 초대합니다.오직 개발자를 위한 컨퍼런스로서 인공지능과 데이터 관련 스타트업들이 보유한 최신 기술에 대해 소개하고, 소프트웨어나 서비스뿐 아니라, 하드웨어나 뇌과학 분야 스타트업들이 어떻게 데이터를 활용하고 있는지 알려드릴 예정이라고 합니다.인공지능이나 데이터 관련 개발자/데이터 사이언티스트, 혹은 평소에 관심있었던 개발자분들은 링크를 확인해주세요:)
12	저희의 타임라인을 책임지고있는 또 다른 flow, FBLearner Flow 이야기 입니다.(파이썬도 사용되네요)
3	CS 224D 를 유투브 에서 다운받으려 하는데 편하게 다운 받는법이 있을까요 ? 일일이 다운받기에는 시간과 효율이 떨어지는거 같아 여쭤봅니다 ㅠ	1	하나씩 다운 받지 않고 전체를 한번에 다운받는 방법은 없는것 같습니다.	7	https://rg3.github.io/youtube-dl/ 플레이리스트 한번에 받아줍니다.	0	으아 감사합니다 선생님들 ㅠ
17	Tensorflow를 Windows 10 에 설치하는 과정을 글로 적어 보았습니다ㅎㅎ 부족한 부분이나 문제되는 부분은 가차없이 댓글로 알려주시면 감사하겠습니다~	1	얼른 레드스톤이 나왔음 좋겠네요	1	좋은글 올려주셔서 참고하여 저도 http://stackoverflow.com/questions/33616094/tensorflow-is-it-or-will-it-sometime-soon-be-compatible-with-a-windows-work/37105739#37105739 답을 달아 보았습니다.	0	GPU 성공하였나요?
88	윈도우에 bash가 들어오면서 ubuntu core가 흡수된다는 말을 듣고 tensorflow 를 설치해 봤더니 잘 돌아가네요ㅎㅎ딥러닝 공부하실분들 6월 이후부터는 우분투 굳이 설치 안하시고 공부하실 수 있으실 것 같습니다!	1	멋지네요. 혹시 자세한 설치 과정 post로 부탁드려도 될까요?	1	우와 이런방법이 있었네요. ^^	1	우분투용 CUDA로 GPU 사용도 동일하게 될까요?	1	실험용이 아니라면 정식 배포될 때까지 기다리시는 것이 좋습니다. 메인으로 사용하기에는 많이 불안정합니다. 저는 몇번 blue screen을 봤습니다.	1	Pc 한대 더 사야하나 고민했는데~^^ 기다려야겠군요	2	VirtualBox를 이용해서 Windows10과 필요한 파일을 설치하니 매끄럽게 실행이 되는군요. 개발환경을 어떻게 구축할까 고민했는데 쉬운 해결방안이 생겼네요. 감사합니다.
71	중복된 내용일지도 모르겠는데요.Tensorflow를 처음 접할때튜토리얼 예제 설명자료에친절하게 넷트웍 그림이라도 넣어주었으면이해하기가 훨씬 수월했을텐데하는 아쉬움에서 제가 만들었던Deep MNIST for Experts 예에 대한 설명자료입니다.일단 넷의 구성에 대한 자세한 그림과 함께라인별로 설명 주석을 달았습니다.입문자분들이 이해하기 훨씬 쉬울 듯 합니다.ppt 파일이 필요하시면 보내드릴께요.	1	앗 혹시 cswcsy@gmail.com로 보내주시면 감사히 사용하겠습니다 ^^	3	혹시 http://jupyter.org/ 를 사용하여 코드에다 그림까지 넣어 주시면 정말 이해에 도움이 될듯합니다.	1	친절한 학습자료를 만들어 공유해주셔서 감사합니다. 슬라이드쉐어에 공유 좀 해주시면 안될까요?^^	1	strwbery@gmail.com 입니다. 감사히 활용하겠습니다 ^^	1	kwmouse7@gmail.com 입니다. 감사 합니다. 많은 도움이 될 겁니다.	1	자료 보내드렸습니다.	0	jky1234@gmail.com 입니다. 저도 좀 보내주세요. 감사합니다. ^^	0	egaoneko@naver.com 입니다. 감사합니다~ 잘 보겠습니다. :)	0	billwington@gmail.com 입니다.^^* 바쁘시더라도 저도 보내주시면 잘 보겠습니다.	0	보내드렸습니다.	0	33550336@naver.com입니다. 좋은자료 공유해주심에 감사드립니다!!	0	Kiwi7580@gmail.com 저도 부탁드릴께요~ ^^	0	javaoracle@gmail.com 부탁드립니다	2	메일 어드레스를 수집하실 요량이 아니시라면 슬라이드 쉐어를 이용하시는게 좋을듯 하네요. ^^	0	imyssu@naver.com으로 부탁드립니다정말 감사합니다~!!	0	hazelee@realignist.me 로 보내주시면 감사하겠습니다. 링크로 올려주셔도 감사히 받겠습니다.	0	저도 부탁드립니다. jamoplan@daum.net  입니다 감사합니다^^	0	저도 부탁드립니다 ! how3219@naver.com 입니다 ! 감사합니다	0	wwwee98@gmail.com 부탁드립니다. 정말 감사합니다! :)	0	kunimi00@gmail.com 입니다.저도 감사합니다.ㅎㅎ	0	저도 부탁드리겠습니다! martinpark725@gmail.com입니다	0	저도 부탁드립니다 ! jincchai.usa@gmail.com 입니다! 감사합니다!!	0	저도요! inureyes@gmail.com 입니다~	0	저도 부탁 드릴게요. +_+ kay@hannal.net 입니다.	0	저도 부탁드립니다.  감사합니다.valaentine@gmail.com     입니다.	0	저도 부탁드립니다!! opklnm102@gmail.com 입니다.공부하는데  좋은자료 공유해주셔서 감사합니다!!!	0	sayduke@naver. com 입니다. 감사합니다.	0	안녕하세요? 서진호라고 합니다. 저도 부탁드려도 될까요? 제 이메일 주소는감사합니다. synabreu@outlook.com 입니다.	3	다 보내드렸습니다.	0	멋지십니다. 저두요 donchang@hanmail.net  감사합니다.	1	imposscross@gmail.com로 부탁드립니다. 막막했었는데 도움이 많이될것 같습니다.	1	입문자입니다. 부탁드립니다. ymjung.joshua@gmail.com 감사합니다 !!	1	저도 부탁드립니다 Kwk236@gmail.com 굽신굽신	5	http://www.slideshare.net/ssuser06e0c5/explanation-on-tensorflow-example-deep-mnist-for-expert	5	슬라이드쉐어에도 올려놨습니다.	0	저도 부탁드립니다 hunylee0@gmail.com 입니다	0	안녕하세요 심상진이라고 합니다 저도 부탁드립니다. dyanos@gmail.com로 부탁드립니다!!	0	저도 부탁드립니다. 이재오입니다. aaljo2@naver.com	0	감사합니다. 슬라이드쉐어에서 다운 받았습니다.	0	저도 부탁드립니다. tegg89@gmail.com 입니다.	1	파일 보내드렸습니다.	1	이제 막 모든 세팅 끝마치고 하나하나 시작해보려고 좋은 예제들을 찾고있었는데 감사드립니다. 부탁드리겠습니다 realxiao@naver.com	1	sungjin7127@gmail.com 부탁드립니다 감사합니다	1	jhj7905@naver.com 부탁드립니다^^	4	제가 자료를 좀더 보완해서 슬라이드쉐어에 ppt로 올리겠습니다. 오늘 저녁에	6	Slideshare에 ppt  화일 https://www.slideshare.net/mobile/ssuser06e0c5/explanation-on-tensorflow-example-deep-mnist-for-expert.
69	일본에서는 텐스플로우로 무엇을 하고 있을까요? 나프다의 정개발(DoHyun Jung)님께서 알려주신 사이트:https://goo.gl/sgQcVS 일본 스텍오브플로우의 TF 관련 리스트  번역입니다."중학생도 알 TensorFlow 입문 그 3 deep 아니 learning - 퍼셉트론""딥 학습에서 "얼굴이 닮은 AV 여배우를 가르쳐주는 bot"를 구축""특히 프로그래머에서도 데이터 과학자도 없지만, Tensorflow을 1 개월 만진 때문에 매우 알기 쉽게 해설"재미있는 제목이 많습니다.	1	저도 일본 싸이트를 보고 공부했습니다.  입문자들이 쉽게 이해하도록 설명하는 자료들이 많아요.	7	이내용 입문자들에게 도움이 많이 될 자료인데, 그림은 번역이 안돼네요.  제가 담주에 해서 올릴께요.  https://translate.google.com/translate?sl=auto&tl=ko&js=y&prev=_t&hl=en&ie=UTF-8&u=http%3A%2F%2Fqiita.com%2Ftags%2FTensorFlow&edit-text=	1	흥미로운 주제들이 있군요	0	AV....ㅋㅋㅋㅋ	0	좋네요
89	*지원 마감* 되었습니다. 많은 분들이 지원해주셔서 감사합니다. 중간중간 좋은 결과가 나오면 업데이트 하겠습니다.---[딥코딩 프로젝트 팀원 2~3명 모집] 저희 연구실에서는 자연어 또는 스크린샷등의 프로그램 요구사항만으로  소스코드를 자동 생성시키는 DeepCoding 프로젝트를 진행하고 있습니다. 저희 학교 (홍콩과기대) 3명의 학부 학생 (졸업프로젝트), 중국 칭화대 1명 (1~2명 추가 참여예정)이 참여하고 있습니다. 프로젝트 진행은 대략 일주일에 한두번 관련 논문 발표와 토론 (Skype/Hangout), 그리고 구현등의 작업은 Github등에서 원격으로 진행됩니다.목표는 최근 DeepMind에서 발표한 코드생성 논문 (아래 카드와 생성된 코드 그림 참조, http://arxiv.org/pdf/1603.06744.pdf) 보다 더 좋은 결과를 만들어 내는 것입니다.한국에서 이 프로젝트에 참여하실분 2~3분 정도 모집합니다. 제한은 없지만 대략적인 조건은:1. 대학생/대학원생 (추후 방문연구등의 지원을 위해)2. Python/프로그래밍 자신있고, TensorFlow에 관심이 많으신분3. 6개월 이상 이 프로젝트에 집중하실수 있는분.프로젝트 진행과 본인의 기여도에 따라 작성될 논문의 공동저자와 방문연구/연구비 지원등의 혜택이 있을수 있습니다. 관심있으신 분들은 페메나 이메일 hunkim+deepcoding@gmail.com 으로 연락 주시면 됩니다. 참고로 저희 연구실은 프로그램 분석과, 자동 버그수정, 예측등의 연구를 진행하고 있습니다.  (http://www.cse.ust.hk/~hunkim 최근 논문 참조)	0	허헛 코딩을 자동으로 해주는 시대가 오다니...	0	기대가 됩니다!	0	으음 ㅎ 학생만 가능한가요?	1	이명정 대리참여좀 ㅜ 하고싶다	0	도전해보고 싶네요^^	1	학생들에게는 좋은 기회이겠네요... 메일드렸습니다!	0	정말 도전하고 싶은데 초보라.. ㅠ	0	대학원생이 아닌게 아쉽네요 ㅎㅎ 다른쪽으로 기여는 안되나요?ㅋ	0	초보라 힘들지만 능력만 된다면 참여하고 싶네요 ㅎㅎ	0	오오.. 참여하고 싶군요.	0	대학원생이였으면 해봤을듯 합니다.중간이나 종료 후에 공유해 주시면 좋을듯합니다ㅎㅎ	0	대학원생 조건만 아니어도 바로 지원 했겠네요	0	우와 벌써 마감되었네요..ㄷㄷ	0	
0	Hi Everyone,If you are interested in empowering your #BigData & #DataScience careers with international and industry-oriented higher education, come and check Data ScienceTech Institute #Bachelor, #MSc and #Executive #MSc programmes, campuses in #Nice Sophia-Antipolis and #Paris, as well as live online education (full HD) accessible from compatible timezones (Europe/Paris ± 3h) --> No need for visa in that case!Work placement opportunities for on-campus students!Come and see us here 
51	GPU가 달린 MAC을 사용하시는 분들에게 좋은 소식:"As an update: Tensorflow can now use GPUs on Mac OS X. The relevant PR is https://github.com/tensorflow/tensorflow/pull/664 and after a brew install coreutils the Linux installation 'build from source' instructions should work. I see a 10x speedup compared to the CPU version with an NVIDIA gforce 960 and Intel i7-6700K."지금은 master 코드를 compile 해야하지만 0.9버전에는 컴파일된 버전이 포함될것이라 합니다. (7일전에 master branch에 merge되었다고 합니다.)http://stackoverflow.com/questions/33656689/would-tensorflow-utilize-gpu-on-a-mac-if-installed-on-a-vm/36995253?noredirect=1#comment61549853_36995253	2	그러나 AMD 쥐퓨가 달린 맥이라는... ㅠㅠ	0	맥에 엔당께 달린것도 있나요?	0	Tensorflow에서 GPGPU는 전혀 불가능한 건지....ㅜ	0	좋은 소식 감사합니다 . 당장 컴파일해야겠네요	1	좋은 소식이군요. 드디어 제 15인치 맥프레에서 TF 공부를 할 수 있게 되었네요 ^^	2	tensorflow 설치 자체를 처음 해보는데요. GPU 버전으로 설치 성공했네요. 이것 저것 찾아 보면서 설치하느라 시간이 조금 걸렸네요. 이제 열심히 공부만 하면 되겠습니다. ㅋ
0	Hi Everyone,If you are interested in empowering your #BigData & #DataScience careers with international and industry-oriented higher education, come and check Data ScienceTech Institute #Bachelor, #MSc and #Executive #MSc programmes, campuses in #Nice Sophia-Antipolis and #Paris, as well as live online education (full HD) accessible from compatible timezones (Europe/Paris ± 3h) --> No need for visa in that case!Work placement opportunities for on-campus students!Come and see us here 
27	지난번 안혜민님이 올리신 tensorflow over 라즈베리 파이 입니다. 파이썬 에디터로 vscode를 쓰는데 괜찮습니다. linear_regression 하나 돌리는데 37초 걸립니다. 재미로 공부할 때 좋습니다. vs code over raspberry pi 는 http://www.hanselman.com/blog/BuildingVisualStudioCodeOnARaspberryPi3.aspx 를 참조하세요.	0	음 도전해보려 했는데 37초 걸린다는 말씀이 학습을 시키는데 37초가 걸린다는 말씀이시죠?	0	예제는 선형회귀 분석하는 소스 입니다. 해를 구하는데 37초 걸립니다. 피시에서는 1초 미만으로 걸렸던 것 같네요.	1	상당히 느리네요 ㅠ 라즈베리 파이 특성상 발열이 심하더라고요..	1	지난번 올려주신 화면으로 참조하여 저도 환경을 동일하게 잡아 보았어요.^^ 산딸기에 텐서가 돌아가는 것이 재미있네요.
87	저도 지난 3월에 TensorFlow를 시작하면서 입문한 Python, 가장 도움을 받은 Effective Python책인데 이책에서 제공된 Github 예제를 읽고 보기 쉽게 Notebook으로 바꾸어 보았습니다.https://github.com/hunkim/effective_python_notebook파일 이름도 주제에 맞게 바꾸고 일부 파일에 설명도 달았습니다. 두고 두고 볼만 합니다.
15	http://danijar.github.io/introduction-to-recurrent-networks-in-tensorflow	0	깔끔하게 잘 정리된 문서내요. 감사합니다.	0	pack/unpack 사용하는게 잘 이해가 안되네요. 다른곳에서는 split을 많이 사용하던데 pack/unpack이 더 좋은것인가요?	0	저렇게 될 경우 rnn의 파라미터를 업데이트 하는것인가요?아니면 따로 만들어준 weight/bias를 업데이트 하는것인가요?	0	rnn의 마지막 output에 대하여 activation 을 하는 것인가요?그렇다면 마지막 output이 아니라 output의 avg / mean 을 softmax 하게 될 경우 성능 혹은 정확도에 영향을 줄 수 있을가요?
77	이번 연휴에 CS231n 강의를 보려던 차에 YouTube에서 내려갔다고 해서 이번 연휴동안 토렌트에서 mp4 파일들만 받아서 시딩 + 웹 서버로 공유합니다. 당연히 저는 한게 아무것도 없구요... 제 노트북으로 쓰고 있는 녀석이라서 연휴가 끝나면 내려가지 않을까 싶습니다.	0	감사합니다.	0	감사합니다.	0	감사합니다 :)	0	감사합니다 :)	0	혹시 토렌트 마그넷 알 수 있을까요?	0	감사합니다 :0	0	감사해요~~	0	다운중입니다. 감사합니다.	0	감사합니다.	0	밤중에 윈도우 VM(이자 부트캠프)에 문제가 좀 생겨서 새벽동안 잠시 서버와 시딩을 끕니다. 김종이에게 부탁해서 시드는 일본 서버(http://cs231n.hibiya.moe)에서 계속 유지될 예정입니다.
24	TensorFlow Sequence-to-Sequence Models 튜토리얼 참고하여 영어-한글 표기 변환기 만들어봤습니다.https://transliterator.herokuapp.com/표기 변환기는 구글맵에서 외국 지역명을 표기할 때 주로 쓰이는 건데요. 저는 안드로이드에서 영어로 된 앱을 한글로 검색할 수 있도록 자동 인덱싱에 사용하려고 만들었습니다.아직 데이터량이 많지 않아서 그런지 오래 학습을 시켜도 테스트 오류값(perplexity)이 2 이하로 떨어지지 않네요. 혹시 데이터 수집 아이디어 있으시면 알려주시기 부탁드립니다. 또는 오류값 줄이는 pull request도 너무 환영합니다~!그리고 프로그램을 실행 했을 때 초기 모델 restore하는데 시간이 좀 걸리고, 메모리를 240메가나 점유하네요. 처음 생각으로는 안드로이드 앱에 포함 시키려 했지만 웹서버 API로 처리해야 할 것 같습니다.	1	멋지네요.	1	"학습에 필요한 양질의 대량 데이터가 필요합니다. 수집 아이디어나 데이터가 있다면 추가 부탁드립니다~!" 변환결과를 수정하기 기능이 있으면 어떨까요?	2	학습필요:  ㅋㅋ	1	멋지군요!	1	Sung Kim 제안해주신 수정하기 기능과 고유 링크 기능 추가했습니다~!
0	AWS 가입해서 EC2 인스턴스로 하나 돌려보고 있습니다.좋은 정보 주셔서 감사합니다.^^여기에 가입을 해서 사용하시는 분 계신가요?아직은 서툴어서 막 사용하기가 부담 스럽네요.ㅎㅎ특별히 사용하면서 요금이나 정책등의 주의사항이 있을까요?	1	사용하신다음 반드시 stop 또는 terminate하시면 됩니다. 그리고 로그인 하실때마다 bill 한번 확인하시면 좋습니다.	1	비용에 알림을 걸어두시는 것도 좋은 방법 같아요. 저는 $5랑 $10가 넘어가면 알람이 오도록 설정해두고 있어요. :)
5	CV 와 ML
61	그동안 우리에게 큰 즐거움을 주었던 스텐포드의 CS231의 강의가 법적인 문제로 youtube에서 내려갔습니다. 안타깝네요. 아래 등 6가지 법위반 소지가 있다고 통보를 받았다고 합니다."they sent list of 6. Closed captions, forms for students/invited speakers, potential copyright material, "quality/brand", ..." - karpathy당분간은 https://archive.org/download/cs231n-CNNs 에서 다운로드 가능합니다. 소장할 가치 충분히 있습니다.https://tensorflowkorea.wordpress.com/2016/05/04/stanford-cs231n-%EA%B0%95%EC%A2%8C%EA%B0%80-%EB%8B%AB%ED%98%94%EC%8A%B5%EB%8B%88%EB%8B%A4/	0	다른 강의들은 계속 올려져있는데,  이유가 궁금하네요.	1	자막도있었군요 이 게시물로 처음알았습니다.. ㅠㅠ근데 224d와 같은 다른강의도 비슷하게 내려갈 예정인지 궁금하네요	4	많은 분들이 아시겠지만 Slide는 여기에 있습니다. http://cs231n.stanford.edu/syllabus.html	8	archive.org로 직접 비디오를 받으시면 느리셔서 토렌트를 받으시거나 하시는 분들도 계실 것 같은데, mp4 파일만 받아서 시딩하고 있습니다. 연휴 내내 시딩할 예정이니 참고하세요. :)	0	아직 다 못봤는데... 어쩌면 좋죠...ㅜㅠ
3	안녕하세요 CNN의 MaxPooling에 관하여 질문 드립니다.MaxPooling이라는 것이 이미지 데이터가 인접해 있을 수록 비슷한 값을 가질거라는 생각 때문에그 영역에서 가장 큰 값을 추출한다. 라는 개념으로 이해 하고있습니다.이 MaxPooling을 이용하면 계속 이미지의 크기가 작아지는데 그렇다면 MaxPooling을 많이 사용하면 별로 좋지 않다고 생각되는데그러면서도 이것을 하는 이유는 컴퓨터의 연산 처리 속도를 향상 시키기 위함인가요? 아니면 어떠한 다른 이유가 있나요?	3	연산 속도 보다는, 피쳐를 위치에 덜 의존적으로 만들기 위한 것으로 보입니다.https://www.quora.com/What-is-pooling-in-a-deep-architecture/answer/Abhishek-Dubey-59?srid=dxlM&share=1	0	헐ㅋ ㅜㅠ 죄송합니다 이상한게 잔뜩 눌렸네요
2	Hey everyone, I am working a curated list of awesome TensorFlow experiments, libraries, and projects. Inspired by awesome-machine-learning. Check it out here at 
31	https://github.com/samjabrahams/tensorflow-on-raspberry-pi/안녕하세요 이런데다가 글쓰는건 처음인데 신기한게 있어서 공유하려고 글을 써봤습니다. 라즈베이파이에서 텐서플로우를 돌릴 수 있게 하는 패키지를 깃헙에서 발견했어요. 인트로의 "We did it! It took a lot of head-banging ~~" 부분에서 제작자의 기쁨을 느낄수가 있네요 ㅋㅋㅋ 집에 쟁여놓고 있는 라즈베리파이 있으신분들은 한번 시도해 보시는것도....	0	좋은 정보 알려 주셔서 감사합니다. 한번 해보시고 모임에서 발표 해주시는 것은 어떨까요?	1	퇴근 후에 시도해봐야겠네요!	0	파이로 하면 효율 상당히 떨어지지 않나요?	1	음... 학습을 일반 컴퓨터에서 진행한뒤 그것의 결과를 저장해놓고  라즈베이파이에 옮겨서 불러와 하는식의 방식이라면 괜찮으려나요? 꽤 흥미로운 주제내요 한번 해봐야겠습니다 감사합니다 ㅎㅎ	2	저도 이 패키지로 해봤는데요. 회귀분석에서는 PC와 '같은' 결과를 '오래' 걸려서 나오더라구요. 라즈베리파이에서 결과가 나오는게 신기했습니다.:) https://www.facebook.com/sunghyun.lim.16/posts/10207874991505891
11	이번에 0.8/master부터 Mac OS X에서 CUDA지원이 된다고 해서 설치 완료했습니다.그런데 이전에는 CPU를 400%정도 사용해서 연산을 했었는데,CUDA를 설치해 GPU를 사용하면서 CPU를 100%만 사용하네요.CPU도 400%를 사용하고 GPU도 사용하면 train을 더 빨리 할 수 있을 것 같은데 보통 이렇게는 안하는 것인가요?왜 CUDA를 설치하니 CPU사용률이 떨어지는건지 궁금합니다.	0	예제는 mnist와 cifar10 기본 제공되는 파일로 테스트했습니다.	0	실제 연산은 GPU가 하고  CPU는 메모리 옮기기나 reduction만 하니깐요	6	GPGPU와 CPU를 동시사용하면 일반메모리-그래픽메모리 데이터 이동시 병목이 생겨서 오히려 느려집니다. 한번 섞어서 프로그램 짜 본적이 있는데 cpu만 사용한것만 못하더군요. cuda 를 사용할때는 연산할 데이터를 전부 cuda 프로그램 내부에 로드시키고 그 안에서만 구동해야 합니다. 그래서 동시 구동은 하지않고 CPU는 관리만 해주는 것일 것이고요. CPU 모드일때 400% 였던건 아마 BLAS 라이브러리에서 intel ssl 같은 가속기능을 사용했지 않나 싶네요	0	축하 드립니다. 대략 x10, x20 정도 차이가 나나요?
47	Higher Order RNN. RNN의 연결을 마치 Resnet 의 forward 연결처럼 옆으로 이어주니 기존의 RNN이나 LSTM보다 성능이 매우 뛰어 나다고 합니다.재미있는 연결입니다. 이거 혹시 구현하여 TensorFlow에 PR로 보내면 받아 줄까요? 지금 RNN, LSTM, GRU만 있는듯 하던데...https://arxiv.org/abs/1605.00064	0	RNN보다 빠르다니! 오호!	1	엇 이거.. 예전에 어디선가 본기억이 나서 한 번 찾아봤습니다.http://www.dbpia.co.kr/Journal/ArticleDetail/NODE02444214	1	딥러닝 이전에 많이 쓰였던 hmm에서 이미 사용되던 방법이 아닌지요? 결과까지 볼 수 있으니 흥미롭긴 하네요	1	Gated-HORNN 같은 경우에 attention model을 hidden layer에 적용시킨 모델로도 볼 수 있지 않을까요? 흥미롭네요
6	텐서플로 gpu모드로 돌리는데, gpu util이 생각보다 낮고(30%) cpu부하가 있는 데요,텐서플로에서 csv로 부터 읽어서 랜덤큐잉을 하고 label과 features를 구별해서 학습단계에서 넣고 있습니다.queue = tf.RandomShuffleQueue(    capacity=capacity,    min_after_dequeue=min_after_dequeue,    dtypes=[tf.float32],    shapes=[[n_input+1]])inputs = queue.dequeue_many(batch_size)-- 세션부 --inputs_value = sess.run(inputs)#y값 구현부는 생략!batch_xs = map(lambda x:x[1:] , inputs_value)sess.run(optimizer, feed_dict={x: batch_xs, y:batch_ys , dropout_keep_prob: 0.5})아무래도 큐잉이후 텐서에서 꺼내서 레이블과 피처를 분리하는 부분때문이 아닌가 생각이 되는데 이부분이 맞을지..참고로 배치 사이즈는 크게 작게 다 해봐도 gpu util이 안올라가고 있습니다~잘아시는분 있으실까요?
10	정리된 많은 정보가 있습니다.https://github.com/jtoy/awesome-tensorflow?utm_content=buffer77a84&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer
12	Dynamic capacity networks (http://arxiv.org/abs/1511.07838) 를 tensorflow로 구현해봤습니다 (https://github.com/beopst/dcn.tf). 이 알고리즘의 주요 아이디어는, coarse한 network의 output을 기반으로 주요 input patch들을 추출하여 이 patch들에만 fine network를 적용하는 것입니다.그런데 논문의 결과가 그대로 재현되지는 않네요. Cluttered MNIST에서 Fine Model의 error rate가 논문에 나온 것보다 훨씬 작게 나옵니다 -_-; 관심 있으신 분들은 한번 보시고 혹시 제가 잘못 구현했거나 놓친 부분이 있으면 git에 report 해주시면 감사하겠습니다!
25	TensorFlow tutorial에 있는 word2vec의 해설서 같은 느낌으로 만들어봤습니다. 	0	정말 멋지네요.
40	함께 로봇잘키워 2017/2018년 신춘 문예 도전해볼까요?http://bot.wpoem.com"겨울소리 보고 걸어여라""그만의 빛에 없다오늘 같은 그저 내밀지 않는다"정말 간단한 TF char-rnn 으로 만들어 본것인데 100번에 한번 재미있는것이 나옵니다. 우선 학습할 시 데이타가 많지 않아, 엉성하지만  공개하고 데이타를 좀 모아 볼 생각입니다.관심있으신 분들 같이 word-rnn, attention같은거 붙여서 2017년 신춘 문예 한번 도전해 볼까요? 로봇이 만들어 낸것에 우리가 손좀 보면 제출할수 있을듯 합니다. :-) PR/issue (아이디어) 다 환영합니다.	0	오 ㅎㅎ 저도 어제 (https://github.com/sherjilozair/char-rnn-tensorflow)를 돌려보고 다른걸 좀 해보려고 했었습니다. 그런데 한글 txt가 잘 안읽히더라구요.. 혹시 한글 txt를 읽을 때 주의할 점이 있나요?	0	세편의 자작시를 넣어 보았습니다. 다시 나의 느낌으로 되돌려 준다면 무섭겠죠?ㅎㅎ	1	정말 신기하고 재미있습니다. 가슴이 막 뛰네요^^	1	저는 멜로디를 학습해보는게 어떨까 조심스럽게 추천드리네요. 물론 로봇시 이 다음 단계루요. 시의 경우 학습데이타를 넣는 폼을 하나 만들어 일반에 공개하면 좋을 듯 합니다.	1	오늘 또 봤는데 문장 수준이 좋아진게 보이더라구요 ㅎㅎ	0		0	안녕하세요? 저는 학부에서 음악을 전공하고 지금은 대학원에서 콘텐츠전공하고 있는데요, 얼마전에 머신러닝을 접하게됐고 너무 궁금해서 여기저기서 자료들 구해서 보고 있습니다. 프로그래밍을 몰라서 자료를 보더라도 막연한 기분이긴 합니다. 음악이든 텍스트이든 훈련이라는걸 한번 시켜보고 싶은데 어떻게 하면 좋을까요? 혹시 도움을 받을 방법이 없을까요? 부탁드립니다.	1	좀 좋은데요.^^
31	문장 러닝을 위한 Convolutional Neural Network 논문입니다. 좋은 점은 저자의 Theano 코드는 물론, 블로거의 설명과 TensorFlow 코드도 있네요. 딥러닝을 word2vec에 적용하고 싶으신 분들에겐 좋은 공부자료가 될 것 같습니다.	0	나한테 도움 되는거네요. 근데 내가 공부안하는게 함정
110	스텍오버플로우에서 한달간 놀다 보니 이렇게 되었습니다. 앞의 두분은 구글 TensorFlow개발자라 따라잡기 힘들듯 합니다.여러분들도 스텍오버플로우에서 많이 뵈어요.http://stackoverflow.com/questions/tagged/tensorflow비결: 1. 질문이 올라오는지 스텍오버플로우 하루에 한번씩 방문         2. 모르는 질문 (저도 초보라 대부분 모르는 질문)이 올라오면 구글하면서, 코드 돌려보면서 답을 찾는다.         3. 답을 올리고 응답을 살핀다. (틀린 답일수도 있으니)이거 하면서 제가 더 많이 배우게 되었습니다. :-)	0	대단하십니다	0	대박
42	https://tensorflowkorea.wordpress.com/2015/12/04/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC-1/	0	처음 접하시는 분들에게 매우 도움이 될듯합니다.
42	예전에 연구실 세미나용으로 CNN에 대해 간략하게 설명한 PPT를 공유하고자 올립니다. (사실 대부분의 내용이 CS231n과 겹치는.... ㅠㅠ)공부하면서 느끼는게 참 그 강의 좋은 거 같아요	1	남혁이도 여기있었구나 반가움ㅋ
93	AWS $100 Credit 받아 가세요. 제가 진행중이였던 모두를 위한 딥러닝 시즌 1종강하였습니다. 종강 기념으로 마지막 실습 비디오에 AWS credit을 받으실수 있는 팁이 담겨 있습니다. 	1	감사합니다. 강의 듣고 신청했어요.^^	0	감사합니다~!
16	19살의 학생이 만들었다고 하는 최초의 법률봇이라고 합니다.http://www.donotpay.co.uk/인공지능이라기보다 간략한 룰에 의해 법률적으로 연착된 비행에 대한 보상을 요구하는 이메일, 주차 범칙금에 대한 어필을 하는 이메일 등을 생성해줍니다. 많은 사람들이 사용해서 상당한 범칙금을 줄여주었다는데...우리나라에서는 어떤 경우에 사용할수 있을까요? 관공서나 경찰서, 검찰등에 보내는 이메일등을 자동으로 생성해주면 좋을것 같습니다. 혹시 이쪽으로 경험있으신 분들이 계신지요?
52	주피터 노트북 사용하다 정리해봤어요	1	마침 필요했던 내용이었습니다. 잘 보겠습니다.	1	저도 회사 컴에 막 Jupyter notebook을 깔고 tutorial 찾는 중이었는데 고맙습니다!
46	TF-KR 첫 모임: Docker 환경에서 TensorFlow를 설치하고 응용하기	1	매우 흥미있는 자료네요. 감사합니다.	1	안드로이드 스튜디오에서 텐서프로우 활용 어플 실행도 강의하면 좋을 듯하네요	0	강의를 잘 듣고 간단히 환경을 구축하다 진행상에 막히는 부분이 있어서... 질문을 드려봅니다. 아래 사진과 같이 docker-compose.yaml을 일부 수정하여 빌드를 하고 실행을 하는데 run_jupyter.sh의 퍼미션 오류가 발생하여 컨터이너 실행이 불가하여 문의를 드려봅니다. 혹시 경험을 하신분이 계신지요? ㅎㅎ
71	여기 계신 분들이라면 분명 관심있는 내용이겠지요! :-)	0	아주 흥미진진한 자료인 듯 하네요.	0	와우! 좋은 자료 감사합니다.	0	좋은자료 감사합니다-!!	1	https://tensorflowkorea.wordpress.com/2016/06/30/wide-deep-learning-with-tensorflow/	1	중복되는 것 같아 댓글로 달았습니다. ; )
88	텐서플로우 입문 서적	0	감사합니다!	0	으아 이게 여기로 갔네요 ㅋㅋㅋㅋ	0	ㅋㅋㅋ 저희 학교에서 텐서플로우 스터디를 하고 있어서 스터디 그룹에 공유하려던게 여기로 갔네요ㅋㅋㅋㅋㅋ 텐서플로우 코리아 자료 정말로 잘 활용하겠습니다.	0	Dong-hee Na님, 실수로 여기에 공유한 자료, 감사합니다 :)	0	우와 감사합니다	0	감사합니다.	0	혹시 텐서플로우 공부전에 어떤 걸 공부해놓으면 될까요??	0	저는 지도학습이나 비지도 학습같은 일반적인 알고리즘을 먼저 공부했어요 인공신경망 자체에 대해 깊숙히 공부하기 시작한건 최근이라 뭐라 말씀드리기가 어렵네요. ㅋㅋ
8	매스웍스, ‘국방/우주항공 산업을 위한 매트랩 & 시뮬링크 기술 세미나‘ 개최- MATLAB에서의 머신러닝(기계학습)과 딥러닝 등	0	나중에 영상구할수 있는지 혹시 아시나요?	1	네...세미나 자료는 받으실 수 있으실 것 같습니다.영상은 통상 행사가 끝나면 홈페이지에 업로드 하는걸로 알고있습니다. 자세한건 매스웍스로 문의하시면 좀더 자세히 아실 수 있으실 것 같습니다.	0	감사합니다
16	http://api.ai 사용해보신분들 계신가요? http://wit.ai 등 다른 plarform과 비교해서 어떤가요?	1	Wit.ai, Api.ai로 ChatBot을 개발하거나 ChatBot Builder를 개발한 경우 팀/스타트업에게 확인한 내용은 영어일 경우에는 비슷한 것 같고 한국어인 경우에는 그나마 API.ai가 좀 낫다는 평가입니다.
11	딥러닝을 공부하고 있습니다만 예제들이 MNIST처럼 supervised learning들은 나와있는데, unsupervised learning은 TF로 어떻게 해야 하나요?	0	저도 궁금하네요 :)	3	https://tensorflowkorea.wordpress.com/3-텐서플로우-클러스터링-first-contact-with-tensorflow/여기에 보면 kmeans 를 텐서플로로 한 게 있습니다	1	autoencoder나 word2vec같은 것도 unsupervised입니다 어짜피 unsupervised가 클러스터링이니 입력 데이터를 출력데이터로 사용하면 unsupervised 죠이에 대한 예제는 해당 키워드로 검색하면 바로나옵니다
6	딥마인드같은 회사는 어쩌다 유명하게 된건가요좋은 제품이나 논뮨을 내서 구글에 팔리게 된건가요	1	만드시면 구글이 인수해요	1	유투브에 breakout게임을 강화학습 한걸 올려서 유명해진걸로 알고있습니다	3	Yoshua Bengio, an AI researcher at the University of Montreal, estimates that there are only about 50 experts worldwide in deep learning, many of whom are still graduate students. He estimated that DeepMind employed about a dozen of them on its staff of about 50. “I think this is the main reason that Google bought DeepMind. It has one of the largest concentrations of deep learning experts,” Bengio says.
7	tensorflow엔 따로 변수 추출, 차원 축소하는 툴은 별도로 없는건가요? API를 뒤져봐도 잘 보이진 않아서 sklearn으로 random forest랑 PCA를 학습해보고 있는데 혹시 텐서플로우에도 있는데 제가 다른 이중 공부를 하나 싶어서요 ^^;	1	Rotation forest 로 한번 찾아보셔도 될것 같아요ㅎ	1	이건 잘 모르고 그냥 던지는 말인데요, 첫번째 레이어가 변수 추출 역활을 하는것이 아닌가요.. 그리고 차원 축소는 히든 레이어의 개수데로 축소된다고 볼수도 있을거 같은데요. Pca 처럼 원래의 dimension 은 않 가지고 있어도, transformation 통해 dimension 는 다 부셔졋지만. 오히려 더 optimized 된 dimension 으로요.	1	autoencoder가 차원축소 방법으로서 pca와 비슷한 역할을 한다고 할 수 있습니다. 좀 오래됬지만 잘 알려진 방법으로는 denoising autoencoder를 여러개 쌓아 greedy-layerwise 방식으로 weight를 학습하고 마지막에 output layer를 쌓아 모든 weight를 fine-tuning 하는 stacked denoising autoencoder가 있습니다. 그런데 위에분 말씀대로 굳이 이러한 방식을 쓰지않고 feedfoward neural net을 써도 어느 변수가 선택되었는지 명백하게 알수는 없지만 차원축소가 내부적으로 이루어진다고 할 수 있을듯합니다
25	Many to many RNN에 관한 질문과 답입니다. 아직 답이 하나밖에 없는데 좋은 답이 달리길 기대합니다. 여러모로 활용도가 많은 모델 입니다. 
1	머신러닝 강의를 처음 들어보는 사람인데요.text파일 정의한 공식을 사용하는걸 해보고 있는데 계속 에러가 나서요. 혹시 어떻게 하면 되는지 도와주실 수 있나요??octave를 사용한것입니다.	0	파일명을 소문자로 바꿔 보시겠어요??
13	#accuracy vs. #precision둘간의 개념 차이를군대에서의 영점사격 경험으로 정리해봅니다.*영점사격: https://namu.wiki/w/사격%20훈련#s-2.2과녁에 총을 5방 쐈을때,과녁 중심에 가깝게 맞출수록 accuracy가 높다.#반복해서 동일한 곳을 맞출수록 precision이 높다.accuracy: A > B, A < C, B < Cprecision: A < B, A < C, B == C[A]----------x--x-------x+x-------x-------------[B]----------x-----------+----------------------[C]----------------------x----------------------	1	accuracy = validity / precision = reliability 와 같은 개념이군요 ㅎ
1	UBIC, 7월부터 ‘FRONTEO’로 사명 변경…AI 전문 기업’으로 도약 선포- 이디스커버리를 넘어 헬스케어, 마케팅, 로봇 서비스 등 다양한 영역에서 인공지능 기반 서비스
51	[TF-KR 첫 모임 발표영상] 오늘의 비디오는 Kazunori Sato 님께서 설명해주시는 Machine Intelligence made easy: Vision/Speech API, TensorFlow and Cloud ML 입니다. 구글에서 하는 재미있는 것들을 볼수 있습니다. 참고로 Sato님은 일본에서는 연예인급의 개발자라고 합니다.https://www.youtube.com/watch?v=foJwi2t3EU8&feature=youtu.be발표자료: http://sssslide.com/speakerdeck.com/kazunori279/machine-intelligence-made-easy	1	김교수님과 동급이네요.   제옆 레이디까지 교수님을 알던데요.	1	일본에서는 개발자가 연예인급 인지도를 갖기도 하나봐요!	3	사토 카즈노리씨는 개인적으로 글을 통해 많은 가르침을 받고 있어 존경하는 개발자 이십니다. 연예인이라는 비유가 적합한지 모르겠네요. 구글의 DA로서 지방이나 해외 어디든 자신을 부르는곳이 있으면 달려가서 묵묵히 GCP에 대한 복음을 전파하시는 분 이십니다.
4	Vmware로 우분투 깔고 안드로이드스튜디오 깔고거기서 스마트폰에어플 런 못시키나요안드로이드스튜디오에서 런버튼이 활성화가 안되서 요	0	vmware ubuntu는 gpu가 enable안되는 것 같습니다.
8	[대구 지역 스터디 모임]  Tensorflow를 이용해서 머신러닝, 딥러닝 같이 공부하실 분을 찾습니다~   같이 공부해보실분 뿐만 아니라 넓은 아량으로 도움 주실 고수분도 환영합니다 ^^장소: 경북대학교 정문  기간: 9월(or 8월)  장소는 스터디 하기 좋은곳으로 지원을 해주셨습니다(아직 공사중) . 딥러닝에 관해서 전혀 모르시는 경우라면, 기간도 조금 있으니 아마 남은기간동안 조금 공부하셔서 같이하시면 더욱 좋을 것 같습니다. 댓글이나 페이스북 메세지로 연락을 주시면 감사하겠습니다 !! ^^;;(전에 말씀해주신분들은 다시 연락안주셔도 됩니다)	1	우와! 많은분들이 참여하시면 좋을것 같습니다.
23	[TensorFlow 딥 한라산 모임] 이번주 토요일 시간되시는 분들은 모두 모두 환영합니다. 천천이 가면서 딥러닝과 아이티 이야기 나누어요. 지금 까지 3분이 신청하셨습니다.
7	KAIST, 다보스포럼서 ‘딥러닝에서 자율기계까지’ 주제로 휴머노이드 로봇 ‘파이봇' 공개- ‘제4차 산업혁명’은 디지털·물리학·생물학 등 학문 간 경계가 무너지고 생활방식·일하는 방식·놀이문화에 근본적 변화가 예상된다.
48	최고의 인기를 모으고 있는 TF를 6분만에 간략하게 설명합니다. 김홍배님이 곧 한글버전도 만들어 주실듯 합니다.들으면서 기억나는 것들:"6개월 밖에 안되었는데 깃헙에서 가장 인기""모든 형태의 computation 모델링 가능""Can be the Premier library. :-)"	5	이번 주말에 제멋진 나래이션으로 올리겠삼.  ㅋㅋ	3	기대할게요~~
13	RNN을 이용한 classification 관련해서 궁금한게 있습니다.Sung Kim 교수님 RNN 강의를 들어봤는데 그 중 Many-to-one 방식을 사용하면 time sequence data를 classification 하는데 사용할 수 있을 것 같았습니다.그런데 만약에 각 data들의 length가 모두 다르면 보통 어떻게 처리하는지요? 강의에 보여주신 예제는 (아마도?) time step이 고정된 것 같은데일반적으로 TF에서 RNN을 이용해 길이가 다른 (Variable length) data를 처리하는 방법이 있는지요? 예시코드 같은게 있으면 알려주시면 감사하겠습니다.	1	저도 평소에 궁금했어요 ㅠㅠ	1	보통은 대략 최대 사이즈를 정한다음 이보다 적은 경우는 padding (공백을 뜻하는 특수 값을 입력)을 하여 같은 길이를 유지 하는 것으로 알고 있습니다.	7	안녕하세요. 데이터의 길이가 가변적인 문제는 오래전부터 RNN을 적용해서 푸는 것이 적합하다고 알려진 문제입니다. 오히려 RNN의 가장 강력한 2가지 장점(long-term dependency 학습/variable length 처리)에 해당한다고도 볼 수 있습니다.가변길이의 데이터는 Masking이라는 것을 구현해서 효과적으로 처리할 수 있습니다. 최대길이의 Length 를 정하고, 그것보다 길이가 짧은 데이터는 먼저 missing value들을 0으로 padding 시킵니다. 그다음 zero padding된 index들을 masking으로 기억해두었다가 Feedforward 및 BPTT를 할 때, masking시키지 않은 value가 있는 부분만 연산을 하게 됩니다.zero padding만으로 구현할 경우, 0으로 padding된 값조차 데이터로 인식해서, 무조건 최대 길이까지 살펴본 다음 classification을 하기때문에 성능이 낮아지게 됩니다. 또한 계산상의 손해도 발생하구요. 그래서 masking이라는 것이 필요하고, 이는 간단히 말해 masking된 부분을 RNN이 무시(skip)한다라고 이해하시면 될 것 같습니다.TF에서는 아직 제가 이 예제를 본적이 없어서, Keras에서 masking하는 코드를 살펴보시면 좋을 것 같습니다.http://keras.io/layers/core/#masking	3	텐서플로우의 튜토리얼 중 Bucketing and padding 부분을 참고하시면 될 것 같아요. 여러개의 bucket을 사용하고 남는 부분은 padding을 주는 방식인데, 위에 곽동현님이 알려주신 Masking을 사용하진 않는거 같네요.https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html#bucketing-and-padding	0	다양한 답변들 감사합니다!! 제가 이해하기에 혹시 위에 말씀주신 padding과 making은 거의 같은 개념이라고 볼 수 있을 것 같은데 맞는지요? 그런데 padding 같은 방법은 데이터들 사이의 길이가 차이가 많은 경우 좀 효율(혹은 성능)이 떨어지지 않을까요? 예를들어 time step의 최소는 10이고 최대는 100이라면?	0	전무익 Bucketing이란 방법이 이를 조금 완화(해결?)해주는 방법이라 보면 될까요? 그런데 이런 방법을 쓰지 않고 각 data 시퀀스를 naive하게 자기 길이만큼만 계산하고 (classification) output을 내는 방법은 속도문제때문에 잘 쓰이지 않는 것인지요? 아니면 그렇게 할 경우 성능이 떨어지게 되는 것인지요??	1	저는 masking만 사용했었는데, 제가 알기로 이 bucketing과 masking을 같이 쓰는 방법이 선호되었던 것으로 기억합니다. bucketing을 안하면 메모리 혹은 속도에서 비효율이 발생했던 것 같아요.김진화 님이 torch에서 관련된 기능을 구현하셨었는데, 살짝 조언을 구해봅니다 ㅎㅎhttps://github.com/Element-Research/rnn#rnn.MaskZero 에 보시면 MaskZero / TrimZero 등등의 여러가지 방법을 볼 수 있습니다. TF에도 구현된 게 있는지 찾아봐야겠네요.TrimZero 논문 : https://bi.snu.ac.kr/Publications/Conferences/Domestic/KIIS2016S_JHKim.pdf	1	곽동현 인용 감사합니다. bucketing은 Xu et al. 2015 (ICML)의 homogeneous sampling과 유사한 방법 같네요. cuDNN 5에서 RNN 구현된 것이 있는데 여기서는 어떨지 모르겠네요.	3	찾아보니 TF에서도 최근버전은 dynamic_RNN을 통해 variable sequence length를 지원하는 것 같네요. 아직 공식페이지에는 업데이트 안된걸로 보아선 아직 시험중일수도... 정보가 별로 없는데 아래 링크의 예제코드가 좀 도움이 됬네요. https://danijar.com/variable-sequence-lengths-in-tensorflow/
25	오늘 제주 Deep NLP 첫 모임과 일정입니다. 생각보다 많은 분들이 오셔서 즐거운 시간되었습니다.혹시 7월 제주 오시는 TF-KR 멤버들 있으시면 게스트로 모십니다.	0	즐거워보입니다~ ^^	1	벌써 오셨네요ㅡ	1	저도배우고싶습니다.	0	저도 가고싶네요~~7월에 시간을 한번 맞춰봐야겠습니다그런데 공부하는 target 강의나 교재가 있는건가요?
36	곧 제주 TF 스터디 첫 모임이 시작됩니다. 근처에 계시는 분들 모두 환영하며 곧 뵙겠습니다.	1	부럽네요^^	1	아름다운 제주와 제주대학교에서 하다니 가고싶어지네요.
68	안녕하세요? 얼마 전 부터 조금씩 머신러닝을 공부하고 있습니다. oreilly에 최근에 올라온 Hello Tensorflow 라는 글을 참고해서 DeepLearning Ninja001라는 제목으로 딥러닝과 Tensorflow를 조금 파보는 글을 최대한 쉽게 적어 보려고 노력했습니다. 틀린 부분이 많을 수 있으니 가르침 주시면 정말 감사하겠습니다 ^^; 그리고 올해 9월부터 대구에서 머신러닝, 딥러닝과 관련해서 스터디 모임을 만들어보고자 합니다. 장소는 후원을 받기로 확정이 되었습니다.(위치는 경북대학교 정문) 같이 으쌰으쌰해서 열심히 공부해보실분 뿐만 아니라 이미 어느정도 실력으로 쌓고 넓은 아량으로 도움 주실분도 환영입니다. 댓글이나 페이스북 메세지로 연락을 주시면 감사하겠습니다 !! ^^;;	2	왠일인지 눈만 말똥말똥 잠이오지 않아 수면용으로 읽어보았는데 재미있게 보는 바람에 더 말똥해지는 밤이 되었네요 ㅋ	1	내용이 너무 좋습니다.	1	좋은자료 감사합니다	1	멋진 자료 감사합니다. 대구 스터디 모임 응원합니다.	1	좋은 자료 공유 감사해요.	1	좋은자료 감사합니다. 대구 스터디에 관심이 생기는군요.^^	1	대구에 있습니다. 스터디 참여하고 싶습니다~	1	좋은자료 감사해요~	1	대구 스터디 모임에 흥미가 있네요참가 할 수 있을지는 모르겠지만...
16	DL 관련 프레임워크를 랩핑하여 편의성을 제공하는 패키지 들이 몇개 나오고 있네요. 대표적으로 Keras가 될것 같은데요... 다른 것으로 간단하게 Tensorflow를 랩핑한 Tensorpack에 대한 자료가 있어 공유합니다.http://tensorpack.readthedocs.io/en/latest/실제 사용은 해보지 않아 얼마 만큼 편의성과 활용성이 있을지  확인을 해야겠네요.** Keras -  http://keras.io/
6	텐서플로우 이용한 안드로이드 앱개발 관심잇는분 계신가요	1	서비스가 뭔가요
15	seq2seq using tensorflow?잘 알아두면 매우 유용한 seq2seq에 대한 질문인데 혹시 답해주실 분들은 답해 주셔도 좋을것 같습니다.
2	우분투에서 bazel로 텐서플로우 빌드한것을 윈도우에 안드로이드 스튜디오 에서 사용가능한가요
23	안녕하세요혹시 구글 클라우드 환경에서 텐서플로우를 사용하시는 분이 계시면 조언 부탁드립니다.https://haroldsoh.com/2016/04/28/set-up-anaconda-ipython-tensorflow-julia-on-a-google-compute-engine-vm/를 그대로 따라하고 있습니다.(구글 클라우드 VM computer engine에서 screen으로 항상 실행되고 있는 jupyter notebook을 제 컴퓨터에서 접속하는 방법입니다.)google cloud SDK shell에서 아래 명령을 실행시킬 때gcloud compute ssh  --zone=<host-zone> \  --ssh-flag="-D 1080" --ssh-flag="-N" --ssh-flag="-n" <host-name>"unknown option: -D"와 같이 flag를 인식하지 못하자 혹시 '-'를 빼 주어야 하는가 하고 아래와 같이 '-'를 빼 주었더니 gcloud compute ssh  --zone=<host-zone> \  --ssh-flag="D 1080" --ssh-flag="N" --ssh-flag="n" <host-name>아래와 같은 오류가 나며 연결이 되지 않습니다.Unable to open connection:Host does not exist-------------------------------------------flag 를 모두 빼고gcloud compute ssh <host-name>만 실행하면 해당 인스턴스의 ssh 화면까지는 접속이 되는데, 그래도 인스턴스의 'localhost:8888' 에 접속할 수 없어 jupyter notebook을 실행할 수는 있어도 접속할 수는 없습니다.-------------------------------------------****** 이 부분이 가장 중요한 문제인 것 같습니다. ******포스팅에 나와 있는 --ssh-flag="-D", "-N", "-n" 들의 옵션을 붙이면"unknown option"이라고 하고 실행되지 않습니다.포스팅은 아래 페이지를 거의 따라했다고 합니다.https://cloud.google.com/dataproc/tutorials/jupyter-notebook#configure_your_browser이 페이지는 compute engine이 아닌 dataproc cluster에서 jupyter notebook을 실행하는 구글의 공식 튜토리얼 페이지입니다. 해당 페이지에는 --ssh-flag="-D", "-N", "-n" 의 flag가 그대로 나와 있습니다.몇 시간 째 검색해봤는데 원인을 잘 모르겠네요ㅠㅠ어떤 것들이 원인이 될 수 있을까요?
6	안녕하세요. 매번 눈으로만 보다가 살포시 질문글 하나 남겨봅니다. 혹시 윈도우즈 상에서 docker를 통해 GPU를 활용한 Tensorflow 구동에 성공하신 분 계신가요? 멀티부트 하면 복잡해 질 것 같아서 돌아가는 중인데 어째 더 큰 벽을 만나는 듯한 느낌입니다. windows 10 환경에서 어찌어찌 jupyter를 띄워서 import tensorflow와 hello world같은 기본 예제는 성공했습니다만, cpu에서만 코드가 돌아가고 가상머신이 gpu device 자체를 인식하지 못하는 것 같습니다.  윈도우즈 하에서 tensorflow를 사용하려면, 우분투를 멀티부트로 설치해서 돌리는 방법이 아무래도 제일 나은걸까요? 혹시 이것과 관련한 경험있으시다면 조언 부탁드립니다!	0	저는 현재 가상머신으로 잘 돌아가는데 가상머신은 어떠신가요?	1	저는 우분투 멀티부트를 추천드립니다. 지피유 관리도 그게 제일 낫습니다. 우분투 설치가 훨씬 쉽습니다	6	nvidia가 grid나 k시리즈 gpu들, 일부 쿼드로 시리즈 제품 말고는 드라이버 상에서 가상환경에서 구동되는것을 차단해서 어떻게든 불가능하다고 합니다..	1	HDD Sata Selector & SSD 구매 추가로 해서 별도 OS설치가 정신건강에 좋습니다 ^^	1	저도 시도해 봤습니다만....... 실패했습니다. ;;
7	텐서플로우 앱 실행해본시분 계신가요?없으면 저랑 같이 어떻게 실행할지 스터디 하실분계신가요실제로 돌려보고 응용하는 것도 중요한것같은데요원리 연구도 좋지만요텐서플로우 아래 예제 설치해보신분 계신가요안드로이드 스튜디오를 우분투에 설치해야하나요우분투 설치할고 바젤 설치하고 그다음에 우분투에 안드로이드 스튜디오 설치해야할까요
80	https://www.tensorflow.org/mobile.htmlTensorFlow에서 이미 공식적으로 모바일을 지원하네요? 저는 몰랐는데 혹시 이미 사용해보신분 계신가요?	1	텐서 플로우를 이용해서 안드로이드 앱이나 iOS 앱으로 만들수 있습니다.	2	학습은 따로 하고, 학습한 정보로 결과를 만들어 낸다는 말은듯 싶네요.	1	오 좋은 정보 감사합니다 몰랐네요
9	프로그래밍하려면 설치 환경 만들고버그잡는게 알고리즘짜는것 보다 더 힘들게 느껴질  때가 잇는데요쉽게 하는 방법이 잇을까요?인터넷에 올린 자료도 틀리는 경우도 많고	1	저도 궁금하네요ㅎㅎ 익숙하지 않은 프레임워크 다룰땐 설치가 반인경우도 있더라고요ㅜㅜ	0	그렇게 코딩이 된다는...ㅌㄷㅌㄷ	0	같은 작업을 많은 개발자들이  반복적으로 하고  있는것 같습니다설치 자동화 인공지능 아이디어에 한표~~	1	사실 vagrant같은거 만들어서 하면 쉬운데... ㅎㅎ	3	Cuda 설치가 안 되서 이틀째 헤매고 있습니다. 정말 환경 설치가 정신건강에 안 좋은 영향을 미치는 것같아요.	1	docker..	0	이미지가 잘되어있는것 같이쓰면 편한데요 그 이미지 조차도 실행 안되는 경우도 종종 있습니다. 도커가 쉽다지만 도커도 오류가 없는게 아닙니다. 예전에 이 그룹에 질문 올려보고 스택오버플로우에도 찾아봤는데 아무도 답하지 못하더라고요, 결국 운영체제 밀고 버츄얼박스로 깔았다는....	0	소프트웨어 공학을 약식으로라도 따라 가는 훈련을 하는게 도움이 됩니다.	0	요즘엔 도커 이미지를 대부분 지원하기 때문에 쉽게 맛보기가 가능합니다	0	도커 이미지 배포가 답입니다
133	여러분들의 왕성한 활동으로 3,000+멤버 그룹이 되었습니다. 감사드립니다. 운영진으로 활동하고 수고하고 계신 Soonson Kwon, 김택수, DongHyun Kwak, Taehoon Kim 님에게 감사드리고 추가로 Lucy Park 님이 운영진으로 합류하여 더 재미있고 활발한 그룹이 될것으로 기대 합니다.	2	우와~ 축하드립니다! ^_^	2	우와아. 축하드립니다^^!	1	축하드립니다.	1	축하드립니당 ^^	1	축하합니다^^
53	이게 필요한 사람이 얼마나 되련지 모르겠지만..Sung Kim 교수님의 강의를 들으면서 작성한 실습 코드 입니다. CNN, RNN 부분은 누락되었으며 나중에 올리도록 하겠습니다.자기가 직접 짜보는게 중요하고 그것을 변형해보면서 자신에게 맞게 바꿔나가는것이 가장 좋습니다. 그냥 참고용으로 봐주세요. 	3	감사합니다. 제 수업페이지에서 링크할께요.	7	http://hunkim.github.io/ml/ 에서 링크를 걸어 두었습니다.	3	감사해요
3	bazel 이 뭔가요 인터넷 검색해도 이해안가서요As a prerequisite, Bazel, the Android NDK, and the Android SDK must all be installed on your system.Get the recommended Bazel version listed at: https://www.tensorflow.org/versions/master/get_started/os_setup.html#sourceThe Android NDK may be obtained from: http://developer.android.com/tools/sdk/ndk/index.htmlThe Android SDK and build tools may be obtained from: https://developer.android.com/tools/revisions/build-tools.htmlhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android	1	구글에서 만든 build 툴이라 보시면 됩니다.	0	구글이 아마 자기들이 만드는 프로젝트들은 대부분 bazel로 밀어주려는 것 같습니다.
3	feature라는 말이 자주 나오던데어떤 의미인가요	3	저도 전문가는 아니지만 제가 아는거로 설명 드리자면 .. 데이터를 트레이닝 시킬때 그 데이터들의 특징을 추출하는데요. 그때 그 특징을 말하는것 같아요~ 예를 들면 강아지 이미지트레이닝에서는 강아지 사진에서 강아지의 코, 눈 , 귀의 모양같은 그런 특징을 추출해서 트레이닝 시키는 거죠!	0	통계쪽으로 공부하셨다면, 독립변수나 설명변수가 되겠고...input 값이라거나 뭐 그런 식으로도 들어보셨을 수도 있겠네요 ㅎㅎ	0	일반적으로 데이터는 많은 정보가 있고 노이즈도 있습니다. 그 중에서 대표가될수 있은 성질을 feature라 합니다 예를들어 두 class가 있을때 각 클래스를 대표할수 있는 변수가 feature가 되고, 이를 식별하기 위한 방법으로 feature selection 또는 extraction방법을 씁니다 대표적으로 entopy를 이용해서 feature를 식볍합니다 entropy는 p(x|c)(1-p(x|c))에 log를 취한형태라 볼수 있습니다 식을 보시면 0이 될때가 특정 class에서 1이 될때 이고, 이것은 한 클래스에서만 나타나는 대표가 될수 있는 feature라는 의미입니다 여기에 log를 취했으니 음수가 되서 -를 취하고 prior을 곱해준 것으로 볼수 있고요. 복잡하게 아야기를 길게 늘어 놓은것 같네요....	1	독립변수요ㅋㅋIndependent variable / dependent variableFeatureInput variable / target variableColumnAttirbute다 비슷한 말이에요.도메인에 따라,관심변수가 무엇이냐에 따라이름만 바뀌는 친구들입니다	1	예를 들어, 어느 전자제품상가에서 고객들의 정보를 이용해서 어떠한 목적으로든 머신러닝을 한다고 생각해봅시다.이 때, 고객들의 정보중 어떤 정보를 사용해야 할까요?고객의 정보는 다양할것입니다. 간단하게 이름, 성별, 나이, 주소, 수입, 구매이력 등등 많은 것이 있겠죠!그중에서 머신러닝에 이용이 될 만한 정보를 뽑아낸 것을 feature라고 부릅니다.아마도 주소나 이름 같은건 아무런 의미를 지니지 않겠죠? 대신 나이와 수입 등은 중요한 정보를 가질 수도 있습니다.만약 전자제품상가의 입장에서 새로운 고객이 왔을 때 어떤 제품을 구매할 것인지를 예측하는 regression model을 만든다고 할 때, 이름/주소 같은 것은 제외한 성별,나이,수입 등을 가지고 머신러닝을 할 것 입니다.이 때 사용되는 성별,나이,수입 과 같은 것을 feature라고 합니다.	1	이해하기 쉽도록 설명한 자료입니다.  일본어와 한자를 구별하는 넷을 구성시, featutes 즉 두 문자를 구별하는데 어떤 특징들이 효과적인지 보여주는 예입니다.	0	어떤 정보를 구분/예측하기위한 입력 데이터의 중요한 가공 정보(?)
9	안녕하세요  프로젝트 진행중에 몇가지 질문이 있어서 글을 올렸습니다 저는 딥러닝 CNN을 사용하여 반도체 이미지 분류 프로젝트를 진행하고 있습니다 대부분의 데이터 셋은 물체의 분류가 확실하지만 제가 분류하는 이미지는 너무나 서로 비슷합니다 (nm급,um급) 현재는 분류가 잘되고있으나 크기가 작아지고 비슷해질수록 feature개수가 많지 않아 분류가 점점 어렵습니다 ㅜ 혹시 아주 유사한 데이터를 분류 하는 기법이나 어떤 input data 전처리 기법이 있을까요?(현재는 평균데이터를 빼고 사용하는 전처리를 사용하고 있습니다)	1	저도 비슷한 문제를 겪고 있는데요 아직 삽질 중입니다 ^^
13	혹시 저와 같은 고민을 하실 분들이 계실거 같아서 올려 봅니다. 아직 배우는 입장이라 부족한 점이 많네요.# Distributed TensorFlow # 참고 URL# TensorFlowクラスタで ディ?プラ?ニングの分散?理環境を構築してみる## http://www.intellilink.co.jp/article/column/bigdata-tf01.html# Play New Distributed DeepLearning Tool TensorFlow## http://shipengfei92.cn/play_distributed_tensorflow# Test Process# Docker 설치Skip# TensorFlow 이미지 다운로드$ docker pull gcr.io/tensorflow/tensorflow$ docker images # 컨테이너 시작## 매개 변수 서버$ docker run -it --name tf_paramserver --rm --cpuset-cpus 0 -h tf_paramserver -v /tmp:/tmp gcr.io/tensorflow/tensorflow /bin/bash## 작업자 호스트 1 $ docker run -it --name tf_worker_1 --rm --cpuset-cpus 1 -h tf_worker_1 -v /tmp:/tmp gcr.io/tensorflow/tensorflow /bin/bash## 작업자 호스트 2 $ docker run -it --name tf_worker_2 --rm --cpuset-cpus 2 -h tf_worker_2 -v /tmp:/tmp gcr.io/tensorflow/tensorflow /bin/bash# tf_paramserver 컨테이너 접속, patch $ docker exec -it tf_paramserver /bin/bashroot@tf_paramserver:/notebooks# cp /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py .root@tf_paramserver:/notebooks# vi cifar10_standalone_train.patch----------------------------------------------------------------------------------- cifar10_multi_gpu_train.py  2016-04-13 00:00:00.000000000 +0000+++ cifar10_standalone_train.py    2016-04-13 00:00:00.000000000 +0000@@ -54,7 +54,7 @@ FLAGS = tf.app.flags.FLAGS tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',                            """Directory where to write event logs """                             """and checkpoint.""")-tf.app.flags.DEFINE_integer('max_steps', 1000000,+tf.app.flags.DEFINE_integer('max_steps', 1000,                             """Number of batches to run.""") tf.app.flags.DEFINE_integer('num_gpus', 1,                             """How many GPUs to use.""")--------------------------------------------------------------------------------root@tf_paramserver:/notebooks# vi cifar10_cluster_train.patch--- cifar10_multi_gpu_train.py  2016-04-13 00:00:00.000000000 +0000+++ cifar10_cluster_train.py    2016-04-13 00:00:00.000000000 +0000@@ -49,14 +49,16 @@ from six.moves import xrange  # pylint: import tensorflow as tf from tensorflow.models.image.cifar10 import cifar10+PS_NODE = "172.17.0.2" + FLAGS = tf.app.flags.FLAGS tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',                            """Directory where to write event logs """                             """and checkpoint.""")-tf.app.flags.DEFINE_integer('max_steps', 1000000,+tf.app.flags.DEFINE_integer('max_steps', 1000,                             """Number of batches to run.""")-tf.app.flags.DEFINE_integer('num_gpus', 1,+tf.app.flags.DEFINE_integer('num_workers', 2,                             """How many GPUs to use.""") tf.app.flags.DEFINE_boolean('log_device_placement', False,                             """Whether to log device placement.""")@@ -147,7 +149,7 @@ def average_gradients(tower_grads): def train():   """Train CIFAR-10 for a number of steps.""" -  with tf.Graph().as_default(), tf.device('/cpu:0'):+  with tf.Graph().as_default(), tf.device('/job:ps/task:0/cpu:0'):     # Create a variable to count the number of train() calls. This equals the     # number of batches processed * FLAGS.num_gpus.     global_step = tf.get_variable(@@ -171,8 +173,8 @@ def train():     # Calculate the gradients for each model tower.     tower_grads = []-    for i in xrange(FLAGS.num_gpus):-      with tf.device('/gpu:%d' % i):+    for i in xrange(FLAGS.num_workers):+      with tf.device('/job:worker/task:%d/cpu:0' % i):         with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:           # Calculate the loss for one tower of the CIFAR model. This function           # constructs the entire CIFAR model but shares the variables across@@ -231,9 +233,7 @@ def train():     # Start running operations on the Graph. allow_soft_placement must be set to     # True to build towers on GPU, as some of the ops do not have GPU     # implementations.-    sess = tf.Session(config=tf.ConfigProto(-        allow_soft_placement=True,-        log_device_placement=FLAGS.log_device_placement))+    sess = tf.Session("grpc://%s:2222" % PS_NODE)     sess.run(init)     # Start the queue runners.@@ -249,9 +249,9 @@ def train():       assert not np.isnan(loss_value), 'Model diverged with loss = NaN'       if step % 10 == 0:-        num_examples_per_step = FLAGS.batch_size * FLAGS.num_gpus+        num_examples_per_step = FLAGS.batch_size * FLAGS.num_workers         examples_per_sec = num_examples_per_step / duration-        sec_per_batch = duration / FLAGS.num_gpus+        sec_per_batch = duration / FLAGS.num_workers         format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '                       'sec/batch)')--------------------------------------------------------------------------------root@tf_paramserver:/notebooks# cp ./cifar10_multi_gpu_train.py ./cifar10_standalone_train.pyroot@tf_paramserver:/notebooks# cp ./cifar10_multi_gpu_train.py ./cifar10_cluster_train.pyroot@tf_paramserver:/notebooks# patch ./cifar10_standalone_train.py ./cifar10_standalone_train.patchroot@tf_paramserver:/notebooks# patch ./cifar10_cluster_train.py ./cifar10_cluster_train.patch# cifar10_standalone_train.py 실행 root@tf_paramserver:/notebooks# python cifar10_standalone_train.pyFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.2016-06-22 04:32:03.827128: step 0, loss = 4.68 (5.0 examples/sec; 25.740 sec/batch)2016-06-22 04:32:42.643370: step 10, loss = 4.66 (37.9 examples/sec; 3.376 sec/batch)2016-06-22 04:33:16.520687: step 20, loss = 4.64 (38.0 examples/sec; 3.368 sec/batch)2016-06-22 04:33:50.173917: step 30, loss = 4.63 (38.2 examples/sec; 3.354 sec/batch)2016-06-22 04:34:23.718043: step 40, loss = 4.60 (38.3 examples/sec; 3.340 sec/batch)2016-06-22 04:34:57.105776: step 50, loss = 4.58 (38.4 examples/sec; 3.337 sec/batch)2016-06-22 04:35:30.482207: step 60, loss = 4.57 (38.3 examples/sec; 3.338 sec/batch)...2016-06-22 05:27:22.916810: step 960, loss = 3.28 (36.7 examples/sec; 3.483 sec/batch)2016-06-22 05:27:57.595190: step 970, loss = 3.34 (36.9 examples/sec; 3.468 sec/batch)2016-06-22 05:28:32.598608: step 980, loss = 3.15 (36.7 examples/sec; 3.484 sec/batch)2016-06-22 05:29:07.700732: step 990, loss = 3.06 (36.7 examples/sec; 3.486 sec/batch)# master node - tf_paramserver$ vi ps.py--------------------------------------------------------------------------------import tensorflow as tfcluster = tf.train.ClusterSpec({"worker": ["172.17.0.3:2222",                                           "172.17.0.4:2222"],                                "ps": ["172.17.0.2:2222"]})server = tf.train.Server(cluster,                          job_name="ps",                          task_index=0)server.join()--------------------------------------------------------------------------------$ python ps.pyworker0 - tf_worker_1$ vi worker0.py--------------------------------------------------------------------------------mport tensorflow as tfcluster = tf.train.ClusterSpec({"worker": ["172.17.0.3:2222",                                           "172.17.0.4:2222"],                                "ps": ["172.17.0.2:2222"]})server = tf.train.Server(cluster,                          job_name="worker",                          task_index=0)server.join()--------------------------------------------------------------------------------$ python worker0.pyworker1 - tf_worker_2$ vi worker1.py--------------------------------------------------------------------------------mport tensorflow as tfcluster = tf.train.ClusterSpec({"worker": ["172.17.0.3:2222",                                           "172.17.0.4:2222"],                                "ps": ["172.17.0.2:2222"]})server = tf.train.Server(cluster,                          job_name="worker",                          task_index=1)server.join()--------------------------------------------------------------------------------$ python worker0.py# cifar10_cluster_train.py 실행 - tf_paramserver$ python cifar10_cluster_train.pyFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.2016-06-27 06:37:00.934784: step 0, loss = 4.68 (8.1 examples/sec; 15.769 sec/batch)2016-06-27 06:37:42.109417: step 10, loss = 4.66 (68.7 examples/sec; 1.862 sec/batch)2016-06-27 06:38:18.171853: step 20, loss = 4.64 (71.1 examples/sec; 1.800 sec/batch)2016-06-27 06:38:54.324842: step 30, loss = 4.62 (71.1 examples/sec; 1.800 sec/batch)2016-06-27 06:39:30.495178: step 40, loss = 4.60 (70.6 examples/sec; 1.813 sec/batch)2016-06-27 06:40:06.795960: step 50, loss = 4.58 (67.3 examples/sec; 1.902 sec/batch)2016-06-27 06:40:42.679505: step 60, loss = 4.57 (71.5 examples/sec; 1.790 sec/batch)......2016-06-27 07:36:16.794548: step 970, loss = 3.18 (68.9 examples/sec; 1.859 sec/batch)2016-06-27 07:36:54.019029: step 980, loss = 3.10 (69.1 examples/sec; 1.853 sec/batch)2016-06-27 07:37:31.309284: step 990, loss = 3.16 (69.2 examples/sec; 1.849 sec/batch)
84	[TF-KR 첫 모임] 오늘의 비디오는 최종욱님의 TF 디버깅입니다. (촬영해주신 권장호, 심상현, 전승현 님에게 큰 감사를 드립니다.)이런 깊이 있는 TF디버깅에 대한 내용은 세상 어디에도 없는 정말 듣기 어려운 강의 입니다. 강추합니다.강의영상: https://www.youtube.com/watch?v=01nDEZe0BfU&feature=youtu.be발표자료: https://wookayin.github.io/TensorflowKR-2016-talk-debugging관련코드: https://github.com/wookayin/TensorflowKR-2016-talk-debugging
13	FP + TensorFlow == TensorBuilderCode NNs Faster and Easier.
1	Data ScienceTech Institute is very proud to have its #BigData & #DataScience MSc and Executive MSc programmes recognised by the French Government via Campus France under its prestigious "Programmes taught in English" section, for "Mathematics" and "Engineering and Technology", amongst the most prevalent French #HigherEd institutions.Applications (and a few spaces) still open for Autumn 2016:https://www.datasciencetech.institute/Campus France:http://www.campusfrance.org/fria/taughtie/index.html?mfid=7http://www.campusfrance.org/fria/taughtie/index.html?mfid=4
79	NVIDIA에서 nvidia-docker라는 것을 만들어 GPU환경을 사용할 수 있는 도커 환경을 꾸며놨네요..이것으로 셋팅해서 Tensorflow를 올려봐야 겠네요.	1	첨 알았어요...ㅋ.ㅠㅠ	0	희소식	2	nvidia가 무서워지고 있네요...	1	아. 지금 cuda 때문에 헤매고 있었는데, 이걸로 해 봐야겠네요.ㅋ	1	nvidia-docker 덕분에 서버에 간단히 적용하여 사용하고 있습니다.Tensorflow는 사용하지 않았지만, Caffe를 nvidia-docker를 이용하여 사용을 해봤습니다.다음번엔 tensorflow를 올리고, 적용하고 실제로 그래픽 드라이버를 잘 사용하는지 확인해볼 계획입니다.	1	좋았던점은 cuda/cudnn의 버전마다 이미지를 제공해줘서 원하는 버전의 이미지를 가져와 사용할 수 있었던 점인것 같네요
3	인고지능과 관련이 있는건데요카메라로 실시간으로 인식해서사과인지 자동차인지 구별하게개발하는 방법이 있을까요안드로이드 어플로 개발해야 할거 같은데요지금시작이라 감도 안잡히네요	1	인식 자체를 안드로이드 단말단에서 하기에는 무리가 있을 것 같습니다.. 서버에 이미지 처리 및 인식하는 기능을 두고, 앱에서는 촬영 및 사진 전송후 서버로부터 결과물을 응답받는 형식이 좋을 것 같습니다	1	요즘 말씀하신 용도로 딥러닝기술을 활용하기 위해서 Deep compression 기술이나 FPGA 기반 기술에 대한 연구가 활발하게 진행되고 있습니다.	1	NN쪽으로 공부를 해보셨다면 TensorFlow로 서버사이드에서 이미지를 분류하시고 분류결과를 모바일로 돌리는게 좋지 않을까 생각합니다.	2	텐서플로우 공식 예제로 구현되있는거 있어요. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android	2	음... 저번에 라즈베리파이에서도 이야기 한 내용인데학습은 서버에서만 하고 그 학습된 데이터를 폰에 옮기는 식으로 효율을 높일수 있을거라 생각됩니다.	0	요즘 스노우라는 앱이 인기던데요..그 앱의 안면 인식 기술이 생각하시는 부분과 비슷하지 않을까요?^^	1	안드로이드에서 작동하는 것을 만들면 대박	4	압축기술 사용해서 하면 학습은 컴퓨팅파워 좋은 곳에서 하고 실제 적용만 모바일로 옮기면 불가능할 것 같지는 않습니다	0	딥러닝이요	0	Http://Clarifai.com	0	저도 clarifai 추천 드립니다. 가장 현실적인 답인것 같네요.
21	제가 이걸 이용하여 테스트를 해보고 까먹고 있었습니다.저번에 파이3에서 선형회귀를  2000번 트레이닝 한 결과 몇초 안 걸리더군요 추후에 다양하게 딥러닝 모델을 올려보고 알려드리겠습니다.ps. 파이 2에서 선형회귀가 35초 걸렸다고 하신 말씀을 들었었는데,3에서는 성능이 매우 올라간걸까요? 아니면 제가 사용한 데이터의 문제였을까요?	0	파이의 가벼움을 이용하여 진행 할 수 있는 프로젝트가 뭐가 있을까요?	1	파이3 스펙 향상이 있었지요 ㅎ
45	혹시 아래 책을 같이 번역하실 분 계신가요? 페이지가 얼마 안되기는 하는데 텐서플로우 첫 책인만큼 제대로 확인하고 싶기도 하고 저자만 수락한다면 웹에 무료 오픈도 고민하고 있어서 글 올립니다. 돈을 보고 할 영역은 아닌것 같고 회사업무상 코드공유 등을 못하니 오픈소스쪽에 이런 형태의 기여도 좋을 것 같아서 제안드립니다.참고로 아직 저자에게 컨텍해보거나 출판사를 알아본것은 아닙니다. ^^;	1	허락받지 않고 번역해서 공짜로 올리면 저작권 위반입니다.	0	안녕하세요ㅎㅎ  같이 번역에 동참하고 싶습니다 ㅎ 미약한 실력이지만 도움이 된다면 하고싶네요 ㅎ	1	Kwon-Han Bae 의견 감사합니다. 그래서 출판사를 통해서 번역 자체가 가능할지부터 일단 문의는 해뒀습니다. 위에 알아보지 않았다라고 하는것은 진행된것이 없다는 의미였습니다^^;	0	다른곳을 통해서도 많은분이 말씀해주셔서.. 일단 관련 전공자+현재 업무로 딥러닝을 활용해주신분 위주로 같이해야 할것 같습니다^^;;	3	출판사에서 확답이 오게되면(보통 1주 이상이 걸리더라고요..) 어떤분과 어떻게 작업할지 다시 올리겠습니다~ 감사합니다!	2	좋은 생각입니다!	0	Lee SangHoon 혹시 전에도 리얼타임 분석관련된 책을 번역하시지 않으셨었나요? 책에서 뵈었던것 같은데.. 참 좋은 일인 것 같습니다~^^	4	다른분이 이미 컨택하셔서 저자의 허락을 받았다고합니다. 웹에 공개하는 형태로 진행되었고 그분이 따로 번역할 분을 모아서 오늘부터 스타트 되었습니다.(저도 같이 번역 진행합니다.) 여기에 남겨주신 분들께 같이하지 못하여 죄송합니다.ㅠ	2	시간이 좀 된 글이라 내용 업데이트가 안되어있어서 혹시 모르는 분들을 위해 댓글 남깁니다. 현재 한글화 작업은 끝났고 아래 링크에서 확인 가능합니다.https://tensorflowkorea.wordpress.com/2016/04/28/first-contact-with-tensorflow/
63	SyntaxNet의 설치를 쉽게 설명해줍니다. 매우 좋은 글입니다.	3	블로그 저자입니다 공유 감사드립니다~!!SyntaxNet 활용가이드도 현재 작업중인데 조만간 업로드 하겠습니다~!!
100	TF-KR 첫모임: 오늘의 영상은 NumPy를 제대로 사용하는 철학을 보여주는 하성주님의 강의입니다. 저도 많이 배웠습니다. 동영상: https://www.youtube.com/watch?v=Dm2wkObQSas&feature=youtu.be발표자료: https://speakerdeck.com/shurain/zen-of-numpy	1	영상 보고 있는데 재밌네요 ㅎㅎ 감사합니다.
25	TensorFlow 코딩 연습을 위해  jupyter 노트북을 만들어 Github에 백업중(?) 입니다. Sung Kim 교수님 Softmax 쪽 코드에다가 차트몇개 딱딱 붙여보고 있습니다. 	1	화이팅요... 전 NN XOR 부터 동작을 잘 안하더라구요. x_data를 Transpose하고 돌렸는데 학습이 제대로 안되더라구요. 혹시 NN으로 XOR을 해결하시게 되면 코드 공유를 부탁드릴께요. ^^
1	위험한 일 대신해주는 로봇은 왜 안나올까요건설로봇같은거	3	안녕하세요 김여여님. 최근에 KAIST팀이 우승한 DARPA 챌린지의 경우, 대회 컨셉이 일본의 원자력 발전소 사고를 해결할 수 있는 로봇을 만들어보자였습니다.그리고 항상 자주 글을  올려주셔서 정말 감사합니다만, 약간의 지식이나 정보의 공유가 없는 너무 단순한 형태의 질문은 다소 삼가해주시면 좋을 것 같습니다. 감사합니다.	0	요즘 로봇이 인간 일자리를 뺐는다는 말이 종종 들리죠. 이게 더 커지면 기업이 따 당하죠.
22	안녕하세요 여러분, 교수님 조언을 듣고 다시포스팅해요저희는 패션 스타트업이입니다.현재 다양한 패션정보를 수집해서 비슷한 상품을 소개하고있는데, 상품분류에서 Imgae deep learning을 적용하고 싶어서 이렇게 포스팅드립니다. 현재 수십만장의 상품정보를 수집하고있는데 수집된 상품중 큰카테고리화는 하였지만 분류하는데 한계가 있어 나머지부분은 이미지를 활용하여 분류하려고합니다. 아래 github를 통해 비슷한 기술을 찾아놓았는데 저희싸이트에 맞게 modity 하려고 하는데 같이 도와주실분을 찾습니다.제가 개발자 출신이아니고 어려운분야라 쉽게 다가기가 어렵습니다지금 시작하는 초보분이라도 같이 연구하면서 공부하면 어떨까 해서 이렇게 포스팅을 합니다.  혹시 가능하신분 언제든지 환영합니다!!예) t-shirt 중  색깔별, 프린트가 있는옷 등을 이미지분류https://github.com/paucarre/tiefvisionhttps://github.com/saiprashanths/dl-dockerhttps://github.com/AntreasAntoniou/DeepClassificationBot	1	재미있는 주제네요.	1	연구주제는 재미있고 제가 관심도 있는 분야인데 기업의 영리목적인 연구라서 조금 조심스러운 면이 있는것 같습니다	1	좋은 자료 공유 감사합니다	0	앗..제가 하고있는 프로젝트랑 비슷한 면이 있네요
4	온라인 금융대학원이 나 인공지능 대학원도 잇나요
4	안녕하세요 CNN을 사용해 실수 점수로 레이블링 된 image의  regression을 해보려고 합니다.Tensorflow로 구현된 참고할만한 프로젝트가 있을까요?	0	https://github.com/sjchoi86/Tensorflow-101	0	개인 데이터셋으로 사용하는 코드도 예제로 있습니다.	0	강동호 감사합니다.
17	RNN을 이용해서 뭔가를 만들어보고 싶은데요~RNN으로 제 데이터로 새로운 어플리케이션을 만들기 위해서는 어떻게 단계를 거쳐나가면 좋을지 조언해주시면 정말 감사하겠습니다.현재 김성훈 교수님 동영상 한번 보고 따라했구요TensorFlow RNN 튜토리얼 보면서 http://colah.github.io/posts/2015-08-Understanding-LSTMs/이 글 읽고 있는 중입니다.아 그리고 TF RNN 튜토리얼 돌리는데 시간 얼마나 걸리셨나요?해보신분 알려주시면 감사하겠습니다!
5	안녕하세요 혹시 Image deep learning 쪽으로 개발하거나 공부하고 계신분 있나요?? 프로잭트성으로 개발할려고하는데 도움주실분 찾습니다!! 사례도 있고요!!!	0	저희 그룹에 하시는 분들이 많을 것으로 예상되는데 구체적인 내용을 더 알려 주시면 다 자세한 답을 받으실듯 합니다.	0	재미난 주제라면 많이들 모일것 같네요 한번 자세히 올려보심이
49	[TF-KR 첫 모임 이후 설문조사 결과]지난 18일 있었던 첫 모임에 대한 설문 조사 결과 입니다. 많은 분들이 2번째 모임에도 (친구까지 데리고) 참여하겠다고 해주셔서,  두번째 모임을 잘 준비해보겠습니다.다른 설문 내용은 https://www.surveymonkey.com/results/SM-J6J3G7YT/ 더 보실수있습니다.혹시 두번째 모임에서 다루었으면 하는 부분이 있으면 댓글로 알려주시면 참고하여 좋은 강사님들을 섭외 하겠습니다.감사합니다.	0	Tensorflow가 이미지처리 외에 시간에 따라 쌓이는 센서 데이터등의 분석에도 효과적인 툴인가요??
22	뛰어난 인재좀 친구로 두고 싶네요 창업하게요 ㅋㅋ천재는 문제 접근법을  아는 사람 같은데요막연하게 어렵다 쉽다 말하는게 아닌T Times - 	1	정말요. ㅋ 창업 아이디어는 있는데, 같이 할 인재가 별로 없네요. ㅋ
95	아주 기초만 정리세미나를 듣고 간단한 것만 따라해봤어요	3	좋은 슬라이드 감사합니다.	1	감사^^	1	저도 살펴보겠습니다. 감사합니다.
18	안녕하세요, 지난 주 Tensorflow-kr 기본/중급 세미나를 듣고, 후기를 작성중입니다. 세번째 , 네번째 세션은 직접 테스트해보면서 작성하고 있어서  아직 정리하지는 못했습니다.	0	잘 읽었습니다. 세번째 네번째도 기대 합니다.
7	혹시 ubuntu 16.04버젼에 cuda, tensorflow 설치해 보신분 있나요? Cuda 7.5가 아직 16.04를 지원 안 하네요. ㅜㅜ cuda8.0은 되려나요? 흠 그리고, python 3.5에서도 텐서 잘 구동되는지요?	1	2.7에 특화되어 있을텐데요	4	Ubuntu 16.04 + Cuda 7.5 +  cudnn v4 + Python 3.5 사용중입니다만 전혀 문제 없었습니다.	3	Python 3.x 잘 되요	1	http://askubuntu.com/questions/760934/graphics-issues-after-installing-ubuntu-16-04-with-nvidia-graphics
7	https://www.quora.com/How-do-I-train-myself-to-transition-from-a-career-in-software-engineering-to-AI/answer/Peter-Norvig?srid=urPAJ&share=2e0aa2ff	0	위에거 정확한 해석이 안되는데요 부탁좀 드려도 될까요	1	소프트웨어 엔지니어로서 AI로 커리어를 전환하려면 어떻게 스스로를 훈련 해야될까? 라는 제목이네요. 하지만 본문에서는 그것이 전환이라고 생각하지 않는다고합니다. 다만 기술이 추가될 뿐이죠. 이미 우리 (소프트웨어 엔지니어)는 다양한 시스템을 만들고 있으며, 복잡도, 추상화, 디자인, 테스트 등을 고려하고 있죠.  다양한 분야에서 AI의 중요도가 많이 높아져 가고 있지만 그것이 별개라고 생각하기 보단 소프트웨어 엔지니어링 입장에서는 마땅히 공부해야할 것들로 보고 있네요. 저 역시 비슷한 생각입니다. 인공지능은 이제 특정 학자나 교수 보다 많은 개발자와 엔지니어분들이 다같이 참여해서 더 나은 구현물과 다양한 아이디어가 필요합니다.
259	그동안 많은 분들이 들어 주셨던 모두를 위한 머신/딥러닝 강의 (http://hunkim.github.io/ml/)가 오늘 AWS 실습강의를 마지막으로 시즌 1을 종강합니다.https://youtu.be/9VckXVoJEe0재미있는 것들이 많이 생겨나고 있는데, 시즌2는 더 잘 준비하여 재미있는 강의로 여러분들과 만나려고 합니다. 시즌 1을 들으시며 부족하거나 개선해야 할점들, 시즌2에 추가되었으면 하는 내용들이 있으시면 알려 주세요. 미리 감사드립니다.	2	감사합니다. 방학동안에 열심히 들을께요. 그리고 시즌2도 몹시 기대할께요^^	1	감사합니다. 많은 도움이 되었습니다 :) 다음 멋진 강의 부탁드립니다!	1	감사합니다. ^^많은 도움이 되었습니다. ^^	1	감사합니다!	1	좋은 강의 감사합니다^^	1	점말 많은 도움이 되었습니다. 감사합니다.^^	1	강의 잘 봤습니다. 좋은 내용 공유해주셔서 감사합니다.	1	시즌1 강의 감사합니다. 두고두고 복습을 좀 해야 겠습니다.^^	1	강의 너무 도움됬습니다. 정말 감사합니다. 다음 시즌이 있을것 같다니 정말 기대됩니다. 감사합니다.	2	좋은 강의 올려주시느라 고생 많으셨습니다! ^^	1	좋은 강의 잘 들었습니다, 감사합니다^^	1	멋진 강의 저도 잘 봤습니다 감사합니다! :)	1	정말 감사합니다. 강의 덕분에 정말 많은 도움이 되었습니다. 시즌2도 기대하겠습니다~!! ㅎㅎ	2	강의 잘 듣고 있습니다. 감사합니다.	1	진심으로 감사드립니다. 김교수님 덕분에 많은 분들이 AI에 효과적으로 다가설 수 있었다고 생각합니다. 저도 그런 사람 중에 하나구요.	1	멋진 강의 감사드립니다! 시즌 2를 기다리겠습니다 ㅎㅎ	2	한국어로 이런 고품질의 강의를 들을수 있어 행복했습니다. 너무 감사합니다.	2	욕심이겠지만 한국에 계셔서..자주 뵈었으면 하는..ㅎㅎㅎ	1	감사합니다. 시즌2도 많이 기대하고 있습니다.	2	교수님 진심으로 감사드립니다	1	지금 듣고있습니다! 이런 강의를 주신점 진심으로 감사합니다!	1	수고 하셨습니다~	2	이 강의를 볼 수 있어서 정말 행복했습니다!!	3	교수님 강의 덕분에 입문이 가능했네요. 감사드립니다. 시즌2는 강화학습에 대해 강의해 주셨음 좋겠습니다.	2	정말 진심으로 감사드립니다	2	수고 하셨습니다~	1	수고하셨습니다~ 감사합니다~	1	교수님 수고하셨습니다. ㅎㅎ 감사합니다 ㅎㅎㅎ	1	교수님 수고하셨습니다. 멋진강의 감사합니다. ^^	1	감사합니다..  많은 도움이 되었습니다.	1	정말 감사합니다. 매일 조금씩 보고 있습니다.	1	멋지고  소중한  강의  넘   넘  감사합니다  ~~^^	0	지금 듣고있습니다 감사합니다~	0	인프런 강의로 보고 있습니다~^^너무 이해하기 쉽게 잘 설명해주셔서 감사드립니다~^^	1	이런 명강의를 한국어로 들을 수 있다는 것은 큰 축복입니다. 감사드려요~	1	교수님~^^ 시즌2에는 RL강의해 주세요!! ㅠ-ㅠ	2	RNN, LSTM 에 대해 교수님의 설명을 듣고 싶어요~	2	교수님 nn xor에서 화면에 나온 코드만 가지고 테스트해보니 잘 되지 않습니다. 깃헙에 코드를 공유해 주시면 좋겠습니다. 아니면 제가 못찾은 거라면 링크 부탁드립니다
51	[TF-KR 첫 모임] 두번째 비디오 입니다. (촬영해주신 권장호, 심상현, 전승현 님에게 큰 감사를 드립니다.)오늘 비디오는 James Ahn님의 "CNN과 Data Mutation을 이용한 Time Series Classification" 입니다. https://www.youtube.com/watch?v=IiB6oElqCxA"경제적 자유"라는 재미있는 표현이 나옵니다. (촬영용 전용마이크가 없어  음질이 조금 아쉽습니다.)
10	안녕하세요.질문이 있어서 글을 작성합니다.Deep learning 방법 중 unsupervised pre-training 방법이 최근에 사용되지 않는다고 봤습니다..그 이유가 무엇인가요?제가 생각해본 답은 아래와 같습니다.1. 데이터가 많아짐: unsupervised pre-training의 장점은 데이터가 작을 때 효과적이기 때문에, 최근 데이터가 많아져서 그 효과가 크지 않음2. ConvNet의 아키텍쳐가 발달하면서 unsupervised pre-training의 효과를 커버할 수 있음	1	pre training 을 하는 이유가 초기 가중치를 잘 정해서 학습이 잘 되게 하자는 거 같은데최근엔 relu나 가중치 초기화하는 다른 기타 방법들이 많이 등장해서 pre training 없이도 학습이 잘 되기 때문이지 않을까요?	1	pre-training 으로 파라미터 initialization하는것보다 random initailization이 성능이 더 좋아서 그런거아닌가요?	3	Unsupervised learning을 통해 미리 feature를 학습한 뒤 supervised learning을 하자는 아이디어였지만, 실제로 기대만큼 잘 되질 않고 오히려 random init이 더 나은 결과를 보여서 더이상 쓰이지 않는걸로 알고 있습니다.	5	제가 알고 있는 범위에서 random initialization은 성능이 좋지 않다는게 정설입니다. RBM이 트레이닝 속도를 빠르게 한다는 것을 힌튼 아저씨가 발견하고 이 것을 바탕으로 weight 값의 초기 분산값을 일정하게 조정해서 초기에 발생하는  saturation을 막은 방법이 xavier 방법입니다. 하지만 xavier 방법은 ReLU를 고려하지 않았기 때문에 He 방법이 나온 거구요. 최근에는 초기화만 잘하면 sigmodal방식도 성능이 나쁘지 않다는 이야기도 있습니다.	1	개인적으로 최근 트렌드는 그냥 ReLU 에 닥  He's initialization 입니다.	2	사실 과거의 unsupervised pre training 은 말씀하신 weight initialization 성격이 강했고 general feature를 찾겠다는 성격이 강해서 초반 layer들에만 pretrained weight을 주거나 변화율을 낮추거나했는데지금 쓰는 weight initializer + normalization들은 모든레이어에서Data 및 gradient signal들이 일정한 variance로 잘 흐르도록 만들어 주기때문에 더 나은 접근이 아닌가 생각드네요
32	재미있는것이 열리는군요 어떠한 목적으로 이것을 개최한걸까요?	0	kaggle과 같은 방법으로 진행되네요. 참가자들의 다양한 의견 공유를 위한 커뮤니티도 지원해주면 좋겠군요.	0	재밌겠네요 ㅎㅎ
39	이거 CNN등을 이용하면 동영상을 보고 보복운전 여부 판단 또는 가능성을 예측하여 리스트 금방 만들어 볼수 있을것 같은데 국내 도급이 매우 시급합니다. Soonmin Bae 님 동영상+CNN 이미 하고 계신가요?	0	정말 별 아이디어가 다 나오네요.	2	저희는 아직 선행기술 확보 수준으로 진행 중이고 본격적으로 제품화하고 있지는 못 합니다. 아직 우선 순위 상 내년에 착수할 것 같습니다~~ ^^영상에서 활용할 곳은 정말 많은데요.
28	대전지역 TensorFlow 모임 준비에 대하여지난주 토요일 서울을 시작으로 TensorFlow 모임이 시작이 되었는데요.많은 전문가분들의 좋은 강의와 함께 다양한 분야의 전문가분들과의 매우 유익한 교류 기회의 장이였습니다.대전은 타지역에 비해 딥러닝 기술이 실제 연구나 산업현장에 응용할 가능성이 높은 분야가 많습니다.전문가분들은 새로운 비지니스 모델을 찾을 수 있고연구소나 기업은 최신 딥러닝 기술과 함께 이분야 국내 최고 전문가와의 교류의 기회를 가질 수 있을 것으로 생각합니다.딥러닝이란 기술이 너무나 빨리 발전하는 기술이라지금 이시기를 놓치면 경쟁자들과의 싸움에서 영원히 뒤쳐질 수밖에 없다고 생각됩니다. 가급적 가까운 시일내에 개최를 목표로 추진해보겠습니다만,전문가분들과 대전지역 관련 연구기관과 기업에 종사하시는 전문가분들의 도움이 반드시 필요합니다.특히 Sung Kim 교수님대전분들 저한테 연락 좀 주셔요.강사진 구성, 장소 섭외, 후원기업 알아보기 등 할일이 많네요.	3	저 참여하고 싶습니다	3	저도 참여하고 싶습니다!	3	키야...말이 현실이 되었네 감사합니다!!저도 물론 참여하고싶습니다	3	저도 참석하고 싶네요	2	저도 참석할께요.	2	Keei Placeholder 저도 참여하고 싶습니다	1	저도 참여하고 싶습니다
122	[TF-KR 첫 모임] 오늘 부터 비디오를 하나씩 공개하겠습니다. (촬영해주신 권장호, 심상현, 전승현 님에게 큰 감사를 드립니다.)첫 비디오는 저희들에게 놀라움과 기쁨을 선사했던 Taehoon Kim 님의"텐서플로우 설치도 했고, 튜토리얼도 봤고, 기초 예제도 짜봤다면" 입니다.이 강의에 대한 질문이나 코멘트 있으시면 댓글로 올려주세요. 태훈님께서 다 답해 주실 것입니다.https://youtu.be/076pp-42unI(촬영용 마이크가 없어 음성의 질이 조금 좋지 않습니다.)	2	기대 만빵입니다. 슬라이드가 아주 훌륭하던데요. 동영상도 기대됩니다.	10	흑 T.T 다음에 혹시 모임을 하게 되면 저희학교 촬영 장비를 빌려드리겠습니다. 마이크를 따로 빼면 좋을 거 같습니다.	9	슬라이드는 http://www.slideshare.net/carpedm20/ss-63116251 에서 PDF로 받아서 봐 주세요 :)
5	tensorflow 초기화에 관한 질문이 있습니다.W = tf.Variable(tf.zeros....)로 하면 초기화 값이 0이 되는데 그렇게 되면 학습이 안되는거 아닌지 궁금합니다.그리고 init = tf.initialize_all_variables() sesson을 열기 전에 초기화 한다고 알고 있는데... 무조건 초기화를 해줘야하는지 궁금합니다.답변 부탁드립니다.	1	weight 초기화는 학습 속도와 관련이 있습니다. 자세한 설명은 찾아보시는게 좋을 것 같구요. 제가 알고 있는 범위에서는 도움을 드리면. activation function을 sigmodal형태를 사용하시면 Xavier initialization 사용하시고 ReLU 계열 사용하시면 He initialization 사용하세요.	1	두 번째 질문은 initlalize_all_variables를 해주는 이유는 Variable의 초기화는 train과정에서 의존성을 가지면 안됩니다. 당연하겠죠 초기화는 한번 해주는 것이니까요? 그래서 initialze_all_variables는 디폴트 그래프와는 다르게 별도의 그래프? 또는 의존 관계를 만드는 것과 같습니다. 결국 init 오퍼레이션을 train 전에 실행 시켜주어야 합니다. 도움이 되셨으면 좋겠네요.
25	Caffe 모델을 tensorflow로 변환하여 활용하는데 참조할 수 있는 github입니다.
8	뜬금없는 질문드립니다 흐흐 파이썬책 추천좀 해주세요 시중에 책이 넘 많아서 뭘봐야할지 어렵네요	1	http://www.tutorialspoint.com/python/	0		0	위키독스에 점프 투 파이썬이라는 무료 교재가 있습니다. 그외 머신러닝 인 파이썬도 괜찮구요.	1	<처음 시작하는 파이썬>도 괜찮습니다http://www.bandinlunis.com/front/product/faceBookView.do?prodId=3903423	1	단순히 텐서플로우 사용목적이시라면, http://cs231n.github.io/python-numpy-tutorial/ 충분합니다.
107	올여름에 앤드류 교수님의 책을 쓰신다고 하시네요. 미리 free draft copy를 보고싶으시면 아래링크에서이메일을 등록하시면 됩니다~ 개인적으로 정말 기대되네용	1	저는 이거 등록해도 confirmation 이메일이 계속 안오는데 저만 그런가요?	1	고급정보네요!	1	감사합니다. 근데 저는 크롬에서는 안되네요. 익스플로러에서만 되고 바로 확인메일 왔습니다.
130	구글 딥마인드에서 일하는 David Silver 님의 ICML 2016 RL tutorial입니다.  1은 일반적인 RL이고 2는 알파고 집중 분석합니다. (이세돌 사진도 슬라이드에 나옵니다. ㅠㅠ) AI = DL+RL이라는 아주 강한 표현이 나오는 군요. :-)http://icml.cc/2016/tutorials/deep_rl_tutorial.pdfhttp://icml.cc/2016/tutorials/AlphaGo-tutorial-slides.pdf	0	요즘 RL에 계속 관심이 생기는데 저도 읽어보도록 하겠습니다. 자료 감사합니다!	9	저는 현장에서 듣고 있습니다~ 구글 딥마인드팀이 3개의 베스트페이퍼 중에서 2개,, 논문은 무려 20개나 억셉트 하는 저력을 발휘했답니다~ 기회가 되면 다른 자료들도 공유해 보도록 할께요.	1	저런 표현을 자신있게 할 수 있는 자신감이 부럽네요. ㅎㅎ	1	교수님은 RL에 주로 관심이 많으신가요?	0	아주 잘 정리된 자료입니다. 재미있게 읽었습니다.	1	Model-based RL에 대해 많이 궁금했는데 그 부분은 좀 모자라네요. Value-based와 Policy-based RL에 대해서는 깔끔하게 정리된 자료네요. 멋집니다.
13	안녕하세요.지난주 TF-KR 모임 참석후에 의욕이 샘솟는 양인황이라고 합니다.제가 생각한 것이 딥러닝으로 풀 수있을지에 대한 궁금증이 생겨 이렇게 글을 올리게 되었습니다.유투브에서 동영상을 실행을 하면, 자동으로 자막을 만들어주는 서비스가 있는데 이 부분을 유투브 내에서가 아닌 전반적인 한국어 영상에 통용되는 서비스를 만들어 보고 싶습니다.대략적으로 딥러닝을 이용하여 하면 될 것 같다는 생각은 가지고 있으나, 어떤 방식으로 처음에 접근을 하면 괜찮을지 조언을 구하고자 합니다.또한 제가 하려는 부분에 초기 방향을 잡을만한 레퍼런스가 있다면 알려주시면 정말정말정말로 감사드려요ㅎ끝으로 제 글을 읽어주셔서 감사합니다^^	1	(bi-directional) RNN의 오디오 입력->텍스트 출력으로 생각하시면 될듯 합니다. 다만 훈련데이터가 많이 필요합니다.	0	바이두 Andrew Ng 교수님 강의나 논문에 많이 나옵니다.	1	비슷한 프로젝트를 최근에 막 시작했는데요. 좀 쉽게 접근하실려면, STT(speech to text) open api를 활용할수도 있습니다. Google speech api 는 단, 15초 이하 짧은 음성만 지원하구요. 언어자체는 80개국어 정도를 지원합니다. MS Cognitive Speech api는 30개국어 지원하는데, 한국어도 되고, 긴 음성도 되며, 리얼타임도 됩니다.	1	저희는 STT이후에 text를 Word Embeding 처리 후 RNN등으로 Text Classification 하는걸 TensorFlow로 태스트 중인데요. 생각보다 stt결과가 오류가 좀 있어서, stt 결과를 문맥을 보고 오타를 좀 바꿔주는것도 word2 vec이나 paragraph2vec으로 혹은 RNN으로 가능하지 않을까 실험 중입니다.
8	안녕하세요? 최근 제 연구에 deep learning을 적용해보고 있는 박사과정학생입니다. 저의 경우 화학 구조의 atom 정보를 이용하여 데이터를 만들어보려고 하고 있습니다. Atom이 적어도 수백개 이상일 것 같은데, atom의 coordinate 정보(x, y, z) + property로 feature를 만들어도 atom 수 * property 수로 수천개 이상의 가능한 feature가 나올 것 같은데요. 이렇게 많은 feature를 사용하여 문제가 없을지 궁금합니다. 감사합니다.	0	유기 분자 구조의 경우에는 fingerprint라 불리는 molecular descriptor를 주로 사용하는 것 같습니다. python에서 RDKit이라는 라이브러리가 알려져 있어요	0	feature size (1000+) 가 크고, observation/training set size가 작으면, 딮러닝으로 하기엔 적절하지 않은듯한데요... 만약 딮러닝으로 된다고 하묜, 레이어를 낮게 놔야 하고, 얏게도 잘 나오면, complexity 가 낮다는 말이고, 그러면 feature extraction이 간단하는것이고,..그면 아무 알고리즘써도 된다는 건데... observation 이 많이 있나요??
7	안녕하세요..첫 모임 너무 좋았구요, 특히, Sung Kim 교수님 너무 수고 많으셨습니다.그런데, 이번 TensorFlow 모임에서 첫번째 발표자인 Kaz Sato의 Cloud Vision API 데모(hierarchical 구조) 영상은 어디에서 확인할 수 있나요?상당히 인상 깊었는데....ㅎㅎ	2	자문자답입니다. 구글링하다 찾았네요...http://vision-explorer.reactive.ai/#/?_k=aodf68	0	저희가 찍은 영상도 곧 올라올 예정입니다.	0	ㅎㅎ 그리고 전 별로 한것이 없고 강사님들과 운영진님들 수고 정말 많으셨습니다.
1	감사..
228	어제 제가 했던 talk인 "텐서플로우 설치도 했고 튜토리얼도 봤고 기초 예제도 짜봤다면"의 슬라이드와 제가 구현한 텐서플로우 코드들을 공유합니다. 텐서플로우를 공부하시는데 도움이 되셨으면 좋겠네요 :)1. 이미지(사람의 얼굴 사진)을 이해하고 스스로 만드는 모델http://carpedm20.github.io/faces/https://github.com/carpedm20/DCGAN-tensorflow2. Atari 게임을 화면의 픽셀만 보고 배우는 모델https://github.com/devsisters/DQN-tensorflow/3. 이미지 버전의 '왕 - 남자 + 여자 = 여왕'https://github.com/carpedm20/visual-analogy-tensorflow4. 뉴럴 네트워크로 만든 튜링 머신https://github.com/carpedm20/NTM-tensorflow5. 강화 학습 모델들https://github.com/carpedm20/deep-rl-tensorflow/6. Question Answering, Language Modelhttps://github.com/carpedm20/MemN2N-tensorflow7. Character-level Language Modelshttps://github.com/carpedm20/lstm-char-cnn-tensorflow8. Teaching Machines to Read and Comprehendhttps://github.com/carpedm20/attentive-reader-tensorflow9. Neural Variational Inference for Text Processinghttps://github.com/carpedm20/variational-text-tensorflow10. Text-based Games using Deep Reinforcement Learninghttps://github.com/carpedm20/text-based-game-rl-tensorflow발표 슬라이드: http://www.slideshare.net/carpedm20/ss-63116251#likes-panel	1	텐서플로우 구현으로는 독보적이신듯 합니다! ㅎㅎ 항상 잘 보고 있어요. :)	1	열심히 해야 겠다는..감사합니다.	1	감사합니다.	1	감사합니다 ^^	1	발표도 잘 들었습니다. 저도 방학때 논문 하나씩 읽고 여기 구현도 다 읽겠습니다. 감사합니다.	0	많이 자극 받았습니다. 감사합니다!	0	복받으실 겁니다~!! 감사합니다.	0	짱짱맨! 최고예요!	0	감사합니다.	1	손규빈	1	Thanks for the sharing, these are great!	0	많은 도움이 되었습니다. 감사합니다! :)	1	헐 짱이라 아니할 수 없네요.주말에도 쉼없는 이러한 열정은 도체 어디서 나오시나요?	0	감사해요^^	0	멋지고 존경스럽습니다. ^^;	0	많은 도움되었습니다^^	0	어제 강의 잘 들었습니다. 최신 논문을 읽어서 이해햐고 구현하는게 쉽지는 않은 데 대단합니다.  감사합니다.	0	우와...
47	제주도에서 TF 스타디 모임을 시작하려고 합니다. 혹시 제주에 계시거나 지인이 제주에 있으면 많이 홍보해주세요. 혹시 7월중 제주로 여행하시면 스터디 강사나 게스트로 초청합니다.	0	제주도에서 하시니 공간적인 제한이 있네요~  하시면 실시간 방송 부탁 드려요~	0	구체적인 기간 정해지면 참여하고 싶네요!	1	날씨 만큼이나 김박사님의 열정이 뜨겁네요 ㅎㅎ	0	고향이 제주도인데 학교가 서울이라 아쉽네요 ㅠㅠㅠ	3	아마도 저는 지구 끝까지 찾아 갈 수 있는 분위기 입니다. 요즘. 물론 처가 집이 제주도이긴 하죠.
101	텐서플로우 설치와 간단한 사용을 다루었습니다.	1	알기쉽게 잘 만드셨네요.	1	발표 잘 들었습니다~~	1	쉽게 설명해주셔서 잘 이해가 됐습니다. 감기 빨리 나으세요~	1	감사합니다. 많이배웧습니다.
33	광주에서 서울로 서울에서 다시 광주로 돌아왔습니다. 발표에 많은 관심을 가져주셔서 감사합니다. 오늘 만난 분들 좋은 인연으로 자주 뵙기를!! 스스로 더 열심히 노력해야겠다는 큰 다짐을 해봅니다. TF-KR이 더욱 번창하길 바라며!!	0	오늘 발표 잘 들었습니다. 수고하셨습니다~!	0	상담감사해요!	0	형님 수고하셨습니다~! 저희 GIST 딥러닝 모임도 관심가져주세요 :)	1	뵙고 재미있는 이야기도 많이 하고 정말 즐거웠습니다. 자주자주 뵈요!	0	만나서 반가웠습니다. 발표를 들으며 이해가 조금은 깊어졌네요. 정말 좋았습니다.  또 뵈어요!
119	오늘 참여해주셔서 첫 모임을 흥미진진하고 신나게 해주신 모든 분들에게 감사드립니다. 앞으로도 이런 재미있는 모임을 더 많이 같이 만들어 가면 좋겠습니다.여러분들은 오늘 모임 어떻게 보셨는지 생생한 후기들 많이 올려 주세요.TF-KR 운영진 드림 (오늘 맛있는 음식을 준비해주신 김택수님은 아쉽게도 같이 사진을 촬영하지 못했습니다.)	0	오늘 좋은 자리 마련해주셔서 감사했습니다!	0	준비하시느라 고생하셨습니다.	1	감사합니다	0	많은 도움이 되었고 또 즐거웠습니다.	0	정말 수고들 많이 하셨고 좋은 시간이었습니다. 감사합니다.	0	좋은 자리 마련해주셔서 감사합니다! 다음 행사에 일손이 필요하시면 꼭 불러주세요ㅎㅎ	0	교수님 감사드려요. 좋은 모임과 시간이었습니다. 아직 내용이 뭐라고 하는지 이해가 되지 않지만 대략적인 숲을 본 것 같네요. 다음 기회도 기대하고 기다릴께요. 함께 수고해 주신 모든 분들께도 감사드려요^^	1	오늘 좋은 자리 만들어주셔서 감사드리며, 김성훈 교수님과 관계자분께도 진심으로 감사의 말씀 전해드립니다. :) 집에 갑자기 일이 생겨 끝까지 있지 못했지만 ㅠㅠ 다음 모임도 만들어주심 꼭 참석하겠습니다~	2	못가서 아쉽네요. 내년엔 아예 발표자로 참가할 수 있도록 공부해야겠다는 ㅎㅎ	1	유익한 시간이었습니다. :) 좋은자리 마련해주셔서 감사합니다!!	2	좋은 자리 마련해 주셔서 감사합니다~ 김밥과 음료수로 입은 즐겁고, 알찬 내용으로 머리도 즐거웠습니다~  앞으로 좀 더 많은분들과 같이 좋아하는   내용으로 소통하고 싶어요~	2	즐거운시간이었습니다~~다음번이 또 기다려지네요	0	좋았어요 ^^ 오늘 수고 많으셨어요	1	수고 많으셨습니다! 다음엔 저도 참석할 수 있길...ㅜ	1	수고하셨습니다~ㅎ	1	오늘받은 스티커..^^	1	오늘 좋은 자리 마련해주셔서 감사합니다~~~!	2	이런 자리를 마련해주셔서 정말 감사드립니다!	3	자리 마련해 주셔서 감사합니다. 어디가서 들어볼려면 너무 힘든 이야기드링었는데 자리를 마련해주시고 피자와 김밥까지...T_T 감사합니다. 다음 모임에는 뭐라도 발표하는 사람이 될 수 있을지 모르겠네요. 개선하면 좋겠다 싶은건, 1. 회고를 합시다. 그냥 '좋다'가 아니라 좋은점-개선할 점- 새롭게 발견한 것들을 가지고 나누는 자리가 있었으면 합니다. 2. BoF에서 좀 더 사람들을 섞어서 앉게할 방법을 찾아보았으면 합니다. BoF주제들을 신청할 때 받아서 준비하거나 랜덤으로 섞어져서 앉게 하는 방법을 찾아보면 어땠을까 하는 생각도 해봅니다. 3. 뒷정리 잘하고 가겠습니다. T_T 치우시느라 다들 고생하셨습니다.	1	좋은자리 마련해주셔서 감사합니다!! ㅎㅎ	4	저도 못가서 너무 아쉬웠습니다! 다음엔 광클하겠습니다.	1	수고 많으셨어요 ㅎㅎ	1	오랜만에 참 유익하고 즐거운 모임이었습니다. 모임 주최하시고 발표해주신 분들 모두 고생많으셨어요. 고맙습니다! ^^	1	사람들 평이 좋은 것을 보니 대박이었나보네요~ ^^ 준비해주신 분들 수고 많으셨습니다. ICML 2016과 겹쳐서 아쉽게도 참석 못했네요~ 지금 뉴욕인데 다음 기회에는 꼭 뵈도록 하죠~
33	Sung Kim 교수님과 함께 360도 사진을 찍어 보았습니다.	1	ㅎㅎ 아쉽네요. 다음 기회에!	1	아.. 오늘이군요. 얼른 씻고 나가야겠네요. 2시전 도착할것 같네요	0	인물 좋네요.	0	이 카메라 좋네요. 어디서 구할수 있나요?
74	곧 다른 발표자료도 올라오겠지만 어제 제가 했던 talk인 "텐서플로우 코드 디버깅을 위한 가이드" (A Practical Guide for Debugging Tensorflow Codes) 의 슬라이드와 관련 코드를 먼저 공유해드립니다.Slide: https://wookayin.github.io/TensorflowKR-2016-talk-debuggingCode: https://github.com/wookayin/TensorflowKR-2016-talk-debugging저도 어제 무척 즐거운 시간이었고, 많은 분들 만나뵐 수 있어서 좋았습니다. 도움이 많이 되었을지 모르겠지만 재미있게 들어주셔서 감사드립니다. 좋은 휴일 되세요~
19	어찌 교수님은 제 얼굴의 반쪽이시나요??? 제 나름의 연애인 만나 기뻤습니다. 강의도 넘 좋았고 많이 얻어 가네요. ^^자주뵈요 교수님^^;;;;	0	ㅎㅎ 사진으로 보니 꼭 그렇지는 않은것 같아요.
12	오늘 뵙게 되어 영광이였습니다. 감사합니다사진과 영상은 아래 링크에서 감사하실 수 있습니다.코딩신이 함께하길...https://www.facebook.com/iamprogrammer.io/
36	오늘 정말 유익한 시간이었습니다!😆더불어 많은 좋은 분들을 알게 되어 더더욱 좋았던 것 같습니다!준비하느라 고생해주신 김성훈교수님과 여러 스태프 및 관계자 분들께 다시한번 감사하다는 인사 드리고 싶네요~다음번 2차 모임이 있다면 꼭 참여하겠습니다!!그럼 다들 좋은 주말 되세요😍😍
48	모두 반가웠습니다! 많은걸 느끼고 갑니다못 오신 분들을 위해 영상 촬영을 했으니이번주 중으로 올리겠습니다!	1	스태프로 수고 많았네^^	1	고생많으셨습니다! 다음에 또 뵙기를!	1	수고 많으셨습니다 ^^
21	소중한 경험을 가질 수 있는 행사를 준비해 주셔서 감사합니다.저녁 모임도 참석하고 싶으나 지방에 사는 이유로 아쉽게도 먼저 자리를 뜹니다.다음 행사도 꼭 참석하고 싶습니다.감사합니다!!!
15	첫번째 발표가 진행되고 있는 구글 캠퍼스 360도 사진입니다.	1	오, 용욱님 신청 성공??
29	intermediate/advanced 트랙에도 사람들이 많네요~!!
7	잠시 후 뵙겠습니다. 라이브 방송이 가능하다면 멋진 분들과 함께하고 싶습니다
13	텐서플로우 정보를 교류하기 위해 많은 사람들이 구글 코리아를 방문하였습니다. (360도 사진)
65	첫번째 TensorFlow KR 모임이 잘 진행 중입니다~
9	대전 지역에 스터디 모임 있나요??	2	있으면 좋을거 같네요.. 없으면 만들어 보는건 어떨까요?!	5	대전지역 스타디 모임이 생기기를 응원합니다.	2	오~ 저도 같이 공부하고 싶습니다^^	4	제가 제일 시니어 같은데.  ㅋㅋ  한번 뵙시다.	6	함께 세미나할 아주 좋은 장소도 무료로 제공 가능.  비지니스 아이디어도 공유하고	2	저도 대전에 있는데 함께 하고 싶네요^^	2	저는 광주에 살지만 참석하고 싶습니다.
59	데미스 하사비스를 포함한 DeepMind사의 연구자와 스텐포드 대학의 심리학 연구자가 인간의 뇌를 해부학적으로 분석하여 이를 인공지능에 적용시키고자 한 'Complementary Learning Systems (CLS) 이론'의 개정판을 발표했습니다.딥마인드의 'Deep Q-Network (DQN) '를 비롯해 많은 AI연구가 CLS에 근간을 두고 있는만큼 이번 발표도 큰게 주목받고 있습니다.	0	읽어도 무슨 말인지 잘 모르겠어요. 정개발님의 해설이 필요해보입니다.	9	제가 알면 블로그에 적었겠죠. ^^; 발번역을 전제로 알아 들은 내용을 요약해 봅니다.사람의 뇌는 대뇌피질이 담당하는 단기 기억과 해마가 담당하는 장기기억으로 나누어지는데 서로 상호 보완적이라고 합니다. 그리고 느린 학습과 빠른 학습이 있다고 하는데 느린 학습은 대뇌피질에서 경험을 구조화 하면서 이루어지고 빠른 학습은 해마에서 개인의 특정 경험을 통해서 이루어 진다고 하네요.CLS 이론에서는 두 시스템은 "리플레이 (replay)"라는 프로세스를 통해 이 두 기억이 양방향으로 데이터를 주고받으며 느린 학습과 빠른 학습 사이의 틈을 메우고 있다고합니다. 리플레이는 설치류의 뇌 연구에서는 실제로 발견되고 인간도 자고있을 때 꾸는 꿈이 이 리플레이에 해당한다는 설도 있다고 합니다.이번 논문의 핵심 부분 중 하나는 이 리플레이의 역할을 확장하는 것입니다. 구체적으로는 리플레이를 통해 대뇌 피질이 해마의 데이터의 학습에 이용 될뿐만 아니라 더 폭 넓은 역할을하고 있다는 것. 예를 들어, 대뇌 피질의 학습 내용을 목적과 얻을 수있는 보상에 따라 재구성하는 기능입니다.또 다른 주요 내용은 해마에서 데이터의 일반화 기능이 지금까지 학자들이 추측한것 보다 강력하다는 것 인데요, 대뇌 신피질에서 새롭게 학습 하는 데이터가 이전에 학습 된 데이터와 상충되지 않는경우 경우 학습하는 데 필요한 시간이 기존 생각했던 것보다 훨씬 짧아진다고 하네요.	0	역시 큰게 주목 받는군요...	0	문득 든 생각인데 이 논문의 가치는 기존 딥러닝에 비해서 학습 데이터의 양을 비약적으로 줄일 수 있는 단초를 제공하고 있다는 점이 아닐까 합니다.
10	FPGA-accelerated deep convolutional neural networks최근 deep convolutional neural networks의 모바일 디바이스나 소형 UAV등에 대한 응용 연구가 활발히 이루어지고 있는데요. 역시 가장 큰 문제는 소형화 및 저전력화가 가장 큰 어려움. 기존 CPU와 GPU 기반으로는 두조건을 맞추기가 매우 어려움. 이에 따라 parameter 수를 줄이거나 bit수를 줄이는 Deep compression 기술과 함께 FPGA 기반의 SoC을 활용하는 기술들이 개발 중입니다. 본 논문은 Programmable SoC을 이용하여 CNN에서 연산의 대부분을 차지하는 matrix multiplication을 처리하는 Accelerator 개발에 관한 내용입니다.  Deep compression 기술과 함께 사용될 경우 시너지 효과를 극대화 할 수 있는 기술인 듯 합니다.Emerging applications such as micro-UAV (unmanned aerial vehicle), domestic robot and internet media data analysis need fast computing systems to perceive the real world.Hardware specialization in the form of field-programmable gate array offers a promising path towards major leaps in computational performance while achieving high-energy efficiency.As most of the computational workload can be converted to matrix multiplications, we adopt a matrix multiplier-based accelerator architecture. A common design that can efficiently handle variable network structures is needed.Converting convolutions to matrix multiplications (we will use ‘unrolling’ to describe it) is a good choice to handle broader spectrum of network structuresA performance of 77.8 Gflops is achieved. Compared with an Intel Xeon X5675 (3.4 Ghz, 6-core) processor, 3.54× speed-up is achieved. The energy efficiency is also better than an Nvidia K20 GPGPU by a factor of 4.7×.http://onlinelibrary.wiley.com/doi/10.1002/cpe.3850/full
71	내일 (토요일) 11:50분 입니다! 등록에 성공하신분들 축하드리고 모두 뵙겠습니다. 좋은 강의들도 있지만 무엇보다 서로 만나서 이야기하고, 아이디어를 나누고, 소셜하는 기회가 많으면 좋겠습니다.아쉽게 신청하신 모든 분들을 모시지 못해 죄송합니다. 두번째 모임에서는 더 많은 분들이 참여할수 있도록 노력하겠습니다.대기하신 분들중에 결제를 하신 부분은 제가 오늘 온오프믹스에 환불 요청을 하였으니 일주일 이내 모두 환불 처리 될것입니다. 	0	식사를 하고 참석하는게 맞을까여?	2	설레는 첫모임이군요!	2	내일 뵈요.	1	아쉽네요 ㅎㅎ	1	꼭 가고 싶었는데 다음기회를 노려야 겠네요	0	얼.... 이걸 이제야 봤네요 ㅠㅜ
2	데이터를 받아서 데이터 값에 의해 인공지능이 판단을 하여 양품, 불량을 골라주고 '차후 어떻게 될거다' 같은 예측을 하게 하려면 어떤 알고리즘을 사용해야 되나요?ㅎ	0	먼저 판단과 예측에 사용 할 데이터가 어떤것인가를 정해야 할것 같네요.	0	숫자입니다.예를 들면 양품기준이 10이면 10 이하로 내려가서 0으로 갈수록 품질이 좋고 10이상으로 계속 올라가면(20, 30,...) 품질이 안좋은 식이요.	0	Input 은요??	0	앞서 말씀해주신 분들 답변과 마찬가지로 input이 어떤가 중요 할 것 같네요. 단순히 참거짓 형태라면 회귀분석만 해도 대략적인 추이를 예상할 수 있지 않을까요
5	안녕하세요!딥러닝에 필요한 그래픽카드 장착된 일반 PC사려고 하는데 어떤게 좋은가요? 비교 구매하기 좋은 사이트를 알려주셔도 좋구요특정 모델 알려주셔도 좋아요!	2	얼마나 투자할수 있느냐에 따라 달라지지 않을까요? 일반 PC라 하니깐 이상하긴 한데 대부분 조립형 PC로 맞추시는 걸로 알고있습니다.	2	아는 사람중에 컴터 아는 사람 골라서 금액말하고 그래픽카드 지정해주고 알아서 해달라 하시면 되요	3	https://developer.nvidia.com/cuda-gpus여기 참고해보세요..  점수와 가격 사이에서 선택하시면 될꺼 같습니다..	1	일반pc라면 geforce 중에서 골라보시면 될꺼 같습니다.	1	텐서플로우 지원 GPU를 참고하셔서 최소 사양의 GPU를 체크하세요 텐서플로우가 지원하려면 cuda 일정 버전 이상 지원 그래픽 카드만 되는것으로 알고 있습니다.	2	어짜피 공부용이지?? 걍 가격대 성능비 짱인 960 또는 750 Ti 쓰삼... 공부하면서 딱히 느려서 못써먹겠다는 느낌 못받을꺼야. 980 1080은 돈이 남아 돌거나 회사에서 사주겠다고 하면 쓰고.... 1080을 질러서 나중에 공부 안하는 너를 발견한다면 나에게 아주 싼값에 넘기는 것도 아주 좋은 옵션이야 :)	1	현시점에서 적절히 타협한다 하시면 960 수준이 이상적일것 같습니다
5	안녕하세요. 새로 장비(gtx1080) 를 구입하여 삽질 중 혹 먼저 경험하신 분들이 계실가 여쭤봅니다.기존에는 ubuntu16.04, tensorflow 0.8,  cuda7.5, cudnn V4로 사용중이다가gtx1080 의 rc 드라이버를 설치하고,  cuda8을 써야하고 한다기에 cuda8, cudnnV5로 바꿨습니다. 드라이버와 다른사항들은 설치가 다 된것 같은데. 텐서플로에서  아래와 같은 에러를 주네요.  cudnnV4을 사용하게 되면 시작은 되지만 한 참 돌다가 matrix 연산 에러로 죽고,.. 물론 코드는 기존에 잘 동작하던 코드입니다.tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAMF tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAMF tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAMAborted (core dumped)해보신 분이 계실가요?	0	해보지는 않았습니다만,https://github.com/tensorflow/tensorflow/issues/2033에 tensorflow 이슈가 올라가 있네요. 댓에 있는대로 빌드를 해보시거나 아쉽지만 당분간 예전 드라이버를 쓰시는게 어떨까 싶네요..	0	저 같으면 rc 버전 모두 내리고 스테이블로 사용하겠습니다	1	소스를 직접 빌드하여 해결하였습니다.  중간에 험난한 과정을 거치긴했지만^^;;  조언 감사합니다.	0	와........ cuda8, cudnnV5 저도 성공했습니다... gtx 드라이버 부터 말썽을 피우더니... 하루종일 걸렸네요 ㅠㅠ
1	이미지 인식속도 빠른가요사과를 보여주면 바로바로 사과인지 알아보나요?어느정도 프로세서 성능가져야할까요	1	어디서부터 설명을드려야할지 ..음.. '사과인지 알아본다'라기보다는..물체에 대한 다양한 정보를 '학습'시키는 것이 관건입니다. 이때 프로세서의 성능이 좋을수록 학습이 좀더 빨라지고요.. 이미 구글등의 선구자들이 트레이닝 시켜놓은 뉴럴넷을 가져와서 활용만 하셔도 상당히 좋을 것 같습니다	3	전에 카이스트에서 노트북으로 사물인식하는 시연을 봤었는데요. 학습은 오래 걸려도 인식은 노트북의 GPU 로도 상당히 빠르더군요. 카메라로 동영상을 찍으면서 인식하는데 대단히 빨랐어요.	1	간단하게말하면 처음에는 줘도 뭔지를 모르는것을 기계한테 이게 무엇인지 학습시킵니다(머신러닝) 그러면서 초반에는 좀틀릴때도있고 맞을때도있는데 점점 그것을 학습시킬수록 정확도가 높아지는거에요 시간은 거의 문제가 되지않는다고 봅니다	0	맥스풀링이라고 사진특징분석하는게있는데 딱히 모르셔도되요
9	혹시 TensorFlow GPU 장비에서 성능 테스트 해보신분 계신가요?CPU 머신에서는 거의 CPU를 100% 사용해버리네요.소문에 의하면 GPU 장비로 넘어가면 성능차이가 수배에서 수십배 난다고 하는거 같은데요. ㅎㅎㅎ(그런데 K80 이나 K40이나 가격이 덜덜덜 하네요. 타이탄이 싸긴한데...)	4	아마존 g2.2xlarge에서 돌려봤는데 알고리즘마다 차이가 꽤 있겠지만 제가 돌린 텐서플로 번역 모델 예제는 생각보다는 그닥 빠르지 않았습니다. CPU보다 3배쯤 빠르더군요. 아마존 같은 공유 환경이 아닌 전용 하드웨어에서 bare-metal로 돌리면 더 차이가 나지 않을까 싶습니다.	1	(참고) 샘플을 돌려보니 집에 있는 K2000 은 CUDA Capability 가 3.5 가 안된다고 CPU 모드로 돌더군요. (K2000 은 3.0) TF 은 CUDA Capability 3.5 이상인 GPU에서만 동작합니다. (소스코드를 직접 고치면 될 수 있을 것 같지만요) 링크의 테이블 참고하세요 https://developer.nvidia.com/cuda-gpus	1	전 많이 차이가 납니다. 간단한건 맥북에 CPU 버젼으로 돌리고, 큰 건 서버에 Titan를 사용하는데, 거진 100배 차이가 나는 것 같습니다.	1	gpu에서 영상처리 열배정도납니다Gpu메모리에한번에 얼마정도올라가는가가 중요한것같습니다당연하겠지만 메모리관리 전략에 따라 많은차이가날거라고생각합니다
5	안녕하세요. 늦은 시간에 글을 올려 죄송합니다. sungkim 교수 님이 올려주신 강의를 보며 linear regression 예제 코드를 따라하고 있는 도중 이해가 안되는 부분이 있어, 다음 단계로 넘어가지 못하는 상황입니다. 올려주신 예제 코드에선 x 와 y 에 1, 2, 3 값을 주어 학습을 시키셨는데요. 호기심이 발동해 x와 y 에 각 100, 200, 300 을 주고 학습을 시켜봤습니다. 그런데 스텝이 진행 될 수록 cost, Weight, bias 가 모두 Nan으로 바뀌었습니다. 이유가 무엇인가요?...남은 하루 잘 마무리 하시길 바라겠습니다.!import tensorflow as tfx_data = [100,200,300]y_data = [100,200,300]X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)W = tf.Variable(tf.random_uniform([1], -1, 1))b = tf.Variable(tf.random_uniform([1], -1, 1))hypothesis = W * X + bcost = tf.reduce_mean(tf.square(hypothesis - Y))a = tf.Variable(0.1)optimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost)init = tf.initialize_all_variables()sess = tf.Session()sess.run(init)for step in range(2001):    sess.run(train, feed_dict={X: x_data, Y: y_data})    if step%20 == 0:        print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W), sess.run(b)	2	X랑 Y가 너무 커서 gradient descent에서 이동하는 step의 크기가 너무 커서, 적정 부분으로 수렴하지 않고 발산하면서 생기는 문제아닐까 싶네요. 학습과정을 보시면 W와 b가 한 step마다 +, - 를 반복하면서 절대값이 커지고 있죠. float32형에 담을 수 있는 숫자의 크기에는 한계가 있기 때문에 이 한계를 넘으면 inf(-inf)가 되고, 이 inf인 상태에서 계산을 해서 nan이 되었을 겁니다.	0	발산했네요
64	텐서플로우는 한번 돌려 보고 싶은데, docker 깔기도 귀찮다 하시며는, https://datalab.cloud.google.com/?name=udacity&cpu=2&memorygb=7.5깔고 나서, 뭐돌리지 하시며는, https://github.com/joelgrus/fizz-buzz-tensorflow/blob/master/fizz_buzz.py시작이 반이다?!	0	어! 죤!	2	"시작이 반이다" 라는 말같지도 않은 말을 남기고, 마음이 불편했다.시작이 어떻게 반이냐?? 시작은 시작이지...그러다가, 한참 생각뒤에, ReLU 가 보였다.그려, 시작(activated)은 반이다. ㅋ	1	음 현재 이용이 불가능하다고 뜨는데 이용 가능한 시간이 정해진것인가요?
2	http://ocean.kisti.re.kr/downfile/volume/esk/OGGHBK/2007/v26n3/OGGHBK_2007_v26n3_67.pdf
8	피처란 무엇인가? input image를 컴퓨터가 이해하기 쉽게 변환하는것을 피처라고 한다.영상과 음성은 다른 미디어지만, 딥러닝에서는 그냥.. 합쳐서 처리를 쉽게 해준다.멀티 모달리티딥러닝이 주로 하는역활은 서로 다른 도메인의 데이터를 합쳐서 피처를 찾아낸다.
16	같이 스터디 하면 좋은게 1달을 공부할거를 30분만에 배울수있다.대화를 통해서 많은 것을 배울수있다.
0	Tensorflow가 업데이트 되었다고 들었는데 이제는 ubuntu 16.04에서도 tensorflow를 사용할 수 있는건가요?	1	0.8에서도 몇가지 추가적인 과정을 거치면 가능했지만 이번에 공식적으로 지원합니다!	0	어...전 지금까지 16으로 업데이트해서 작동시켰는데 문제가 있었나요???
2	RX480이 199달러로 출시될 예정이라고 합니다.지금 GTX 1080이 비레퍼로 나오고, 1070은 아직 레퍼로만 출시해있는 상황에서1080을 비레퍼 혹은 레퍼로 구매를 한다 (레퍼 구매할 가능성이 큽니다)orRX480 2개를 사서 크로스파이어 작업을 해서 사용한다.그리고 1080이나 1070의 레퍼랑 비레퍼랑 가격 차이에 비해 성능차이를 생각했을때레퍼가 더 나은가요???둘의 성능차이가 크면 되도록 레퍼를 구매하려고 합니다.	0	tensorflow가 openCL 서포팅이 되나요? 안되는걸로 기억하는데 (지금은 될지도 모르겠네요) 안된다고 하면 AMD 선택지는... ㅠㅠ	0	저는 일단 opencl버젼으로 나오는 거 기대하고 amd sli구성해보려고 하고 있습니다!!	2	아마 AMD 에서 GPU 오픈 이라는 뭔 재단을 구성해서 이미 그런것들을 하고 있더라구요.. http://gpuopen.com/professional-compute/Caffe 지원하네요.	2	아직 RX480 크파에 관해서 벤치마킹 데이터도 안나와서 좀 더 지켜봐야 할것 같구요... 기본적으론 GPU 갯수와 성능이 전혀 비례하지 않기에 RX480 2개가 겨우 1080 조금 넘어서는 정도라면 차라리 1080 사는게 훨씬 나아요. 거기다가 OpenCL을 완벽히 지원하는 딥러닝 라이브러리도 아직 딱히 없어서...	1	또한 성능에 영향을 미치는 큰 요인중 하나가 그래픽 메모리인데, 1080의 8GB도 조금 작은 축에 속해서 비록 하시는 작업에 따라 갈리겠지만 성능을 잘 뽑을진 의문입니다.
2	Donam Kim 빛보다 빠른 배신.. 어버버.. 가입 승인 감사합니다. ^^	0	:) 배신이라뇨... 제가 의리 있게 가입승인 눌러 드렸구만ㅋㅋㅋ	0	카운터스트라이크 온라인 좀비 모드에 그런 표어가 있었습죠.한 때 그 게임 매니아 였던지라...	1	김선호 저도 선호님이 좋아요. 쿨럭...	0	헛 교수님 안녕하세요 :)
3	[질문] TensorBoard잘 실행되던 텐서보드가 anaconda로 tensorflow 설치 후 캡쳐화면처럼 아무것도 나타나지 않습니다. 화면도 좀 이상하구요.왜 그러는지 아시는분 계시나요..(자꾸 질문 올려 죄송합니다..)	1	질문 많이 올려주셔서 감사합니다. 혹시 맥인가요? CSS 버그가 있었는데 그 버전 사용중이신가요?	1	http://bibliotheque.tistory.com/83위 블로그 글에서 3.5 부분에 해당되는 작업(tensorboard복사)을 해보시기 바랍니다.	1	음 전 아예 tensorflow 자체가 먹통이 되었었는데Anaconda virtual env 에 다시 설치하니 다 살아났습니다0.8 부터인가 protobuf등 dependency도 같이 설치해주더군요Official tensorflow install page 에 anaconda env 파트를 따라했습니다
1	안녕하세요!얼마 안되는 자료를 바탕으로 dnn을 만들어보려고 시도한 코드입니다.(tensorflow -Tutorials-masters 라는 코드를 예제 삼아 짜보았습니다...)ValueError: Dimensions 30 and 20 are not compatible같은 에러가 나오는데 아래 코드 부분의 어디를 어떻게 수정 해야하는 것이며 무엇이 문제인 건가요??데이터는 아래의 것입니다.day temperture1 temperture2 temperture31 19.6  19.3 20.32 19.5  19.3 20.53 19.7  19.4 20.84 20.3  19.6 21.15 20.6  19.8 21.36 21  20.6 21.47 21.3  20.9 21.58 21.1  20.4 21.69 21.2  20.3 21.710 21  20.2 21.711 21.4  21         21.912 21.8  21.3 22.113 22.2  21.8 22.314 22.3  21.7 22.415 22.5  21.7 22.516 22.8  21.8 22.517 22.5  21.7 22.518 22.1  21.6 22.519 22.1  21.6 22.520 21.9  21.3 22.621 22.7  22.1 22.722 22.6  22.3 22.823 22.9  22.8 2324 23.1  23.2 2325 22.9  23.1 23.126 23  22.9 23.227 22.8  22.8 23.428 23.3  23.1 23.429 23.6  23.6 23.430 23.1  23.5 23.5코드는 아래의 것입니다.import tensorflow as tfimport csvimport numpy as nptrax = []tray = []tex = []tey = []with open('weather.csv','rb') as weather:  reader = csv.DictReader(weather)  for i in reader:    trax.append(i['day'])    tray.append(i['temperture1'])    tex.append(i['day'])    tey.append(i['temperture3'])    def weightsset(shape):    return tf.Variable(tf.random_normal(shape, stddev=0.01))def Model(x, w, w2, wf, keep,hidden):        x= tf.nn.dropout(x,keep)    h = tf.nn.relu(tf.matmul(x, w))        h = tf.nn.dropout(h, hidden)    h2 = tf.nn.relu(tf.matmul(h, w2))        h2 = tf.nn.dropout(h2, hidden)        pred = tf.matmul(h2, wf)        return predx = tf.placeholder("float", [None,30])y = tf.placeholder("float", [None,10])w = weightsset([30,30])w2 = weightsset([20, 20])wf = weightsset([20, 10])keep = tf.placeholder("float")hidden = tf.placeholder("float")pred = Model(x, w, w2, wf, keep, hidden)cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))trainop = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)predop = tf.argmax(pred,1)       with tf.Session() as sess:    sess.run(tf.initialize_all_variables())        for i in range(1000):        for start, end, in zip(range(0, len(trax), 30), range(30,len(trax),30)):   sess.run(trainop, feed_dict={x:trax[start:end], y:tray[start:end],keep:0.8, hidden:0.5})    print i, np.mean(np.argmax(tey, axis=1) == sess.run(predop, feed_dict={x:tex, y:tey, keep:1.0, hidden:1.0}))	0	w2 = weightsset([20, 20]) 이 맞나요? 30, 20 아니면 20, 30이 되어야할거같은데	0	안남혁님께서 말씀해주신것처럼 w와 w2의 차원을 일치시켜주셔야됩니다.	0	예제속에선 둘다 미묘하게 다르던데 어떤 의미를 지니고 있는건가요??	0	W2 = weight(앞에서 받아온것, 뒤에 넘겨줄것)이라고 이해하시면 좋습니다 그렇기에 전달되는 차원이 같아야 되고 주는 차원역시 뒤에와 같아야 합니다
2	수학이나 공학문제 경우 문제점만 정확히 인식해도 해결되는 경우가 많은데요. 인공지능도 그러겟죠? 현재 인공지능쪽에서 안풀리는 문제가 무엇인가요?저의 관심사중하나는 물리세계를 컴퓨터상에 만들어 놓고 시뮬레이션 하고인공지능이 공학이나 물리학 문제를 해결하거나 설계하게 만들고 싶은데요.	0	아뇨 문제점을 인식해도 변수가 너무많아서 계산이 안되요...	1	일단 현재 인공지능에서 제일 문제가 되는 부분 중 하나는 계산능력인 것 같아요! 문제를 정의했어도 충분한 시간 안에 계산할 능력이 안되는거죠!예를들어 요새 다시 떠오르는 Neural Network의 경우 아이디어가 나온건 굉장히 오래전이었지만 당시 컴퓨터의 계산 능력으로는 계산할 수 없는 양이어서 주목받지 못했죠.그러다가 계산능력이 많이 향상된 지금 다시 주목받기 시작한 겁니다.다른 댓글에서도 언급했듯이 1mm^3의 조그마한 우주를 시뮬레이션 해보고싶다고 했을 때, 어느 수준에서 구현을 해야 유의미한 우주가 구현될까요? 지금 우리의 물리학적 지식으로는 쿼크가 제일 낮은 단계의 입자인 것으로 알고있습니다. (원자가 더이상 분해되지 않는 기본단위로 알려졌었지만 더 나누어서 쿼크로 나뉜다는 것은 이젠 기본 상식이죠)그렇다면 쿼크레벨에서 구현하면 원하는 우주가 나올까요? 저는 환원주의에 대해 부정적인 입장이어서 나오지 않을 거라고 생각하지만 혹시나 또 모르겠습니다.만일 구현된다고 가정한다면, 몇 개의 쿼크 오브젝트가 구현에 필요할지도 문제입니다. 그 많은 수의 쿼크 입자를 시뮬레이션할 컴퓨팅 파워가 우리에게 있을지도 문제구요.	0	테니스 공이 어디로 떨어질 지는  원시인도 압니다또한 지구위성이 어떠한 궤도로 돌아야 할 지도 정확히 계산됩니다그러나 수 많은 각 개체에서 나타나는 위치와 속도의 불확정성원리에 의해 발생할 수 있는 리스크와 대비할 수 있는 비용 문제로 인해 해결할 수 없는 시나리오를 더욱 강화할 수는 있을꺼라는 생각이 듭니다그러나 안타까운 건 TRAINNING 데이터 수집이 무척 비쌀꺼라는거...
38	지난번에 Google의 자연어 처리 오픈소스인 SyntaxNet에 관한 소개를 올렸었습니다. 이번에는 해당 패키지를 Ubuntu 및 Mac에 설치하는 메뉴얼을 작성해보았습니다.	0	권수정	0	TF나 syntaxnet이나 설치하는게 만만한 일이 아니네요 ㅠㅠ 친절한 포스팅 감사합니다^^
5	SyntaxNet에대한 Docker 이미지가 있군요.간단하게 테스트해 볼 수 있는 환경구성으로 좋을 것 같습니다.
2	구글이 스타크래프트 인공지능만들어서 승부한다는데요 어떤 알고리즘써서 딥러닝 시킬 까요	2	역시 강화학습이지 않을까요알파고때는 경우수가 많은 하나였지만이번엔 이동 공격 생산 뭐 경우 수는 각 유닛마다 많지 않은 여러 유닛을 학습할 거 같아요처음 시작시에는 이동 생산 캐기 그리고 유닛 만드는 커맨드센터만 있는 5개의 개체지만 점점 개체가 많아지면서 복잡해지지 않을까요?그냥 상상만 해보았습니다 ㅎㅎ	0	컨트롤하는 능력을 상대선수에게 맞추기 위해 로봇 컨트롤을 학습시킨다는 설도 있던데	0	컨트롤은 당연히 컴퓨터가 잘할 수밖에 없는 영역이구요(apm으로 따지면 ㅎㄷㄷ할테니)바둑과 달리 상대방이 뭘 하고 있는지 알 수 없고 극히 제한된 정보만으로 파악하고 대응하는 걸 잘할 수 있느냐가 관건이 되겠죠	1	상대방에 대한 정보가 파악되지 않는 초반 빌드의 경우 유전알고리즘처럼 인공지능끼리 경쟁시켜서 최적 조합을 찾는 식이 되고 중후반은 알파고와 비슷한 방식으로 가지 않을까 싶습니다. 초반엔 cost function을 자원이나 고급테크 유닛이 얼마나 빨리 많이 생산되는지로 잡으면 될 것 같은데, 중후반부에는 아군 피해와 적군 피해를 추정하는 방식을 써야 하지 않을까 싶네요.	0	컨트롤만 극강이라면 극초반러쉬로도 승부가 가능할 것도 같구요	1	컨트롤이 극강이라... 초반에... 일꾼 러시 가면 무조건 이길듯 합니다.	0	이게 딥러닝을 썼다! 라고 광고하려면, 게임의 컨트롤이나 유닛 특성 등에 대한 정보를 사전에 쥐어주지 않고 cost function만으로 최적화가 되는 걸 보여줘야 할 것 같은데 과연 어떻게 할런지 궁금하긴 합니다. 컨트롤을 사람의 키보드·마우스 움직임을 모사하는 방식으로 갈지 아니면 별도 API를 쓰는 방식으로 갈지도 궁금하고요.	0	찾아보시면 딥마인드에서 알파고 이전에 벽돌깨기 게임을 학습시킨게 있어요. 논문도 있고요.그 방법일 듯 합니다.	0	스타크래프트는 1:1 로 인공지능이 최고수 프로게이머 이길수 없음 정보가 제한되고 뭐하고 있는지도 알수없고 해킹하지않는한 인공지능도 어떻게 할수 없음 바둑은 판이 다 보이고 얼마나 프로게이머 수준의 인공지능 개발이 가능한가가 흥미로울듯 하네요
0	감사합니다
1	tf.Print도 하나의 Operation이라고 생각했습니다.그래서 아래와 같이 코드를 작성했는데. 에러는 발생하지 않는데.동작하지 않네요.노드의 연결이라는 관점에서 동작해야 할 것 같은데 안되네요.y_ = tf.placeholder(tf.float32, [None, 10])y_ = tf.Print(y_, [y_], message="y_ : ")혹시, 이유를 아시는분 계신가요?(다른 방법으로 출력하는 방법은 알고 있습니다.)보충 설명으로 아래와 같은 경우는 잘 됩니다.y = tf.nn.softmax(tf.matmul(x, W) + b)y = tf.Print(y, [y], message="y : ")	1	tf.Session.run()에서 실행해 주어야하지 않을까요?
124	[6/18 첫 오프모임 홍보 #2]알차고 유익한 강의, 구글 코리아 후원의 모두가 탐내는 선물, 간단한 점심(간식)과 저녁 제공, 무엇 보다도 여러분같은 좋고 재미있는 분들이 많이 모이는 꼭 가봐야하는 모임입니다. 이 모임의 신청은 한국시간 6월 2일 오전 10시부터 선착순으로 아래 링크에서 가능합니다. 광클릭 연습 필수. :-)http://onoffmix.com/event/69537그럼 성공적으로 참여 신청하고 6/18일 즐겁게 뵙도록 하겠습니다.TensorFlow-KR 운영진 드림	2	감사합니다~	2	Yoon Seok Heo 형 같이가요!	3	기대 됩니다!!	3	혹시 발표 자료도 공개 되나요?	0	와!!!!! 반드시 가야할 곳이 또 생겼군요 ㅎㅎㅎ^^	1	아... 꼭 참석하고 싶었는데 ㅠ 하필 또 결혼식이 잡혀있는 날이라...	0	기대가 아주 큽니다	1	Ad 트랙 신청하고 기본트랙도 구경해도 되나요? ㅎㅎㅎ?? 너무 욕심인가요..^^;;	2	일단 고고합니다	2	6월18일에는 학교 기말시험있어서 못가네요ㅠ 다음기회에는 꼭 참석하도록 하겠습니다^^	2	기대됩니다! 제 실력에 맞을지는 모르겠지만 꼭 참여하겠습니다.	1	ad트랙은 20명.. 빡세네요 ㅠㅠ	0		1	손상현	0	... 기말고사 꼬인 주 토요일이라... 중간고사 꼬인 주 토요일에 커널스터디 ot 갔다가 시험 말ㅇ...	0	기본 마감 됏던데 추가로 해도 되는 건가요?	0	ㄴ 일단 접수가 되길래 기본 으로 신청 해서 결제 해두 었습니다	0	헐~ 뻘짓하다가 신청을 조금 늦게 했더니 벌써 마감.....tensorflow에 대한 열기를 바로 반영하네요.....정규 시간은 참석 못해도, 뒷풀이(?)에는 참석해서, tensorflow korea의 글짱님들 뵙고, 담소(?) 나누는 정도는 가능하겠지요?	2	혹시 아이를 데리고 가면 어떨까요? '아빠가 이런거 해'하고 보여줄 수 있을 것 같아서요	2	ㅠㅠ 다음에는 꼭 성공할꺼에요 ㅠㅠ	1	이번 오프라인 모임 내용을 동영상/자료 공개 하실 예정 인가요?	0	혹시 주차가능한가요? ^^
52	TF 즉시 실행모드. Reinforcement learning 등 다양하게 사용될수 있을듯 합니다.https://github.com/tensorflow/tensorflow/pull/2747곧 merge될듯 합니다.	0	Interactive Session과는 어떤 차이점이 있는건가요?	1	세션을 통하지 않고도 바로 실행된다는  의미가 아닌까요?
37	안녕하세요. 최근 딥러닝 열공중인 게임 개발자입니다. 다름이 아니고 유투브에 머신 러닝을 통해 슈퍼 마리오를 플레이 하는 동영상이 있는데요(https://www.youtube.com/watch?v=qv6UVOQ0F44), 이걸 텐서플로우로 구현한다면 어떤식으로 해야 할지 조언을 듣고자 글을 올립니다. 게임 유져들의 행동으로 부터 학습하여 성장하고 반응하는 몬스터의 AI를 딥러닝기법으로 온라인 게임에서 구현하는 것이 목표인데요... 의견 주시면 감사하겠습니다.	4	http://keunwoochoi.blogspot.kr/2016/06/andrej-karpathy.html?m=1혹은http://www.danielslater.net/2016/03/deep-q-learning-pong-with-tensorflow.html?m=1참고해보세요.	2	혹시 https://github.com/SimonRamstedt/ddpg 도 참고하시길.
28	다양한 ML/DL 툴들입니다. 단연 TF가 별과 포크에서 최고힙니다.
51	구글 딥마인드가 인공지능의 반란(?)에 대응하기 위한 수단으로서 비상버튼 알고리즘을 개발했다는 소식입니다.링크의 논문에 설명된 원리는 인공지능의 행동을 강제로 변경하는 트리거를 내장시키고 이를 기계가 인지하지 못하게 하면서 트리거 동작시에 기계 스스로 그렇게 생각했다고 여기게끔 만드는것이라 하는군요. (미드 퍼슨 오브 인터레스트 제작진의 인사이트에 다시한번 경악하게 됩니다.)	10	이 논문을 인공지능이 읽어보지 않을까요?
56	이번 Pycon2016 중 머신러닝, 딥러닝 과 관련있는 Talk와 Tutorial 목록을 올려 두었습니다. 유투브 링크, 슬라이드 링크가 걸려있습니다. 도움되셨으면 좋겠습니다.
18	안녕하세요~ "모두를 위한 머신러닝/딥러닝 강의(https://hunkim.github.io/ml/)"를 들었는데요. 다음으로 들으면 좋은 강좌가 있나요? 그리고 저는 한국어 형태소 분석기를 만들어 보고 싶은데요. 혹시 참고 할만한 강좌나 논문이 있을까요? 전에 CRF 로 형태소 분석기를 만들어 본 적은 있어서요. 이걸 RNN 이나 CNN 으로 만들어보고 싶은데 어떻게 해야 될지 모르겠네요.ps. 보너스 강좌는 아직 안 올라 온거죠? 맨 마지막 강좌에서 가입은 했는데, 광고 메일만 계속오고 그 다음으로 어떻게 해야 될지 모르겠어요.	13	제가 6월 중까지 출장중이라... :-) 보너스 강좌는 곧 올라고오 시즌2도 곧 시작할 예정으로 보입니다.
36	잘 짜여진 파이썬 코드를 보고 싶을때 여러분들은 어떤 코드를 읽으시나요? TensorFlow를 좀 깊이 이해해 보고 싶으면 어떤 좋은 방법이 있을까요? 이 (개인적으로) 이 두가지를 동시에 하는 방법은 https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/ops코드를 하나씩 읽어 보는 것입니다. 마침 0.9도 나왔다고 하는데 1.0이 나오기 전에 Python부분만 이라도  다 한번씩 읽어 보려고 합니다.	3	C++ 소스 코드 추천	0	텐서 플로 C++코드 아름답습니다. 끝없이 이어지는 심플 펑션들!
0	인간이 사물이나 추상적인 개념화하는 과정이 멀까요사과는 색깔 모양 맛 등이 잇고 인간이 부여한 이쁘다 이런 표현도 잇고민주주의라는 개념같은건 어떻게 개념화 시킬까요	0	정말 딥러닝 이십니다
82	PyCon 2016에서 다룬 TensorFlow비디오입니다. 저도 보는 중인데 강의보다는 같이 코드를 다루고 바로 실습도 해보면서 이야기합니다.처음 해보시는 분들에게 많은 도움이 될것 같습니다.	0	좋은 자료 감사합니다~	0	공유 감사합니다.	0	감사합니다 교수님	0	감사해요~	0	잘보겠습니다
85	면접에서 텐서플로우를 이용해 문제 해결하는 과정인데 잼있네요~^.^ 마지막 제프딘의 조언까지ㅎ 	0	ㅋㅋ 진짜 멋지네용.. 출근버스에서 터짐..	0	마지막에 제프딘의 깨알같은 코멘트 ㅋㅋ
28	안녕하세요. 4월과 5월 서울대학교에서 딥러닝(각각 2일 풀타임) 실습과 이론을 병행한 한국인지과학협회 주관 강좌가 있었는데요. 늦었지만, 혹시 이번 목~금에 대전 KAIST 에서 있을 딥러닝 실습 3차 강의 망설이시는 분들이 있을가 하여, 지난 2차 실습 강의 후기를 올려봅니다.   일시: 5월20일(금) ~ 5월21일(토)장소: 서울대 301동주제: 딥러닝 실습 일단 유료 강의이고, 제가 들은 강의는 2회차 강의 였었습니다. 전체 등록 가능 기간 중, 초반 1~2주에 선 사전등록을 하면 약간(?) 저렴합니다. 저의 경우, 4월 즈음 1회차때 5명의 팀원들을 데리고 사전등록 기간 내에 유료 등록 하려 했었는데요, 그때는 이미 수강인원이 조기 초과 되어 등록할 수 없었던 경험이 있습니다.  그때 서서라도 들을테니 교육좀 듣게 해달라고 제가 사정 메일을 보냈던 기억이 있었네요.여튼, 신청자가 많아, 2차 강의를 열겠다고 답변 메일을 받았었고, 2차 강의는 개설 되자 마자 수강 등록을 했던 기억이 있습니다.어느덧 3차 강의도 지방에서 열리게 되었네요. (http://nacsi.kr/tutorial/tutorial13-3.html)강의는 오전은 이론 수업이고, 오후는 실습 실험입니다. 오전 수업은 각각 한번은 서울대학교 장병탁 교수님이, 또 한번은 카이스트의 김준모 교수님이 강의를 해 주십니다. 오후 실습은 첫날은 Theano 기초와 caffe 를, 그리고 또 하루는 Theano 심화와 TensorFlow 를 다룹니다. (3차 강의는 Theano 심화 대신 Torch7 이 포함되었네요.) 개인적으로... 여러 툴을 비교해가며 빠르게 훓어 보는게 더 의미가 있을거 같아서... 3차 강의 커리큘럼이 더 마음에 드는거 같네요.수업은 오전 수업이 쉬는시간 없이 2시간 스트레이트 강의라 다소 초 집중이 필요하고 그로 인하여 오후에는 다소 피곤해 질 수 있다는 점 빼고는 100점만점에 99점 정도를 주고 싶은 명 강의였었습니다.특히, 두분 교수님들의 강의는 박사과정들에게는 죄송하지만, 뭔가 차원이 다른 인사이트 까지를 느낄 수 있는 매우 좋은 강의 였었습니다.2시간 동안 설명 주시는 슬라이드 자료가 거의 150페이지가 넘는 자료 였던 것 같습니다. History 부터 깊은 이론 까지, 어찌보면 매우 깊은 내용 까지 최대한 설명하시느라 매우 템포가 빠르게 진행되는데요..이 때문에, 완전 기본 지식이 없으신 분들이 듣기에는 다소 내용이 빨라서 이해하는데 다소 힘들 수 있다는 생각이 듭니다.저의 경우는 컴퓨터 전공에 빅데이타 개발 실무 일을 하고 있는 전형적인 개발자 직군 종사자 인데요. (AI 나 인공지능 자체는 학부나 대학원때 수업을 들었던 적이 있긴 하지만..)전통적인 머신러닝은 실무에서 다루고 있기도 하고, 딥러닝 쪽은 성김 교수님 강좌와 Andrew Ng 교수님 코세라 강의로 사전 이론 공부를 한 상태에서, TensorFlow 또한 실무에서 일부 다뤄본 경험이 있습니다.  이상태에서 이번 강의를 들어서 인지, 처음 부터 끝까지 빠르게 다시 한번 훓터 주시니 일전에 약간 이해 못하고 넘어갔던 부분도 번쩍 하고 이해가되는 순간이 여러번 있었던 매우 유익한 시간이었네요.실습은 제가 Tensorflow 위주로만 경험이 취우쳐 있어, 다른 툴들에 대하여 항상 궁금한점이 많았었는데요. 다른 툴들의 장단점을 몸소 느껴 볼 수 있어, 좋았었습니다.특히 TensoFlow를 좀더 실무적으로 활용할때 참고할만한 여러 Tip 들도 소개가 되어, 매우 유익했습니다. 어쩌다 보니 후기가 칭찬 일색이 되어 버렸네요. 중간에 몇번 언급한 것처럼, 굳이 안좋은 부분을 지적 드리자면, (1) 사전 지식이 없이 수업을 들으신다면,머리에 과부하가 생길 수 있다는 것과 (2) 실습환경이 한때 폭주하여, 약간 실습 지연이 첫날 좀 있었다는 것 정도 인것 같습니다.  개인적으로, 이분야에 실무를 하시고 계신 현업 분들은, 짧은 시간에 알찬 교육들이 많지 않으므로, 서울 계시더라도 기차타고 가셔서 1박 하시고라도 꼭 볼만한 교육이라고 추천 드리고 싶습니다.ps. 저는 아래 강좌의 주최측과는 아무런 관련이 없습니다. ^^	3	사전 이론 공부의 중요성. :-)	0	조만간 한번 놀러가야겠네요 ^^
3	[반골 분석가의 의문 2]저는 IT 선진국이라는 곳에서 매번 새로이 발표되는 contents를 해석할 수 있는 또는 해석하여 전달할 수 있는 것처럼 보이고 이를 논의없이 받아 들이는 KR에 반합니다. 그래서 이런 글 계속 올릴 지도 모릅니다.역시 먼저 아래를 보시죠...------------------------------------------------import tensorflow as tfimport numpy as npimport tensorflow as tfimport numpy as npIn [24]:xy# unpack=True이면 반환되는 numpy array가 transpose된다.xy = np.loadtxt('train.txt', unpack=True, dtype='float32')# #x0 x1  x2  y   [A B C]# 1   2   1   0   0   1# 1   3   2   0   0   1# 1   3   4   0   0   1# 1   5   5   0   1   0# 1   7   5   0   1   0# 1   2   5   0   1   0# 1   6   6   1   0   0# 1   7   7   1   0   0print (xy), type(xy)[[ 1.  1.  1.  1.  1.  1.  1.  1.] [ 2.  3.  3.  5.  7.  2.  6.  7.] [ 1.  2.  4.  5.  5.  5.  6.  7.] [ 0.  0.  0.  0.  0.  0.  1.  1.] [ 0.  0.  0.  1.  1.  1.  0.  0.] [ 1.  1.  1.  0.  0.  0.  0.  0.]] <type 'numpy.ndarray'>uppack=True로 하는 이유보통 x0, x1, x2, ya, yb, y3 = np.loadtxt('train.txt', unpack=True, dtype='float32')로 하여 각 변수를 직접 대입하는 경우가 많기 때문이다.In [4]:xy_pack = np.loadtxt('train.txt', unpack=False, dtype='float32')print (xy_pack)[[ 1.  2.  1.  0.  0.  1.] [ 1.  3.  2.  0.  0.  1.] [ 1.  3.  4.  0.  0.  1.] [ 1.  5.  5.  0.  1.  0.] [ 1.  7.  5.  0.  1.  0.] [ 1.  2.  5.  0.  1.  0.] [ 1.  6.  6.  1.  0.  0.] [ 1.  7.  7.  1.  0.  0.]]unpack=False로 하는 경우이때, 각 벡터는 하나의 관측치가 된다.python의 list의 element는 R의 vector와 달리 다양한 type을 허용한다.이는 각 list가 특정 변수의 모든 관측치를 나타내기(vector) 보다는모든 input과 output에 대한 instance를 표현하는데 적당한 자료형이라는 것이다.결국 numpy.array의 row list는 변수를 나타내기 보다는 관측치를 표현하는 것이 적절하다.이제 입력 데이터와 종속 데이터를 분리하자.In [5]:x_data = np.transpose(xy[0:3])y_data = np.transpose(xy[3:])print(x_data); print(y_data)[[ 1.  2.  1.] [ 1.  3.  2.] [ 1.  3.  4.] [ 1.  5.  5.] [ 1.  7.  5.] [ 1.  2.  5.] [ 1.  6.  6.] [ 1.  7.  7.]][[ 0.  0.  1.] [ 0.  0.  1.] [ 0.  0.  1.] [ 0.  1.  0.] [ 0.  1.  0.] [ 0.  1.  0.] [ 1.  0.  0.] [ 1.  0.  0.]]각 data는 각 시행의 input 과 output을 나타내는 행 벡터로 표현되었다.In [10]:x_data = xy_pack[:,0:3]y_data = xy_pack[:,3:]print(x_data); print(y_data)[[ 1.  2.  1.] [ 1.  3.  2.] [ 1.  3.  4.] [ 1.  5.  5.] [ 1.  7.  5.] [ 1.  2.  5.] [ 1.  6.  6.] [ 1.  7.  7.]][[ 0.  0.  1.] [ 0.  0.  1.] [ 0.  0.  1.] [ 0.  1.  0.] [ 0.  1.  0.] [ 0.  1.  0.] [ 1.  0.  0.] [ 1.  0.  0.]]결국 쓸데없이 data를 transpose할 필요 없다.input과 parameter의 type definitiontf.placeholder 변수형과 data의 구조만 정의tf.Variables 변수형과 초기값을 주어 구조는 자동으로 포함됨In [17]:#tf Graph Inut - type과 변수의 수만 정의해주어 재활용 가능하도록 한다.X = tf.placeholder("float", [None, 3])Y = tf.placeholder("float", [None, 3])# Set Model Weights - 3개의 입력변수로 부터 3개의 범주를 추정하는 모델W = tf.Variable(tf.zeros([3,3]))print (W)<tensorflow.python.ops.variables.Variable object at 0x7f8210649d50>tf.placeholder 변수형과 data의 구조만 정의tf.Variables 변수형과 초기값을 주어 구조는 자동으로 포함됨In [15]:# Construct Modelhypothesis = tf.nn.softmax(tf.matmul(W, X))# Cross Entropycost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), reduction_indices=1))--------------------------------------------------------------------------------------여기서 이상한 점 못 느끼셨나요?저는 이상했습니다.W는 3x3 매트릭스이고,  X는 None x 3 매트릭스 입니다.수학적으로 당연히 inner product가 불가능합니다.오히려, tf.matamul(X, W) 였었으면 이해하겠는데..... 에러가 날 뿐입니다.그럼 이유를 알아야 하겠습니다. 이유는 비판을 위한 이유가 아닌 왜 그렇게 구현했으며, 그렇게 구현한 사상의 basis는 무엇일까를 이해하는 근원적인 자유입니다.추적해 보겠습니다. 근데 모르겠네요.... ㅠㅠ....---------------------------------------------------------------------------------------tf.placeholder 변수형과 data의 구조만 정의tf.Variables 변수형과 초기값을 주어 구조는 자동으로 포함됨In [56]:# Construct Modelhypothesis = tf.nn.softmax(tf.matmul(W, X))# Cross Entropycost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), reduction_indices=1))# hypothesis = tf.nn.softmax(tf.matmul(X. W) # SyntaxError: invalid syntaxW는 3 x3 미트릭스, X는 ? x 3 매트릭스. matmul(W, X)가 가능한가?이하에서 이를 확인해보자.In [61]:# 2-D tensor `a`a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])# 2-D tensor `b`b = tf.constant([7, 8, 9, 10, 11, 12, 13, 14, 15], shape=[3, 3])c= tf.matmul(a,b); print c# d = tf.matmul(b,a); print d # [3, 3] %*% [2, 3] generating error# 이해하고 있는  boundary 내에서 tf의 data object는 ndarray였다. 이것으로 판단하자.a = np.array([range(12)])a.shape=(3,4); print ab = np.array([range(21,100, 7)]); b.shape = (4,3); print bc= tf.matmul(a, b); print c # TypeErrorc= tf.matmul(b, a); print c # TypeError# 이건 도데체 뭐지요? 둘다 error가 날 이유가 없는데...............ㅠㅠ.# 말도 안되는 식을 만들어 보겠습니다. (3*4) x (2*3) - 이거 비슷한거 해봤는돼...ㅠ...ㅠ.Tensor("MatMul_38:0", shape=(2, 3), dtype=int32)[[ 0  1  2  3] [ 4  5  6  7] [ 8  9 10 11]][[21 28 35] [42 49 56] [63 70 77] [84 91 98]]---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)<ipython-input-61-5cfb7304b786> in <module>()     12 b.shape = (4,3); print b     13 ---> 14 c= tf.matmul(a, b); print c # TypeError     15 c= tf.matmul(b, a); print c # TypeError     16 # 이건 도데체 뭐지요? 둘다 error가 날 이유가 없는데...............ㅠㅠ./home/baram/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in matmul(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)   1207                                    transpose_a=transpose_a,   1208                                    transpose_b=transpose_b,-> 1209                                    name=name)   1210    1211 sparse_matmul = gen_math_ops._sparse_mat_mul/home/baram/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc in _mat_mul(a, b, transpose_a, transpose_b, name)   1176   """   1177   result = _op_def_lib.apply_op("MatMul", a=a, b=b, transpose_a=transpose_a,-> 1178                                 transpose_b=transpose_b, name=name)   1179   return result   1180 /home/baram/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)    528             for base_type in base_types:    529               _SatisfiesTypeConstraint(base_type,--> 530                                        _Attr(op_def, input_arg.type_attr))    531             attrs[input_arg.type_attr] = attr_value    532             inferred_from[input_arg.type_attr] = input_name/home/baram/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc in _SatisfiesTypeConstraint(dtype, attr_def)     59           "DataType %s for attr '%s' not in list of allowed values: %s" %     60           (dtypes.as_dtype(dtype).name, attr_def.name,---> 61            ", ".join(dtypes.as_dtype(x).name for x in allowed_list)))     62      63 TypeError: DataType int64 for attr 'T' not in list of allowed values: float16, float32, float64, int32, complex64, complex128윽 죽겠습니다.... 계속 이성에 마비가 오네요....저 솔찍히 물리학과 졸업했는데, 양자역학, 고전역학, 다 이해하는데, ternsor를 이해못해서 나는 아닌갑다하고 포기했느데, 또???	1	유튜브에 가서 다시 동영상 보시면 w,x는 오타고 tf.matmul(x,w) 자막이 있습니다.그리고 pycharm에서 실행하는 부분에서 tf.matmul(x,w)로 되어있습니다	0	결국 Google에서는 공개하는 코드 작성자가 간단한 Linear Algebra도 헷갈리는 것이고 자체 테스트도 제대로 안한 거군요. 당분간 Tensorflow에 기반한 결과는 그 신뢰성을 심각하게 의심해야 할 것 같네요.	3	"TypeError: DataType int64 for attr 'T' not in list of allowed values: float16, float32, float64, int32, complex64, complex128" 이부분은 op가 int64를 지원하지 않기때문입니다. 제가 만든 PR에서 문서가 수정되었습니다. https://github.com/tensorflow/tensorflow/pull/2435	2	결국 합리적이어야 하는 부분은 알아서 수정하면서 하면 되겠군요..ㅎㅎ
4	인공지능이 무서워 질때는 사물을 개념화하는 능력이라고 생각하는데요사과라면 사과가 무엇인지 이해하고민주주의가 뭔지 인간처럼이해하면 상당히 무서워질거라고 생각합니다	0	모든 정보를 요약해서 구조화하고 자기만의 포로토콜과 확률에 기반하여이해하지 않을까요? 기계가 사람의 사사로운 탐욕이나 감정, 부패라는게 있을수 있냐에 따라 달라질것같아요
8	안녕하세요 완전 극초보입니다. 가입해서 눈팅만하다가 문뜩 궁금한게 있어 질문드립니다. 텐서플로우가  cpu버전 gpu버전 따로인데 이 두개가 어떤 성능적인 차이가 있는가요? gpu의 병렬처리보다 cpu의 처리 속도는 얼마나 뒤쳐져 나오는가요???극초보인지라 살살 다뤄주시길 바라며 답변해주신다면 정말 감사하겠습니다!	1	Cpu가 걸어다니는 거라면Gpu를 사용하게되면자동차를 타고다니는 느낌입니다	1	저도  cpu 버전을 사용해보지 못했으나, 인터넷 검색하지면 알 수 있겠지만, 상황에 따라 100배 정도 차이가 나는 것으로 알고 있습니다.gpu는 벡터(동일한 data type) 연산에 특화된 processor이므로 이해가 갈 듯 합니다. gtx960 4MB 정도 투자하시죠.....^^	1	저도 tf, 딥러닝 뉴비라 아직은 cpu로하고있는데 윗글들 보니 gpu를 사야겠네요. :)	3	cpu가 대학생 1명이고 gpu가 중학생 1000명일 때 구구단을 수만번 계산했을때를 상상하시면 됩니다	3	보통은 30배 정도 차이로 얘기합니다케바케이긴 하지만요	5	같은작업을했을때 cpu로 80분걸리는작업을 gpu는 1분30초? 정도걸렸어요	1	모델과 데이터 양에 따라 체감하는 성능 차이는 다를꺼 같네요 학습용이라면 클라우드로 한두번 실행해 보면 되니 별 필요 없을 것 같습니다	0	제 경우에는 맥북프로(2015년 하반기) CPU 보다 아마존 GPU가 5배 정도 빠르던데요. (텐서플로우의 Sequence-to-Sequence Models 튜토리얼을 돌려봤습니다.)비싼데 생각만큼 빠르진 않더라구요. 5배차이니까 요새는 그냥 맥북에서 돌리고 있어요. 대신 팬 소음이ㅠㅠ
0	[NEW] TensorBuilder is light wrapper over TensorFlow that enables you to easily create complex deep neural networks using the Builder Pattern through a functional fluent immutable API. 
79	Tensorflow 0.9 RC가 나왔네요. Python 3.5와 OS X에서의 GPU 가속을 공식 지원하고, 이제 FP16 연산 및 3D Convolution, HDF5을 지원하며 Tensorboard에 많은 기능이 추가되었네요 :)	0	다운 받아 사용해봐야 갰습니다. 이제 곧 1.0이 나오겠습니다.	0	!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!	2	여담으로 FP16을 TF에서 이렇게 빨리 지원해줄줄 알았더라면 기다렸다가 1080을 살걸 그랬어요... 얼마전에 타이탄 구매했는데ㅜㅜ	0	ㅠㅠ 아직 0.7쓰는데 update속도 빠르네요	1	0.8로 1주일전에 업데이트했는데..
3	안녕하세요현재 word2vec 코드구현 후 진행중입니다.king-man +woman = queen 결과를 재현하고 싶은데 이게 마음대로 잘되지 않네요 ㅜㅜtext8 데이터셋을 이용하여 skip-gram으로 해당 단어로 부터 거리가 2 or 4 or  6인 단어들을  예측하게하고 옵티마이저는 AdagradOptimizer 를 사용하였구요 iteration은 백만번 동안 64개의 배치 데이터로 학습하게하였습니다. 또cbow로도 해당 단어로부터 거리가 1 or 2 or 4 를 보도록 윈도우를 만들어 해당 단어를 예측하게 하였을때도 king-man +woman = queen 재현이 잘 안되가 않습니다.similar 단어는 비슷하게 나오는 것 같습니다.gensim으로 파라미터 수정없이 그냥 학습시켰을때는 king-man +woman = queen 이 나오더라구요...다른 분들은 king-man +woman = queen 재현에 성공하셨을때 각 파라미터를 어떻게 설정하셨었나요?
4	텐서플로우로 구현하다 궁금한 점이 생겨 질문드립니다.예전에 옆 그룹(AI Korea 그룹) 에서 텐서플로우가 느린 이유는 conv2d와 같은 op에 [N, H, W, C] 형태의 텐서를 입력을 받기 때문이라는 글을 읽었습니다.이를 해결하기 위해 op에  [N, C, H, W] 형태의 텐서를 입력값으로 주고 data_format argument에 "NCHW"를 주면 해결이 되는데, 문제는 batch_norm이네요.batch_norm 같은 경우 명시적으로 data_format를 지정해줄 수도 없어서 자동으로 [N, H, W, C]의 포맷으로 처리를 하는 것 같아서 dimension 에러가 뜨는데 이를 해결하려다 보니 다시 transform을 해야 할 상황인데요.. 이러면 batch norm을 할때마다 오버헤드가 발생하지 않을까 싶은데 이를 해결할 수 있는 방안이있을까요?	0	일단은 https://github.com/tensorflow/tensorflow/pull/1759 를 보면 아직까지 크게 진전된 부분은 없는거 같긴한데, 음 잘 모르겠네요.. ㅠㅠ
9	드뎌 tensorflow도 설치하고,jupyter notebook을 서버로 운용하면서, 궁금하고 하고 싶었던 내용을 첫 시도하고 있습니다.Sung Kim 교수님의 강의를 들으면서특히 실습 자료에 있어, training data에 대한 transpose를 할 이유가 없는데 왜 할까 라는 궁금증이 있었는데,역시 할 필요가 없는게 아닐까 생가드네요..더 공부를 하면 알 수 있을까요?실제 대규모 data에서 data를 transpose한 다는 것은 매우 많은 시스템 리소스를 요구하는 일입니다. - 특히나 저장소 공간에 있어서는...일단, 아래를 보시죠.In [1]:import tensorflow as tfimport numpy as npIn [2]:# unpack=True이면 반환되는 numpy array가 transpose된다.xy = np.loadtxt('train.txt', unpack=True, dtype='float32')# #x0 x1  x2  y   [A B C]# 1   2   1   0   0   1# 1   3   2   0   0   1# 1   3   4   0   0   1# 1   5   5   0   1   0# 1   7   5   0   1   0# 1   2   5   0   1   0# 1   6   6   1   0   0# 1   7   7   1   0   0print (xy)[[ 1.  1.  1.  1.  1.  1.  1.  1.] [ 2.  3.  3.  5.  7.  2.  6.  7.] [ 1.  2.  4.  5.  5.  5.  6.  7.] [ 0.  0.  0.  0.  0.  0.  1.  1.] [ 0.  0.  0.  1.  1.  1.  0.  0.] [ 1.  1.  1.  0.  0.  0.  0.  0.]]uppack=True로 하는 이유보통 x0, x1, x2, ya, yb, y3 = np.loadtxt('train.txt', unpack=True, dtype='float32')로 하여 각 변수를 직접 대입하는 경우가 많기 때문이다.In [4]:xy_pack = np.loadtxt('train.txt', unpack=False, dtype='float32')print (xy_pack)[[ 1.  2.  1.  0.  0.  1.] [ 1.  3.  2.  0.  0.  1.] [ 1.  3.  4.  0.  0.  1.] [ 1.  5.  5.  0.  1.  0.] [ 1.  7.  5.  0.  1.  0.] [ 1.  2.  5.  0.  1.  0.] [ 1.  6.  6.  1.  0.  0.] [ 1.  7.  7.  1.  0.  0.]]unpack=False로 하는 경우이때, 각 벡터는 하나의 관측치가 된다.python의 list의 element는 R의 vector와 달리 다양한 type을 허용한다.이는 각 list가 특정 변수의 모든 관측치를 나타내기(vector) 보다는모든 input과 output에 대한 instance를 표현하는데 적당한 자료형이라는 것이다.결국 numpy.array의 row list는 변수를 나타내기 보다는 관측치를 표현하는 것이 적절하다.이제 입력 데이터와 종속 데이터를 분리하자.In [5]:x_data = np.transpose(xy[0:3])y_data = np.transpose(xy[3:])print(x_data); print(y_data)[[ 1.  2.  1.] [ 1.  3.  2.] [ 1.  3.  4.] [ 1.  5.  5.] [ 1.  7.  5.] [ 1.  2.  5.] [ 1.  6.  6.] [ 1.  7.  7.]][[ 0.  0.  1.] [ 0.  0.  1.] [ 0.  0.  1.] [ 0.  1.  0.] [ 0.  1.  0.] [ 0.  1.  0.] [ 1.  0.  0.] [ 1.  0.  0.]]각 data는 각 시행의 input 과 output을 나타내는 행 벡터로 표현되었다.In [10]:x_data = xy_pack[:,0:3]y_data = xy_pack[:,3:]print(x_data); print(y_data)[[ 1.  2.  1.] [ 1.  3.  2.] [ 1.  3.  4.] [ 1.  5.  5.] [ 1.  7.  5.] [ 1.  2.  5.] [ 1.  6.  6.] [ 1.  7.  7.]][[ 0.  0.  1.] [ 0.  0.  1.] [ 0.  0.  1.] [ 0.  1.  0.] [ 0.  1.  0.] [ 0.  1.  0.] [ 1.  0.  0.] [ 1.  0.  0.]]결국 쓸데없이 data를 transpose할 필요 없다.----------------------------------------------------------------------------------강의 source에서 불필요한 data의 transpose는 피하는게 좋지 않을까 생각합니다.	6	개인적으로 transpose 문제는 강의 전체상 크게 문제될건 없다고 봅니다. 사실 문제라고 할것도 없는게... 큰 데이터를 transpose 해서 메모리가 문제가 생길정도를 다루는 수준이라면 이미 transpose 하는 형태의 데이터를 받을지 아닐지는 분석가가 결정을 해야 된다고 봅니다.그러나 선형대 개념이 약하신 (저같은) 분이라면 왜 저렇게 하는지 조금 이해하고 넘어갈 필요는 있다고 생각이 드네요.중간에.. python의 list의 element는 R의 vector와 달리 다양한 type을 허용한다. 라고 하셨는데 python의 list와 tensorflow에서 활용하는  numpy의 array는 조금 다릅니다.numpy array는 속도와 메모리 연결성(이라고 하나요? 데이터를 메모리에 올릴때 붙여서 올리는 거)을 위해 C 사용한 파이썬 구현체로 오히려 R의 vector와 비슷합니다.실제로 분석가에 따라 numpy로 하나의 instance를 row vector로 만들기도 하고 테이블의 column vector를 하나의 row vector해서 계산하기도 합니다.저 같은 경우는 pandas로 데이터를 읽어온 후 전처리하고, 각 instance을 row vector로 뽑아서 분석을 합니다. 사실 이전에 사용했던코드를 바꾸기 귀찮아서 습관적으로 하는 거 같습니다.	1	tanspose를 한 이유는 numpy가 row major order 이기 때문에 그렇게 하신것 같습니다.교수님께서 우선 데이터를 불러 오실때에는 ppt로 설명해주신 데이터 값을 그대로 보여주시기 위해서 로딩을 하신것 같아 보이네요아마 실제적으로 데이터를 로드 할때에는 tanspose 연산 없이 바로 row로 데이터를 부르는게 더 좋겠지요	0	전치행렬 용도는 대체로 표시용이더라고요. 표시가 편하거나 설명이 편하거나...	0	일단, 최성철님의 의견에 동의합니다.저는 sas로 데이터 분석을 시작했는데( 더  앞에서는 엑셀이겠죠^^)sas에서는 데이터 저장소로 sas data set 밖에 없었고, 이는 관계형 DB의 구조와 거의 동일합니다.그러다 R을 접하고, R에서는 벡터와, matrix라는 동일한 데이터 형을 가지는 저장소와 data.frame이라는 DB 구조의 데이터 저장소를 동시에 제공합니다. 그래서 용도에 따라 편하게 사용하 수 있었습니다.python에서 list를 접하고 이에 대한 확장인 Array.arry와 Numpy.array를 list의 확장이니 data.frame처럼 여겼는데, 잘 못된 판단이었죠..^^pandas 패키지에 R의 data.frame과 같은 object가 있는 것 같네요.tensorflow에는 dataframe과 같은 object가 있나요? 있겠죠? 없으면 문제가 있을 것도 같은데...	1	아마도 pandas의  dataframe의 object는 ndarray를 원소로 하는 list를 특수한 list로 object화 하지 않았을까하는 생각이 드네요...
29	혹시 이 책 읽어보신 분 있나요? github에 예제 프로젝트가 좋은 평가를 받고있는 거 같은데, 1. python은 어느 정도는 안다2. 머신러닝은 처음이다.일 때 읽을만 할까요?아니면 더 좋은 책이 있으면 권해 주시면 좋을 거 같습니다.	2	safari로 살짝 봤는데. deep learning에 대한 기본 계념을 python 코드로 설명한 책이네요. 막상 tensorflow의 경우, 내부적으로 해주는 것이 많아서 개념을 별도로 익히셔야 하는데. 개념을 익히시는데 도움이 될 것 같네요. 하지만 개인적으로는 오래되긴 했지만 앤드류 응 강의를 직접 보시고 바로 tensorflow 사용하시는게 좋을 것 같네요.	2	이분 포스트 박사 과정인데 글을 재미있게 씁니다. fb나 g+에 글 올리시니까 친구나 follow 신청해 보세요.	1	구매해서 읽어봤고요. 머신러닝 기초부터 설명하고 있고요. 하지만 영어가 초급영어는 아니란게 아쉬운... 그리고 지금 뜨고 있는 cnn 은 정말 한두 페이지 소개만 하는...	1	다른 교수님 강의에 앞서 기초지식 가지는 용도로 좋아요.
5	RNN을 이용한 학습 중 궁금한 점이 있어 질문합니다.Sung Kim 교수님의 word 기반 RNN 학습 예제를 변형해 코드를 작성중인데,학습 도중 어떤 지점마다 loss가 상승하는 것을 관찰할 수 있습니다. epochs가 증가할 때 이런 일이 뚜렷하게 나타나는데요,제가 코드를 잘못 작성한 것일지, 학습 데이터를 관리하는데 문제가 있는지, 원래 그런 것인지 잘 모르겠습니다.첨부된 사진을 보시면 epochs가 1에서 2로 넘어가는 순간 loss가 상승하는데 어떤 부분에서 잘못 되었을지 알 수 있을까요 ?LSTM, rnn_size=256, num_layer=2로 RNN을 구성하고 테스트중입니다.	0	Loss가 출렁이는건 자연스러운 현상입니다만 감소 추세가 안보이고 잘 수렴하지 않는다면 문제일것 같네요... 많이 돌려도 잘 줄어들지 않나요?	0	혹시 dropout을 설정하셨나요?
23	딥러닝 논문들을 조사하며 느낀 딥러닝 연구의 몇가지 트렌드들을 정리해봤습니다. 즐겁게 읽어주세요!(언제나 그렇듯 오타수정 / 번역 기여 환영합니다!)	2	언제나 정리가 대단하신 것 같아요.	1	Leonardo YongUk Kim // 개인적으론 '윽... 나 딴거해야하는데...'라며 연구시간 아까워하며 정리하고 있습니다ㅠ 그래도 영어로 쓰면 죄책감이 좀 덜해요...>.< 감사합니다!
52	2010년도부터 나온 논문들 중 많이 인용되고 중요한 논문들 약 100편을 모아봤습니다. 혹시 빠진 논문이 있다거나, 아니면 (벌써) 구식이 되어 빼도 상관없겠다는 논문이 있다면 Push 주시거나 아니면 댓글로 의견 부탁드려요 ^^	1	감사합니다.	0	대단합니다. 시간될때 하나씩 읽어봐야겠습니다. 감사합니다.	5	딥러닝 페이퍼 500개 관계도 시각화... 이것도 같이보면 좋을것같군요. http://dnlcrl.github.io/projects/2015/10/10/500-deep-learning-papers-graphviz-python.html?imm_mid=0dd0f3&cmp=em-data-na-na-newsltr_20151202http://dnlcrl.github.io/assets/dl-gviz/test48.svg.	0	훌륭한 자료가 될 것 같습니다.^^	0	네 정말 훌륭한 자료가 될 듯 합니다.
2	가입승인 감사합니다! 최근에 TF를 공부해보려하는데 몇가지 질문이 있습니다 ㅎㅎTF의 visualization 기능에 감명받아서 Tensorboard를 사용해보려고 하던 중이었는데 튜토리얼에 있는대로 따라한 것 같은데도 자꾸 summary에 feed하는 단계에서 invalid assignment라고 에러가 나네요 ㅠㅠ저는 지금 Jupyter에서 python3 으로 실행해보고 있는데 검색을 해보니 TF가 아직 python3에는 대응이 잘 안되는 부분도 있다는 얘기가 있어서 당황했네요. 그래서 질문 드리고 싶은게 혹시 Tensorboard 사용에도 python3을 사용해서 생기는 문제가 있는건가요? 아니면 단순히 제가 에러나는 부분을 찾질 못한걸까요..? 파이썬 자체도 TF를 해보려고 같이 입문한거여서 아직 익숙지 못합니다... 단순히 버젼이 높은게 좋은 줄 알고 python3으로 했는데 python2.7로 개발하는게 나을까요?	0	Python 2.7쓰세요^^ anaconda python 3.5는 좀 호환이 좋지 못한 것 같습니다...theano랑도 잘 안맞고요 ㅠㅠ
40	ubuntu 14.04 에서 TensorFlow 및 CUDA 를 설치한 경험을 올립니다. CUDA Toolkit 이 최신 ubuntu 16.04 는 지원을 하지 않습니다.Deep Learning 관련 참고할 책이나 문서를 찾는 분들이 계시면 아래 두 사이트를 추천을 합니다.http://neuralnetworksanddeeplearning.com/index.htmlhttp://www.deeplearningbook.org/TesnorFlow 설치는 사이트를 참조를 했지만 동작을 제대로 하지 않았다.CUDA 역시 약간의 삽질이 필요했다.다음 방법으로 해결을 했다.나의 느낌으로는 우분투를 포함하여서 최신버전은 피하는 것이 좋을 것 같다.아마도 최신 버전은 아직은 대응이 되지 않는 것 같다.<TensorFlow 설치>PIP 설치$ sudo apt-get install python-pip python-dev설치전 이전 버전 제거$ sudo pip uninstall tensorflow$ sudo pip uninstall protobuf# Ubuntu/Linux 64-bit, CPU only:$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl=> 이 버전이 문제가 있어서 아래 버전으로 설치$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled:$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl=> 이 버전이 문제가 있어서 아래 버전으로 설치$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl<CUDA 설치>cuda toolkit 7.5 를 설치를 했다가 cuda toolkit 7.0 을 설치를 했다.cuda toolkit 7.5 를 설치를 하면 다음의 에러가 발생한다.ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory=> 이 error 는 cuda toolkit 7.0 이 설치된 상태에서 설치하면 발생을 하지 않습니다.Cuda toolkit 7.5 설치 및 제거sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.debsudo apt-get updatesudo apt-get install cudasudo apt-get autoremove cudasudo dpkg -P cuda-repo-ubuntu1404-7-5-localsudo dpkg -P cuda-toolkit-7-5sudo dpkg -P cuda-visual-tools-7-5Cuda toolkit 7.0 설치sudo dpkg -i cuda-repo-ubuntu1404-7-0-local_7.0-28_amd64.debsudo apt-get updatesudo apt-get install cuda	0	감사합니다!	0	Thx	1	cuda 7.0, cudnn v4 사용하는데,  새로 빌드를 해야하는지요? 설치 문서를 보면 cuda7.5이외에는 소스에서 직접 설치하라고 나와서요	0	그리고 빌드를 하여 사용한다면 빌드 후 소스(빌드된)를 해당 환경 site-package 아래에 위치만 하고 import 하면 되는것일가요?	0	cuda toolkit 7.5 는 cuda toolkit 7.0 이 설치된 상태에서 설치를 하면 정상적으로 설치가 됩니다. cuda toolkit 7.0 을 삭제하고 cuda toolit 7.5 를 설치를 했던 것이 error 의 원인이었던 것 같습니다.
56	여기사이트 이용하니까 텐서플로어랑 python 잘되네요.   	0	ㅋㅋㅋㅋ 기본부터~ 심화까지 정보의 바다군요!
1	$ docker run python python --versionPython 3.5.1 이렇게 버전확인은 되는 거같은데요docker에서 실행은 어떻게 하는건가요?	0	Docker에 운영체제는 뭘 올리셨나요??
26	인공지능 중요논문이나 최신논문들 해설을 동영상으로 찍어 누구나 이해할수  만들면 좋은거 같네요수많은 사람이 참여해서 하면요누구나 석박사 과정을 거치지 않고 석박사 수준의 실력을 가질수 잇을거 같은데요그럼 대기업과 경쟁에서도 이길수 잇을듯하네요	6	말씀하신 내용과 비슷한 일을 하는 유투버가 있어요. https://www.youtube.com/user/keeroyz/videos
1	docker에서 python 치면 이상하게 나오네요.,.왜 그런거죠	0	1. python 인스톨 X2. 환경변수 설정 X둘 중의 하나 입니다
0	혹시 텐서플로우에 theano의 scan과 같이 텐서를 iteration할 수 있는 함수가 있나요?	0	TF에서는 For loop을 사용할 수 있습니다	0	tf.scan
3	주식투자 인공지능으로 할때는 어떤 라이브러리나 알고리즘, api 사용하시나요	2	Sklearn 으로 머신러닝 알고리즘 돌려보고 있어요. 딥러닝은 텐서플로우 써 보려고 시도 중. ㅋ theano도 괜찮다고 들었습니다. ^^ 딥러닝으로 자동화된 주식투자가 가능할.것으로 기대하고 있답니다. ㅋ	0	논외지만 dataset은 어디서 얻나요??
4	ssd 256GB 와 seagate 2TB HDD가 있습니다.ssd를 반으로 나누어 128GB에 windows 10을 설치하고, 나머지에 ubuntu를 설치하여 tensorflow를 구동하려 합니다.참고로 gtx960 4GB gpu를 이용하여 tensorflow를 설치하고자 합니다.ubuntu의 설치 경로를 어떻게 정하면 좋을까요?특히나, /home 폴더를 ssd에 설치해야할 지, hdd에 설치해야할 지가 궁금합니다.어떤 방법이 tensorflow의 성능을 극대화할 지 잘 모르겠네요.	0	벌써 이틀째 tensorflow 설치를 위해 안간힘을 쓰는데 아직 설치하지 못하고 있네요.	0	혹시 도와주실 수 있는 분이 계시면, pc와 모니터들고 이동하겠습니다...	0	참고로 ubuntu 14.04에서 anaconda 패키지로 pycharm이나 jupyter notebook으로 작업을 하는 것이 최종 목적입니다.	1	윈도우 10을 먼저 설치하시고 우분투를 설치하려고 하시면우분투가 알아서 멀티부트를 만들어 줍니다그때 ssd 부분에 파티션을 나누셔서 하셔야할텐데우분투는 ext4를 사용해서 아예 다른 파일시스템이 생긴다고 보시면 됩니다기본 설치위치는 / 이 될테고요 ...ssd 128에 나눠서 우분투 설치하시면 /home도 거기에 있게 될거에요	0	감사합니다~거기까지는 잘 되었고 tensorflow 설치에 애를 먹고 있어요^^	1	제 노트북이 윈도우 10 플러스 우분투입니다. 지피유버전까느니라 한 10번다시 엎었네요. 지금은 잘 됩니다. 여기추천드려요  http://ishuca.tistory.com/m/post/entry/Ubuntu-1404-%EC%97%90%EC%84%9C-%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4%EC%97%90-Tensorflow-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0	0	저같은경우는 속도를 위해서 ssd를 우분투를 30기가정도 사용하고 윈10을 나머지 전부 (180기가 +일반하드 1tb)세팅 하였습니다. 무엇이 문제가 되는지 정확히 몰라서 말씀을 드리긴 힘들지만, 위 링크를 보시면 아시겠듯이 저는 지피유 버전 설치할때, 쿠다 무한루프가 걸려서 잘 안됬었어요. 위 링크 한번 따라해보세요	1	제 블로그를 참조해 보시면 도움이되려나?  http://icanibe.blogspot.kr/2016/04/machine-learning.html?m=1	0	저는 mac 사려고 하는데 기종 어떤게 좋을까요? mac for work라는 모델이 gpu 딸려서 2016년에 나온다고 하는데 이거 살까 클라우드만 사용할 까 고민중입니다.
53	13분만에 140명 모두 마감 되었습니다! 신청해주신 분들에게 정말 감사드리며 남은 기간동안 열심히 모임을 준비하겠습니다. 더 넓은 장소를 준비하지 못해 부득이하게 대기하신 분들에게는 죄송하다는 말씀을 드립니다. 혹 등록하신분중 불가피하게 참여하지 못하시면 대기하시는 분들을 위해 등록을 취소해주시면 감사하겠습니다. 다시 한번 모든 분들에게 감사 드립니다. TF-KR 운영진 드림.	0	정말 치열하네요 ㄷㄷ Advanced를 원했으나 금방차서 기본이라도 ㅠㅠ	2	간신히 등록완료  ㅋㅋ	0	무시무시한 속도였어요. 결제하는데 시간이 걸려서 진땀을 좀 흘렸네요	0	증원 계획은 없으신가요? 흑흑ㅜㅜ	0	아쉽네요!	1	출근하느라 놓쳤네요 ㅠ하필 시간이 겹칠줄이야.. 더 공부해서 다음 모임에서는 스피커로 나갈수있도록 노려보려합니다..!	3	책도 준비했는데 허무하네요 ㅎㅎㅎㅎ 허탈...	0	간신히 등록했습니다! 감사합니다!	0	헐~	4	아, 오늘이었군요 T.T	0	전 대기 30번째 정도네요.	1	저는 10시 정각부터 신청하기 시작했는데,  결재완료까지  시간을 좀 지체했더니  대기자로 등록이 되었네요.  왠지 시스템이  원망스럽네요.  자석을 더 확보가능한가요?	0	정말 대단하네요	1	서서라도 보고싶네요!	0	너무하십니다...ㅋㅋ 사실 늦게 봤구요.. 정말 인기 최고네요..	0	자고 일어나니 대기인원만 100명이 넘네요 ㅋㅋㅋㅋ	1	축하드립니다. 몇분 늦어서 신청은 못했지만, 좋은 모임이 될 것으로 기대됩니다. ^^	1	대박이네요~ ^^ 모임 후기 꼭 부탁드려요~!!
23	조금 요약 해보았습니다. 정확한 내용은 아래 링크로 ㅎㅎ 비디오 컨텐츠도 2개 있습니다.DeepText로 FB 사용자들을 더 잘 이해하고, 더 좋은 서비스를 ~- 글로벌 환경에서 DeepText로 전통 NLP보다 보다 빠르고 정확하게  다양한 언어에 대응- 엔지니어들은 FBLearner Predictor platform 안에서 클릭 몇번으로 쉽게 DeepText model을 만듬- CNN, RNN을 포함한 여러 모델들을 이용- 초당  20여개 언어로 이루어진 수천개의 포스트 학습, model traning: FBLearner Flow, Torch 사용- 출발은 FB AI Research 팀의 Yann LeCun, Ronan Collobert의 연구를 바탕으로 함.앞으로 방향…- 사용자의 관심사 더욱 잘 이해하기( 페북 페이지 속 게시물의 label 은 페이지 정보로 부터…)- 글 따로 사진 따로가아니라, 글 사진 함께 이해하기- 새로운 Architecture: BRNNs(Bidirectional recurrent neural nets) , 분류작업에 CNN, RNN 보다 에러가 적었고 , 20% 감소한 경우도 있음	0	기존의 Bidirectional RNN과는 다른 구조인가요?	0	페북은 따로 프레임워크를 만들기보단 토치로 가나보네요.
6	성공하였습니다!	0	흠 전 나중에 결제해도 되는시스템인줄 알고 일단 참여한다음 결제했는데 대기로 뜨네요. ㅋㅋㅋ 온오프믹스 유료모임을 처음해봐서 잘 몰랐습니다 ㅜ	0	Advanced 성공하셨네요....부럽습니다..	0	축하드립니다! 전 다음기회에...
29	2분만에 50명 등록 입니다. 참여하실 분들은 서둘러 주세요.http://onoffmix.com/event/69537/	1	신청하였습니다 ~	1	마감됬다는 군요.. ㅠ..	0	저도 신청했어요.	0	전쟁이네요...ㅎㅎ	0	별생각없이 Advance로 신청 해버렸네요 ㅋㅋ Basic 듣기는 좀 애매한데... Advance 듣기는 딥러닝을 전혀 모르는 상태라 ㅋㅋㅋㅋ	0	오, 캘린더에 기록까지 해놓고 까먹고 있었는데, 다행히 이 글 보고 신청했습니다.	0	신청했어요. 이런 모임에 가는 것을 싫어하지만 ...	1	결제를 해야 정원에 포함되는 거였군요... ㅠㅠ 결제 시도하는 사이 이미 정원초과가....	0	저도 정각에 클릭 했지만 결재하다 정원 초과 advanced 62 대기자네요 으악...	2	그래서 온오프 믹스에서는 일단 이체 신청을 해놓으시고 나중에 결제하시는게 좋습니다 ㅋㅋ	0	신청했습니다~ 기대됩니다	0	기본트랙 참여했는데 어드밴스드 세션 들을수있을까요?	0	사람 너무 빨리차네요 ㅠ	0	와우.. 메시지 보자마자 들어 갔는데 벌써 다 찼네요.. ㅠㅠ	0	'아차' 하는 순간에 모임참가가 다 차버려서 대기자가 되버렸네요 ㅠ.ㅠ	0	기본 트랙으로 신청을 해서 조금 아쉽네요.	1	18분만에 완료된건가요 ㄸ..	0	아.. 깜빡하고 있었는데 늦었네요 ㅠ	1	저두 신청했어요~~	1	I'm in!	0	잠시 다른 일보다가 놓쳐버렸는데 꼭 듣고싶은데 다른 참여방법이 없나요? 순식간에 마감되버렸군요.	1	혹시 다음 모임 개설 날짜라도 알 수 잇을까요? 이거 대기라도 타야겟네요ㅠㅠ	1	대기가 너무 많네요 ㅠ	1	ㅜㅜ 너무 빨리 찾어요 ㅜ 다른 참여방법은 없나요 너무 아쉽습니다	1	ㄷㄷ마감했네요	1	추가 참여는 어려운가요?	1	ㅠㅠ신청 실패 ㅠㅠ	1	Advanced Track 성공했습니다 😁	1	회사에서 다른 업무로 잠시 바빴더니,이미 정원이 차버렸네요 ㅠ ㅠ	1	정원초과인데 일단 대기자로 결제했고 대기 89명째 입니다.	1	ㅜㅜ 추가신청은 안 받으시나요?	1	대기자인데... 너무나 머네요 ㅜㅜ 되려나 이거	1	93번 대기자인데 절대 안되겠죠..?	1	첫번째 등록이었는데 결제 안하면 안되는걸 몰라서 죽 밀렸네요 하하	1	고등학생인데 수업시간이여서 늦었네요	1	일단 대기 결제..	1	헛 순식간에 마감 ...	1	아.. 아쉽네요 ㅠㅠ	1	일하다 깜박했는데 이미 대기자만 100명이네요;; ㅠㅠ
1	king - man + woman 을 하면 자꾸 king이나 woman이나와word2vec 구현이 제대로 돌아가지 않는것 같아 질문드립니다.word를 300차원으로 임베딩하여 학습한뒤 각 300차원의 word벡터를모두 같은 크기가 될 수 있도록 각 word벡터의 norm으로 노말라이즈 해야할까요?	0	학습 데이터는 어떤것을 사용하셨는지요 >?	1	https://code.google.com/archive/p/word2vec/source/default/source구글  word2vec레퍼지토리에 있는 questions-word데이터로 했습니다.데이터 자체가 a:b = c:d로 되어있더라구요...사실 현재 코드안의 버그면 잡으면 되는데현재 궁금한 것은 각 벡터를 노말라이즈 해야하나 말아야하나가 궁금하여 질문 드립니다	0	학습데이터의 양이 작은 경우, 학습데이터에서 해당 단어의 출현 빈도가 낮아 벡터가 생성되지 않은 경우, iteration 수가 작아 벡터가 제대로 학습되지 않은 경우를 추측해볼 수 있겠습니다. 충분한 양의 데이터로 충분히 iteration 학습한다면 king-man+woman은 queen의 벡터와 유사할 것입니다. 이 과정에서 normailize는 필요하지 않은 것으로 알고 있습니다.
7	코끼리 몰이꾼과 비교하여 TF가 좋은 점1. 상대적으로 빠르다 (그래도 느리다)2. GPU 지원3. 학습 모델의 다양함	0	저기 죄송한데 코끼리 몰이꾼이 뭔가요? 궁금한데 저빼고 다들 아시나봐요	0	머하웃입니다. 요샌 sparkml도 있습니다~	0	그래도 제한적이지만 분산이 아직은 spark나 머하웃이 더 편한듯 합니다.
110	DeepOSM대박 프로젝트네요. 항공사진을 통해 벡터데이타를 거꾸로 뽑아네는 Deep 러닝 프로젝트입니다. 어느 순간 데이타가 쌓이기 시작하면 DB 업체들은 뭐 먹고 사나요.Tensorflow 기반으로 도로데이타를 뽑아내는데 75%이상의 정확성을 보여준다고 하네요.	1	재미있는 아이디어 좋은 결과입니다. 75%라면 아직 성능 개선의 여지가 많을것 같습니다.	1	저도 생각만 해봤던 주제네요. 제 생각엔 이 주제는 블랙박스보다는 직관적인 방법이 더 좋을거라고 생각했는데 역시 딥러닝이 답인걸까요 ㅎㅎ 무튼 정확도가 올라가면 참 좋겠네요
74	한국분들의 논문입니다. CNN을 사용하여 다성 음악 (polyphonic music) 소리를 듣고 사용된 악기가 무엇인지 알아내다고 합니다. F-measure가 0.5정도 나오는데 이전 방법에 비해 16%이상 성능이 개선 되었다고 합니다.딥러닝이 정말 여러분야에서 성능을 개선하고 있네요.https://arxiv.org/abs/1605.09507	0	이제 악보 받아적는 것(채보)도 곧 기계가 할 수 있겠군요.	1	이것과 비슷한것을 하신분을 만났었습니다매우 신기하더군요 그분은 위에 분 말씀처럼 음악의 음계도 분석해서 악보도 만드는것으로 알고 있어요정확한 설명을 못들었는데 한번 읽어봐야겠어요 감사합니다	3	네, 전공한 분야는 아니지만, '인공지능'이 (모든 분야에서 보편적으로) 도구화되는 시대로 들어섰다는 생각입니다. 이게, 소위 4번째 산업 패러다임 변화겠지요..	2	어이쿠 좋아하는 음악 몇일 틀어놓으면 인공지능이 하루종일 나를 위한 음악을 작곡해주겠군요	2	제가 속한 대학원의 음악오디오연구실(MARG)에서 제출한 논문이군요 이렇게 보니 반갑네요.
67	유명한 CS231n 강의를 한국어 번역한 자료가 있어 공유해봅니다.참고로, 이슈카님 블로그에 더 많은 번역 자료가 있어 공부하기 좋을 것 같습니다.	0	혹시 쓸만한 text to speech 프로그램 알고 계시면 알려주셔요.   나레이션을 넣어야 이해가 쉬운데 ㅠㅠ	6	헐... 발번역인데...이해 안되시는거 있으면 댓글로 질문 남겨주세요
1	안녕하세요?TensorFlow와는 전혀 관련이 없는 질문이지만, GPU 환경(CUDA)에서 PCA를 사용하고 싶은데, 생각외로 api형태로 제공되는게 눈에 확 띄지않네요. (opencv gpu모듈에 당연히 있다고 생각했는데 없네요.)혹시나 도움주실만한 사항이 있으면 말씀해주시면 감사하겠습니다 :)	0	Torch 에는 누군가 작성해놓은 코드가 있는것 같네요 https://github.com/koraykv/unsup/blob/master/pca.lua
5	[질문] 그래픽카드 알아보는 중인데요.tensorflow gpu 버전 설치하신분들 NVIDIA 어떤 제품 사용하시나요? ㅎㅎ	1	760 2gb 쓰다가 이번에 타탄x 로 넘어갔어요 전 ㅎㅎㅎ	1	980ti 사용중입니다. 중고로 샀어요. 최근에 좀 저렴해졌습니다.	1	저는 몇년 전에 샀던 gtx 560 쓰는데요. 별 문제 없네요. 물론 돈있으면 비쌀수록 빠른...	1	전 960 4개 샀는데요. 아직 써보진 안 아서 잘모르겠어요.
5	[질문] 모두를 위한 딥러닝 강의 RNN 예제 hello를 문장으로 돌려보고 싶어서아래와같이 코드를 수정했습니다.그런데 사진처럼 잘 돌아갈때도 있고 index out of range 에러가 날때도 있어요왜 이런걸까요...ㅠ아직 파이선 초보이고 제가 바보같은 실수를 하고있을 수도 있지만 너그럽게 봐주세요..#!/usr/bin/python# -*- coding:utf-8 -*-import tensorflow as tf from tensorflow.models.rnn import rnn, rnn_cell import numpy as np sentence = ['the','eye','is','the','mirror','of','the','soul']word_rdic = ['the','eye','is','mirror','of','soul'] # id -> word word_dic = {w: i for i, w in enumerate(word_rdic)} # word -> id sample = [word_dic[c] for c in sentence] # to index x_data = tf.placeholder(tf.float32, shape=(7,6))x = np.array([ [1,0,0,0,0,0], # the [0,1,0,0,0,0], # eye [0,0,1,0,0,0], # is [1,0,0,0,0,0], # the[0,0,0,1,0,0], # mirror[0,0,0,0,1,0], # of[1,0,0,0,0,0]], # thedtype='f') # Configuration word_vocab_size = len(word_dic) rnn_size = 7 #word_vocab_size # 1 hot coding (one of 7) time_step_size = 7 # 'the eye is the mirror of the' -> predict 'eye is the mirror of the soul' batch_size = 1 # one sample # RNN model rnn_cell = rnn_cell.BasicRNNCell(rnn_size) state = tf.zeros([batch_size, rnn_cell.state_size]) X_split = tf.split(0, time_step_size, x) outputs, state = rnn.rnn(rnn_cell, X_split, state) #outputs, state = tf.nn.seq2seq.rnn_decoder ( X_split, state, rnn_cell) print (state) print (outputs) # logits: list of 2D Tensors of shape [batch_size x num_decoder_symbols]. # targets: list of 1D batch-sized int32 Tensors of the same length as logits. # weights: list of 1D batch-sized float-Tensors of the same length as logits. logits = tf.reshape(tf.concat(1, outputs), [-1, rnn_size]) targets = tf.reshape(sample[1:], [-1]) weights = tf.ones([time_step_size * batch_size]) loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [targets], [weights]) cost = tf.reduce_sum(loss) / batch_size train_op = tf.train.RMSPropOptimizer(0.01, 0.9).minimize(cost) # Launch the graph in a session with tf.Session() as sess:   # you need to initialize all variables   tf.initialize_all_variables().run()   for i in range(100):     sess.run(train_op, feed_dict={x_data:x})     result = sess.run(tf.arg_max(logits, 1))     print (result, [word_rdic[t] for t in result])	1	result의 값을 한번 출력해보시면 어떨까요? print (result, [word_rdic[t] for t in result]) -> print (result)print( [word_rdic[t] for t in result])이 값이 좀 큰 값이 나오는것 같아요.
135	오랫동안 기다려왔던 karpathy 의 Reinforcement Learning의 블로그 포스트. 앞부분에 본인이 공부했던 자료들을 쫙 나열하는데 매우 도움이 되는 자료들로 보입니다. 요즈음 RL+TF가 대세인듯합니다. :-)"재강화학습(RL)은 요즈음 정말 핫하다. 이제 컴퓨터가 자동으로 ATARI 게임을 (화면의 픽셀정보만 보고) 스스로 학습하고, 이세돌을 바둑으로 이겨내고, 시뮬레이션을 통해 네발로 달리고 점프하는 것을 배우고, 로봇은 복잡한 동작을 자동으로 배운다는 것은 이미 알고 있을것이다. 이런 것들은 일반 프로그래밍 기법 (explicit programming) 으로는 쉽지 않다. 재미있는 것은 이런 모든 것들이 RL을 통해 가능하다는것. 나도 작년부터 RL 에 대하 관심을 가지게 되었는데:  우선 Richard Sutton’s 책 (https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html) 을 보고, David Silver’s 수업 (http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html) 을 듣고, John Schulmann’s 강의들 (https://www.youtube.com/watch?v=oPGVsoBonLM) 을 보고, RL Javascript 라이브러리 (http://cs.stanford.edu/people/karpathy/reinforcejs/) 도 만들어 보고, DeepMind DeepRL 그룹에서 인턴으로 일하고, 최근에는 OpenAI Gym (https://gym.openai.com/) 의 디자인과 개발에도 조금 참여 하였다."http://karpathy.github.io/2016/05/31/rl/	1	와, 역시 믿고 보는 karpathy군요!공유 감사합니다.	1	어디서 연봉 백만불인가 제시했다더니, 안 간 모냥이군여 ! 이런 냥반이 좀 학계에 남아줘야 할텐데 말임다...
38	TF로 RNN을 이해하는데 매우 좋은 글입니다.
56	hackerlists 에 텐서플로우 관련 리스트가 올라왔습니다. 튜토리얼 부분에 익숙한 두 분의 이름이 있습니다. 좋은 자료 다시 한 번 감사드립니다.^^
96	[Tag2vec]https://tag2vec.herokuapp.comhttps://github.com/muik/tag2vec얼마 전 Deep NLP 스터디 모임에서 간략히 소개했었던 Tag2vec을 좀 더 완성해서 공개합니다.자연어 처리를 위해 기본적으로 필요한 단어 벡터 공간(Word2vec)이 필요한데요. 한글은 영어와 다르게 형태소 분석으로 단어를 분리해야하는 번거로움으로 고민이었습니다.그런데 인스타그램에 올라오는 글을 보면 연관성 있는 태그가 연속해서 나열되어 있습니다. 이 태그들을 문장처럼 취급해서 학습하면 어떨까해서 구현해봤습니다.더불어 콘솔에서 확인하는 것보다 웹사이트에서 훨씬 쉽게 확인할 수 있어 데모 웹사이트를 만들었습니다. Word2vec의 기본 기능인 nearby를 좀 더 확장해서 여러 단어, 부정 단어도 지원하도록 기능을 구현해봤으니 확인해보세요~결과가 어설픈 부분이 아직 좀 많은 것 같은데요. 학습데이터가 많지 않은 것과 실제 문장이 아닌 영향으로 그런것 같은데 혹시 개선할 의견 있으면 환영입니다~!#tensorflow #tag2vec #word2vec	1	재미있네요!	1	멋진 연구 입니다!
47	딥러닝 논문 함께 봐요~!안녕하세요. 모두의연구소김승일입니다.모두연 #DeepLAB 논문반 에서는 매주 월요일 저녁 8시에 모두의연구소에 모여 논문 1-2편의 세미나를 진행하고 있습니다. 혼자 논문 보기 힘드신 분들 함께 보시죠 ^^모임 참여 신청은 modu@modulabs.co.kr 로 성함/이메일/전화번호/DeepLAB논문반 참여라고 보내주세요. (참고로 월 44,000원의 공간이용료가 있습니다.)===현재까지 세미나를 진행한 논문 리스트는 다음과 같습니다.- Learning to Respond with Deep Neural Networks for Retrieval-Based Human-Computer Conversation System- Deep Speech: Scaling up end-to-end speech recognition- SSD : Single Shot MultiBox Detector- A Fast and Accurate Dependency Parser using Neural Networks- Adieu Features? End-to-End Speech Emotion Recognition using a Deep Convolutoinal Recurrent Network- Deep Learning for Robust Feature Generation in AudioVisual Emotion Recognition- Video Emotion Recognition with Transferred Deep Feature Encodings- Deep Network with Stochastic Depth- Towards Good Practices for Very Deep Two-Stream ConvNets- Deep Metric Learning using TripleNet Network- Delving Deeper into Convolutional Networks for Learning Video Representations- Learning Spatiotemporal Features with 3D Convolutional Networks- Multi-Scale Context Aggregation by Dialated Convolutions- Colorful Image Colorization- SqeezeNet : AlexNet-Level Accuracy with 50x Fewer Parameters and 1MB Model Size- Word2Vec- U-Net : Convolutional Networks for Biomedical Image Segmentation- Exploring the Neural Algorith of Artistic Style- VGGNet and ResNet- Recurrent Memory Network for Language Modeling- Grid Long Short-Term Memory- Learning Deconvolution Network for Semantic Segmentation- Fully Convolutional Networks for Semantic Segmentation- You Only Look Once -  Unified Real Time Object Detection- Texture Synthesis using Convolutional Neural Networks- Unsupervised Representation Learning with Deep Convolution Generative Adversarial Networks- Spatial Transformer Networks- Generating Images from Captions with Attention- Generating Sequences with Recurrent Neural Networks- End-to-End Memory Networks- AlexNet- Overfeat : Integrated Recognition, Localization and Detection using Convolutional Networks- Recommender System using Deep Learning- Restricted Boltzmann Machines for Collaborative Filtering- Collaborative Deep Learning for Recommender Systems- Deep Content-Based Music Recommendataion- A Neural Algorithm of Artistic Style- A Unified Framework for Automatic Wound Segmentation and Analysis with Deep Convolutional Neural Network	2	장소 위치가 정확히 어디쯤인가요? :)	2	논문선정은 어떻게 하는건가요?	3	아.. 모두의 연구소 한번 참여해보고 싶었는데요... 멀리 이사를 와버려서 ㅠㅜ	1	우와. 대단하신 분들
0	한가지 궁금한 점이 있습니다.  예를 들어 웹사이트의 문서를 분석해서 관심 있는 항목 (다른 link 라든지, 특정 주제 관련 단어라든지) 을 자동 추출하도록 Deep Neural Network 를 훈련시킬 수 있을지요?  이런 경우는 Recurrent Neural Network 비슷한 형태가 유리할지요?
34	여기 와서 홍정모 교수님과 김성훈 교수님 강의 동영상을 보고 있는데, 정말 도움을 많이 받습니다. 저처럼 입문하시는 분들에게 적극 추천드립니다. 아직은 자유롭게 딥러닝 아이디어를 펼칠 수는 없지만 두 분의 강의를 통해서 일정 정도의 실마리(혹은 자신감)을 얻을 수 있었습니다.감사합니다.
8	안녕하세요CS231n에서 softmax를 텐서플로우로 구현하려고 하는데요 ㅠㅠSung Kim 교수님 수업 내용을 바탕으로 구현했는데...Cost를 구하면 분명히 2.3이라는 숫자가 나오는데Optimizer를 돌리면 cost도 Nan이 나옵니다 ㅠㅠㅠㅠ 왜그런가요?고수분들의 도움을 부탁드립니다 ㅠㅠㅠㅠㅠㅠ	0	hypothesis가 0으로 가서 그럴수도 있습니다. (tf.log(0)은 NaN이 나옵니다) tf.clip_value같은 함수를 hypothesis에 적용해주면 해결될 것 같습니다.	0	유인완 답변감사합니다! 근데 tf.log(0)이 문제인거면 sess.run(cost)도 hypothesis를 분명히 사용할텐데, cost도 Nan이어야 하는거 아닌가요? ㅠㅠcost는 숫자가 나오는데 optimizer는 왜 Nan일까요 ㅠㅠㅠ	0	optimizer를 run하면 Variable 들이 cost를 minimize하는 방향으로 업데이트 되는데, 이때 값이 변한 tf_W가 만든 새로운 cost가 NaN이 나오는 것 같습니다.	1	유인완 오 말씀하신 얘기가 맞았습니다. learning rate를 엄청나게 줄이니까 되네요! 감사합니다!!! exploding gradient만 있는게 아니라 exploding cost도 있군요...
6	[스터디원 모집] #싸이그래머 QGM : 파트 5 - 머신러닝의 50가지 그림자* Unsupervised Deep Learning + 연결주의 심리학 + 베이지안 머신러닝 + 양자컴퓨팅* 매주 수요일, 저녁 7 - 10시 30분. 강남, 무료* 텐서플로우와 바로 연결되지는 않지만 그 이론적 근거가 되는 '딥러닝' 이론 스터디가 포함되어 있습니다.* 이 스터디는 정통심리학 그룹 싸이그래머에서 진행합니다.* 네이버D2의 지원을 받습니다.* 자료는 모두 공개&공유됩니다(정리 중)안녕하세요, 어느세 QGM(=퀀텀그래피컬모델링)이 파트 5에 들어섰습니다. 하지만 언제나 첫 시작하는 느낌으로 스터디를 하고 있습니다. 새로 참여하실 분들 언제나 환영합니다. 댓글 다시거나, 이벤트 참여를 누르시거나, 바로 스터디 장소로 찾아오시면 됩니다.<이번 파트에서 새롭게 추가된 부분은 Unsupervised Deep Learning 입니다. 이번부터 진도가 나가는 '벤지오 교수의 딥러닝북의 3부'가 이런 테마로 구성되어 있더군요. 그 외에는 이전 파트와 동일합니다.>이번 스터디는 이런 것들을 공부할 생각입니다.(연결주의 심리학) '지각심리 시각부분에서 선택적 주의에 대한 수리모델'에서 '읽기에 대한 수리모델링'까지 - 연결주의(즉 뉴럴넷)쪽에서의 심리 프로세스를 구성하는 방식을 배웁니다.(머피ML) 확률모델링 기반 머신러닝 스터디입니다.Mixture Model, EM 알고리즘, Linear Model의 여러 변형들 (Latent linear models, Sparse Linear Model), 그리고 커널 기법들이 주 내용입니다.(벤지오Deep) Linear Factor Models로 시작해서 오토인코더 관련한 내용들이 많아보입니다. 15장 The Manifold Perspective on Representation Learning 까지 진도를 나가는게 목표입니다.(양자컴퓨팅)양자컴퓨터의 물리적 구현에 대한 논의로 시작해서, 양자노이즈 등등으로 내용이 이어집니다. 오, 신이시여...https://www.facebook.com/events/1265723793446128/	0	커리큘럼 & 자료 - http://psygrammer.github.io/qgm/	0	https://www.facebook.com/groups/psygrammer/
4	https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/examples/tutorials/word2vec/word2vec_basic.py 예제를 시도할 때 (Ubuntu, anaconda)Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so.이런 오류 메시지가 나왔습니다.찾아보니 https://github.com/BVLC/caffe/issues/3884 이런 곳에서 conda install nomkl이라고... mkl 은 Intel Math Kernel Library 인 듯 합니다. https://www.continuum.io/blog/developer-blog/anaconda-25-release-now-mkl-optimizations	0	얼마 전부터 anaconda에서 MKL을 기본으로 지원하게 되면서 발생하게 된 문제인것 같더군요. 저도 같은 버그를 겪었는데, tensorflow뿐만 아니고 matplotlib나 scikit-learn의 일부 함수들을 사용할때도 문제가 발생하는 대참사가...말씀하신대로 nomkl을 사용해서 mkl라이브러리를 사용하지 않도록 하셔도 되고, anaconda를 재설치하셔도 됩니다.(최근 버전은 문제가 없는 것 같습니다) 저도 처음에는 mkl을 사용하지 않는 방향으로 갔다가, dependency가 꼬여버렸는지 여기저기서 오류가 나서 결국 anaconda를 밀어버렸습니다 ㅠ	0	그러고 나니 한참 뒤에 다른 에러가...libpng warning: Application was compiled with png.h from libpng-1.6.17libpng warning: Application  is  running with png.c from libpng-1.2.53libpng error: Incompatible libpng version in application and library	0	저는 문제 없이 돌아가는데요...   (제가 만든 script 첨부합니다. test 해보지는 않았습니다.)https://github.com/jongchul/tensorflow-exercise/blob/master/google_cloud/startup-script.sh
103	딥러닝을 이용한 자연어 처리의 연구동향일본 NAIST 신도 교수가 최근에 정리해서 발표한 "최신 딥러닝을 이용한 자연어 처리기술"을 번역한 자료입니다.일본에서는 이런자료들을  많이 만드네요.기존 기술의 한계와 이를 보완하고자 개발되는새로운 기술들에 대한 간단한 소개정도를 실은 자료입니다. 세부적인 기술내용은 저도 잘 모르겠습니다. 제가 워낙 언어분야에는 소질이 없어서요. ㅠㅠ참고논문을 찾으시면 될 듯 합니다.	1	항상 좋은 자료 감사합니다!	1	좋은 자료 감사합니다.	1	좋은 자료 감사합니다.
9	모두의 딥러닝을 보던 중에 궁금한 내용이 생겨서 질문 드립니다.이 슬라이드에 보면 필터를 6겹을 사용했는데,1. 6겹을 사용한 이유2. 6겹을 사용했을 때의 장점3. 필터를 몇겹을 할 지 정하는 방법이 궁금합니다.. 많은 답변 부탁드려요!!	4	6곂이라기 보다는 6장 이라는 표현이 더 생각하기 편함니다. http://www.kdnuggets.com/wp-content/uploads/layer2visualization.png 에서 한장한장이 필터라고 보시면 됩니다. 필터는 많으면 많을수록 좋은데, 하드웨어가 딸립니다.너무 적으면, 그 레이어에서, 다 못 catch 하고요.. 오른쪽에 있는 dimension은 6 으로는 맞고요, ? 는 stride에 따라거 작아짐니다.RandomForestㅇ로 억지로 비교 한다면, numTree 로 생각하실수도 있을거 같은 개인적인 생각입니다.	1	여기서는 BW image 라서 필터가 a*a*1 인데, 칼라로 들어오니 a*a*3이니 약간 더 복잡하네요.	1	겹이 아니고 서로 다른 convolution matrix를 6개 사용하는 겁니다	3	보통 filter 갯수를 2의 지수승으로 많이 사용합니다(GPU 때문에 이렇게 한다는 걸 봤던거 같네요) 6개는 강의에서 example로 들어놓은 거라고 생각되구요 filter를 많이 쓸 수록 더 다양한 feature를 뽑아낼 수 있겠죠 너무 많으면 학습이 더 안될 수도 있고 overfitting이 일어날 수 있다는 건 잘 아실거라 생각하구요	3	제 생각으로 cnn 의 feature map 형태/개수는 전통적인 vision object detection 에서 사용되는 local feature 와 연관이 있습니다. 다양한 영상의 형태에도 robust 하게 일관된 (동일 객체를 비슷한 값으로 뽑아주는) 값들이 나오도록 만들어주는 feature 를 선정해야 하고, 그 조합으로 이루어지는 feature sequence 도 무조건 많으면 좋으냐의 문제도 생각해볼 점이라고 생각합니다.현재의 cnn 은 일단 training 과정에 그 작업을 맡겨놓고 있으나, 더 좋은 넷을 위해서는 위에서 언급한 관점에서의 분석이 되어야 한다고 생각합니다.	0	답변 달아주신 분들 모두 감사드립니다!!
74	내부적으로 딥러닝을 사용한것인지는 모르겠지만 한글입력시 매우 도움이 될것 같습니다. 딥러닝으로 맞춤법 검사뿐만 아니라 더 좋은 표현으로 바꾸어주는 일종의 문장 첨삭기능도 가능할까요?	0	유용하게 사용할곳이 많겠네요 ^^
8	뽀송뽀송하고 시원한 밤 보내시길 빕니다 여러분.. ㅜㅜ 많은 분들의 의견 부탁드립니다질문 : Cpu가 꽤 성능이 좋은 것인데 괜히 nvidia gtx 960 같은걸로 학습시켜도, cpu만 가지고 학습시키는 것보다 빠를까요..? 없느니만 못하진 않을까(?) 싶습니다..내용 : AMD 의 그래픽 카드가 사망하셔서..울며웃으며 그래픽카드를 알아보고있습니다..어차피 난 엔비디아와는 연관없을거라고 위안하며..그래픽카드와 함께하는 텐서플로우란건 2년이내 겪을일 없으리라 생각하며 살다가..지금 패닉입니다.. 좋게생각해야죠. 이젠 저도 nvidia로 갑니다!하여, 질문 드립니다.Cpu가 i5, i7급이라해도 gpu는 있는 것이 더 나은가요?아무래도 사정상 gtx 960정도를 사용하게 될거 같은데...제가 컴퓨터를 켜질못하는상황이라 인터넷이 불편하여 정보를 못알아보고있습니다 ㅜㅜ. 물론검색하면 바로나오는...돈값하는 gpu들이 딥러닝학습시간을 화끈하게 줄여준다고는 하지만..아, 말이 깁니다..간추리자면 질문은 이렇습니다.Cpu가 꽤 성능이 좋은 것인데 괜히 nvidia gtx 960 같은걸로 학습시켜도, cpu만 가지고 학습시키는 것보다 빠를까요..?	1	제 생각은 "네" 입니다...	1	네 일반적으로 몇십배 빠를거에요	3	6600대비 980인데 정말로 수십배 차이납니다	1	저는 저렴하게 gtx1060 mini를 알아보고 있습니다.	5	대략 30여배 차이난다고 보시면 평균적일듯 합니다	1	예. Cpu 성능이 아무리 좋아도 비교도안됩니다...	4	엄청납니다. 그저께 1070 구매해서 돌려봤습니다. tensorflow deep mnist 예제를 2분만에 끝내더군요windows 10에서 bash올려서 i5-3기가 헤르쯔 되는 녀석은 40분 걸렸습니다	1	네 1060도 cpu에 비해서 아주 좋은 성능 보여줄겁니다.	1	저는 gtx970모델을 사용하고있습니다. 경험상 cpu로 4시간정도 걸리던 모델이 2분안쪽으로 완료됩니다.개인적으로 쓰실거라면 960도 무리가 전혀없을거같습니다	1	CPU: Intel(R) Core(TM) i7-4720HQ CPU @ 2.60GHz, 그래픽:지포스GTX960M(메모리4G)노트북에 꽂혀있는 지포스GTX960M(메모리4G)를 이용했을때 CPU를 이용했을때보다 5.5배 더 빨랐습니다.http://bryan7.tistory.com/709	1	제온 E5 2609랑 750 Ti도 비교가 안되더라구요...	0	제 우문에 현답을 던져주신 여러분 감사합니다. 정말 많은 도움이 되었습니다!	0	간단히 매트릭스 곱셈 해보시면...비교도할 수없는 속도가...
3	안녕하세요 tensorflow로 DNN을 공부하고있는 학생입니다.Mnist의 이미지파일을 DNN으로 분석한 오픈소스를 분석중에 있습니다.소스코드에서는 이미지의 크기가 28*28이라서 n_input을 784로 선언을 하였고, 분류할 클래스가 10개라서 n_classes를 10으로 선언을 하였습니다.제가 갖고 있는 데이터가 두번째 사진과 같은데, 제 생각에는 n_classes는 2가 맞는거 같은데, n_input값을 아무리 바꿔도 계속 에러가 나더군요...n_input과 n_classes를 어떻게 넣어줘야 작동을 할까요...?감사합니다.	2	MNIST의 경우 Class가 One-hot vector형태로 변환되어있기때문에 num_classes가 10으로 설정되어있습니다.학습할 데이터의 형태가 그림에 있는대로라고 한다면가지고계신 코드에 적용하기 위해서는 클래스를 one-hot vector형태로 바꿔주셔야 합니다데이터의 형태를 바꿨다는 가정하에 input 은 50개, class는 2개일것입니다.
1	안녕하세요? Tensorflow Tutorial에 예제에 보면 카테고리 feature에 대해 wide learning에서는  SparseColumn을 deep learning에서는 EmbeddingColumn을 사용하고 있는데 각각 무엇이고 왜 사용하는지 궁금합니다.	1	짧은 글인데 도움이 되실지 몰겠네요. https://tensorflowkorea.wordpress.com/2016/06/30/wide-deep-learning-with-tensorflow/
35	아래 채팅룸 이야기 나온김에 slack을 만들었습니다. https://tensorflowkr.slack.com 자동 가입 폼은 따로 만들어야 할 듯 하네요.추가: 가입용 링크를 자동으로 생성하는 앱을 런칭했습니다. https://tensorflowkr-login.herokuapp.com/ 이 링크로 가셔서 이메일을 입력한 후 가입하시면 됩니다.	0	음? 리밋이라네요 ㅠㅜ
78	안녕하세요~ 김성훈 교수님의 시즌 1 강의 보너스 영상으로 AWS 인스턴스를 이용하는 방법이 올라왔었습니다.이런식으로 원격 자원을 이용하시는 분들께 도움이 될만한 글을 적어 보았습니다.많은 분들이 Pycharm 을 사용하시는데, 이때 원격 자원에서 바로 컴파일 할 수 있게 도와주는 팁입니다.부족한 글이지만 필요하신 분들께 도움이 되었으면 합니다^^	1	제가 원하던 자료 입니다. 감사합니다. 아무래도 쥬피터보다는 저도 Pycharm이 편해서 항상 고민이었거든요.	1	pycharm community 버전은 안되고 pycharm pro버전만 되는 건가요? ㅠㅠ	2	오 멋진 꿀팁이네 !!! 공유 감사드립니다.	1	개인적으로 pycharm 사랑하는데 꿀팁이네요!	1	제가 삽질했던 부분 한가지를 추가하자면 deployment에서 remote쪽 mapping path가 "/"로 시작하더라도 sftp 설정에 넣은 root path에 상태 위치로 지정되네요. ftp 생각하면 당연한건데 한참 헤맸네요 ㅋㅋ
2	안녕하세요. 다름이 아니라 https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/cnn_customdata_basic.ipynb 를 돌려보고 나서 질문이 생겨서 질문 드립니다.위 링크에서 학습 된 모델에다가 제가 새로운 이미지를 넣고 돌려서 어떻게 나오는지 결과를 보고 싶은데, 그렇게 하려면 어떻게 해야하는지 궁금합니다.참고할 자료나, 예제를 알려주시면 정말 감사하겠습니다!
4	[스터디원 모집] "의사결정RL : 파트 5" - 의사결정의 심리학 + 파이썬(tensorflow)을 이용한 강화학습 스터디 * OpenAI Gym + tensorflow (실습) + 강화학습 + 신경경제학* 2주에 한번 월요일. 7시 30분 ~ 10시 30분. 강남, 회비 없음.- 이벤트 링크 - https://www.facebook.com/events/1210055399014463/* 이 스터디는 정통심리학 그룹 "싸이그래머"와 수리 사회-심리학 그룹 "싸이지먼트", 자연어처리 그룹 '바벨피쉬'에서 함께 진행합니다.* 발표 자료는 공개&공유됩니다(정리 중)* 텐서플로우로 강화학습 구현들을 자주 살펴보고 실습도 할 예정이라, 그룹과 관련성이 높다고 생각해서 공유합니다.의사결정에 대한 심리학적 이론 + 강화학습 이라는 주제로 스터디를 시작한지 어느새 1년이 넘었습니다. 알파고 이후로 강화학습쪽이 더 집중을 받고 있지만, 이 스터디의 장기적 목표는 '불확실성하에서 인간이 어떻게 보상에 반응하여 의사결정을 하는가'를 공부하는 것입니다. 물론 수리적 모형을 좀 더 많이 해보는 것이지만요.파트5에서도 파트4에 공부하던 것들을 이어서 합니다.* (강화학습기초) - 유다시티의 기초 강좌입니다. Q function쪽은 거의 끝났고 그 다음 주제로 넘어갑니다.* (딥강화학습) - 현재 Q-learning에 대한 근사방식들을 공부중입니다. * (신경경제학) - 의사결정에 대한 심리학적 수리모형들을 살펴봅니다.파트5에서 새롭게 하는 것은 다음과 같습니다.* 강화학습 사례 소개 - 좀 이런저런 사례들을 살펴보는 시간을 가질까합니다.* OpenAI Gym - OpenAI에서 내놓은 Gym이라는 강화학습 테스팅 프레임워크를 튜토리얼 정도의 수준으로 실습을 많이 해볼 생각입니다.전문가 모임이 아닌 / 배경,하는일 상관없이 - 관심있는 누구나 함께하실 수 있는 취미모임입니다. 새로 참여하시는 분들 언제나 함께 합니다.함께 하실 분들은 댓글을 달아주시거나, 링크된 이벤트에 참석을 누르시거나, 바로 해당 시간, 해당 장소로 찾아오시면 됩니다.	0	https://www.facebook.com/groups/psygrammer/	0	https://www.facebook.com/groups/psygement/	0	https://www.facebook.com/groups/babelPish/	0	커리큘럼 & 자료 - http://psygrammer.github.io/dprl/about/
4	tf api 로 아래 numpy 코드와 같은 구현을 하고 싶습니다.select, gather 등 사용해봤는데 뭔가 맘대로 잘 안되네요.그룹분들께 도움을 요청해 봅니다.data = np.array([1,2,3,4,5])data2 = np.array([0,0,0,1,1])data[data2 == 0] *= 2print data# output# [2 4 6 4 5]	6	indentation 은 적당히 봐주세요.def func(x1, x2):  x1 = tf.convert_to_tensor(x1)  x2 = tf.convert_to_tensor(x2)  assert x1.get_shape() == x2.get_shape()  mask = tf.equal(x2, tf.zeros_like(x2))  return tf.select(mask, 2 * x1, x1)
14	머신러닝, IoT 등 최신 기술로 세계 학생들과 겨룬다!- 미국 시애틀 마이크로소프트 본사에서 ‘이매진컵 2016’ 월드 파이널 개막
13	안녕하세요? 눈팅만 하다가 메시지 하나 올립니다. 이번 가을학기에 서울소재 대학교(좋은 학교에요 :-))에서 data science 강의 하실분을 찾고 계십니다. 혹시 관심있으신분 메시지 부탁드립니다. 박사학위 소지 여부는 상관없고, 데이터 관련 실무경험자를 우대한다고 합니다.	0	구체적이고 자세한 정보를 dethink@hotmail.com으로 보내주시겠어요??
28	혹시 홍정모 교수님 deep learning강좌 누가 올리셨나요 ? https://youtu.be/g3nhLjYRT5I
2	혹시 AWS g2.2xlarge에서  ConvNet MNIST, CIFAR-10 등의 Image Processing 예제를 돌렸을 때 트레이닝에 들어간 전체 시간을 비교해 볼 수 있는 참고 자료나 경험담 있을까요..? (결국 제가 궁금한 것은 g2.2xlarge에서 x 정도 픽셀을 가진 n 개의 이미지 데이터셋을 CNN으로 훈련시키고 평가할 때 대략 걸리는 시간입니다...! 학생이라 돈이 없어서...당장 GPU 살 수도 없고 ,,  가늠해보고 싶어서요.)	1	Code에 넣으시는게 제일 확실합니다.	1	4xlarge에서 간단한 CNN은 돌릴만 합니다. MNIST를 돌리고, conv 두 겹, fc 두 겹을 만들어서 돌리면 한 에폭에 1분정도 걸립니다.	0	전 맥북 로컬에서 mnist 테스트 했을깬 회당 30초 정도 였는데.. Aws에선 안돌려봐서... ^^;;	1	개인적으로 AWS GPU 인스턴스는 비추입니다... 웬만한 PC의 7~8배속 쯤 나오는 듯 한데 GPU 메모리도 너무 작고 CPU와 IO속도도 신통치 않고... 데이터좀 올리고 내리고 하고 인스턴스 시간 좀 쓰다보면 GPU 살돈이 나와서리 메리트가 별로 없더라고요...
5	What is Missing in AI from Google, Facebook, Amazon and Uber
9	안녕하세요? 한국어 자연어 처리에 관심이 있는 개발자입니다. 개인적으로 형태소 분석기까지는 개발했는데, 의미론 부분은 머신러닝으로 해결이 가능할지 탐색 중입니다. 머신 러닝은 초보에 가까우니, 많은 관심과 도움 부탁드립니다.
11	[질문] 큰 용량의 매트릭스 주로 어떻게 처리하시나요?제가 데이터를 매트릭스(.npz)로 변환했더니 줄여서(down sampling) 20GB가 나오더라고요. 하나의 매트릭스로 만들었더니 인덱스 가져오는데도 너무 느리고... 이런 경우 어떤 형태로 저장해쓰시나요? (그래도 (.npz)가 protobuf(.pb)에서 로드하는 것보단 빠르겠죠?)	2	중요한 질문인데 답이 안달려있네요. 혹시 stackoverflow등에서는 답이 없던가요? 학습한 모델을 로드할수 있으므로 데이터를 잘라서 이전에 학습된 모듈을 읽어온다음 계속 학습을 이어가면 되려나요?	0	Sparse면 indexing 해 보시죠	0	numpy에 대해 잘은 모르지만, npz이 zip으로 압축하는 방식인 것 같은데, 압축하지 않고 그냥 저장하는 방식이면 압축/압축해제에 드는 비용이 줄어들지 않을까요? 당연히 저장 공간은 그만큼 더 차지하겠지만요...http://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk
0	텐서플로우를 이용해서 Lenet-5를 실험하고 있는 과정에서 혹시 이러한 논문이 있는지 궁금합니다. Lenet-5 원래 모델과 텐서플로우에서 제공하는 모델(Lenet-5 Conv2 Table 사용 X)을 적용했을때의 차이점에 관한 논문이 있는지요 ???
1	대화 에이전트 개발자 (챗봇)게임스토리 작가사업기획자위 인재를 모집합니다.VR AI 전문 소프트웨어 개발 업체볼레크리에이티브와 함께하실 인재를 모집합니다.볼레크리에이티브는 대화형 AI 데이트 시뮬레이션 VR 게임을 개발하는 회사입니다.아래 명시된 분야 외에도 본인이 필요하다고 생각되신다면 주저없이 연락주시기 바랍니다.회사관련 정보는 회사 페이스북 또는 "볼레크리에이티브" 검색을 통해 확인할 수 있습니다.##############################[모집분야]##############################서버사이드 개발자 (대화 에이전트, 챗봇)####################담당업무--------------------영어 기반 자연어처리 라이브러리나 api 서비스를 응용해서 대화 에이전트(챗봇) 개발개발 형태. 웹20%, 서버30%, 챗봇50%주 언어는 자바이지만 다양한 언어로 개발 지향우대사항--------------------- 챗봇 개발 경험- 검색엔진 개발 경험- AWS 같은 클라우드 기반에서의 개발 경험- clojure, scala, python, haskel 같은 비주류 언어에 관심과 경험- 반응형 웹 개발 경험- 다양한 프로젝트 경험- NoSQL 관심과 경험- 다양한 웹서버, 디비서버 경험- 오픈소스/새로운 기술을 익히는데 흥미를 느끼는 사람- DB 튜닝 가능- 영어게임 스토리 작가####################담당업무--------------------대화형 인공지능의 영어기반 스토리라인과 대화 멘트 작성필수--------------------- 영작우대사항--------------------- 미연시 작가 경험- 기본적으로 문장작성능력이 뛰어나야 하며 귀가 간지러울 정도의 매력적인 필력을 가지신 분- 영어 원문 소설을 번역하신 분 또는 영어로 소설을 써보신 분 우대사업기획####################담당업무--------------------- VR 게임 소프트웨어 사업 기획- 회사의 전반적인 전략 기획- 투자제안서, 사업기획서 작성 등- 대외 사업개발 및 업무 협의우대 사항--------------------- 영어 또는 중국어- 경력 5년차 이상으로 팀 매니지먼트 가능##############################[절차]##############################1. "recruit@volercreative.com"으로 이력서를 자유양식으로 보내주시면 됩니다.  포트폴리오가 있으시다면 보내주시면 참고가 됩니다.2. 이력서 검토 후 일주일 이내 이메일과 문자로 결과를 통보해 드립니다. 서류전형 통과시 면접일정과 관련된 정보를 드릴 예정입니다.3. 1차 실무진 면접 (개발 직군의 경우 소양 테스트)4. 처우 및 입사일정 협의5. 2차 대표이사 면접##############################[복지]##############################4대 보험주 5일 근무성과에 따른 스톡옵션 부여탄력 출퇴근제자유 휴가제도서 구입지원개발 장비 본인 선택제##############################[문화]##############################별도의 직급체계가 없는 수평구조자유로운 발언과 토론을 지향주체적인 개발 목표 수립##############################[회사위치]##############################서울 서초구 서초대로 397, 부띠크모나코 2101호 (강남역 9번출구 3분거리)* 채용절차는 상황에 따라 변동이 있을 수 있습니다.
83	# PyCon APAC 2016에 참가하실 14명의 학생 대표를 모십니다!안녕하세요! 며칠전 Sung Kim 님께서 공지[1]해주신대로 TF-KR가 첫 모임 참가금의 절반을 올해 PyCon Korea 에 후원하기로 하였습니다.다만, 처음 계획과 달라진 사항이 몇 가지 있습니다:1. 애초에 참가금의 절반인 679,450원을 파이콘에 후원/기부/스폰서십의 형태로 전달하려고 하였으나 해당 금액에 적합한 스폰서 프로그램이 없는 관계로, 파이콘 코리아 운영진과 논의하여 티켓 구매의 형태로 진행하기로 했습니다.2. 파이콘 티켓의 금액이 5만원이기 때문에 13장의 티켓을 구매하고 나면 29,450원의 잔액이 발생하게 되었는데, 이에 가천대학교의 Sungchul Choi 님께서 20,550원 추가로 기부해주셔서 총 14장의 티켓을 잔액 없이 구매할 수 있게 되었습니다. (우왕!)3. 결국 TF-KR는 총 14장의 파이콘 티켓을 구매할 수 있게 되었고, 이를 커뮤니티에 기여할 용의가 있는 학생 분들께 드리기로 결정하였습니다. 학생 분들로 굳이 한정 지은 이유는, 재정적 지원이 더 필요할 법한 분들께 드리기 위함입니다.어쩌면 TF 관련 코드를 공개하거나, 질문/ 답변을 활발하게 해주시는 분들 위주로 지원을 해드리는 것이 더 바람직할 수 있으나, 이번에는 파이콘 측의 인쇄 일정 등으로 불가피하게 선착순 이벤트(!)를 진행하게 되었습니다. 대신, 이번 이벤트로 파이콘에 참석하시게 되는 분들은 참석 후기를 꼭꼭 공유해주시면 많은 분들에게 도움이 될 것 같네요 :)이번에 학생 대표 14명을 선정하는 원칙은 다음과 같습니다:1. 파이콘에 참가하고 싶은 (초|중|고등|대)학(원)생 분들은 한국시간으로 7월 21일 00시(GMT+9)부터 본 게시물에 "제가 참석할게요!"라고 댓글을 달아주세요. 해당 시간 이전에 댓글을 달아주시는 것은 무효입니다 ^^;2. 위의 방식으로 자정부터 선착순으로 14분을 받겠습니다. 혹시라도 14명의 학생분들이 내일(7월 21일) 중으로 모이지 않는다면 Regular 티켓 대신 Patron 티켓으로 구매해서 파이콘 쪽에서 남은 인원수에 대한 재정 지원을 할 수 있도록 하거나, 학생이 아니신 멤버분들께 티켓을 드리도록 하겠습니다.3. TF-KR의 지원을 받아 파이콘에 참가해주시는 분들은, 다녀와서 자기가 들은 내용을 그룹에 자유롭게 공유해주시면 됩니다!그럼, 내일(7월 21일) 자정부터 관심 있는 분들은 자유롭게 댓글 부탁드립니다! 선정되신 분들께는 이번 주중으로 티셔츠 사이즈 등을 여쭙기 위해 개별적으로 연락드리겠습니다 ^___^[1]: https://www.facebook.com/groups/TensorFlowKR/permalink/313534292320969/[2]: https://www.pycon.kr/2016apac/registration/purchase/ 페이지 내 "Patron" 섹션 참고	2	고등학생은 불가능한가요 ㅠㅠ	2	고원지 파이콘 가실거면 한번 신청해보세요!	2	홍보해도 되나요?	1	우아... 너무 좋습니다	0	Sungchul Choi 님 큰 감사!	1	야기 고등학생 얼리버드 신청한 사람 있는데... ㅠㅠ	1	본 포스트라면 지금 제가 댓글 달고 있는 이 포스트에 한국시간으로 21일이 되는순간 여기 댓글을 달면 되는건가요? 그리고 감사합니다 ㅠㅠ	0	Hanwoong Jeong	1	이주림 Minsuk Choi 파이콘!	1	2시간 22분 정도 남았습니다.	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할께요!~!	0	제가 참석할게요!	0	제가 참석할게요!	0	제가 참석할게요!
3	안녕하세요,혹시 러닝된 네트워크를 저장해서 실행할 수 있는 방법이 있을까요?네이티브 프로그램에 넣어서 데이터 입력에 대한 결과를 간단히 보려고 합니다.	1	학습된 값이라면 tf.train.Saver() 라는 기능이 있어요	1	텐서플로우내에 저장기능이 있습니다.좀 원시적으로 가자면 학습된 가중치들을 배열로 저장해서 연산해보는 방법이 있겠구요	0	답변감사합니다. 만약 해당 저장기능을 쓴다면 텐서플로우 없이도 입력데이터를 넣어서 결과를 볼 수 있나요??	0	텐서플로우의 세이버는 세션자체를 저장하고, 복구하는 기능이라 아마 안될겁니다텐서플로우 없이라고 하면 역시 가중치를 배열로 저장해서 따로 연산하는 방법밖에 생각나지 않네요...자세한건 더 고수분들이 설명해주실듯	0	자문자답입니다. Tensorflow serving 을 사용하면 가능하지만.. 윈도우는 지원하지 않습니다..	1	주말은 좀 쉬시는게...
32	텐서플로우도 오픈채팅이 있으면 좋을것 같아서 하나 만들어보았습니다.다른 언어를 공부할때 오픈채팅방에 참여를 했더니,정보교류나 팁 등을 빠르게 교류를 할 수있어서 시너지 효과가 좋은것 같습니다.혼자서 공부하다 막막하고 할때 서로 정보 교류를 했으면 합니다.많은 참여 부탁드리겠습니다.^^ 	0	카카오톡라	0	방이 꽉 찼다네요 ㅠㅠ	2	슬랙이면 더 좋았을것 같습니다 ㅜㅜ	1	카카오면 대화가 다 날라가는 측면만 봐도 슬랙 추천드립니다 ㅎ	2	말이 나온 김에 slack 을 하나 만들었습니다. https://tensorflowkr.slack.com 임의의 이메일에 대해 초대->가입하게 만드는건 초대 페이지를 만들어야 가능할 것 같고, 일단 gmail.com 으로 끝나는 사용자 모두가 가입할 수 있도록 옵션 설정해 놓았습니다.덧)gmail.com 이 안되네요;	0	자동 초대 메일 발송하는 앱 런칭해서 추가했습니다.	1	https://tensorflowkr-login.herokuapp.com/ 에 이메일 입력하시면 초대 됩니다.
5	질문을 하나 하고 싶습니다강화학습을 공부하다보니 bias와 variance가 계속 나오는데 학습알고리즘에서 bias나 variance가 높을경우 구체적으로 어떤 문제가 발생하는지 궁금합니다. 높으면 안 좋다고는 하는데 정확히 왜 안 좋은 지를 모르겠어서요!혹시 아시는 분 있으시면 설명해주시면 감사하겠습니다	2	구글에 bias-variance decomposition을 검색해보시기 바랍니다	2	bias variance trade off는 학습 모델의 에러를 바라보는 관점 중 하나입니다. 그렇게 어려운 개념은 아니니 위키를 보시면 이해가 되실듯 합니다. 간략하게 말씀드리면 bias는 true target function을 얼마나 잘 맞추느냐와 관련이 있고 variance는 현재 가진 학습모델이 얼마나 일반화가 잘되느냐와 관련이 있습니다. 두 가지는 일반적으로 trade off 관계가 있다고 알려져있고, boosting이나 neural net은 bias가 낮은 대표적인 모델이며 random forest는 variance가 낮은 대표적인 모델입니다. 다만 최근에는 이러한 trade off를 잘 극복하고 많는 학습모델들이 좋은 결과를 내는것을 볼수있습니다. 강화학습의 경우에도 유사한 의미로 적용되는지는 잘 모르겠네요.
135	머신러닝의 자연어 처리기술(NLP, Natural Language Processing)자연어 처리를 처음 접하시는 분들을 위해 정리한 자료입니다.전반부는 게이오 대학 학부생인 유우키군의 재밌는 발표자료를 보완해서 작성했고, 후반부는 KAIST 이진표씨의 발표자료를 그대로 옮겼습니다.  내용은 단어의 분산표현의 필요성단어문맥행렬이란 ?  특이치분해(Singular Value Decomposition)를 통한 단어벡터(Word Vector) 만들기단어벡터의 의미문맥으로부터 단어를 예측하거나 반대로 단어로 부터 문맥을 예측하는데 할용되는 기술인 CBOW와 Skip-gram 모델에 대한 설명	1	감사합니다	2	이진표	1	좋은 정보 감사합니다~
6	안녕하세요.Sung Kim 교수님의 시즌1 동영상강의 정말 감사히 잘들었습니다.현재 github에 올라와 있는 CNN example(MNIST datasets을 이용) code를 참고하여 CIFAR10 datasets을 가지고 code를 작성해보았습니다.(사실은 거의 보고 따라한 수준입니다...ㅠㅠ) 이해를 하기위해서 직접 작성하고 있는데 몇가지 질문 드릴것이 있어서 말씀드리려고 합니다. 제가 작성한 코드에 대한 파일도 같이 올렸습니다.1. CIFAR10의 datasets에서 labels의 값을 확인하면 0 ~ 9 까지의 값으로 되어있는데 저는 이것을 통해 One-hot encoding을 통해 바꿔주었습니다. (예를 들어, label이 2인 경우 [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) 그런데 tensorflow 홈페이지에서 발견한 소스코드에서는 굳이 One-hot encoding을 하지 않고 있는 그대로 Training에 이용한 걸로 이해했습니다. One-hot encoding을 하지 않아도 되는 것인가요??2. One-hot encoding 이후에 코드를 작성하였습니다. 코드 중에 model  function 작성내용중 tf.nn.lrn(...) 부분이 있는데 논문(ImageNet Classification with Deep ConvolutionalNeural Networks)을 찾아보니 Local Response Normalization(LRN)에 대한 함수이더라구요. 그러면 왜 LRN을 사용하는 이유는 무엇인가요? error rate를 줄여준다고 논문에는 써있는데 어떠한 원리로 줄어드는건가요?3. with 블록 부분에서 for문을 사용하여 training을 시키는데 구글링을 하여 CIFAR10을 구현한 글을 보면 100만 step까지도 training을 하더군요. step의 길이를 이렇게까지 크게 하는 이유는 무엇인가요?제가 글을 잘 쓰는 편이 아니고 질문도 매우 길어졌는데 읽기 힘들게한점 죄송합니다. 답변 부탁드리겠습니다.	0	텐서플로우 MNIST 데이터 셋은 로딩 할 때 one hot encoding으로 불러오는 옵션이 있는것으로 알고 있습니다.
19	대전 연구단지에서도 딥러닝의 열기가 후끈합니다.오늘 연구소와 기업체 두곳을 대상으로딥러닝 강좌를 열었는데80 여명이 넘는 연구원들이 참여했습니다.강의하시느라 고생 많으셨습니다.사진 속 인물은 강사가 아니고 강사를 소개하는 대표님.	2	앞으로 어디서 모임하시나요?	1	좋은 강연 잘 들었습니다!
26	0.9 에서의 BasicRNNcell 예제 코드TensorFlow 0.9 업데이트에서 RNN 관련 API 가 상당히 많이 바뀐 이후로 from tensorflow.models.rnn import rnn, rnn_cell 을 사용하면 아래와 같은 오류 메시지가 출력됩니다.ImportError: This module is deprecated.  Use tf.nn.rnn_* instead.새로운 RNN 모델 사용방법의 자세한 안내에 대한 API 문서가 아직 나와 있지 않은 것 같고, TensorFlow 공식 Github issue 에도 종종 이러한 문의가 들어오지만 아직은 답변이 없네요ㅜㅜ오늘 0.9버전 업데이트 후 실행되던 코드에서 오류가 나서 되게 당황했었는데 저같이 새로운 RNN API 사용법이 헷갈리시는 분들, 또는 처음 접하시는 분들을 위해김성훈 교수님 강의 내용https://www.youtube.com/watch?v=A8wJYfDUYCk&feature=youtu.be을 그대로 따라 만든 짧은 코드를 공유합니다.https://gist.github.com/j-min/481749dcb853b4477c4f441bf7452195	1	감사합니다. 혹시 https://github.com/nlintz/TensorFlow-Tutorials RNN코드들도 0.9에서 돌아갈수 있도록 도움 부탁드려도 될까요?	2	gist 코드는 제가 만든 비디오 노트로 넣어 두겠습니다.	2	혹시 교수님 강의에서 진행하신 코드 전부 파이썬 3 tf 0.9 동작되는 코드 깃헙에 잇는데 필요하신가용?
9	MNIST 를 이용한 NN imporeve 과정을 하다가 갑자기 궁금해져서 테스트를 해봤습니다.github : https://github.com/seojey79/eml여기서 테스트 코드는 "ML lec 10 - adaptive NN"결과 파일은 "MNIST_perf.xlsx" 확인하시면 됩니다.이미 많은 분들이 해본신 내용이겠지만TensorFlow와 Python 코드 둘다 익숙해 지는 것이 필요하다 생각해서 함 보고 공유드립니다. 여기 아래부턴 테스트 내용을 간단히 옮긴 것입니다.----------------------------------------------------------------Q1: learing-rate은 결과에 영향을 미치는가?Q2: dropout과 deep 하게 hidden-layter를 설정하면 정말 성능이 좋게 나오느가?      - 이는 테스트 중 우연히(?) 잘 나오게되는 경우를 보게 되서 그래서 Test Case를 다음과 같이 나눠서 진행했습니다.case 1 : softmax (LR (learing-rate):0.01)case 2 : softmax (LR : 0.001)case 3 : NN (LR : 0.01)case 4 : NN (LR : 0.001)case 5 : NN-xavier (LR : 0.01 )case 6 : NN-xavier (LR : 0.001 )case 7 : NN-dropout-deep (LR : 0.01 )case 8 : NN-dropout-deep (LR : 0.001 )테스트 중 특이점은 아래와 같은 것들이 있었구요.* optimizer's learning rate : sample 확인중 learning rate이 주는 영향을 확인하기 위해 두개의 값으로 비교하며 테스트** 테스트 케이스  : MNIST의 Cost 최초 값은 W가 0에서 시작하는 경우 훨씬 작은 값에서 시작하는 특징을 가지고 있음. 이로 인해  NN에서  W's 를 random으로 설정하는 경우 타 테스트 대비 너무 높은 오차가 발생함. 이를 방지하지위해 최초 값을 softmax 처럼 Zero에서 시작하도록 다시 테스트함결과는 * learning rate가 결과에 미치는 영향: 비교 케이스가 적긴 하지만 낮은 경우에 보다 좋은 성능을 보여주는 결과가 나옴. 로직이 고도화될수록 더 크게 영향을 줌.** dropout(with more deep(Hidden layter : 3->5)의 경우 반드시 결과가 좋게 나오지만은 않음을 확인*** 강의 내용의 내용 다시 확인    - NN의 성능     - W's의 초기화가 성능에 미치는 영향 이런 것들이었습니다.추가적으로 해볼만하다 느낀 것들은 * 적절한 Learning-Rate 설정을 위한 알고리즘 별 비교 **  NN의 hidden layer가 성능에 미치는 영향 및 적절한 값을 설정하는 방법 파악 *** training 회수 설정에 대한 고찰.
1	안녕하세요! Tensorflow를 공부하고 있는 학부생입니다!First contact with tensorflow 책을 보면서 공부하고 있는데요.jupyter notebook을 사용하고 있는데 Cuda가 문제인건지...mnist를 이용한 Single layer neural network가 작동하지 않습니다.터미널에서 오류를 보니 tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_MISALIGNED_ADDRESS :: No stack trace available라고 뜨더군요. 혹시 이런 상황을 겪으신 분이 계신지 궁금합니다...감사합니다!	0	cuda버전이랑 tensorflow에서 지원하는 버전이 다를 때 이런 문제를 보았습니다.설치한 cuda 버전,cudnn버전이 사용하시는 tensorflow버전에서 지원하는지 확인해 보세요.버전이 다르다면 새로 빌드하시거나 버전에 맞게 설치하시면 잘 실행될꺼예요.
3	Sung Kim 교수님 Youtube를 통해 ML에 대해 잘 배우고 있습니다. 한가지 질문이 있습니다. CNN 에서 Max Pooling을 진행할 때 Convolution layer에서 Sampling을 통해 Pooling image set을 만든다고 하셨는데 여기에서 Convolution layer가 6개이면 6개 전체에 대해 Sampling을 다 진행하는 건가요, 아니면 그 중 하나의 layer만 골라서 Pooling image set을 만드는 것인지 궁금합니다. 동영상에서는 하나의 layer를 골라서 진행한다는 것으로 이해를 했습니다.	2	다시 동영상을 들어보니 하나의 layer씩 전체를 다 이용해서 만드는 것이군요.
33	Deep_NLP_Study_2016.07.19_RNN	4	이번주 제주에서 있었던 RNN 세미나 발표자료입니다. 설명도 잘해주시고 자료도 매우 훌륭합니다. Yang JeongSeok 참고 하세요.	0	RNN에 대하여 잘 정리하신 자료네요.공유해주어서 고맙습니다.
1	Session 1 of #CADL Creative Applications of Deep Learning is now online, w/ github https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow-i/info https://github.com/pkmital/CADL
12	안녕하세요!텐서플로우를 시작한지 얼마되지 않아서 고수분들의 의견을 여쭙고자 합니다.맥북프로(nogpu)에서 cnn mnist관련 예제를 돌려보면 accuracy가 0.9 이상은 나옵니다.좀더 빠른 환경을 구축하고 싶어 GTX-1080 두놈을 꽂아서 ubuntu에서 개발환경을 셋팅해서 cnn mnist 예제를 돌렸더니 같은 샘플코드임에도 불구하고 거의 0.1%대에 머물러 있더군요. 속도는 많이 빠릅니다 ㅡ.ㅡ 혹시 learning rate이 너무 낮은가 해서 조정해 보았지만 현상은 비슷한데... 저도 이제 막 직접적으로 실습해보기 시작한터라 여러 가지 시도는 해봐야겠지만 이 부분에 대해 경험이 있으신 분이 있으시면 조언 부탁드립니다.감사합니다.	7	질문과는 별개로... 'GTX1080 두놈을 꽂아서'에서 부러워하면 되는건가요...ㅠㅠ	0	그러게요.. 1080 두개... 부럽...	0	ㅎㅎ 개인적으로 할 수 없고 회사 지원을 받았답니다 ^^ 그런데 활용이 안되면 ㅡ.ㅡ  기대와 달리 training accuracy변화가 일어나지 않아서...	0	일단 러닝이 되고있는지, weight에 변화가 일어나고 있는지, loss는 줄고 있는지, 입력값이 제대로 잘 들어가고 있는지, 각각 값들을 찍어보셔야 할 듯 합니다	0	네. 제가 별도로 작성한 코드가 아니라서 코드자체는 의심을 하고 있지는 않은데요. 유독 기존에 짜여진 cnn 코드가 이런 현상을 보입니다. 맥북에서 CPU로 실행 시켜보면 잘 돌아가는데 말입니다.	0	예를 들어 GPU 모듈 로드에 실패했을 경우 콘솔창에만 에러가 뜨고 제자리 걸음인데 IDE에는 나타나지 않을 수 있습니다	0	1080설치된 컴퓨터에서 cpu모드로 한번 돌려서 확인 해 보는게 어떨까요?	0	현재는 주로 콘솔창에서 작업을 하고 있구요... 인식은 한듯보이구요 ^^ Tensorflow CPU버전을 설치해봐야 겠네요. 그런데 두버전이 동시에 설치되나요?	0	Gpu 버젼에서 디버이스를 cpu로 동작하게 하는게 가능한걸로 아는데요	0	네 그렇게 하면 되겠군요 ^^	0	도환형님! 영어이름보고 처음에 제가 아는 그 도환형님인가 했습니다 ㅎㅎ 그간 건강하셨는지요? 이렇게 뵙게 될줄이야... ㅋㅋ 반갑습니다 형님!	0	현권 반갑다 ^^ 어디서 지내나? 멀리있는것 같던데?	0	이도환님 혹시 GPU 말고 PC의 다른 사양은 어느정도가 되시나요? 저도 GTX-1080 두개로 PC를 맞추려고 하는데, 감을 못잡아서요.ㅎ	1	프로그램 실행중에 nvidia-smi로 vram과 core utilization rate를 확인해보시어 GPU가 제대로 돌고있는지 확인해보시는건 어떨까합니다. 제대로 돌고있다면 precision 문제를 의심해볼수 있을것 같습니다. 제가 MNIST를 titan black 또는 k20에서 돌렸을경우 0.9 이상은 나옵니다	1	제가 구성한 PC 사양입니다.CPU: 6th i7 Skylake 6700Mother Board: Gigabyte Z170X-DESIGNAREGraphic Card: GEFORCE GTX-1080 x2Memory: 32GSSD: 256×2HDD: 2Tx2CPU를 Xeon계열로 하시게 되면 MB도 사양이 바뀌어야 하구요메모리도 종류가 사양이 바뀝니다. 따라서 비용도 증가하구요~ ^^도움이 되셨길...그리고 Ubuntu는 16.04로 설치해서 사용중입니다.	0	system specification과 accuracy는 상관이 없는게 정상이라고 생각합니다. 뭔가 잘못된것 같은데 어떤 경우인지 궁금합니다.	3	저도 경험한 사례네요. docker의 r0.9devel 컨테이너로 no gpu로 돌리면 학습이 되는데 r0.9devel-gpu로 돌리면 학습이 안되더군요 신기하게 cuDNN 5.0 기반으로 최신 tensorflow를 빌드해서 사용하면 정상적으로 학습이 되었습니다. 참고 하시기 바랍니다	0	네 감사합니다. 기존설치버전에서는 cuDNN 5.0이 지원되지 않아 4.0으로 낮춰서 했었는데 말씀하신대로 다시 빌드를 해봐야겠군요. 좋은 정보 감사합니다.	1	Ubuntu 16.04, GTX 1080에서 최신버전의 cuda 8.0 rc 및 cuDNN 5.0 라이브러리로 빌드했더니 문제가 해결되었습니다. 학습이 정상적으로 잘되고 있습니다. 조형헌님께 감사드립니다.^^	0	이도환 안녕하세요 저도 비슷한 문제를 겪고 있습니다. 혹시 tensorflow version은 r0.9인가요? 답변 주시면 감사하겠습니다 ^^.	1	형, 잘 배워서 제게도 좀 전수해주세요.늘 핫한 기술에 학구열을 불태우시는 모습 존경스럽습니다.
53	Tensorflow tutorial을 이해하기 쉽게 설명해주는 동영상 자료	1	감사합니다 Pretty Tensor 가 아주 직관적이네요 ㅎㅎ	0	가르치는 기술도 점점 발전하네요.	1	제가 돌려보니 이 jupyter notebook에서 다음과 같이 중간에 에러가 나서 유튜브 동영상에 질문을 올려놨는데, Sangjin Sim 님이 해결해 주셨습니다.TensorFlow Tutorial #02 - Convolutional Neural Networkhttps://youtu.be/HMcx-zY8JSg?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZBut I have an error in doing your code in your notebook.( https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb )# Flatten Layerlayer_flat, num_features = flatten_layer(layer_conv2)---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)<ipython-input-43-6edd54bdb271> in <module>()----> 1 layer_flat, num_features = flatten_layer(layer_conv2)<ipython-input-33-eee8e5b8eccb> in flatten_layer(layer)      8     # The number of features is: img_height * img_width * num_channels      9     # The shape uses a TensorFlow datatype, so convert it to numpy.---> 10     num_features = np.array(layer_shape[1:4], dtype=int).prod()     11      12     # Reshape the layer to [num_images, num_features].TypeError: long() argument must be a string or a number, not 'Dimension'I performed same version of TensorFlow (0.8.0) like you.Can you help me about the above error?	2	심상진 님의 도움으로 다음과 같이 해결하였습니다.# Error# num_features = np.array(layer_shape[1:4], dtype=int).prod()# Correctionnum_features = np.array(list(map(lambda x: int(x), layer_shape[1:4])), dtype=int).prod()Thanks to Sangjin Sim	1	저는 python 2 환경에서 돌려봤는데요. 소스는 python 3 버전인가 보네요. math.ceil() 함수 앞에 int() 로 형변환을 해줘야만 python 2 환경에서도 소스가 제대로 돌아갑니다.	2	https://youtu.be/HMcx-zY8JSg?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ소스 올리신 분이 TensorFlow 함수를 사용해서 좀 더 우아한 코드로 바꿔주셨는데요.python 2 에서도 잘 작동합니다.math.ceil() 앞에  int() 로 형변환은 해줘야 합니다.Thanks for the compliment, I'm glad you liked the tutorial! Also thanks for the bug-report! I don' know why it caused an error on your system - perhaps it's in NumPy. Anyway, I found a more elegant solution using the TensorFlow function num_elements(). The Notebook has been updated with the following line:num_features = layer_shape[1:4].num_elements()	1	대단하십니다.  수고하셨습니다.
31	기초 정리윈도우 도커에서 텐서플로우 환경에서 실행해봤어요기본 이미지에 matplotlib이 없어서 인스톨하면서 태스트	2	TF 학습과정과 결과를 보여주기 좋은 lib입니다. 감사!!
63	Sung Kim 교수님과 그룹에 대한 기사가 있어 스크랩하였습니다.	3	윽 그런데 이 글에 있는 제프딘의 멘트는 제 블로그에 번역해 놓은 걸 그냥 가져다 썼네요. 흠.. 좀 그러하네요...https://tensorflowkorea.wordpress.com/2016/06/07/ask-jeff-dean/
28	OpenAI의 CartPole예제를 DQN으로 푸는 코드를 분석해보았습니다.참고해주세요!	1	DQN 이해하는데 많이 도움이 될 것 같습니다. 고맙습니다 ^^	0	👍👍👍👍👍
1	안녕하세요 텐서플로우 공부하는 학생입니다!다름아니고 텐서플로우의 기본 작동원리가 이해가 잘 안가서 여쭤봅니다. 데이터 셋이  9*2451정도 되고 결과를 1과 0로 표현한 것을 구했습니다. 이 값을 기존의 softmax 예제의 input layer의 뉴런 수를 9로 바꾸고 10층 100개의 뉴런을 가진의 hidden layer, output layer의 뉴런은 1개로 모델을 만들고 돌려봤습니다.이러한 모델을 돌렸을때 sess.run(train, feed_dict={X: x_data, Y: y_data})여기서 X데이터와 Y데이터는 어떤 방식으로 들어가게 되나요?한번의 run 이 실행될때 위의 데이터 셋에서 x데이터의 첫번 째 행의 데이터와 y데이터의 첫번째 행을 읽어들여서 학습을 하는 건가요? 아니면 한번의 run이 모든 데이터를 가지고 한번 학습한걸 뜻하는건가요?일단 저 데이터셋으로 돌려보니 결과가 제대로 나오지 않습니다 ㅠ모든 예측 결과값이 1로 나오네요아직 텐서플로우가 잘 이해가 가지 않네요 ㅠ	0	x,y의 경우는 매트릭스로 들어가 행렬연산으로  전체를 학습하게 됩니다.그래서 보통 batch_size라는 개념으로 파일을 쪼개서 넣게되지요.그리고 예측값이 모두 1로 나오는건 output layer의 노드를 1개로 만들어 그런거 같습니다.0과 1 두개로 나오게 할거면 2개로 하면 해결될거같아요
4	조카가 대학 1학년 마치고 군에 입대해 있는데  머신러닝 입문용 책 추천 좀 해주셔요.  영어로 된것은 힘드나 봐요.	1	아쉽네요..칼텍의 learning from data강의가 정말 좋은데 영어라서 아쉽네요	1	머신러닝인액션 책은 어떨까요?	4	밑바닥부터 시작하는 데이터과학 이책은 어떤가요?http://www.aladin.co.kr/shop/wproduct.aspx?ItemId=84725482
6	안녕하세요^^ 텐서플로우를 이용하여 비디오 인덱싱을 하는 공부중에 있습니다. 예전 (2006년쯤 -.-)에 SNNS (Stuttgart Neural Network Simulator)를 사용하여 NN을 공부할 때는 learning된 결과값을 SNNS2C라는 프로그램으로 *.c와 *.h로 출력할 수 있었는데요.. 텐서플로우에서는 learning된 결과를 다른 프로그램에서 사용하려면 어떻게 해야 하는지 모르겠습니다. 다른 분들은 학습된 결과를 어떻게 뽑아서 사용하시는지 궁금합니다.고맙습니다.	0	저 같은 경우에는 학습된 Variable을 numpy array로 반환한 뒤 binary파일로 만들어서 다른 프로그램에서 쓰곤 했습니다
8	여기 올려도 될지 모르겠는데, 혹시 구글 syntaxnet 쓰시는 분 계신가요?syntaxnet 해보고 싶어서, 설치하다가 bazel test에서 25000번째 컴파일 할때 다운되서, ctrl f1 터미널에서 해보니까 저기서 안넘어 가네요. 테스트 안하고 거기 예제 입력해보면 에러 뜨고,도커로 하니까 -i -t 터미널로 접속하려니까 65000개 load 할 때 안 넘어가네요. 구글 텐서플로우 관한 것만 올려야 되지만 구글 거니까 syntaxnet도 혹시 써보신 분 있으면 혹시 해결책 좀 부탁드려요	1	OS의 버젼이 궁금하네요.. 제 블로그 글 링크합니다 http://cpuu.postype.com/post/197684/	1	우분투 16에서 하고 있어요도커로 하면 저기서 안 넘어가고, 그냥 도커 없이 설치하면, symbolic link 에러 뜨기도 하네요	1	김무훈님, 이글들 참조하세요.	0	좋은 질문 감사!
62	[TF-KR 첫 모임의 마지막 비디오]지난 6/18일 모임 강좌의 마지막 비디오 (RNN)를 올려 드립니다. Taegyun Jeon님은 6/18일 모임후 좋은 곳에 구직을 한것으로 알고 있습니다. 축하 드립니다.Electricity Price Forecasting using Recurrent Neural Networks 전태균 (광주과기원에서 박사과정중이며, 8월에 학위수여 예정이며 곧 백수가 된다는 두려움에 떨고 있습니다. 구직중입니다!)발표자료: http://www.slideshare.net/TaegyunJeon1/electricity-price-forecasting-with-recurrent-neural-networks동영상:  https://www.youtube.com/watch?v=s3n-D7SZDN8	1	전박사님 강의도 멋지게 하네  ㅋㅋ	1	전박사님 강의도 멋지게 하시네 2!	9	아직 구직 중입니다. 허허 :) 논문 제출끝나면 업그레이드된 구현물을 다시 올려드리도록 하겠습니다.	0	송남훈
68	텐서플로우를 공부하다보면numpy 라는 놈을 만나는것 같은데요.이와 관련된 ebook을 오늘 하루동안 공짜로 나눠주네요..ㅎㅎ해당 링크로 들어가면 다운받는 방법이 나오니깐텐서플로우를 하시는 분들은 미리 다운받아 놓으셔도 좋을것 같습니다.^^	1	오..안그래도 numpy공부중이었는데 감사합니다	1	우와 정말감사합니다!!	1	좋은 정보 감사!!	1	좋은 자료 감사합니다 ㅎㅎ	1	여기 pactpub subscription 구매하시면 한달에 3만원 정도에 여기 책은 무제한으로 볼수가 있습니다. 새로운분야 공부할때 편해요.	0	감사합니다	0	늦었군요 ㅜㅜ	1	Junyoung Park 이미 늦었지만 그래도 참고
85	최근 한글 Word2Vec 을 작업할 기회가 있어, Python(Gensim) 과 Scala(Spark)로 각각 Word2Vec NLP 전처리 구현을 해본 경험을 공유해봅니다. 이제 얼른 후처리로 TensorFlow 로 넘어가 보도록 하겠습니다.	1	좋은글 감사합니다. "데이타를 조사제거하고, 의미없이 너무 긴단어 제거하고, 몇몇 전처리를 해 줘야 하는데, 이 역시 Konlpy 등을 이용하면, 어렵지 않게 전처리 가능하다. (물론 Data가 매우 매우 클 때는 Python 으로는 매우 오래 걸리는 작업이긴 하지만..)" 이를 하지 않으면 성능이 많이 떨어지나요?	1	유용한 자료 감사합니다!!!	2	word2vec에 관한 장황한 소개글을 봤을때는 뭐하는 물건인가 하고 덮어뒀었는데 vector algebra 처리해준다는 한방으로 이해가 되네요 >.<일단은 적당한 데이터는 파이썬을 쓰면 쉽다는 말씀이시죠? 고맙습니다 :D	1	감사합니다.
8	TensorFlow 및 SyntaxNet을 활용/스터디하면서 챗봇을 개발하시는 분들은 개발 결과 및 경험을 "봇 그룹 Bot Group"에도 공유해주시기 바랍니다. 감사합니다.https://www.facebook.com/groups/botgroup
6	AI 기획자를 채용합니다. 본인이 아니라도 주변에 괜찮은 후보가 있으면 좀 알려주세요. 많은 관심 부탁합니다.	0	기획자 중에 여기 오실 분이....	0	AI에도 기획자가 필요한 이유가 뭔가요?
1	https://www.youtube.com/watch?v=ZrWP6_gHf3k
4	CNN 구성 중 overfitting 문제가 발생하여 질문 남깁니다.l2 loss 메서드를 이용한 일반화(regularization)를 적용하려고 하는데,여러 단계의 Convolution layer를 구성할 때 모든 레이어에 loss를 적용하는게 맞나요?	0	마지막 단계에만 적용하는거 아닌가여	0	task마다 다르긴 하겠지만 개인적으로 두 케이스를 비교했을 때, last layer에만 적용했을 때 좋은 결과가 나왔습니다.
47	Word2Vec에 대한 질문과 간단한 사용방법을 알려주는 답변입니다.http://stackoverflow.com/questions/38027289혹시 한글로 Word2vec모델 만들어 사용하시는 분들이 계신가요?	1	저는 개인적으로 gensim 라이브러리를 이용하여 만들어본 경험이 있는데, 좋은 데이터셋을 찾기가 어렵더군요 다른분 http://w.elnn.kr/search/ 께서 한국어 위키백과와 나무위키를 이용하여 word2vec을 만드셔서 한번 시도해 보고 있습니다. 128차원으로 우선 트레이닝 하고 있습니다	0	전처리는 koNLPy를 사용하고 있습니다	3	교수님은 이미 알고 계시겠지만 다른 관심있는 분들은 http://www.slideshare.net/lucypark/nltk-gensim 이자료를 참고하시면 도움 되실 것입니다	4	네 저희는 spark mllib 안에 있는 word2vec 라이브러리로 word2 vec 돌려보았구요. 단일머신으로는 gensim이 더 빨랐지만, 학습할 데이타가 점점커져서 분산처리 가능한 spark ml 로 로직을 포팅했습니다.	0	안녕하세요. 올려 주신 코드 잘 보고 있습니다. tensorflow homepage에 있는 word2vector에 대한 질문이 있습니다. dictionary를 만들 때 왜 most frequent words를 이용하는지 궁금합니다. 다른 library들도 이러한 방법으로 사용하는 것 같습니다. 저는 보통 sentimental analysis 할 때 이러한 단어들을 안 쓰는 것으로 알고 있습니다. 감사합니다.
4	안녕하세요! Tensorflow를 공부하고 있는 대학생입니다. 공부하던 중에 Neural Network 에서 Hidden Layer가 잘 이해가 가지 않는데요. Hidden Layer가 필요한 이유가 무엇인가요? Hidden Layer의 갯수가 적은 것과 많은 것의 차이점이 있나요?	0	가장 간단한 예로 xor처럼  input layer와 output layer만 가지고는 해결할 수 없는 문제들을 해결하기 위해 추가적인 hidden layer들이 필요합니다. 짧게 정리하면 linear한 문제가 아닌 non-linear한 문제를 해결하기 위해 필요한 것이죠. Sung Kim 교수님의 https://www.youtube.com/watch?v=GYecDQQwTdI&feature=youtu.be 이 강의를 보시면 도움이 될 듯 합니다. Hidden layer가 많고 적고의 차이점으로는 많을수록 학습하기가 어렵고 연산이 오래 걸린다. 그리고 모든 경우에 해당하진 않지만 hidden layer가 많을때 정확도가 더 높아지는 경우가 있다. 정도일까요? 써놓고 보니 너무 당연한 얘기인것 같네요..;
2	NN 에서 xor 샘플을 돌리는 데 에러가 납니다. 원인 파악이 안되서 올립니다. github에 올려저 있는 예제를 수정한 경우에는 잘 됩니다. (W개수를 10->2) 그러나 순수히 제가 작성한 경우엔 안되네요. 무슨 차이 일까요?에러 내용은 "......InvalidArgumentError                      Traceback (most recent call last)<ipython-input-2-83e144572975> in <module>()     29      30     for step in range(2001):---> 31         sess.run(train, feed_dict={X: x_data, Y: y_data})     32         if step % 200 == 0:     33             print (step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(L2), sess.run(hypothesis))....."예제 코드는 아래와 있습니다.import tensorflow as tfimport numpy as npxy = np.loadtxt("../data/train_xor.txt", unpack=True)x_data = xy[0:-1]y_data = xy[-1]X = tf.placeholder(tf.float32, name='x-input')Y = tf.placeholder(tf.float32, name='y-input')W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))b1 = tf.Variable(tf.zeros([2]), name="b-1")b2 = tf.Variable(tf.zeros([1]), name="b-2")L2 = tf.nn.relu(tf.matmul(X, W1) + b1)hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)cost = -tf.reduce_mean((Y*tf.log(hypothesis)) + ((1-Y)*tf.log(1-hypothesis)))opt = tf.train.GradientDescentOptimizer(0.01)train = opt.minimize(cost)init = tf.initialize_all_variables()with tf.Session() as sess:    sess.run(init)    for step in range(2001):        sess.run(train, feed_dict={X: x_data, Y: y_data})        if step % 200 == 0:            print (step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(L2), sess.run(hypothesis))        co_predict = tf.equal(tf.floor(h + 0.5), Y)        acc = tf.reduce_mean(tf.cast(co_predict, "float"))    print(sess.run([hypothesis, tf.floor(h + 0.5), co_predict, acc], feed_dict={X: x_data, Y: y_data}))    print("Acc:", acc.eval({X:x_data, Y: y_data}))	1	InvalidArgumentError의 구체적인 내용을 적어주시면 원인 진단이 더 쉬울 것 같습니다. 지금 보기로는 아마 feed_dict에 들어가는 x_data, y_data가 float이 아니라서 그럴 수도 있겠네요. data가 int라면 float으로 캐스팅해서 넣어주셔야 합니다.그리고 step%200 == 0일때 로그 찍는 부분에서도 L2, hypothesis를 run 하시려면 feed를 해주셔야 합니다. sess.run의 첫 번째 인자를 cost가 아니라 [cost, L2, hypothesis]로 바꿔주시면 될 듯 하네요.	3	입력 데이타를 좀 손 봐야 합니다. 이거 참고하세요. https://github.com/jinhoyoo/deep_learning_research/blob/master/xor_example.ipynb
3	혹시 윈도우10에서 ubuntu-bash 사용해보신 분들께 질문드립니다.그 윈도우 인사이더..라는게 조금 겁나네요.누군가가 무한 리부팅을 겪었다고도하고..(물론 조금 예전 이야기지만..!)지금, 안정적인가요?	1	현재 인사이더 최신빌드는 rtm수준이라 상당히 안정적인 것으로 평가받고있습니다. 저도 물론 사용하고 있구요	0	저도 윈도우에서 돌리고 있습니다^^
2	[질문] window 7 32bit 에도 tensorflow 설치가 가능한가요? 제가 본건 64bit만 된다고 나와있어서요 ㅠ	2	Tensorflow 자체가 64비트만 되서 32비트에선 안될거 같은데요.	1	윈도우 7은 안됩니다
6	api.ai에 webhook을 걸어서 테스트 해보았는데, 재밌네요. 잘 활용하면 재밌는 것을 많이 만들 수 있을 것 같아요...	0	어떤 재미있는것들이 있을까요? 아직은 intent등과 이에대한 답들을 일일이 너어 주어야 하는데 예문들에게 자동으로 뽑아 낼수 있으면 더 좋을것 같아요. 좋은 프로젝트 진행하시면 알려주세요.
59	Sung Kim 교수님의 모두를 위한 딥러닝 시즌1예제 코드들 입니다.현재 수강중이시거나,코드를 간간히 짜시는 분들에게 유용할것 같아서 공유합니다!각 강좌마다 사용한 Linear, Logistic, Softmax, NN, 등등에 대해서 코드를까먹을때마다 저도 유용하게 사용하고 있습니다. (모델 Save 등)	3	감사합니다. 좋은 코드 많은 분들이 보시면 좋겠습니다.
93	TF첫 모임 참가금 후원 완료!수입: 1,358,900 (참가비 온오프믹스 1,318,900+현장등록 4만원) 지출1: 파이콘 후원 679,450지출2: 공감 후원 679,450잔액: 0 여러분들이 내신 참가비로 투표해주신것 처럼 파이콘과 공감에 각각 50%씩 후원하였습니다. (한표의 중요성!) 파이콘 후원은 일단 Lucy Park님에게 보내 드렸으며 Lucy님이 후원을 진행하고 다시 알려줄 예정입니다.다시한번 참여해주시고 참가비를 보내주신 여러분들에게 감사드립니다. 후원과 이번 처리건에 대한 문의나 의견있으시면 댓글 달아 주시면 됩니다.앞으로 하게될 2, 3번째 모임 참가비도 모두 후원 할수 있도록 하겠습니다.	2	멋지네요~  마음도 뿌듯해지네요~~♡	3	수고 많으셨습니다~~~	1	저도 멋지게 느껴져요^^	2	정말 수고 많으셨습니다. 멋진 일을 늘 멋있게 해내셔요!	1	교수님! 너무 멋지세요^^ 수고많으셨습니다!!	1	키야..멋집니다..!!! 다음에는 저도 꼭 교수님들 뵈었으면 좋겠습니다
21	#스몰마인드 스몰마인드 : 파트 1 - 1회차 후기 * 1회차 모임 후기만 공유하겠습니다. * 스터디 자료는 개인프로젝트 코드 이외에는 모두 공개 & 공유됩니다(정리 중) - https://github.com/psygrammer/smallmind* 정통심리학 그룹 싸이그래머에서 진행합니다. 파이썬, 텐서플로우로 자기만의 머신러닝 프로젝트 만들기 스터디, 스몰마인드 첫모임 후기입니다. 이론 스터디만 하고 있는데, 뭔가 좀 직접 만들어보자는 취지로 시작한 스터디입니다. 토요일 오전에 나오는게 힘든일인지라 아주 조촐하게 모였습니다. 물론 각자 만들고 싶은 것을 만드는 것이라 인원수에 구애받지는 않습니다. 기본 포맷만 있습니다. 머신러닝 프로젝트일 것. 딥러닝 모델링일 것. 텐서플로우 기반으로 구현할 것.먼저 docker 기반으로 텐서플로우 환경 설정을 하는 시간을 가졌습니다. 편하기도 하고 나중을 위해서 좀 유연한 환경을 구축하기 위해 스터디에서 점점 도커를 많이 씁니다. GPU까지 써야할 상황이 아직은 아니라서, 좀 편리함에 집중하고 있습니다.총 3명이 왔습니다. 각자 자기 소개하고, 하고 싶은 프로젝트가 무엇인지 ppt를 작성하는 시간을 가졌습니다. 제목과, 대략적인 개요 그리고 참조할만한 논문이나 깃헙 코드 등에 대해 간략히 적어으면 되는 포맷이었습니다. 딥러닝을 이용해서 - 동영상에서 텍스트 추출, 잡음이 포함된 오디오 신호를 복원하기, 범죄 프로파일링 - 이렇게 각자 만들고 싶다고 발표했습니다.지금까지의 스터디와는 다르게, 개발 단계에서 좀 이런저런 신경을 안쓸수 있게 개인 코드는 꼭 공개하지 않아도 되기로 결정을 했습니다. 하지만 스터디 중간중간 진행되는 튜토리얼 스타일의 자료들과 참고 문헌 & 코드는 정리해서 공유할 생각하겠습니다.이론을 어느 정도 알고 예제 코드 정도는 작업해본 분도 있었고, 전혀 기초가 없는 분도 있었습니다. 4주차 동안(격주로 진행합니다), 각자의 수준에 맞춰서 만들고 싶은 것을 만들고 서로 조언도 해주고 하면서 '집에서 잘 안하니, 강제로라도 꾸준히 나와서 뭘 해보자'라는 취지로 스터디를 해 나갈 생각입니다. 느슨하게 이런저런 자기만의 딥러닝 프로젝트를 하고 싶으신 분들이라면 언제나 찾아오시면 됩니다.1시간은 '딥러닝 이론, 텐서플로우 기초' 관련 공부, 나머지 2시간은 각자 만들기. 이렇게 진행됩니다. 다음 모임에서는 '모두를 위한 딥러닝' 1강에 대한 발표가 있습니다.	0	https://www.facebook.com/groups/psygrammer/	0	멋진 기술이네요 ㅎㅎㅎ
0	텐서플로우예제 전화기에 설치해보니까 이미지 인식 거의 잘안되는 거 같은데요
50	[공유] 파이썬 데이터 분석을 위한 dokcer 이미지 (tensorflow 포함)https://hub.docker.com/r/teamlab/pydata-tensorflow/파이썬을 활용한 data 분석시 사용되는 패키지를 모은 docker 이미지를 공유드립니다. 윈도우에서 사용하기 위해 구성을 했는데 한 가지 치명적인 단점으로 윈도우에서는 주피터로 matplotlib 그래프를 저장하지 못합니다. 주피터에서 matplotlib 실행후 삭제를 하면 저장은 되는데, 그래프가 남아있으면 json parsing 에러가 뜹니다. 제 이미지 말고도 다른 이미지들에서도 공통적으로 나타나는 현상입니다. 다음 버전에서는 해결해 보도록 노력 하겠습니다.본 이미지에 포함된 주요 파이썬 패키지는 아래와 같습니다.python3.4Numpy, ScipyPandasJupyterScikit-learnGensimBeautifulSoup4Tensorflow실행 후 바로 주피터가 실행되니 참고하시기 바랍니다.	0	교수님 프사 마인크래프트 캐릭터 같아요	0	그리고 많은 글머리 중 [공유]는 처음봅니다... 역시 선구자...!	0	제 봉제 인형 캐릭터 입니다. 한류파크에 넣을려고요. 모 전자회사 가면 메일에서 매일 보게 되실겁니다. [공유], [회신], [공지] [드립] 이렇게요	0	근데 안주무시나요?	0	연구자는 월화수목금금금 아침점심낮낮낮으로 알고있습니다...	0	복제복제 인간이 몇명 있을 듯...	0	사실 Terry Taewoong Um은 팀 계정이었다능...	1	교수님의 자료공유에 항상 감사드립니다.	0	와우 감사드립니다^^
1	이미지 인식 앱만들고 싶은 데요 괜찮은 방법이 있을까요?	0	어떤 인식인지 더 자세히 알려주셔야 할 것 같아요
43	오늘 김성 교수님을 뵙습니다~ ^^바다가 보이는 카페에서 열렬히 공부하시더군요.맛있는 커피 감사했습니다.만나뵈서 반가웠습니다~다음을 기약합니다.	0	지난번에 뵜어야 하는데.. 즐거운 시간이셨겠네여.	0	만나서 정말 반가웠습니다. 앞으로도 많이 교류해요.
1	이미지 인식에 가장 많이 쓰이는 기술이 무엇인가요?분류라고 하고 시계인지 사과인지 알아내고두가지 이미지 사이에 유사성을 알려주는 기술요
69	텐서플로우 GPU 버전을 맥북프로에 설치하는 방법과파이참(PyCharm)에서 GPU 버전을 설정하는 방법입니다.install tensorflow gpu version on macbook prohttp://iworkist.blogspot.kr/2016/07/install-tensorflow-gpu-version-on.html	0	좋은 정보 감사합니다.	0	좋은 정보 감사합니다.	0	감사~~~^^*	0	이거 지금도 잘 되시나요? 저는  2번의 build 부분에서 에러가 발생합니다.	1	어제 동일한 일로 밤을 새웠는데, 공유해주셔서 감사합니다~
5	한참 혼자 고민해보다가 통 모르겠는게 있어서 간만에 글을 쓰네요...https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/mlp_mnist_xavier.ipynb 에 있는 코드를 수정해서 google inception-v3 를 파인튜닝 시도 중입니다.인풋은 이미지 100만장 정도 이고요.이미지를 카테고리 분류를 하려고 시도 중입니다.원본과 다른부분은 test 데이터를  10%로 뽑아서 사용 하는 정도 입니다.대강 되고는 있는데 하던중에 ML지식 부족으로 이해 안되는 모양새들이 나와서 조언을 좀 얻었으면합니다. 질문이 너무 기초적인 부분이고 어이없으실지 모르나 간단한 조언이나 공부에 도움될 키워드라도 부탁드립니다.전체적으로 cost와 accuracy, learning rate의 관계에 대한 부분입니다.1. cost가 폭발하는 경우cost가 줄어들다가 다시 늘어나면서 train acc와 test acc가 신나게 떨어지는 경우가 발생하던데요. 처음엔 오버핏인가 했는데 오버핏이면 train acc는 올라가야 하는것 아닌가요?2. cost가 폭발하는데 accuracy는 괜찮은경우?cost가 읽을수 있는 단위를 넘어가는 값이 나오는데 acc는 최대에 가깝게 나오는 경우가 있던데 cost가 높으면 acc가 의미가 없는것인가요? 아니면 acc는 맞다고 봐야 하는건가요? learning rate를 조절하면 발생하지 않는것으로 봐서 learning rate가 너무 높아서 그런가보다... 정도로 생각중인 부분인데 잘 모르겠네요.3.  cost가 올라가고 train acc도 낮아지는데 test acc는 올라가는경우!?!?이게 제일 미스테리 입니다. 트레이닝 정확도는 떨어지는데 test 정확도는 어떻게 올라갈 수 있는걸까요;;;;;; 그나마 트레이닝 배치는 1000개이고 test 배치는 10만 단위니 오차가 큰 경우가 상쇄된다 정도 생각중이긴 한데 맞는지 궁금합니다.4. cost가 내려가는데 train과 test acc.가 둘다 0인경우cost는 점차 감소하는데 acc가 0으로 나오는 경우가 있던데 epoch를 돌리다 보면 어느 순간 acc 가 나타나긴 하더라고요. 이런 경우 어떻게 계산된 정확도가 0이 찍히게 되는것인지 궁금합니다.질문이 너무 많고 두서 없지만 자잘한 힌트라도 부탁드립니다. 꾸벅	1	1,2번에 대해서는.. 확실하지 않지만 drop-out이 말씀하신 현상을 일으킬 수도 있을 것 같습니다.	2	최성준  잘생긴사진이...	1	1번은 gradient exploding 인것같구요 learning rate이 커서 그런것 같습니다.2번은 확실하진 않지만 역시 learning rate이 커서 발생하는것 같습니다3번은 과적합문제입니다 regularization 이나 dropout 혹은 batch normalization로 해결이 가능할꺼같구요4번은 이렇게 봐서는 저도 잘 모르겠네요 문제가 혹시 풀리시면 저도 좀 알려주세요~	0	옵티마이저를 쓰는경우라 데이터 자체의 문제일 수도 있을 것 같습니다Tf.run에 입력으로 주는 데이터를 한번 비주얼리제이션 해보시죠 m w h c 순서가 맞나혹은 정규화는 문제없나레이블정렬을 잘못해서 순서가 꼬이거나One hot encoding을 직접하셨다면 맞게한건지...
1	문장 만들어 주는 인공지능도 있나요?챗봇에 활용가능할거 같은데요	1	RNN등을 이용하면 학습을 통해 가능합니다. char-rnn이나 word-rnn한번 보세요. 챗봇을 위한 모델도 많이 있습니다.
69	텐서플로우 입문했습니다. 매일 눈팅만 하다가 글을 쓸 수 있게 되니까 감개무량 하네요. 아직도 도커의 개념이 이해가 안가고 주피터니 노트북이니 정신이 없어서 손 놓고 있었는데, 어제 이상하게 하루종일 윈도우즈가 업데이트를 반복하길래 얘가 환골탈퇴를 했네요. 윈도우즈 10 Ubuntu Bash에서 인스톨과 실행 모두 깔끔하게 됐습니다.	1	선배님도 대단하시네요 ^^	1	사진 올리면 이렇게 해주는 서비스 있으면 좋을듯 합니다.	1	모두의연구소 에서 함께 논문 보면 어떨까요???https://www.facebook.com/groups/modulabs/permalink/1044047322327117/	1	오.  홍교수님, 드디어.	1	교수님 감사합니다^^	2	따라서 하니까 잘 되었습니다. 감사드립니다!!^^	1	좋은 글 훔쳐가도록 하겠습니다...	2	방금 성공했습니다!!! 이제 윈도우에서 텐서플로우를 할 수있겠네요^^	1	저는 docker를 chroot + Cgroup 이라고 생각 합니다.제가 잘못 알고 있을수도 있습니다.-_-;; 예전에 공용 개발 장비에 나만의 컴파일 환경을 만들기 위해 다른 시스템(만일 debian woody라면 sid 시스템을 위해  chroot를 이용해서 만들어서 사용 했었는데..그것을 보는 느낌이더군요..
4	숫자 리스트를 데이터로 받아 RNN으로 앞으로 나올 숫자를 예측하는 코드를 만들었는데 cost(loss)가 줄지를 않네요.러닝 레이트를 더 크게도 작게도 조절해보고 GRU, LSTM모델을 써보아도 똑같습니다.이유를 알려주시면 감사하겠습니다.import tensorflow as tfimport numpy as npimport input_datarnn_size = 4time_step_size = 4batch_size = 1test_size=100data=input_data.AllClose()X = tf.placeholder("float", [1,time_step_size])Y = tf.placeholder("float", [1,1])loss = tf.constant(0.0)rnn_cell=tf.nn.rnn_cell.BasicLSTMCell(rnn_size)state=tf.zeros([batch_size,rnn_cell.state_size])X_split=tf.split(1,time_step_size,X)outputs, state = tf.nn.rnn(rnn_cell,X_split,state)loss=tf.reduce_mean(abs(Y-outputs))train_op=tf.train.AdamOptimizer(0.01).minimize(loss)with tf.Session() as sess:  tf.initialize_all_variables().run()  for i in range(len(data)-test_size):   for j in range(len(data[i])):    trX=data[i][j:j+time_step_size]    trY=data[i][j+time_step_size+1]    trX = np.reshape(trX, (1, time_step_size))    trY = np.reshape(trY, (1, 1))      for x in range(20000):        fin_loss=sess.run([loss,train_op], feed_dict={X: trX, Y: trY})        print fin_loss
54	#텐서팔로우 파트 1 : 1회차 스터디 후기- 텐서플로우 튜토리얼&공개코드 따라쳐보기 스터디* 스터디 첫 모임이 있었습니다. 1회차 후기만 공유하겠습니다.* 스터디 자료는 모두 공개 & 공유됩니다 - https://github.com/psygrammer/tensorfollow* 이 스터디는 정통심리학그룹 싸이그래머에서 진행합니다. 오늘 첫 모임이 있었습니다. 텐서팔로우는, 계속 기본 예제나 이론 공부만 하는 것을 좀 탈피해보고자는 의도에서 생겨난 스터디입니다. 텐서플로우로 구현된 코드들을 리뷰하는 스터디인거죠.생각보다 많은 분들이 오셔서 당황했습니다. 그리고 사전 공지가 미흡해서, 시간의 많은 부분을 docker 환경을 구축하느라 고생했습니다. 스터디 장소의 느린 네트워크 때문에 docker toolbox 조차 다운받지 못한 분들도 속출.일단 스터디는 다음과 같은 순서로 진행되었습니다. 먼저 도커 환경 안내. 그리고 설치 및 도커 기반 tensorflow 설치 실습. 이후에 참석자들의 자기소개. 다양한 분야에서 오셨더군요. 그리고 제가 준비한 코드리뷰.WildML이라는 아주 좋은 블로그가 있는데, 얼마전에 딥러닝 기반 챗봇을 만드는 포스팅을 했습니다. 친절하게 데이터와 코드도 공개.  챗봇이란 무엇인가에 대한 전반적인 개념 소개가 잘되어 있어서 저 같은 초보자가 보기에 매우 유용했습니다. 챗봇을 크게 retrieval-based model과 generative model로 나눌수가 있다고 합니다. 질문에 대한 정반응 셋이 정해져있고 그걸 검색하는 모형이 retrieval-based model, 챗봇이 대답을 자유롭게 생성해내는 모형이 generative model이죠. 이 튜토리얼에서는 딥러닝으로 retrievel-based model을 구현하고 있습니다. Ubuntu Dialog Corpus라는 공개 데이터를 사용하고 있는데요 - 이 데이터는 context(문맥)과 utterance(응답)으로 구성되어 있습니다. 그리고 Dual Encoder LSTM으로 이 셋을 학습시키는 내용입니다. Dual Encoder LSTM은 2개의 LSTM : context 문장을 모델링하는 LSTM과 그에 대한 응답(untterance) 문장을 모델링하는 LSTM을 최종단에서 결합하는 모형이었습니다. 문장들은 단어로 끊어서 각각 워드벡터로 바꿔줬구요. 그리고 성능측정 지표료 recall@K 라는 것을 사용했습니다. 원래 이 분야에서 많이 쓰는 성능지표인지는 모르겠네요.생각보다 코드 보는 시간보다는 이론적 배경과 구성을 설명하는데 시간이 많이 갔습니다. 그래서 이번에는 슈도코드 수준만 살펴보았고, 다음 시간에 코드 리뷰를 잠깐 더 하기로 했습니다.그리고 코드를 보기에 쉽도록, 다음 시간부터는 파이썬 병렬 처리 책을 하나 같이 읽기로 했습니다. 1시간은 파이썬 병렬 처리 스터디, 그리고 2시간은 텐서플로우 코드 보기. 이런 식으로 진행될듯합니다.스터디는 비록 코드를 보지만, 개발자만의 모임이 아니고 딥러닝과 텐서플로우에 관심있는 누구나 참여하실 수 있는 느슨한 취미 모임입니다. 각자 관심있는 구현체들을 가져와서 같이 살펴보고 돌려보는 시간을 가지며 수다도 떠는 그런 스터디가 되고 싶습니다.함께 하실 분들은 언제나 환영합니다~	0	https://www.facebook.com/groups/psygrammer/	0	https://www.amazon.com/Parallel-Programming-Cookbook-Giancarlo-Zaccone/dp/1785289586	1	재미있는 주제네요. 감사합니다.	1	모임은 언제 열리는건가요?	1	으앗 가볼껄 그랬네요. 어제는 일이 취소되서 한가했는데 ㅜ
30	[제주 딥러닝 모임 #2] [발표 자료 공유]발표자료 파일 첨부합니다.	0	스터디 모임 자료공유 너무 좋습니다.	0	자료공유 감사합니다. 김홍배 대전 모임은 언제 시작인가요?	1	와 정말 좋네요.....
21	Nature of code라는 책이 processing 으로 되어있어서 기초만 정리시각화 등에 활용이 되고 파이썬도 지원합니다	1	감사합니다!
33	OpenAI Gym을 이용한 강화학습 샘플을 쫒아가 보았습니다. 어렵네요. ㅠ.ㅠ	1	좋은 글 고맙습니다 ^^	1	좋은글 감사합니다.	1	저도 얼마전에 분석을 했던 것 같은데 쉽지는 않았던 것 같습니다. 좋은 글을 올려 주셔서 감사합니다.^^	1	좋은 글 감사합니다 ^^
39	기본적인 것이긴 하지만, prediction 시에 한가지만이 아닌 top-3, top-5 등을 하는 방법입니다.tf.nn.in_top_k 함수를 쓰시면 간단히 해결 가능하고, 좀더 세부적인 핸들링을 하시려면 tf.nn.top_k 으로 높은 확률의 것들을 뽑으셔서 다루시면 되겠습니다.예제는 제 깃헙에 "3c_MLP_MNIST_topNresults_160712" 란 이름으로 올라와있습니다. 감사합니다.[Link] https://github.com/terryum/TensorFlow_Exercises	0	이거 분산 컴퓨팅으로 어찌 안될란지...-.-;; 평생의 고민이죠.
60	[제주 딥러닝 모임 #2] [발표 자료 공유]안녕하세요 "제주 딥러닝 모임 #2"에서 기본적인 뉴럴넷 발표를 맡게 된 박일남, 이다니엘입니다.저희가 준비한 내용은 Linear Regression, Logistic Regression, SoftMax Regression에 대한 설명이었고요~Sung Kim 교수님의 강의 자료를 적극 활용하였습니다.^^3가지 Regression에 대해 간략히 요약하면 발표자료의 마지막 2장으로 정리가 될 것 같습니다.감사합니다.	2	이 마지막 2장의 압권적인 슬라이드, 정말 감사합니다.	2	오늘 비도 오고 해서 가지 않으려고 하다 갔는데.. 귀에 속속 들어오는 강의...재밌게 잘 들었습니다. 안 갔으면 후회 할 뻔 했습니다 ^^.  모든 발표자분들에게 감사드립니다.
3	>>> import tensorflow as tf>>> state = tf.Variable(0, name="counter")>>> one = tf.constant(1)>>> new_value = tf.add(state, one)>>> update = tf.assign(state, new_value)>>> init_op = tf.initialize_all_variables()>>> with tf.Session() as sess:... sess.run(init_op)  File "<stdin>", line 2    sess.run(init_op)       ^IndentationError: expected an indented block>>>  ... print(sess.run(state))Traceback (most recent call last):  File "<stdin>", line 2, in <module>NameError: name 'sess' is not defined>>> import tensorflow as t f l^X$m  File "<stdin>", line 1    import tensorflow as t f l$m================================================에러가 나는것 같은데요 왜 그런거죠. sess.run(init_op)  File "<stdin>", line 2    sess.run(init_op)       ^IndentationError: expected an indented block	1	빈칸을 안띄어서 그렇습니다 파이썬에서 with블록, if, for, def로 함수정의 등을 할때는 코드의 가독성을 위해 그다음 라인에서 띄어쓰기를 하도록 syntax가 지정되어있습니다. Tab키를 누르셔서 띄어쓰기하면됩니다.	0	예를들면def add(x,y) : ....(4칸띄어쓰기)return x+y이런식으로 하시면 됩니다.	0	4칸 띄우세요
91	놀라운 구글의 voice to text! 제가 오늘 올린 비디오의 자동 caption을 시험해보니 저의 경상도 억양이 섞인 영어임에도 불구하고 상당히 정확한 text를 만들어 냅니다. 아마 네이티브의 목소리는 99%정확하지 않을까 생각해봅니다.자세하게는 몰라도 대략 DNN-RNN으로 학습한것 같은데 딥러닝의 파워를 다시한번 느끼게 됩니다.	1	알고리즘이 좋아진거 같더라고요. 정말 대단한 회사...	1	Youtube 자동자막도 좋아졌더군요.	2	2015년도 뉴스지만 google voice는  rnm-ctc기반의 모델을 사용한다고 합니다. https://research.googleblog.com/2015/09/google-voice-search-faster-and-more.html?m=1	0	멋지네요!^^	0	DNN과 RNN을 어떻게 연결하나요? 간단한 예제코드가 있나요?	0	혹시 이거 주소좀 알려주실 수 있나요?	3	자세히 보시면 단어가 흰색과 회색으로 나오게 됩니다. 흰색의 경우엔 신뢰도가 높은 경우, 회색인 경우는 낮은 경우로 구분해서 표시해주는 것으로 보입니다. 참고해서 보게 되면 caption과 voice에서 어떤걸 중심으로 들어야 할지 사용자에게 알려줘서 좋아요. 솔직하게 신뢰도를 표현하는게 서비스를 사용하는 입장에서 사용자에게 신뢰성을 유지하는 방법으로는 괜찮다고 생각됩니다.	1	아직 빠르게 말하는건 케치 못하는거같아요. 코미디 영상은 발음을 정확하게 하는데도 너무 빠르게 말해서 자막이 이상하게 뜰때가 많아요 ㅎㅎ..
35	[Deep Learning Contest 2016 안내]엔비디아에서 딥러닝 컨테스트를 진행하고 있습니다. 오는 9월 2일까지 접수를 받으며 우승자는 오는 10월  개최되는 GTCx Korea 2016에서 시상식을 갖게 됩니다.GPU를 활용한 딥 러닝 연구를 하고 계시거나, 관심이 있으신 분들의 많은 참여 부탁드립니다.자세히 보기: 	2	혹시 이거 해보신 분 몇 %정도 나오셨나요? 전 그냥 resnet 돌리니까 78% 까지 나왔습니다. 물론 바뻐서 안하기로 결정했는데. 다른 분들 결과 궁금해서 질문 던저 봅니다.	0	많이 다운 받아서 돌리시는거 같은데 등록은 안해주시네요.. 마지막에 올리시려나... 등록게시판은 마감전까지는 언제든지 수정 가능합니다.	0	경품이 상패와 gpu .... @.@
3	파이썬에서 텐서플로우 임포트할때su 명령어로 치고 임포트하면 되는데 그냥하면 안되는데요왜 그런걸까요?	0	경로나 라이브러리 권한을 확인 해 보세요. echo $PATH 로 경로 지정을 확인 할 수 있습니다.	0	권한 문제인것 같습니다.
7	텐서플로우 그룹내에서 인원을 바탕으로 세분화 시키는 건 어떨까요-금융 투자 그룹, 인공지능 활용-언어인식그룹-이미지 인식그룹외  다른 그룹을 만들어서의사소통을 빠르게 하여인터넷 안에 회사를 세운 개념이 되도록요	4	올라오는 게시물의 수가 굉장히 많지는 않은데 나눌필요가 있을까요?	4	분류를 하고 싶은 직업병인 것 같아요 ㅎ	0	facebook 게시글을 긁어서 텍스트 마이닝 해보면 어떤 사람이 어떤 관심을 가지고 글을 썼는지 알 수 있을지도..!
11	안녕하세요 TensorFlow 내부(C++ core)를 분석중에 있는 초보 학생입니다. Tensorflow의 CNN 연산 중 실제 Convolution 연산을 하는 위치를 찾고 싶어 gdb를 이용하여 flow를 찾아가는 도중에 어려움이 있어서 글을 남깁니다.현재 CNN을 하는 kernel 부분인 Conv2d.h를 통해 Eigen 위치인 .../unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h여기까지는 찾았으나 더 이상 진전이 없네요!제가 찾고 싶은 부분은 아래와 같이 filter 연산을 직접적으로 하는 곳입니다.for(i=0; i < patch_row; i++){   for(j=0; j < patch_column; j++){      for(k=0; k < channel; k++){            ......      }   }}혹시 TensorFlow 내부에 대해서 잘 아시는분이 계시다면 도움 주시면 감사드리겠습니다.	5	정확히 어딜 찾으시는지는 모르겠지만 gemm(General Matrix to Matrix Multiplication) 함수 콜 하는 부분부터 거꾸로 찾아보세요. blas 라이브러리의 함수인데 최적화 문제때문에 fortran을 gcc로 컴파일 해 놨을수도 있습니다.	2	비슷한 일을 해봤는데요. TensorContraction.h 이 파일에 gebp라는 eigen의 행렬곱 연산 api를 호출하는 부분이 있습니다. 이 함수를 감싸고 있는 for loop과 gebp 내부의 for loop이 찾으시는 부분 같습니다. 하지만, 보통 알고 계시는 for loop과는 조금 다르게 생겼을 수가 있는데, 그것은 Tensor의 contraction이라는 행렬곱보다 좀 더 일반적인 연산을 구현해놔서 그렇구요. a.contract(b, index) 이 부분을 호출할 때는 TensorContractionOp 오브젝트만을 만들고, 실제 연산은 나중에 TensorEvaluator에서 evalGemm이라는 함수를 통해서 이루어지는 것 같습니다.	0	답변해주셔서 감사합니다. 말씀하신 gebp 쪽을 확인해보겠습니다!	1	template <typename Device, typename Input, typename Filter, typename Output>void SpatialConvolutionFunc(const Device& d, Output output, Input input,Filter filter, int row_stride, int col_stride,const Eigen::PaddingType& padding) {// Need to swap row/col when calling Eigen.output.device(d) =Eigen::SpatialConvolution(input, filter, col_stride, row_stride, padding);}	2	Eigen에 SpatialConvolution을 만들어 넣어서 확장한 것 같습니다. SpatialConvolution을 더 따라 들어가 보면 무시무시한 다중 for문이 나옵니다.	1	제 경우는 fully connected 레이어에 대한 연산을 보다가 찾은 겁니다. TensorContraction을 언급하셔서 따로 말씀드리진 않았습니다만, 저도 conv 레이어는 홍정모님이 말씀하신 것처럼 다른 곳에서 계산이 이루어질 거라고 생각합니다	0	많은 조언을 토대로 제가 원하는 부분을 찾은것 같습니다. 저의 경우는 tensorflow의 cifar10 예제의 convolution 연산 부분을 확인하는 것이었으며 이의종님과 오영환님께서 말씀하신 Gemm 함수 내부의 gebp struct를 통해서 연산을 실행하는것 같습니다.	1	그렇던가요? 대놓고 함수이름에 convolution이라고 써놓은 함수들의 정체가 궁금해지네요. 허허
5	텐서플로우를 이용해서 Floating Precision에 따른 실험을 진행하는 중에 문제점이 생겼습니다. precision을 변경하기 위해서 다음과 같이 코드를 수정하였는데 실행에서 문제가 발생합니다. ㅠㅠ  fc1_weights = tf.Variable(  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512], stddev=0.1,seed=SEED, dtype=tf.float16)혹시 텐서플로우에서 float16이나 tf.qint8를 사용해 보신분 계신가요 ?
20	RNN 의 경우 State를 저장하는 Memory 라는 요소를 그림에 표시 하면 좋을 듯 싶습니다 (참고: discrete time control 의 block diagram) 	1	왼쪽의 표시에 Memory 요소를 추가하면 오른쪽과 같이 될 것입니다	0	(디지털) 신호 처리 또는 이산시간 시스템 제어 이론에서 거론되는 내용에 관한 참고 자료입니다. 도움이 되기 바랍니다. (혹시 오타 등이 있으면 알려 주시기 바랍니다 ^^;;;;)	1	좋은 아이디어입니다. 감사합니다!	0	http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg 이 그림에도 나와 있는 듯 합니다.
5	안녕하세요. 맨날 눈팅만 하다 master분들의 조언 구해봅니다.소비재 마케팅을 main으로 하는 본사에서 비지니스 확장에 필요한 기술을 가지신 분이나 업체를 찾고 있습니다. -- 문제시 자삭 하겠습니다.--1. OCR2. Picture recognition3. Web Crawling (for either barcode info, or products pictures)4. E-Commerce measurement제가 아는 바는 없고 딱히 도움 청할 수 있는 분야도 아닌것 같아 실례를 무릎쓰고 올립니다.사실 며칠 전 Sung Kim 님(무단으로 mention하게 되어 죄송요..)이 올리신 https://www.facebook.com/groups/TensorFlowKR/permalink/308131179527947/ 게시물을 감명깊게(!) 읽었던 기억도 있고 해서 말입죠... 위 기술을 가진 업체나 개발자를 아는 분 계시면 도움 부탁드립니드.. 꾸벅.
38	이번 ICLR 2016에서 Best paper award를 받은Song Han의 "Deep compression and EIE"발표 동영상입니다.Deep learning 기술의 모바일 디바이스 및드론등의 활용에 필요한 모델 압축기술입니다.상용화에 관심 있으신 분들에게 필요한 자료입니다.http://youtu.be/hfFkS_vHslI발표자료https://www.slideshare.net/mobile/embeddedvision/techniques-for-efficient-implementation-of-deep-neural-networks-a-presentation-from-stanford	1	유튜브 영상이 재생되지 않는데, 혹시 http://videolectures.net/iclr2016_han_deep_compression/ 와 같은 영상이 아닐까 합니다.
95	AI 개발자님들 모십니다.Sung Kim 님께서 올리시는 TensorFlow, RNN, NLP 강의 듣고, 필 받아서 실상에서 사용하는거 만드시고 싶으신분들 연락주세요.저희는 챗봇을 만드는데요, 확보된 데이터도 있고, 시작은 했는데, 앞으로 할일이 쌓여 있습니다.Bleeding-edge(한달된 논문은 너무 올드해 ㅎ) State of the art 기술도 사용하지만, data flow architecture 로 잡아주는 잡(?)기술들과, 데이타가 더 필요해!! 어디서 글거오지?. 실상에서 쓰려면 데이터 청소등.. 데이터과학을 직접 매일 몸으로 부대끼며 스킬업 하실수 있습니다.	0	이영찬	0	와 아이디어 정말 좋네요!!!	0	멋있네요 전 메신저기반의 사업을 하는 사람인데 저희 역시 차세대 메신저 기반은 AI라 생각하고 아직 준비중인데 이미 상품화 하셨다니 분발 해야겠습니다	0	와.. 구체적으로 어떤 조건인지 궁금합니다..	1	오오 멋집니다. 저도 지원하고 싶은 멋진 프로젝트 같습니다.	1	👍 귀국한건가요.	2	오 좐형 ㅎ 뉴스에도 나왔구만요 ㅎㅎ	0	이력서 한번 보내봐도 괜찮을까요? ^^	0	시도해 보구 싶네요...	0	굿아이디어네요 ㅋㅋㅋ	0	완전 초보자 가능할까요?	1	회사를 박차고 나올 순 없지만, 저희도 비슷한 업무를 R&D 중이라, 개발 교류가 가능하다면 교류 형태로 참여 하고 싶네요. 저희 또한 라벨링 된 Real Data도 있구요.
49	지난 달에 있었던 spark 행사에서 구글 Jeff dean 의 발표 내용입니다. Spark 내용은 거의 없고 deep learning 101 정도로 생각하시면 되겠네요. 발표자료와 설명이 간략한데 참 깔끔합니다.	0	좋은자료 감사합니다.
94	시즌2 LAB1-NLP 기반의 챗봇 만들기 (API.ai)TF와 직접 연관은 없지만 곧 들어갈 DEEP NLP 를 위한 준비과정인 비디오 입니다.용어와 개념: https://www.youtube.com/watch?v=jF70X0tUzV8데모: https://youtu.be/jBnzfLGcn5o (영어버전, 비슷한 내용: https://www.youtube.com/watch?v=gHjtsa7BaiQ)수업 웹페이지: hunkim.github.io/ml/side-effect (부작용): 요즘핫한 챗봇 만드는 방법이 그냥 정복됩니다!	2	감사합니다. 시즌2는 슬라이드 디자인이 싹 바꼈네요. 잘 하셨습니다.
3	다양한 데이터를 가지고 NN을 실험해 보고 싶은데, 혹시 추천할 데이터 셋이 있을까요?	2	www.kaggle.com	2	UCI ML 데이터셋은 오래되긴했지만 종류가 다양합니다. 비교된 결과들도 많고요. http://archive.ics.uci.edu/ml/
11	안녕하세요!언어모델링 쪽으로 처음 머신러닝 관련 공부를 하고 있는 완전 초보입문자 입니다. 이번에 RNN을 이용해서 한글데이터 문장들을 입력하면 자동으로 띄어쓰기가 되도록 처리하는 모듈을 만들어보려고 하는데요.ML 강의도 보고, tensorflow RNNLM tutorial 도 나와있어서 대략적인 모델링 이론은 알겠지만 학습 셋을 바꾸고 실제 구현하는 부분에서 어떻게 만들어야 되는지 아직 감이 안오는 것 같습니다. ( 깊게 공부를 안해서일까요.. ㅠ)단순하게 생각해보면 입력 형식은 한글완성형 음절 하나씩 들어가게하고, 결과는 띈다(1)/안띈다(0) 으로 처리를 하면 되지 않을까 .. 막연히 생각하고 있는데혹시 이런 분야 쪽으로 ( 자연어 처리 관련이면 다 좋습니다 )보면 좋을 자료가 있다면 공유해주시면 감사하겠습니다. 시간이 좀 걸리겠지만 완성하게 되면 자료는 정리해서 다시 공유드리도록 하겠습니다. 추가질문) 저는 아직 입력을 넣게 되면 이러 이런 과정을 거쳐서 모델이 어떻게 나올 것이다 라는 그림이 명확하게! 안그려지는 것 같은데 기본 이론을 좀 더 깊게 공부해야 하는 걸까요..? 지금은 tensorflow의 코드를 따라가며 보려고 하고 있습니다.	0	띄어쓰기가 포함된 문장을 char단위로 넣으면 알아서 띄어쓸거같네요??	0	띄어쓰기 안된 문장을 입력했을때 자동으로 띄어쓰기가 되는 모듈을 만들고 싶은거죠??
44	안녕하세요. 이제 막 강화학습 및 딥러닝을 시작하는 모두의연구소 이웅원  연구원님이, 초보의 입장에서 초보의 마음으로 초보에게 도움이 되도록 적고 있는 OpenAI 코드 리뷰입니다. 수정해야 할 사항이 있다거나 추가하면 좋은 내용이 있다면 피드백 주세요. 이웅원 연구원님께 큰 도움이 될 것 같습니다.	2	감사합니다!	2	좋은 정보 감사!	1	저도 gym에 대한 글을 준비하고 있는데요. 함께 보면 도움이 많이 될 것 같네요. 감사합니다.	1	잘 정리를 하신 것 같습니다.저도 github 간단한 내용은 정리를 했습니다. https://github.com/sangjinhong/deep_learning
58	Neural Image Caption Generator에 대한 설명자료를 만들어봤습니다.이미지의 인식에 사용되는 CNN(Convolutional Neural Networks)과 자동번역등과 같이 시계열 데이터의 분석등에 활용되는 LSTM(Long and Short Term Memory)을 이용하여 자동으로 사진에 대한 설명문을 작성하는 네트웍 구성에 대한 설명여러 참고자료를 이용하여 이해하기 쉽도록 만들어봤는데  쉽게 이해가 되실지는 잘 모르겠습니다.  활용분야는 매우 다양합니다.시각 장애인을 위한 시각인지 앱, 자동차의 ADAS에서 운전자에 대한 warning system,Automatic decision making은 물론 위성이나 항공 촬영영상의 부가가치를 높이는 기술로 개발이 가능	1	고생 많으셨습니다~	1	많은 도움이 될것 같습니다.	1	설명이 빠진 부분이 있는데,  입출력쪽에 복잡하게 tanh 함수값으로 바꾸는 이유는 모든 값들을 -1~1사이에 있도록 normalization하기 위함입니다.
10	안녕하세요 tensorflow에 막 입문하여 공부를하다 궁금한게 있어 첫글을 남깁니다.MNIST에 사용되는 트레이닝셋은 많아야 학습을 잘할테니 다운받아서 쓴다치고 테스트셋은 임의로 만들어서 사용해보고 싶은데 이에 대한 가이드 같은것은 없을까요?그냥 있는거 가져다다 쓰다보니 뭔가 하는느낌이 아니라 실행만 해보는느낌이라..그리고 이쪽분야는 처음공부하는 부분이라 공부의 방향성을 못잡겠네요youtube에 있는 국민(?) 강의도 끝까지 다 봤는데 예전 c,c++ 할때 처럼 스스로 학습하는 느낌이 아니라 이미 다 만들어져 있는걸 실행 해보다 보니 어느 방향으로 응용을 해야할지도 감이 안오구요 ㅜㅠ조언좀 부탁드립니다.	3	아래 링크의 MNIST dataset 파일 포맷을 참고하셔서 직접 숫자를 작성한 것에 대해 데이터셋을 만드시면 가능 하겠네요. idx1, idx3 확인하시고 test image/label 쌍으로 만드시면 되겠습니다. http://yann.lecun.com/exdb/mnist/	0	파일 포맷 처리하기가 귀찮으실수도 있을거 같아서 예전에 kaggle에서 진행했던 포맷으로 작성한 내용을 올려드립니다. 그냥 csv 포맷으로 one row = one image라고 생각하시고 test.csv만 작성하시면 됩니다. https://tgjeon.github.io/kaggle_MNIST/	2	폴더로부터 이미지를 읽어와서 데이터셋을 만드는 파이썬 코드와 (https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/basic_gendataset.ipynb) 이 데이터를 이용해서 간단한 CNN을 돌리는 코드 (https://github.com/sjchoi86/Tensorflow-101/blob/master/notebooks/cnn_customdata_basic.ipynb) 입니다. ㅎㅎ 아마 이 자료들을 조합하시면 원하시는 걸 하실 수 있을 것 같습니다.	0	두분다 자료 감사합니다!! 잘 참고 하겠습니다~
12	Nvidia-docker환경에서 tensorflow 소스를 컴파일하고 실행하는 내용을 정리 하였습니다.GPU 관련 사용에서 호스트PC 환경과 동일하게 사용되는 것을 확인 하였습니다.
0	-- Last week-end for On-Campus International Applicants living outside the EU/EEE for Autumn 2016! --Data ScienceTech Institute and its industrial partners are delighted to have their #DataScience and #BigData MSc and Executive MSc programmes recognised by the French Government via Campus France under its prestigious "Programmes taught in English" section, for "Mathematics" and "Engineering and Technology", with all the leading French #HigherEd institutions.https://www.datasciencetech.institute/Campus France (using Flash):http://www.campusfrance.org/fria/taughtie/index.html?mfid=7http://www.campusfrance.org/fria/taughtie/index.html?mfid=4
10	nvidia-docker 환경을 구성 해본 내용을 간단히 기록해보았습니다.GPU 사용이 편할 것이라 보고 구성을 하였는데...이제 환경을 사용해보면서 구체적인 부분은 파악할 수 있을 것 같아요.^^	2	좋은 자료 감사합니다.	1	첨부 파일을 볼 수 없다고 하네요 ㅠㅠ
5	안녕하세요 텐서플로우 갓 입문한 대학생입니다.tensorflow 홈페이지 cnn 튜토리얼을 토대로 공부하고 있는데요cifar10 데이터셋으로 트레이닝하여 ckpt파일 까지는 나오는데여기서 이미지파일을 입력받아 어느 카테고리에 속하는지출력해주는 코드를 짜려면 어떤 식으로 접근하는게 좋을까요?	1	CNN모델을 tf.argmax()로 처리 한뒤 이미지를 feed_dick으로 주게 되면 예측한 것 중에서 가장 확률이 높은것을 뽑아줍니다.이것으로 접근해 보심이 어떠신가요?
7	안녕하세요. 이제 막 텐서플로를 공부하기 시작한 김준이라고 합니다.간단히 자기 소개를 하자면 직전 회사인 쿠팡에서 추천 플랫폼 개발/운영으로 데이터 사이언스를 시작해서 현재 회사에서 이제 막 이것 저것 해보려 합니다. 앞으로 잘 부탁드립니다.  궁금한게 있으면 여지없이 올릴테니 고수님들의 조언 부탁드립니다.------------------------------------------------------------그런 의미에서  질문 하나 드릴께여. Tensorflow를 python3로 올려서 jupyter로 보고 있는데요.로컬인 (Macbook)에선 잘 돌아가는데요.이를 AWS  EC2  인스턴스(Ubuntu)에 올려서 설치하자니 TF 자체는 잘 도는데 라이브러리 설치가 쉽지 않네요. pip3로  install 하니 에러가 발생하구요.그래서 apt-get을 이용해서 설치하니..실제 동작시에 library 를 찾지 못하는 에러가 발행하더군요.예를 들어 '_tkinter' 를 못 찾는 에러가 는데찾아보니 python 라이브러리가 여기저기(?) 깔리더군요.깔끔히 밀고 새로 깔고 싶은데 reference 가 필요할 것 같습니다.* 정리1.  Ubuntu(AWS  EC2  인스턴스) 환경 에서의 TF 및 libraray 설치(?) 가이드2. Ubuntu(AWS  EC2  인스턴스) 환경 에서의 TF 의 특이점이상입니다.	2	ㅋㅋㅋ 이렇게 질문하시면 설치가이드 url을 알려주실것 같은데요	1	virtualenv 나 docker 추천합니다	1	어떤 라이브러리를 설치하시려는지 잘 모르겠지만 pip로 설치가 잘 안되시는 거라면 여러 패키지들을 지원해주는 아나콘다 인스톨러 추천 드립니다. ^^	1	TensorFlow를 사용하면서 많이 겪는 어려움이 path설정입니다.echo $PATH로 설정을 확인해 보세요.
185	[모두를 위한 딥러닝 (Deep NLP) 시즌2 시작!]딥러닝 시즌2 강좌의 주제를 Deep NLP로 정하고 첫 비디오를 올렸습니다.https://www.youtube.com/watch?v=O9THzrcCLoA&feature=youtu.be제주에서 Deep 러닝 스터디 모임이 열리고 있는데 여기서 배운 내용을 기반으로 제가 정리하여 비디오로 만든다고 보시면 됩니다. 잘 정리해서 만들어 보겠습니다. 제주 스터디 모임에 참여해주시고 질문/토론해주시는 분들에게 감사드립니다.수업자료등은 수업 홈페이지에 있습니다.  hunkim.github.io/ml/. 커멘트와 질문, 건의등은 언제나 환영합니다.	0	감사합니다 ~	0	기대합니다 ^^	0	빨리 시즌1 보고 따라가야겠네요^^	0	감사합니다.	1	감사합니다^^	0	부지런하십니다.	0	감사합니다!!	0	감사합니다	0	감사합니다!	1	와앙!!! 감사합니다 ㅎㅎ	0	감사해요~~  기대 만땅요~	0	진짜 멋지십니다.	0	NLP 너무 기대됩니다!!	0	감사합니다!!!😆	0	대단하십니다. 열정에 짝짝~	0	앞으로 잘 보겠습니다. 감사합니다.	1	감사합니다.열혈시청자 1인입니다. 꾸벅.	0	감사합니다.
19	워크샵 영상입니다. 페이스북의 torch 구글의 tensorflow에대한 튜토리얼 영상도 있습니다.
3	며칠째 고민을 해봐도 제 지식으로는 방법이 생각나지 않아 질문을 드립니다.현재 하려는 것은 답의 개수가 유한한 질의응답으로문장 + 변수(단어, 수치, etc..) 를 input으로 주면 output으로 가장 일치하는 것을 정답으로 출력하는 모델을 만들려고 합니다.여러 방법들 중에 word-to-vector가 단어들을 나열하면 연관된 단어를 찾아주는 것으로 알고있는데 이를 이용해서 해결할 수 있는지, 또는 다른 방법들이 존재하는지 궁금합니다.	1	텐서플로우 모임에서 발표된 '텐서플로우 설치도 했고 튜토리얼도 봤고 기초 예제도 짜봤다면'에서 질의응답이 가능한 모델이 소개되었던 것 같습니다.
3	안녕하세요! TensorFlow와 머신러닝을 처음 접하게된 기계공학 전공의 학부생입니다. 리눅스환경에 텐서플로를 anaconda로 설치하였고, 공식홈페이지의 설치 메뉴얼을 따라갔습니다. 그리고 튜토리얼 파일을 실행해보려고 Tensorflow Mechanics101의 fully connected feed 파이썬 파일을 여는 커맨드를 입력했는데, 계속 파일이 존재하지 않는다고 하네요. 제가 설치과정에서 github를 clone하는것까지 했는데 왜 안되는지 혹시 알려주실 수 있으신가요?	0	음 설치는 제대로 됐나요? python 쉘을 실행 시킨후. import tensorflow를 하셔서 제대로 설치된지 확인이 필요합니다. 스크린샷을 같이 올려주면 좋을 거 같습니다.설치 관련해서 저희대학에서 만들고 있는 강의 일부입니다.https://www.youtube.com/playlist?list=PLBHVuYlKEkUIbVgM5H_9fh7cE9u45fR1J	0	혹시 IDE에서 인터프리터 지정을 하셨나요?
40	딥마인드의 DQN 논문 관련 발표 동영상이 있어 공유합니다.특히 깊이 있는 Q&A가 인상적이었습니다~ Replicating Deep Q Learning with TensorFlow(https://www.youtube.com/watch?v=suNNrEHDR-I)	0	이선엽 <- 발표자	3	발표를 그렇게 잘하지 못해서 부끄럽네요 ㅎㅎ 다음에는 더 연습해서 좋은 발표하겠습니다	0	DQN 논문이 이해하는데 쉽지 않았는데 많은 도움이 되었습니다^^
8	https://github.com/soumith/convnet-benchmarks(중복이라면 삭제하겠습니다)git에 i7-5930K CPU + NVIDIA Titan X + Ubuntu 14.04 환경에서의  convnet의 동작 속도를 비교해놓은 자료가 있군요.Imagenet Winners Benchmarking에는 AlexNet, Overfeat, OxfordNet, GoogleNet 등을 비교했고, Layer-wise Benchmarking에는 3D input 3D output, densely connected를 갖는 Spatial Convolution layer, 그의 forward, backward 속도를 비교해놓은 듯 합니다.환경적인 부분에서 차이가 날 수 밖에 없지만, 혹시 참고하실 분이 있을까봐 올려봅니다.
178	따라하다 보면 50분안에 TF설치에서 부터 Inception 돌려보며 TF의 개념을 잡게해주는 스스로 하는 lab입니다. 저도 오늘 50분을 만들어 돌려볼 생각입니다.https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0	2	저도 오늘 해보겠습니당ㅎㅎ	1	두번째 페이지까지 갔다가 윈도우즈가 없어서 좌절 orz	2	mac os 쓰시는 분들은 docker toolbox 말고 docker beta 사용해보셔도 될것 같습니다. 잘동작하네요	0	이것 때문에 제 개인 시놀로지 nas를 밀어봐야하나 고민되네요.	0	잠시 후 시작해보려다가, 아직은 방전된 힘이 다 올라오지 않아서 차마 ㅋㅋ 참으라고 하네요.
11	이우소프트에서 AI개발자를 채용합니다. 
7	tensorflow를 사용하면서 궁금한 점이 있습니다. 변수생성 후 초기화 연산 수행에 관련된것입니다.tf.Variable을 이용하여 변수를 생성하고나서-----------------------init = tf.initialize_all_variables()sess = tf.Session()sess.run(init)-----------------------1. 이런식으로 초기화 연산을 생성 후 실행하는 이유가 무엇인가요?2. 초기화를 진행 한것과 그렇지 않은 것의 차이는 무엇인가요?	0	초기화하지 않으면 초가화 안 되었다고 에러가 납니다	0	그래프로 만 든 것을 새션 실행시 할당해야 하므로 꼭 초기화가 필요해요.  실제 디바이스를 정해서 분산 연산하니 ...	1	친추 감사드립니다...ㅎㅎㅎ 그렇다면 tensorflow의 모든 연산 수행은 lazy evaluation으로 봐도 괜찮은 건가요?	1	초기화 없이 사용하는것은 안되기도 하지만 초기화 전후 값을 살펴보면a = tf.Variable(0.8) 일때 초기화 전에는 값이 0.800000011920929초기화 후에는 0.80000001 식으로 값이 정확해지는 부분도 있습니다.https://jihobak.github.io/2016-06-26-deeplearning-ninja001/	6	텐서플로우에서는 초기화 뿐만이 아니라 그래프로 표현되는 모든 연산은 세션이 만들어지고 나서 평가됩니다. 이렇게 하는 이유는 cpu나 gpu 디바이스에 개개의 연산을 주고 받는 번거로움을 덜고 한번에 위임하기 위해서입니다.(https://tensorflowkorea.wordpress.com/2016/06/28/hello-tensorflow/)	4	변수는 모델 파라메타 값을 저장하는 용도로 사용하는 데요. 변수 노드에는 특별히 저장하고 복구하는 연산 노드가 따라 붙어 있습니다. https://tensorflowkorea.wordpress.com/2016/06/17/tensorflow-white-paper1603-04467-summary/ 여기에 중간쯤(ㅠ.ㅠ) 보시면 변수 노드에 대한 이야기가 좀 있습니다.
43	윈도우7에서 텐서플로우 설치 및 실행	1	좋은자료 공유 감사드립니다 혹시 CUDA도 사용이 가능할까요?	2	좋은 자료 감사합니다. 덕분에 평소에 궁금해하던 내용들이 해결되었습니다 :)
9	안녕하세요, tf.Saver를 이용해서 모델 save를 하면 아래 그림과 같이 loss가 갑자기 올라가버리는 현상이 있는데 비슷한 경험을 하신 분 계실까요?몇 번 실험을 해봤는데 save를 하지않는 상황에서는 정상적으로 loss가 떨어지는 것을 확인했습니다. ㅠㅠ	0	저 특이하게 loss가 올라가는 부분이 모델 save를 하는 부분 이라는 말씀 이신가요?	0	네 첫 세이브를 하는 iter 순간 loss가 갑자기 올라간 뒤 쭉 loss 값이 진동을 합니다 ㅠㅠ.. save를 하지 않는 경우는 위와 같은 현상이 일어나지 않구요	0	텐서보드의 문제일수도 있어요가끔 saver 로딩이 잘못되니 삼각형처럼 loss graph 이 보일때도 있더군요
10	[ 질문 ] 텐서플로우 코드 리뷰여러분들 보통 텐서플로우 소스코드 보는데 얼마나 걸리시나요?물론 소스코드 길이와 복잡도에 따라 다르겠지만, 가능하다면 자신이 리뷰한 코드와 걸린 시간?일수? 알려주시면 감사하겠습니다.이 외에도 코드리뷰에 관해 조언해주셔도 좋습니다.저는 현재 김성훈 교수님 '모두를 위한 머신러닝 시즌1'을 마지막강의를 제외하고 다 들은 상태이구요. c, java 를 사용해봤고(아주 잘하진 않습니다.) python은 처음입니다. 현재 '점프투 파이썬'으로 공부중입니다.마지막으로 코드 리뷰할 때 tensorflow에 대한 api도 참고해야하는데 rnn_cell 종류 대해서는 어디서 봐야하나요? (저는 현재 김성훈교수님이 올려주신 many to one rnn 소스코드 살펴보는 중입니다.)코드 리뷰 말고도 RNN,LSTM이나  Tensorflow 딥러닝 코딩구현하는데 있어서 조언 해주셔도 감사하겠습니다!긴글 읽어주셔서 감사합니당~~ :)	1	저도 지금 RNN 짜고있는데 이상하게 api docs에 rnn_cell에 관한 내용이 없더라구요. 저는 그래서 깃허브에서 직접 소스보고 참고했습니다. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py	2	아래 링크보시면 나와있습니다. BasicRNNCell, BasicLSTMCell, GRUCell, LSTMCell 4종류가 있습니다. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/rnn_cell.md
30	CNN 코드가 업데이트 되었습니다. 추후에 강의 내용을 복습겸 다시 들으면서 강의 노트를 .md 파일로 올려 놓겠습니다.많은 분들이 봐주셨습니다. 감사합니다.	3	CNN을 짜다가 막히는 부분이 있었는데 올려주신 코드를 보니 문제를 고칠 수있을 것같아요. 감사합니다.
7	맥북에(cpu only) 이용자 입니다. 텐서플로우는 설치 했는데,  텐서플로우를 파이참에 연동해서 사용하고싶은데요. 연동 하신분 있으시면 참고할 만한 포스팅 있으면 추천 바랄게요.혹시 파이참 사용시에 아나콘다도 설치해야 하는건지 도움주시면 감사드리겠습니다.	0	Miniconda에 가상환경 만드셔서. Tensor 설치하시고요. 파이참환경설정에서 해당 프로젝트의 인터프리터를 만드신 가상환경으로 대체하면됩니다.	0	설치하신후에 파이참 프로젝트 생성할 때 인터프리터 설정만 잘 해주시면 됩니다
18	가입후 인사가 없었는데 인사드립니다. 저는 데이터 마이닝 시대를 거쳐와서 용어가 데이터 마이닝으로 통칭해서 부르는데 deep learning과 tensorflow에 관심이가서 가입하게되었습니다. 많은 도움 부탁드립니다. 저는 주로 SAS, SPSS, R을 사용합니다.	1	ㅋㅋㅋ, 여기서도 뵙네요.	0	폐친분들이 한 50분 계신것 같습니다.	1	잘 지네시죠?
61	Facebook Spam Out 시험 경과보고https://github.com/hunkim/FacebookSpamOut 를 일주일 정도 돌려본 결과 구글의 Vision  API가 나름 잘 찾아 내는것 같습니다. 어제 찾아낸 2개의 생활코딩 스펨.메시지를 보면 거의 내용이 없어 이제 이미지를 이용하여 스펨을 찾아 내는것이 매우 중요할것 같습니다.몇주 정도 더 시험한다음 저희 그룹은 구글 Vision으로 스펨임이 확정되면 자동으로 삭제하는 부분을 넣도록 하겠습니다. PR/Issue 언제나 환영합니다.---[name] => 좋아 바로 이거지    [message] => 생활코딩    [from] => stdClass Object        (            [name] => Sun Young Jeong            [id] => 1142195825843768        )---[name] => xxx.xyz    [message] => 설현. 과거의 <3 <3    [from] => stdClass Object        (            [name] => Hyoungim Choi            [id] => 1336202193061009        )	4	추가로 1회 이상 스펨을 올리시는 분들의 이름과 facebook id의 리스트를 만들어 공개할까하는데 (각 그룹과 개인이 미리 이런분들 블락할수 있도록) privacy 이슈가 있을까요?	1	스팸의 경우 대부분 메세지 내용이 없고 그 길이가 일반 글 보다 짧은 1줄~3줄 사이 입니다길이가 짧은 내용들에 대해서 뽑아서 검출하는건 어떨까요?	5	한가지 생각해 보아야 할 점이 있습니다. 10년째 사이드로 안티스팸 서비스를 굴리고 있습니다. ( http://antispam.textcube.org ) 2000년대 중반~후반에 스팸 전쟁이 딱 이런 과정을 거쳐 흘러갔는데요, 결국 스패밍 프로그램들은 정상적인 유저의 글을 크롤링해서 아주 일부만 스팸 내용으로 변경해서 올리는 소셜 스팸의 형태가 되었고, 결국 bayesian poisoning때문에 베이지안 필터를 써먹기 어렵게 되었습니다. 딥러닝 스팸 필터의 경우 컨텐트 베이스로 학습하는 형태로 가면 결국 베이지안 필터보다 더 나은 결과를 얻긴 어려울 듯 합니다. 다른 어떤 방법이 있을지 고민해 보는 것도 좋겠습니다.	1	이름 공개하면 그게사실일지라도 명예훼손 사유가 될수있어서 위험할꺼같아요
4	안녕하세요 tensorflow를 gpu버전으로 실행하는데 있어 질문을 올립니다.현재 컴퓨터 os는 우분투 14.04 64bit이고, python 버전은 3.4.3입니다.cuda toolkit과 cuDNN을 install 한 후 python에서 코드를 실행했더니 다음과 같은 결과가 나왔습니다.--------------------------------------------->>> import tensorflow as tfI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally>>> a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')>>> b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')>>> c = tf.matmul(a, b)>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))modprobe: ERROR: could not insert 'nvidia_352': No such deviceE tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_NO_DEVICEI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:140] kernel driver does not appear to be running on this host (spark): /proc/driver/nvidia/version does not existI tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.Device mapping: no known devices.I tensorflow/core/common_runtime/direct_session.cc:175] Device mapping:---------------------------------------------오류 내용을 봤을때는 NVIDIA의 GPU 장치가 없어서 그런것 같아서 터미널에서 확인해봤는데 다음과 같이 확인돼었습니다.spark-c@spark:~$ lspci | grep VGA00:02.0 VGA compatible controller: Intel Corporation 3rd Gen Core processor Graphics Controller (rev 09)01:00.0 VGA compatible controller: NVIDIA Corporation GK104M [GeForce GTX 670MX] (rev a1)GTX 670MX는 분명히 NVIDIÅ GPU인데 어째서 위와 같은 오류가 뜨는 건가요?오류내용을 붙여넣기한거라 질문자체가 너무 길어졌습니다. 혹시 아시는 분은 알려주시면 감사하겠습니다.	0	혹시 가상환경인가요?	1	혹시 드라이버가 적합하지 않은걸로 설치된게 아닐까요? nvidia의 일반적인 명령어로 gpu 드라이버 설치하면 잘 안되고, 특정 드라이버를 다운받아 설치해줘야하더라고요.	1	원래 CUDA 설치가 발암 작업?이더라구요.. 저도 삽질하다 블로그에 정리했는데 도움되길 바랍니다. 이렇게 복잡할 필요가 있을까 싶지만 CUDA설치만으로 며칠을 보내다보면 그냥 돌아가는거에 감사하게 됩니다;;;http://m.blog.daum.net/goodgodgd/20	2	다들 정말 감사합나다. 여러분들의 조언 덕분에 nvidia 드라이버를 다시 설치 하여 해결했습니다. 특히 최혁두님이 공유해주신 자료와 제가 찾은 자료를 같이 보면서 했는데 아주 도움이 많이 됐습니다. nvidia 드라이버 설치 URL을 공유하겠습니다. 5일만에 해결했는데.. 엄청난 쾌감이네요ㅎㅎㅎ 진짜 실행되는거 보고나니 너무너무 감사하게되네요.ㅋㅋㅋㅋㅋhttp://blog.daum.net/bagjunggyu/66
30	#딥사이어인 7/4 파트1-1 후기 ([기초!!]파이썬을 이용한 베이지안 머신러닝 & 벤지오 딥러닝북 스터디)--------------------------이 스터디는 Sung Kim 님의 기초강좌를 통해 딥러닝에 관심을 가지고 입문하고, 용기를 얻은 사람들이 만들고 진행하는 스터디입니다. 텐서플로우로 실습도 있을 예정입니다. 스터디 모임 공지를 미처 이 그룹에는 못했는데요, 하지만 이제 막 1회차를 했기에 충분히 이후부터 오시는 분들도 함께 쉽게 공부하실 수 있으리라 생각합니다.--------------------------* 계산적 모형으로 사회현상에 대해 공부하려는 싸이지먼트에서 진행하는 스터디입니다.* 첫 모임 후기만 옮기겠습니다.* 자료는 모두 공개 & 공유됩니다(자료 정리 중)* https://github.com/psygement/DeepSaiyan후기 작성자 : 김성동비가 많이 내리는데도 불구하고 정말 많은 분들이 참여해주셨습니다. 물론 오셨다가 가신 분들도 계시지만.. 거의 25~30명이나 되는 분들이 관심을 가지고 찾아주셨습니다! 먼저 언제나 그랬듯 자기소개하는 시간을 가졌습니다. 정말 다양한 배경을 가진 분들이 계셔서 괜히 제가 두근거렸습니다. 첫 발표라 떨리기도 했고요..첫 발표는 제가 했습니다. 벤지오 교수님의 딥러닝 온라인북 챕터6 Deep Feedfoward Network 관련 내용이었습니다. 발표를 준비하면서 거의 영어 해석과 수식을 찾아보느라 시간을 보냈는데... 영어랑 수학이 중요하다는 것을 또 한번 느꼈습니다. 그리고 그 동안 얼마나 쉽고 직관적으로 공부를 해왔는지 알게 되었습니다. 스터디의 취지에 맞게 뇌가 지끈지끈해지도록 쉽지 않은 내용이었습니다.DFN의 개념과 linear model, XOR 예제 등을 다루며 현대 뉴럴 네트워크의 목표를 얘기했고 어떻게 보면 딥러닝의 가장 뼈대라고 볼 수도 있는 DFN을 상황에 맞게 디자인하기 위한 의사결정 문제를 다뤘습니다. Optimizer, Cost function, Output units, Activation function를 선택하는 문제와 더불어 layer는 얼마나 많아야 하는지, layer 간의 연결은 어떤식으로 할 것인지, 각 layer에는 노드가 얼마나 많아야 하는지에 관한 아키텍처 의사결정 문제도 다룰 것인데 오늘은 Output units을 정하는 문제까지 발표를 했으며 앞으로 2주간 나머지 내용도 공부하게 될 것입니다.챕터를 관통하는 내용은 네트워크가 깊어지면서 각 layer를 지나는 과정에서 정보 손실이 일어나는데 그 손실을 막고 최소화하는 방법이라는 생각이 들었습니다..(맞나요..?ㅠ)발표가 어려워 애먹었으나 위기의 순간 김무성 님이 등장하셔서 구세주처럼 도와주셨습니다...!!첫 발표만 듣고 가시는 분들이 많아서 조금 죄송스러웠습니다. 다들 배경과 사전 지식이 어떠한지를 고려하지 못했다고 생각이 들었지만... 스터디의 취지에 따라 난이도를 낮출 수는 없는지라... 그리고 이 발표가 특히 어려워서... 다같이 모르는 상태입니다. 다음주 발표부터는 미리 발표할 부분을 같이 읽어오셔서 서로 질문하고 보완하면 더 유익한 시간이 되지 않을까 싶습니다. 아마 다음주에는 6.4까지는 확실히 할 거 같고 그 뒤로 대망의 backpropagation은 준비되는데 까지 해보겠습니다...두 번째 발표는 임재성 님이 하셨습니다. 베이지안 머신러닝 책을 들어가기 전에 앞으로 자주 보게 될 MLE(Maximum Likelihood Estimation) MAP(Maximum a Posteriori Estimation)의 개념을 설명해주셨습니다. 직접 추가적인 자료까지 공부해오셨는데 카이스트 문인철 교수님의 기계학습 강의를 참고하셨다고 합니다. 동전 던지기와 비슷한 압정 던지기?를 예로 들어 두 개념과 그 차이점을 설명해주셨는데 MLE는 가정을 하고 데이터를 모은 후 그 가정을 가장 잘 설명해주는 파라미터를 찾는 것. 즉 파라미터가 주어졌을 때 그 데이터가 관측 될 확률(Likelihood)를 최대로 하는 파라미터를 찾는 과정이라고 할 수 있고 MAP는 베이즈룰을 적용하여 가정(사전분포)에 대한 믿음을 더하여 확장한 방식.. 이라고 이해했습니다. 베타분포를 사전분포로 사용하게 되면 a,b 파라미터에 의해 믿음의 정도를 정할 수도 있고 0과 1 사이에서 세타 값이 정해지는 속성 탓에 이항분포의 컨저게이트로 사용된다고 하셨습니다.언제나 어렵다고 피해왔던 베이지안이지만.. 공부하다보니 각기 다른 분야의 내용이 얽히고 섥히고 결국 만나게 되는 기이한 현상...을 체험했습니다. 앞으로도 그렇겠죠? 열심히 해야겠습니다.세 번째 발표는 김성근 님이 하셨습니다. 파이썬 머신러닝 책의 인트로 부분을 설명해주셨습니다. 목차를 살펴보니 책의 구성이 생각보다 알찼습니다.꽤나 상세한 개념 설명과 수식도 포함하고 있으면서도 파이썬 코드도 함께 볼 수 있어 좋았습니다. 데이터 수집, 전처리부터 데이터셋을 나누고 훈련시키고 평가, 예측하는 일련의 머신러닝 프로세스를 포함하여 지도학습, 비지도학습, 강화학습 등의 개념도 알려주셨습니다. 또한 앞으로 파이썬으로 실습하기 위한 환경을 셋팅하는 방법도 알려주셨습니다. 이 책은 파이썬 3 버전을 토대로 작성되었고 numpy, scipy, scikit-learn 등의 패키지를 활용한다고 합니다. 기초적인 내용을 다시 한번 짚어볼 수 있어서 좋았고 이 발표를 처음으로 했더라면 돌아가셨던 분들 중 몇 분은 남아있었을텐데 하는 아쉬움도 있었습니다..어렵다 안된다 생각하지 말고 된다 된다 생각하면서 재미를 붙여야겠습니다.(자기 최면..) 이번주도 죽을 위기를 넘겨가며 또 한번 성장합시다~다음주 스터디도 많이 나와주세요!	2	우아 멋지세요 다들 화이팅!	1	https://www.facebook.com/groups/psygement/	1	멋집니다. 스터디일정에 대해서도 저희 그룹에 알려주시면 많은 분들이 참여하게 될것 같습니다.	0	매주 금요일, 저녁 7-10시, 강남 힐스터디(강남역 4번 출구, 10층 건물), 예약자명 : 김성동	0	다음 모임 일정 곧 자세히 공유하겠습니다~
9	혹시나 임베디드 보드인 Jetson TX1에 TensorFlow를 올려 사용하고 계신분이 계신가요? 이번에 사용할 수 있는 기회가 생겨서 사용해 보려 하는데,자료가 없으면 설치부터 해서 다양한 활용까지 자료를 만들어 볼 생각입니다. 도움을 주실 수 있으신 분들은 많은 도움 부탁드립니다	1	bazel 크로스 컴파일이 관건이라고 알고있습니다ㅎㅎ 응원합니다~ https://m.facebook.com/groups/255834461424286?view=permalink&id=306921162982282
42	오늘 올려드릴 TF첫 모임 비디오는 조만석님의 얼굴인식 구현입니다. 이제 비디오 하나 남았습니다.
36	일본 관동지역 컴퓨터 비젼 스터디 모임의발표자료들인데CNN과 LSTM을 이용한 image caption generator에 대한 논문을 정리한 자료입니다.LSTM을 처음 접하신 분들에게 도움이 될 듯도움이 되신다면제가 주말에 번역을 해서 올리겠습니다.지역별 스터디 모임 자료로 활용해도 좋을 듯	1	감사합니다 큰 도움이 될 것 같습니다^^	1	감사합니다. 혹시 가능하시다면..간단한 설명도 추가해 주신다면...ㅎㅎ	1	멋지십니다	1	칸토cv벵꾜까이가 아직도 있군요!! ㅎㅎ 반갑네요
11	이거 정말 논문인가요 ?제목이 "Deep fried converts" 부터 이상하더니Adaptive fastfood transformLearnig fastfood by backpro.  ㅋㅋ	1	https://www.improbable.com/airchives/paperair/volume12/v12i5/chicken-12-5.pdf  이정도는..아니긴 해도.. 음(?)
27	딥러닝 전문가분들이 요즘 어디서 주로 활동하는지 궁금했는데, 여기 계셨군요... 오늘 가입한 신참입니다. 잘 부탁드려요.	1	교수님 환영합니다.	1	교수님 환영합니다 2.
9	안녕하세요. 항상 눈팅으로 열심히 공부하고있는 대학원생입니다. 질문드리고 싶은 부분이 있어 이렇게 글을 올리게 되었습니다. 질문드리고 싶은 부분은 "자동으로 Multi GPU를 활용한 계산이 가능한가?" 입니다.좀더 부연설명을 붙이자면, Titan x 2대가 있고 신경망을 학습 시킬 때, 그냥 학습시키면 1번 Titan 에서만 계산이 되던 것을 자동으로 1/2번 titan에 계산을 배분하여 학습시켜주는 방법이 있는지 궁금합니다. (GPU 2번이 놀고있어요!!)TF에서는 이를 GPU0번/1번 과 같이 수동으로 배분한다는 것은 알고 있으나, 신경망에서 적절히 분배하여 지정 해주는 일이 쉬운일이 아닌것 같아 이를 자동으로 해주는 방법이 있는지 궁금합니다.잠깐 인터넷에서 찾아 봤을때는, TF말고 다른 언어에서도 이를 자동으로 배분해주는 것은 아직 없는 것으로 판단되기는 하는데,  혹시나 제가 방법이 있는데 잘 못 찾는 것인가 싶어, 여러 전문가 여러분께 질문드립니다. 마지막으로 항상 좋은 정보 올려주셔 감사합니다 :) 좋은 금요일 되세요!!!	1	https://www.tensorflow.org/versions/r0.9/tutorials/deep_cnn/index.html#training-a-model-using-multiple-gpu-cards 해당 내용을 참고하시면 되겠습니다. :)	1	저번주 타이탄 2개로 inception v3 fine tune 했습니다 코드 참고하시면 도움이 되실 것 같습니다 tensorflow/models/inception 아래로 기억합니다
13	keras를 활용해서 NN으로 XOR 문제를 한번 풀어보았습니다. 아래 참고하세요. from keras.models import Sequentialfrom keras.layers import Denseimport numpy as npimport pandasdataframe = pandas.read_csv("xor_data.txt", header=None)dataset = dataframe.valuesX_data = dataset[:, 0:2]Y_data = dataset[:,2]model = Sequential()model.add(Dense(2, input_dim=2, init='uniform', activation='relu'))model.add(Dense(4, init='uniform', activation='relu'))model.add(Dense(1, init='uniform', activation='sigmoid'))model.compile(loss='binary_crossentropy', optimizer='adam')model.fit(X_data, Y_data, nb_epoch=10000, batch_size=16)result = model.evaluate(X_data, Y_data)print(int(model.predict(np.array([[0, 0]])) > 0.5))print(int(model.predict(np.array([[1, 0]])) > 0.5))print(int(model.predict(np.array([[0, 1]])) > 0.5))print(int(model.predict(np.array([[1, 1]])) > 0.5))	0	코드 간단하고 좋네요. https://github.com/nlintz/TensorFlow-Tutorials  코드들 keras로 변환 가능할까요?
24	Tensorflow를 배우는 입장이다보니, 이것저것 미숙한 부분이 많은데요.기존의 docker 컨테이너에서 tensorboard를 위해 추가로 새로운 포트를 여는 방법을 찾다가 저같은 분이 계실까봐 공유합니다.이렇게 한 이유는 컨테이너를 완전히 새로열자니 기존의 자료를 포기할수가 없어서..(별거없지만)이번에도 순전히 저를 위한 글 위주 서술이라 이해가 어려우실수도 있습니다. 아는선에서 얼마든지 답변해드리겠습니다.	2	팁. running container의 자료는 호스트의 설치경로(/var/lib/docker)에서 백업이 가능합니다	3	조금 더 첨언? 해드리자면 도커 컨테이너 환경변수는 inspect 명령어로 확인하고 뒤적거리시면 좀 더 다양한 사후 설정이 가능합니다
3	구글에 개발자들에게 기술지원 하는 ㅇ연락처잇나요	3	그건 잘 모르겠지만 스택오버플로우에 TensorFlow에 대해 질문하면 TensorFlow개발자가 답변해준다는 소문은 들었습니다	2	보통은 github에 contact 메일은 써있습니다.. 몇번보내봤는데 가끔 답장옵니다
63	[서울대학교 스터디 모임]안녕하세요! 서울대학교에서 대학원과정을 하고 있는 이지민이라고 합니다^^지난번 오프라인 모임 때 뵈었던 몇몇 분들과 함께 서울대학교 TF 스터디 모임을 만들게 되었습니다!현재 구성원은 곽동현 , 이진원 , 이우진 , 저 이고요. (곽동현님께서 많은 도움을 주시리라 기대하고 있습니다 ㅎㅎ)7월 11일부터 서울대학교에서 일주일에 한번씩, 자신의 연구와 관련된 TF 오픈소스 리뷰, 파이썬 코드 리뷰 등으로 스터디를 채워나갈 예정입니다!이 그룹에 계신 분들 중 혹시 스터디모임에 관심있는 분이 있으시다면 댓글로 달아주세요! 그럼 좋은 저녁 되시기 바랍니다.감사합니다.😀😀😀+ 추가) 스터디 시간 : 매주 월요일 7:30pm (7/11부터 시작합니다.)장소는 서울대학교입니다!	3	우와~ 재미있겠습니다. 스타디 모임 생중계 계획은 없으신지요? TF-KR에서 많이 홍보할께요.	2	재미있겠네요 ㅎㅎ	3	좋네요! 평일에만 하나요?	3	재미있겠네요 ^^	2	저도 참여하고 싶습니다! 오프라인 모임 때 뵈었던 것 같네요ㅎㅎ	2	재미있겠네요 놀러가도 될까요...	1	조준호	0	서울대 생만 참가가능 한가요	0	헉 평일 7:30이라니 판교에서 가기 힘들겠네요ㅠㅠㅠ 아쉬워요ㅠㅠ	1	저희 대부분 초보수준이라서 내공 약간쌓이신 분들이 오시면 실망하실 수도 ㅠㅠ 이제 시작하는 수준에서 같이 공부하려고 만든 모임입니다~^^	0	Online 브로드캐스트 하면 좋지 않을까요?  많은 사람들이 참여하고 듣고 의견 나눌수 있을거 같습니다.	1	혹시 어느 정도의 기본 수준을 요하는지 여쭤봐도 될까요? 딥러닝 분야 전공자는 아니다보니 조심스럽네요 (...) (덧, 참고로 저도 컴퓨터분야 석사과정이고 위에 말씀 주신 시간으론 참석 가능합니다!)	0	아아 멀군요 ㅠㅠ	0	일정이 제대로 안나와 잘 모르겠지만 가능하면 저두 참여하고 싶습니다!	0	와! 금토만 아니면 참여하고 싶습니다 :)	2	부디 좋은 결과 있길 바랍니다~	0	오오~! 저요~ 적극적으로 참여할 의사도 있고, 마침 서울대생은 아닌데, 사정이 있어서 서울대를 밥먹듯이 갑니다ㅋㅋㅋ 기회가 된다면 꼭 참여해보고 싶습니다.	0	저도 가능하다면, 참여하고 싶네요. 평일이라 매번 가진 못 하겠지만.	0	다 좋은데 시간이 안되네요 ㅠㅠ	1	이제 공부를 시작하려는 사람도 가능한가요? 개발자 출신이고 지금은 it회사를 운영중입니다	4	많은 분들이 관심을 가져주셔서 너무 감사드립니다!! 그룹이 너무 커지면 운영이 힘들것 같아 우선은 여기서 마감하도록 하겠습니다. 감사합니다! 댓글 달아주신 분들은 개인적으로 연락드리겠습니다^^	0	혹시 스터디 참가가 가능할까요?? 마감완료된건가요?머신러닝 공부하고 있는 사람인데요. 꼭 참여해보고 싶어서요.	0	저도 머신러닝 전공하는 석사과정인데 줄서봅니다!	0	지금도 신청가능할까요.. 조심스레 신청해봅니다..!	0	저도 지금은 여기 대학원 다니는데 가능할까요? 성실히 하겠습니다. 학교에 정보화 센터에서 방학동안 하는 머신러닝(텐서 플로우 관련) 강의 듣고 있는데 스터디 통해서 이어나가면 좋을 거 같아서요^^	1	이후에도 여러 분께서 댓글을 달아주셨네요! 관심 가져주셔서 정말 감사드립니다. 아쉽지만 예상보다 인원이 너무 많아진 관계로 더이상 받기가 어려울 것 같습니다. 결원이 생기거나 스터디를 확장할 계획이 있으면 바로 글을 한번 더 올리도록 하겠습니다. 죄송하고 감사드려요!!	0	후아.. 늦어버렸네요.. 일찍봤으면 좋았을텐데 ㅠ	0	저도  it 회사를 운영하고 있습니다.  혹시 결원이 발생해서 자리가 생기면 끼워 주시면 멋지겠습니다.	6	7/11일이 다가 옵니다. 멀리서 응원합니다.
15	우분투에서 안드로이드 스튜디오로 디바이스에 앱 run 성공했네요 아래 자료 참고 하시길,,
3	우분투에서 안드로이드스튜디오 돌리는 사람이 거의 없군요 ㅋㅋ	2	여기 텐서플로운데.. 자꾸 관련없는 질문만 올리시네요. 그것도 큰 문자로만. 자꾸보니까 좀 불편하네요.
30	XOR 연산을  NN으로 하는 강의(https://www.youtube.com/watch?v=9i7FBbcZPMA&feature=youtu.be)에서 하란대로 코드짜면 안될겁니다.  Numpy가 좀 달라졌는지 코드가 이상하게 도네요. 버그 수정한 버전을 올리니 참고 바랍니다. 저도 이거 버그 잡으면서 많이 배웠네요. ^^ https://github.com/jinhoyoo/deep_learning_research/blob/master/xor_example.ipynb	0	역촋	0	정말 감사합니다. 어떤 부분이 달라진 것인가요?
9	NN으로 XOR을 해결해보려고 하는데 코드가 학습이 잘 안되네요. sungkim 교수님 강의를 들으면서 진행하는데 말이죠.cost값이 0.6에서 계속 맴돌고 있습니다. 쭉쭉 떨떨져야 하는데 말이죠. 그리고 accuracy가 0.5이네요. 쩝 ... help me :-)  -- 데이터 -- # XOR# x1 x2 y0   0   00   1   11   0   11   1   0-- 코드 --import tensorflow as tfimport numpy as npxy = np.loadtxt('xor_data.txt', unpack=True)x_data = np.transpose(xy[0:-1])  # 4x2 matrixy_data = np.transpose(xy[-1])     # 4x1 matrixX = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))b1 = tf.Variable(tf.zeros([2]))b2 = tf.Variable(tf.zeros([1]))L2 = tf.sigmoid(tf.matmul(X, W1)  + b1)hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))optimizer = tf.train.GradientDescentOptimizer(0.01)train = optimizer.minimize(cost)init = tf.initialize_all_variables()with tf.Session() as sess:    sess.run(init)    for step in range(2000):        sess.run(train, feed_dict={X:x_data, Y:y_data})        if step % 200 == 0:            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W1), sess.run(W1))    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))    print(accuracy.eval({X:x_data, Y:y_data}))	0	ㅎㅎ 왜 그럴까요? 한단계 더 deep하게 해보시면 어떨까요?	1	저 같은 경우에는 학습을 좀더 오래 했어요 코스트 그래프를 보면 어느지점에서 머물다 갑자기 코스트가 급격하게 떨어지더군요	2	Step수를 한 100000이상 봐야 할지도.. 저도 그래서 cost graph를 그려봐요. GradientDescentOptimizer말고 AdaptiveGradientDescent...던가 하는 걸로 바꿔봐도 좋을거에요. Optimizer의 세계도 오묘하답니다.ㅎㅎ	0	10000번만 해도 0.07 정도로 떨어지네요	1	음 해결했습니다. y_data의 shape를 4x1로 변경하니 잘 되네요 허허	1	코드 오류 잡은 버전 올라갑니다. https://github.com/jinhoyoo/deep_learning_research/blob/master/xor_example.ipynb
4	안녕하세요 유투브 강의만 듣다가 페북에 텐서플로우 페이지가 있어서 가입했습니다. 잘부탁드립니다ㅎㅎㅎ
16	윈도우 배쉬쉘 다들 기대하고 계시는데요. 제가 한번 써봤습니다.프리뷰 버전으로 돌려봤구요. 텐서 플로우 0.9, python3.4 로 헬로우 월드 테스트 돌아가는 것까지 확인했습니다. 다만... 윈도우 배쉬쉘 자체가 gpu를 지원하지 않습니다... 8월 업데이트에는 어떻게 바뀔지 모르겠네요	0	후기 잘 보았습니다. 결정적인 부분이 문제네요.^^	1	Gpu 지원 안하면 있으나마나인데...ㅠㅠㅠ	1	앙꼬없는 찐빵이네요 ㅠ
0	깃허브 짚파일 다운로드 클릭링크가 없는 경우는 어떻게 다운받죠??	0	루트로 가시면 다운로드 링크 있어요 https://github.com/tensorflow/tensorflow
4	혹시 nvidia 에서 나온 태블릿 tegra k1 으로 머신러닝 돌리시는 분 계신가요? 태블릿을 살라고 보다가 엔비디아 에서 게임용태블릿 이라고광고하는게 일어서 192코어라길래 찾아봣는데 의견이 분분허네요 쿠다 지원여부를 찾아봣는데 공식홈페이지에서 된다는 답변을 찾았는데 실제 돌려보신분이 계신가 싶어서 여쭤봅니다 ..텐서플로랑 카페를 돌리려 합니다	1	아마.. 된다고 들은거 같은데... Nvidia Jetson k1 인가가 지원한다고 들었는데, 태블릿도 지원하지 않을까 생각됩니다.	2	위에분이 말씀하신 것처럼 Jetson TK1이 tegra 프로세서를 탑재한 개발보드인데요. 일단 tk1 보드에서도 tensorflow 설치가 쉽지만은 않습니다. cuda가 6.5까지밖에 지원이 안되구요. bazel을 크로스 컴파일해야하는데 이게 삽질이 여간 많은게 아니라고 합니다. 다른 사람이 tensorflow 0.5를 크로스 컴파일해서 pip package 만들어놓은걸로 설치는 해봤는데, 워낙 버전이 예전꺼라 지금 버젼의 모델이 그냥 돌아가진 않아서 포기했습니다. 여기저기서 들어본 얘기로는 nvidia 보드에서는 상대적으로 Caffe가 설치하기 쉽다고 합니다. 참고로 Jetson TK1의 상위 모델인 TX1은 cuda 7.0를 지원한답니다.	0	상세한 설명 감사합니다 텐서플로 모바일 이 최근에 나온걸 보고 좀 쓰기 편하지 않을까 싶었는데 아직 그정도는 아닌가 보네요ㅠ 사게되면 삽질후기 남기겠습니다 두분모두 감사합니다
28	CEVA, 구글 AI 엔진 'TensorFlow' 까지 확장된 2세대 딥러닝 심층신경망 발표- 자율주행(ADAS), 지능형감시장비, 드론, 로봇 등 스마트 디바이스의 임베디드 시스템 내 머신러닝을 구현	1	모바일 디바이스나 드론 개발하시는 분들에게 좋은 정보네요.
3	굉장히 기초적인 질문 하나 올립니다.sequence 모델을 학습하고 있는데 데이터들이 one-hot이 아니라 binary 벡터인 경우 (0100 -> 1101 -> 1001 ->... 같은 형태) loss function을 어떻게 정의해야 할까요? seq2seq 같은 모델에 있는 loss function들은 다 one-hot decode를 기준으로 하고 있는 것 같은데 혹시 제가 놓친게 있는지 알려주시면 감사하겠습니다.	0	그냥 한번더 expand 시키는것은 어떨까요?? 0100 == 4 =~ 0000000000010000, 1101 = 13 =~ 0010000000000000, 1001=9=~ 0000001000000000. 각 dimension에  affinity 가 강하지 않거나, sparse이면, 이런 방법도 될듯한데요..  그렇지 않더라고, 데이터가 많으시면,  이러나 저러나, 다 부우시면,  얼만큼은 잘 나올거 같고요.. (설명이 애매모호한거 죄송합니다... 저도 잘모름니다. ㅎㅎ ). 데이터가 작으시면, 직접 loss function 만드셔도. cosine similarity 이나 edit distance 이 성능은 비슷하게 나올듯하네요.. (딮러닝에서 기초적인 질문은 없는듯합니다.. (: 다 어려워요.. )	1	John Park 답변 감사드립니다. 일단 별 대안이 떠오르지 않아 저도 말씀해주신대로 one-hot으로 하긴 했는데, 어차피 다시 embedding시켜서 low dimension에서 training할 것이라면 혹시 binary vector 그 자체의 값을 가지고 직접 training 할 수 있을까 해서 질문드렸습니다! (multiple label을 가질 수 있는 classification 문제 같기도 하네요(?)
3	$ chmod +x PATH_TO_INSTAL.sh우분투에서 저거 실행햇는데요 No such file or directory이렇게 나오는데요 왜 그런거죠 해당 폴더에 파일이 잇거든요	1	./파일네임	1	으로 한전 해보세요	0	chmod +x ./PATH_TO_INSTAL.sh 가 아닌가요???	0	Installation for LinuxInstall BazelFollow instructions here to install the dependencies for bazel. Then download the latest stable bazel version using the installer for your system and run the installer as mentioned there:$ chmod +x PATH_TO_INSTALL.SH$ ./PATH_TO_INSTALL.SH --user	0	https://www.tensorflow.org/versions/master/get_started/os_setup.html#source	0	PATH_ 까지 치고 탭 키 눌러보세요터미널에서 패스이동 제대로 하셨죠?
43	윈도우10.업데이트에 bash 추가되네요. 이제 윈도우에서 텐서를 쓸 수.있겠어요. ㅋ	1	오!	1	조만간 원10 bash 기반에서 Tensorflow구성 예시가 많이 나오겠습니다.	1	우분투가 되는건가요??	1	8/2 이면 좀 남았군요	0	갈아탈 때가.....오는거신가.....	0	sudo rm -rf / 가 안된다니!!	0	그냥 VMware 깔아서 우분투 써도 되는데..	0	Bazel은 안깔려서 우분투써야될걸요
21	Tensorflow를 지원하는 디바이스가 나오네요...Learning은 어렵겠지만... Deploy 해서 사용하는 수준이 얼마 만큼인지 궁금하네요.	1	좋은 정보 감사. 저도 사용해 보고 싶습니다.
9	keras를 써보니 쉬워서 좋더라구요. 여러분들 생각은 어떤가요?	0	쉬워서 좋긴한데. 네트워크 구성시 detail한 설정이 좀 아쉽더라구요...	0	저도 예제 좀 돌려본 수준입니다만.. 쉽고 좋던데요? 최신 연구를 할게 아니라 객체인식처럼 잘 정리된 문제를 푸는 '툴'로 쓰기엔 tf보다 접근하기 쉽지 않을까요?
3	혹시 ubuntu 14.04 geforce 1080 cuda8로 tensorflow설치하신분 중에 노하우 공유 가능하신분 계신가요?	0	현재 TensorFlow 는 cuda 7.5기준이라 8.0은 문제가 발생할 가능 성이 많습니다.	0	예전에도 비슷한 질문이 있었는데, 현재로서는 tensorflow source code를 빌드해서 쓰셔야 합니다.
4	안녕하세요. 질문드릴것이 있어서 부끄럽지만 이렇게 글을 올립니다.Tensorflow 튜토리얼 sequence-to-sequence-models 샘플을 돌려보고 있는데 메모리가 부족하여 학습을 정상적으로 수행하지 못하는 문제가 있습니다. 학습하려는 모델에서 요구되는 메모리값은 어떻게 알 수 있을까요? 파라미터 값에 따라 필요한 메모리 정보를 알려주는 툴이 있는지도 궁금합니다.	1	이런 공식이 있긴 해요
12	standalone으로 텐서플로우 GPU 서버를 구성하려고 합니다. 적당한 사양(넉넉한 사양)을 알려주시면 널리 공유 드리고자 노력하겠습니다.1간 5천만건 ~ 2억건 정도의 데이터 처리를 하려고합니다. 작습니다...1. GPU 사양 / 가격2. 기타 조건	0	NVIDIA DGX-1가 진리일지요?	0	적당한 사양은 모르겠고 주변보니 타이탄 x 8장씩 꼽아서 쓰는듯한 ㅎㅎㅎ	0	와 저도 이거 고려중인데 조언 좀 ㅎㅎㅎ	0	GPU가성비 분석된 자료들 있습니다 그걸 기준으로 요구성능을 체크해서 올리시면 어떨까요?	1	Nvidia 라이센싱 한국 업체로 리더스시스템즈가 있습니다. http://www.leaderssys.com/site/bbs/board.php?bo_table=2_10
3	Sung Kim 교수님, 가입 승인 감사합니다.
10	Show attend and tell API (https://github.com/jazzsaxmafia/show_attend_and_tell.tensorflow) 의 Keras 플러그인 Using Theano Backend 문제로 인해 질문드리는 중학교 2학년입니다.이를 해결하기 위해 Keras의 Backend 링크 (http://keras.io/backend/) 에 있는 방법을 따라하여 backend를 Tensorflow로 고쳤으나, Import가 그냥 될 줄 알았던 keras가 이번에는 Using tensorflow backend라고 출력하고 있습니다.게다가 show attend and tell API의 model_tensorflow.py를 실행할 때에는 그대로 using theano backend라고 나오네요... 이런 에러가 나오지 않게 하고 API를 정상 실행할 수 있는 방법이 없나요? 기말고사도 공부하면서 이 프로젝트도 하고 있는데 해결 방법을 아직 못찾고 있습니다. ㅠ_ㅠ혹시 이 부분에 대해 아시는 고수님이 계신다면 제발 좋은 답변 부탁드리겠습니다. 감사합니다. :)	0	OPENBlas 가 지원하지 않는 os라 하네요 그리고 using tensorflow backend 는 텐서플로우 사용한다는 알림메세지같은데요?	0	openblas 에서 avs 라는 명령어셋을 사용하나봅니다 우분투에서 그걸 지원하지 않거나 cpu가 avs를 지원하지 않나보네요	0	https://github.com/biocore/qiime/issues/1704참고해보세요
40	오늘은 Deeplearning.tv 시리즈중 TensorFlow에 대한 설명 동영상입니다.처음 TensorFlow를 접하시는 분들에게 많은 도움이 될 듯 합니다. 녹음중 괭이들 울음소리가 함께 녹음 되었네요.	1	항상 좋은자료 감사드립니다
35	윈도우상에서 도커를 이용하여 jupyter환경 구성하는방법 및 호스트가 고정IP일때 외부에서 접속가능하게 하는 방법입니다.많이들 아시는 내용이겠지만, 저같은 초보분들이 참고하실 수 있도록 간단하게 글로 작성해보았습니다.도커설치부터 주피터 접속까지 30분이 안걸리네요 . 좋은 세상입니다.글 위주로 작성하여서 다소 설명이 부족하다고 느끼실 수도 있습니다................혹시 질문 있으시면 제가 아는선에서 답변해드리겠습니다.	0	윈도우상에 pycharm pro버젼으로 연결해도 사용하기 좋다라구요^^http://m.blog.naver.com/fantaziulo/220717034071	0	같은 방법으로 윈도10프리뷰의 bash에 설치한 텐서에도 연결할수 있는데, 아직 약간 불안정한거 같아요..	0	나용이 아, pycharm 저는 2016.1.4버전에서 add remote버튼이 어디에도 없길래 포기한건데 1.3버전에만 있는건지... 윈도우10 프리뷰로 테스트도 해봤는데 프리뷰라그런지 몇몇 불안정한 요소들이 있어서 그건 정식 출시 기다리고 있습니다. 8월 2일쯤 정식출시라는 얘기가 있더라구요
126	Park Ricky님 저희 그룹 운영진에 합류하였습니다! TensorFlow의 엄청난 정보가 있는 https://tensorflowkorea.wordpress.com/ 의 운영자이시기도 합니다. (제가 처음 TensorFlow를 접하고 공부한곳이기도 합니다.)앞으로 저희 그룹에도 많은 소식을 나누어 주시고 또 저희 멤버들에게 큰 도움을 주실 것으로 기대합니다.함께 환영해주세요. PS - FB도 하지 않으시는데 저희 그룹 운영진에 합류하기 위해 FB에 전격 가입하였습니다. 친구 신청도 많이 해주세요.	1	환영합니다!!	1	제가 자주 가는 곳인데... 너무 반갑습니다..	0	오! 반갑습니다~	0	반갑습니다~^^	3	윽 공지까지.. ㅜㅜ	1	멋진 웹사이트를 소개해 주셔서 고맙습니다.	0	텐서플로우 코리아 사이트 잘보고 있습니다~ 감사합니다!	0	많이 배우겠습니다. 감사합니다.	0	마침 Tensorflow에 대한 소식을 접할 Site를 찾고 있던 중이었습니다. 감사합니다.
212	Facebook Spam Out!최근들에 FB그룹에 스펨이 많이 올라옵니다. 특히 그림관련 스템은 정말 보는 이들을 불쾌하게 하는데요, 구글의 딥러닝 (Vision API)기술을 이용하여 그림이 성인물이거나 불쾌할경우 이 글을 자동으로 삭제하게 됩니다. Facebook post될경우 hook같은것이 없어서 (있으면 알려주세요), 5분마다 한번씩 확인을 합니다. 지금 저희 그룹에 적용중인데 한달정도 시험한 다음, 실전에 적용할 예정입니다.소스코드: https://github.com/hunkim/FacebookSpamOut그룹 숫자 아이디만 수정하시면 본인이 관리하는 다른 그룹에서도 사용가능합니다. PR 이나 이슈, 언제나 환영합니다.	18	저는 그냥 그것을 만든 인간들에게 카톡을 날려서 클린한 나프다를 만들었습니다 역시 텐서!!!	3	와우!!! 정말 이거 큰 문제인데 적용해볼 생각을 못했네요!! 바로 적용 해보겠습니다!!	1	왜 요 몇일 하루에 수십개씩 이상한 계정에서 페친 신청을 하는지.  아무래도 타켓팅이 됐나봐요.	0	와우!! 좋은 아이디어인거같아요. 함 써봐야겠어요 ㅎㅎ	5	인공지능 커뮤니티의 인공지능 해결법이군요 ㅎㅎ	1	스팸 계정이 많아서 고생인데 사용후 피드백 드리겠습니다!
43	안녕하세요! Tensor flow를 활용해 Android Application을 개발하는데 관심이 많은 학부생입니다. 이번에 tensorflow를 활용해보는 프로젝트 진행중에 기본적으로 제공하는 App 빌드 예제를 시도해봤는데요, 그 과정에서 bazel 설치법부터 막혀 상당히 고생했습니다. 아랫 글에도 저희처럼 bazel을 궁금해 하시는 분이 계시는듯 해서 기본적인 개념과 설치법을 공유해 보겠습니다. 대단한 글은 아니지만 완전 초보분들께 도움되길 바랍니다 ㅎㅎ	0	와진짜감사합니다! 너무공감됩니다 내용이!	1	뭔지도 모르고 열심히 깔기만했었는데 덕분에 개념이 잡히네요~ 감사합니다	1	챕터4와 챕터5에서 바젤 사용 방법에 대해서 다뤄지는건가요?!	1	유승호 간단하게 예제에서 사용되는 바젤에 대해서만 다룰 예정입니다. Workspace 설정이 핵심 내용이 되며 bazel build 명령어 사용도 이야기 할 겁니다 ㅎㅎ bazel 단일에 대한 깊은 내용은 홈페이지에서 찾으시는게 빠르실듯 합니다!	0	바젤을 꼭 사용하지 않고도 안드로이드에서 테서플로우 활용하는 방법도 있습니다. 예전에 본거라 찾아서 링크 올리겠습니다.	0	Tensorflow 의 MNIST를 안드로이드에서 구현한 소스(일본) 입니다. Android Studio 베이스 입니다.	1	https://github.com/miyosuda/TensorFlowAndroidMNIST	0	민원기 맞습니다!! 저희팀도 저 어플 실행해봤는데 바젤 이외의 방법인줄은 몰랐군요. 다만 텐서플로우 공식 예제는 기존의 빌드도구로 빌드하기 힘든 어떤 부분이 있지 않았을까 생각합니다. 아마 실시간 이미지처리라는 MNIST보다 훨씬 대용량의 처리이기 때문아닐까 생각해봅니다. 아니면 Bazel을 적극 활용하라는 구글의 의도이거나... 안드로이드 스튜디오라면 내장된 그래들 빌드도구일까요? 좋은 정보 정말 감사합니다!	0	Tensorflow 처음 설치하면서 bazel이 꼭 필요한 줄 알았는데 그렇지 않는군요.. 좋은 정보 배워갑니다. 감사합니다.
63	안녕하세요. theano로 개발하다가 이제 막 tensorflow로 넘어온 초짜입니다. 좀 늦은감이 있지만 잘 부탁드립니다.theano는 window10에서 개발하다가 tensorflow를 사용하기 위해서 ubuntu에 설치를 했는데요. 그래픽카드 잡는 것부터 엄청 애를 먹었네요. 다들 잘 아시겠지만 혹시 저처럼 고생하시는 분들을 위해서 포스팅 공유합니다.우분투 14.04에 NVIDIA 그래픽카드 잡는 것부터 cuda, cudnn, tensorflow설치까지 애먹었던 것들을 정리해보았습니다. 참고하세요~http://flyingdcat4.tistory.com/76http://flyingdcat4.tistory.com/77	1	좋은 자료 감사합니다	1	우왕 감사합니다!	1	ㄷㄷ복잡하네요....뜬금없는 이야기이지만.. 설치하시면서 bazel 보시거나 접하셨을꺼같은데 혹시 bazel 사용방법 아시나요?!ㅜㅜ	1	우와 좋은 정보감사합니다혹시윈도우환경에서vm깔고 우분투 깔아서 gpu쓸수 있나요??쓸수 있으면 우분투환경에서 쓰는것보가 많이 느린가요??	1	감사~	1	감사감사	1	감사합니다 !	0	혹시 저처럼 처음 우분투 설치부터 하셔야 하는 분을 위해서 살짝 첨언 드리면요..  16.04에서 설치하는 아래 링크도 참고 부탁드립니다. ^^ (구글에서 찾았는데 짧아서 좋고요. 따라하다보니 생각보다 금방 되더라고요.)개인적으로 리눅스 사용은 10년만이라 ㅠ 우분투가 뭐지 부터 시작해서 16.04로 할지 14.04로 할지 고민 많이 했었거든요.. 다행히 16.04도 잘 동작하니 안심하고 16.04로 시작하셔도 될것 같습니다.http://pythonkim.tistory.com/49
8	#DGM #싸이그래머 Deep Graphical Models 8/31 파트1 - 1회차 후기.* Deep Graphical Models 파트 1 첫 모임이 있었습니다. 첫 후기만 공유하겠습니다. 자료는 정리 중이며 곧 모두 공개 & 공유됩니다.* 이 스터디는 정통 심리학 그룹 싸이그래머에서 진행합니다.* 네이버D2에서 지원합니다.후기 작성자 : 정권우오늘 DGM 스터디가 진행됐습니다. 저는 오늘 처음 참석했습니다. 기대한 것보다 좋은 분위기와, 심도 있는 콘텐츠를 듣고와서, 후기 남깁니다!첫번째 발표는 정성훈님이 해주셨습니다. 내용은 Python Machine Learning Ch.01였습니다. 딥러닝에 들어가기 전에, 먼저 머신러닝의 기초가 되는 3가지 학습법(자율, 지도, 강화)을 각각 설명해주셨습니다. 유명한 아이리스 데이터셋을 기반으로 지도학습을, 직관적인 시각화로 자율학습과 강화학습에 대한 설명을 해주셨습니다. 더불어 데이터 전처리, 모델 선정, 매개변수 선정의 흐름으로 이어지는 머신러닝 시스템에 대하여 상세하게 짚어 주셨습니다.두번째 발표도 정성훈님이 해주셨습니다. Murphy 책의 Ch.12 장 중간부분(Latent Linear Models)을 발표해주셨습니다. 갑자기 난이도가 올라갔지만, 처음 온 분들을 위해 선형대수의 기본(Covariance, Eigenvector/eigenvalue, orthogonal, lagrange transformation) 등을 훑어주시고, 잠재 변수를 찾는 Latent Model에 대해서 설명해주셨습니다. FA의 특수 케이스인 PCA(Principal Component Analysis)를 수식유도와 기하학적 설명으로 쉽게 풀어주셨습니다. 데이터를 3개의 특별한 메트릭스로 표현하는 SVD(Singular Value Decomposition)의 설명까지 이어주시고, 오늘 발표를 마무리해주셨습니다. 여러 질문에도 침착하게 그리고 알기쉽게 설명해주시는 부분이 인상적이었습니다.세번째 발표는 김정주님이 해주셨습니다. Bengio 책의 Ch.14 AutoEncoder 중간 발표를 해주셨습니다. "데이터의 특징을 추출하는 인코딩을 찾는 것이 목표"라는 간결한 설명과 함께 다양한 오토인코더 종류(Undercomplete, Sparse, Denoising)를 설명해주셨습니다. 특히 Denoising Autoencoder 이해를 돕기 위한 시각화 덕분에 어려운 개념들을 잘 표현해주셨습니다. 어려운 영어를 꼼꼼하게 번역하시고 해석하신 것이 인상적이었습니다.발표해주신 분들께 감사드리고, 다음주에 뵙겠습니다.정권우
98	Google Brain Team이 좋은 퀄리티로 문장에서 타이틀을 자동으로 추출해내는 텐서플로에서 동작하는 기계학습 알고리즘을 개발했다는 소식입니다.Google Brain Team이 사용한 환경은 분산환경이지만, 공개한 코드는 단일 머신에서도 동작 가능하도록 코드가 단순화 되어 있다고 합니다.	0	Text summarization 어쩌고 제목도 TensorFlow가 뽑아준 것인지 봐야겠네요. ㅎㅎ	0	아마 시나 꽁트, 연극 영화 대본은 불가능하겠지요?.. ㅋㅋ
2	이제 막 tensorflow공부를 시작해서 tensorflow를 설치하고 있습니다. 제 pc는 MS Window7입니다. 인터넷상의 설치방법 을 보면서  docker를 다운받아서,설치를 하고나서, 설치방법의 단계별 안내에 따라, cmd창에 " docker run -it b.gcr.io/tensorflow/tensorflow:latest-devel" 명령어를 치면,지속적으로 경로error가 뜹니다.경로도 바꾸어 보고,삭제후 재설치도 몇번 했는데,마찬가지입니다.어떻게 해야 정상적으로 설치가 될지 도움주시면 감사하겠습니다.(그리고,tensor flow가 파이썬 2.7과 3.3에서만,가능한가요? 3.5에서도 가능한가요?)	1	단순 추측이지만 사용자이름이 한글이라 그런거 같기도하네요	0	그런 것 같아서, Install될때 경로를 바꾸어 보려고 했는데,경로바꾸는 옵션이 없더군요. 기존에 계속 문제없이 써왔던, 사용자폴더 이름을 바꾸는 것도 문제가 있지 않을까 싶어서,어떻게 해야할지 고견구합니다.	1	제가 윈도우7에 도커로 tensorflow를 돌리면서 작성했던 블로그인데.. 혹시 참고 되실까봐 남겨보아요~http://sweet3.tistory.com/6	0	감사합니다 해볼께요	1	윈도우 텐서플로우는 암 발병의 원인이 됩니다. 본인의 건강을 위해서 우분투 설치를 권유드립니다ㅋㅋㅋㅋㅋㅋ	3	Cmd창 말고, Docker terminal 에서 실행하세요. 그럼 될겁니다.	1	경로 이름에 한글이 들어가 있어서 그런거 아닌가요??
0	안녕하세요 저는 현재 tensorflow를 공부를 하고 있는 학생입니다. 제가 Logistic Classification 부분을 배우고 있는데 궁금한점 있어서 질문드립니다.Logistic Classification를 구현할때 입력 데이터의 값이 x1, x2, x3, x4, x5, y(결과)가 있을 때  x1의 중요도를 다른 입력데이터에 비해 높게 주고 싶은데 이런것도 가능한가요? 예를 들어서 다음와 같은 train 데이터의 x1에 1값이 한번도 나오지 않고 학습을 시켰는데 test 데이터에서 x1 이 1이 되는 경우가 나오면 y가 1이 될 확률을 높게 주고싶습니다.그런식으로 중요도를 다르게 줘서 Logistic Classification를 구현하는 방법이 있을까요?? 의견 혹은 조언을 댓글로 알려주시면 감사드리겠습니다.train.txtx1, x2, x3, x4, x5    y0   0   0   0   0     0 0   1   0   1   0     10   0   1   0   0     10   1   0   0   0     00   0   0   1   1     10   0   1   1   0     0	0	각 요소에 가중치를 부여하면 되지않을까요? ^^;
14	안녕하세요.제가 다루는 데이터로 1, 0 분류를 하는데 데이터의 두 클래스는 완벽한 imbalanced 데이터입니다. 비율은 1:2000 정도입니다.보통 많은 쪽을 샘플링해서 비율을 1:1로 맞추던데 전체 데이터를 학습시켰을 때와 1:1로 균형을 맞춰서 학습했을 때 테스트 데이터에 대한 Precision, Recall이 전자가 훨씬 좋더라고요.그럼 1:N으로 계속 샘플링 개수를 늘려보면서 P/R을 확인해야되는지요?보통 극단적인 imbalanced 데이터를 어떻게 다루세요?	4	이미 알고 계신 것 처럼 over 또는 under sampling을 통해서 balance를 조정 할 수도 있구요, smote 와 같은 synthetic한 데이터를 생성하는 방법도 있습니다. 그리고 learning과정에서 cost-sensitive learning기법을 적용할 수도 있어요. 모든 방법들이 장단점이 있지만 경험상 synthetic데이터를 만들거나 cost sensitive learning을 했을때 결과가 잘 나왔어요 도움이 되었으면 좋겠네요	9	http://www.svds.com/learning-imbalanced-classes/	1	저도 SMOTE, cost-sensitive learning 해서 괜찮은결과를 봤구요, imbalanced data의 binary classification 의 경우 변별력 측정도구를 precision recall 보단 AUROC 로 하시면 좋습니다.
35	#PythonCheat sheets(파이썬 프로그램 할때 참조 하면 좋아요 ^^)https://perso.limsi.fr/pointal/_media/python:cours:mementopython3-english.pdfhttp://www.cheat-sheets.org/saved-copy/PQRC-2.4-A4-latest.pdfhttp://overapi.com/python/
11	다양한 레퍼 클래스들이 많이 나오네요.Caffe모델 기반의 Kaffe랩퍼자료 공유합니다.
36	WildML의 최신 포스트인 "RNNs in Tensorflow, A Practical Guide and Undocumented Features"를 번역해서 정리했습니다. RNN 쓰시는 분들에게 도움이 되었으면 합니다. 포스트에 언급한 내용을 바탕으로 하나의 전체 예제를 따로 만들고 있습니다. 완성이 되면 다시 페북에 올리도록 하겠습니다. 	1	감사합니다~!
4	안녕하세요~ 현재 여러 개의 tensorflow task(텐서플로우 코드를 실행하는 Task) 들이 있을 때, 이것을 효율적으로 여러 대의 컴퓨터들로 분산하는 작업을 하는 중입니다.이 작업을 하려면 컴퓨터 내에서 tensorflow를 동작 시킬 수 있는 gpu의 개수와 그 정보들을 알아내야 합니다.nvidia에서 제공하는 NVML을 사용하면 gpu정보들을 알 수 있지만 여기서 특정 gpu가 cuda가 가능한 지 여부를 알 수는 없는 것 같습니다.그래서 간단한 cuda를 사용하는 프로그램을 만들어 cuda device 개수와 그 정보들을 가져오는 방법도 생각 중입니다.제가 궁금한 것은 혹시 tensorflow 자체에서 tensorflow를 돌릴 수 있는 gpu 개수와 그 gpu에 대한 정보들(메모리사용량등)을 알 수 있는 방법이 있는 가 입니다..ㅠㅜ혹시 없다면 현재 제가 하려는 작업을 어떻게 해야 효율적으로 수행 할 수 있을 지 자문을 구하고 싶습니다..고수분들의 답변 기다리겠습니다.. 감사합니다.	0	gpu 프로그래밍은 잘 모르지만 디바이스 정보를 얻는 방법은 있습니다. 다만 문서화가 안되어 있어 코드를 보시고 응용하셔야 할 것 같아요.https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/test/gpu_info_lib.py
3	안녕하세요텐서플로우로 한달후 중학생 강의를 준비중인텐서플로우 초짜입니다좋은 정보 얻고자 이렇게 글 남깁니다cnn닮은 연예인인식이나 사람인가 동물인가 판별할수 있게만들고 싶은데예제소스나 정보있으면 공유 부탁드립니다	1	기본 기본적인 시파텐예제만 해도 동물과 사물 정도는 판별 가능합니다 :)
8	caffe가 tensorflow보다 많이 빠른가요? 전 tensorflow가 편해서 계속 쓰고 있는데 아는 선배가 자꾸 caffe를 쓰라네요. caffe는 설치하기도 복잡하고 손이 잘 안가네요. gpu에서 돌릴때와 cpu에서 돌릴때 모두 궁금합니다.	5	아주 최근에 나온 벤치마킹 페이퍼 입니다. 상황에 따라 장단점이 있지만 카페가 텐서플로우보다 성능이 뒤진다고 말하긴 힘들 것 같습니다. 정리를 할 시간을 내지 못해 링크만 공유해 드려요.http://arxiv.org/pdf/1608.07249v2.pdf	4	이전에 한분이 분석하기에는 데이터가 커질수록 Tensoflow가 Caffe의 속도와 비슷해진다고 하셨던거 같습니다.	3	텐서플로우로 작성하시면 TPU (https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-learning-tasks-with-custom-chip.html?m=1) 가 구글 클라우드 플랫폼에 서비스로 올라오게 되었을 때 cpu/gpu 보다 빠른 속도로 실행하실 수 있습니다. 개인적으로는 TPU가 얼마나 빠를지 어떤 한계가 있을지 관심있게 지켜보고있습니다.
32	Tensorflow GTX1080을 GPU 쓰기 위해서 Ubuntu 16.04에서 cuda 8.0-patch1 cudnn 5.1.5 환경으로 소스 설치 중에 별거 아닌데 엄청 고생한게 있어서 공유합니다.전에는 안그랬던걸로 기억하는데 최신 버전으로 새로 설치하려고 날리고 진행했는데 CPU빌드에선 괜찮은데 GPU빌드에서만 에러가 우수수 나와서 하루쯤 고생하고 원인을 찾고나니 허무해서 말이죠.tensorflow ./configure 진행 시 cuda 위치를 심볼릭 링크인 /usr/local/cuda 로 줬을 경우 빌드 단계에서 build rule 을 찾을 수 없다면서 에러가 발생하고 멈추는 증상이었습니다.별짓 다해봤으나 안되다가 발견한 해결책은 ./configure 진행시 cuda 위치를  /usr/local/cuda-8.0 으로 주면 빌드가 되네요 ㅠㅜ아무래도 빌드 스크립트 내부 어딘가에서 configure로 설정한 cuda 위치과 관계없이 "cuda-" + [cuda version] 으로 만든  폴더 이름을 하드코딩 해 들어가는 형태로 사용하는 모양입니다.	0	http://qiita.com/Sert/items/48fafa5b28be5b739784http://blog.naver.com/kjpark79/220781100554전 위의 두 레퍼런스 보면서 했습니다. 잔손질이 많이 가긴 하는데... 전에 어디 보니 tensorflow 최신버전에서 속도가 느려지는 버그가 있다는 얘기가 있던데.. 확인하신분 있으신가요?	4	저 역시 동일 환경에서 엊그제 설치했는데 그런 문제가 없었는데요. 저는 아래 링크를 참조했습니다.https://marcnu.github.io/2016-08-17/Tensorflow-v0.10-installed-from-scratch-Ubuntu-16.04-CUDA8.0RC-cuDNN5.1-1080GTX/	0	감사합니다. gtx1070인 데 activate 방식으로 쓰다가 이걸로 쓰니 정말 좋네요^^	1	도커 쓰시면 편하게 세팅하실 수 있습니다. 링크 따라하시면 될듯합니다. https://github.com/est-ai/tensorflow-on-pascal
0	안녕하세요~~연구실 차원에서 텐서플로 작업을 공유하기 위해서 TensorFlow Serving을 사용하려고, 일단 개인 노트북으로 Serving 튜토리얼을 따라하는데, bazel로 빌드하는것부터 에러가 무수히 쏟아집니다... 혹시 Serving configuration 과정이 잘 나와있는 참고자료가 있을까요?	0	그러고 보니 서빙은 언뜻 기억나는 자료가 없네요. ㅠ.ㅠ
7	안녕하세요 항상 눈팅만 하다가는 개발자1인입니다 ㅋ다름이 아니고 tensorflow쪽 예제들을 돌려보면서 조금씩 공부를 하고있는데요..wide&deep 쪽 튜터리얼이 제가 만들어 보고싶은 예측 프로그램에 기초가 될듯해서 돌려보는데 자꾸 에러가 뜨네요..https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py혹시 이 예제 성공하신분 있으신가요?TypeError: argument of type 'float' is not iterable에러가 나는 부분은 lambda식을 변경해서 해결하였는데,tf.SparseTensor 쪽에서 나는 TypeError: Expected binary or unicode string, got nan에러는 어떻게 해야할지를 모르겠네요도와주세요~~	0	어쩌다 보니 자문 자답이 되어버리네요..url로 데이터를 받아서 파일을 만드는 과정에서 제일 아래쪽에 공백라인이 한줄 있었네요.	0	해당 라인을 지우고 예제를 돌리니 잘 돌아가는군요 ^^;;	0	답을 찾으셨다니 다행이네요. TF 0.9 에서 돌려보니 deprecated 경고가 뜨지만 잘 되었습니다.accuracy: 0.833118eval_auc: 0.853076loss: 0.414517
0	결론적으로 hyper parameter를 설정하기 위한 정형화된 방식이 존재하지 않는 것인가요? 이를테면 " y=wx+b 와 같은 간단한 linear regression을 학습 시키는 과정에서 튜닝을 할 땐 특정 방식을 취해야만 하며 이를 위한 코드는 정해져 있다." 와 같은 상황이 아니라 지속적으로 관찰하면서 적합한값으로 hyper parameter 들을(위의 예시에선 learning rate와 같은) 수정해가는 것인가요?	0	네 맞습니다. 이런 저런 경우에 대한 권고 사항들이 있습니다만 다양한 경험이 도움이 될 듯합니다.
35	[스팸/음란물로 부터 우리 그룹을 지키자 프로젝트 #1]다른 그룹들 보니 스펨이 엄청있네요. 일일이 다 지울수도 없고. 우리가 TensorFlow DeepLearning  그룹인 만큼 이런것은 우리 손으로.그래서 일단 1) FB API를 이용해 Feed를 가져 옵니다. 2) Google Vision API를 이용 이것이 음란물인지 확인합니다.데모: http://r.kproperty.xyz/getFeed.php (작은 서버에서 Google Vision API를 호출하기때문에 매우 느립니다. 아래 이미지를 보셔도 됩니다.)제가 올린 그림은 다음과 같이 나옵니다.{safeSearchAnnotation: {adult: "UNLIKELY",spoof: "UNLIKELY",medical: "UNLIKELY",violence: "UNLIKELY"}할일1: adult/spoof등에서 고득점 할경우 자동 삭제및 회원 강퇴.할일2: 한글 문자열을 읽어 스펨인지 아닌지 분류할일3: 댓글도 확인 혹시 할일 2를 TF로 구현해주실분 계신가요?	0	2번은 형태소 분석기로 단어를 추출해서 단어의 빈도로 딥러닝을 시키면 될 것 같아요..!	1	올린 글 자체에 대한 검사과 함께 링크된 사이트의 콘텐츠를 확인하는 방법까지 병행하면 더 훌륭한 결과가 나오지 않을까요?
76	좋은 책 번역해주셔서 감사합니다 Park Ricky님곧 싸인받을 기회가 있으면 좋겠네요^^	1	사인이라뇨. ㅜㅜ. 부디 맘에 드시길 바랄께요. 감사합니다.	0	서점에도 있나요? 내일 서점에서 볼 수 있음 좋겠어요 ㅋㅋ	0	저도 오늘 받아봤습니다 ㅎㅎㅎ ^^	0	사랑입닏ㄱᆞ	0	저도 오늘 받았습니다! 감사합니다.	0	좋은책이 있었네[요..오늘 구하러 갑니다^^	0	바로 구매했습니다.. 좋은정보 감사합니다	0	구매신청해놓고 잊고있었는데 오늘 왔네요 ㅎㅎ	0	이거 어떤가요?
1	안녕하세요...페친분들께 문의드립니다.MAC OS에서 caffe를 설치중인데, 이런 에러 메시지가 뜹니다.$ brew install --build-from-source --with-python boostWarning: boost-1.61.0_1 already installed, it's just not linkedboost뿐만 아니라 다른 것도 그런데 무시하고 넘어가도 되는 건지요?
13	Ubuntu+단일 GPU+TensorFlow 환경에서 복수 개의 코드를 동시에 한 GPU에서 돌려보신 분 있나요?예를 들어, 혼자서 여러 코드를 동시에 돌리거나 리눅스 서버에 여러명이 접속해서 한 GPU를 같이 사용하길 원하는 경우에서요.	3	그렇게하면 처음 프로세스가 거의 모든 GPU메모리를 잡아버리더군요. 꾸준히 kill 해줘야 합니다.  전 jupyterhub 환경으로 했었습니다.	9	Sungchul Choi 댓글보고 좀더 찾아보니 아래 웹페이지에 관련 내용이 있었습니다.https://indico.io/blog/the-good-bad-ugly-of-tensorflow/결론은 TF를 그냥 실행시키면 GPU 메모리를 전부 한 코드에 할당하기때문에 여러 코드를 동시에 돌릴 수 없게 됩니다. 이를 방지하기위해, tf.GPUOptions로 전체 메모리 중 얼마를 사용할 것인지를 지정을 해줘야한다네요.	0	좋은 공부가 됐습니다!
12	가입인사 드립니다,,특허정보를 다루는 일을 합니다 파이썬을 배우고 TensorFlow를 알게되었습니다. 저도 이곳에 도움이 되는 일원이었으면 좋겠는데,,시간이 좀 걸릴것 같아요..^^	0	환영합니다.
24	딥러닝실습 강좌 정보를 올려드립니다. 참조해서 좋은 결과 있기를 희망합니다	2	하루에 40만원이군요.... ㅠㅠ
19	머신러닝 스타트업 Artifacia에서 쓴 가이드라인 입니다. 시간날때 한번 읽어 보심이. 
2	안녕하세요`~ TensorFlow contrib.learn을 활용하여 DNN classification  모델을 구축했습니다. 기존에는 relu를 이용해서 binary classification으로 구현했는데, 1,0 중에서 1이 나올 확률을 결과값으로 출력하려고 합니다. CIFAR10 이던가? softmax를 사용하면 확률로 출력이 가능하다고 하는데 자세히 알려주실 수 있으신분 계신가요?	0	짧은 문장으로는 힘들지 않을까 합니다. 김성훈 교수님의 딥러닝 강좌에 소프트맥스가 있지 않을까요. 정확한 좌표는 다른분께 패스- ^^	1	링크 공유 드립니다. 아래의 링크는 김성훈 교수님의 딥러닝 강좌이며 Softmax regression 편을 보시면 될 것 같습니다.^^https://hunkim.github.io/ml/
3	안녕하세요~그동안 바뻐서 공부를 못하고 있다가 다시 정신차리고배우려고 하는데 numpy 사용시 사진과 같은 에러가 떠서 더 이상진행을 못하고 있네요조언 부탁드리겠습니다	0	트레이닝 데이터셋에 텍스트 문자가 섞여있는 것 같네요. 문자를 float으로 변환할 수 없다는 에러입니다	0	03train.txt 파일 안에는 숫자 정보만 있는게 맞나요?에러만 봐서는 string 문자열이 포함되어 있는거 같습니다.	0	파일안에 뭐가있는지 모르겠지만 loadtxt말고 genfeomtxt를 써보세요	0	03train.txt에 숫자 아닌 문자가 있다는걸 보니, 혹시 주석이 처리 안되어 있다면, '#' 같은걸 넣어주어서 처리하면 되지 않을까요?03.Train.txt 파일 내용을 공유하시면 금방 해결될 것 같네요.	0	TXT파일 입니다..loadtxt대신에 genfeomtxt로 했는데도 안되네요..	0	맨 윗줄 지웠는데도 안되네요..ㅠ
3	Cross validation의 개념 중에서 의문나는 점이 있습니다.유사한 패턴을 보유한 10개의 data set을 가지고, Data 1~9를 Training 시킨 Model1에 Data10으로 '검증'한 후  '보정'을 한다는 표현이 사용되는 데요 제가 이해한 '검증' 이란 개념은, Data 1~9에 잘 맞춰진 Weight1과 bias1 값에 Data10의 feature들을 input하여 출력된 output이 실제 Data10의 y값과 동일한지 파악하는 것입니다.다음으로 '보정'의 의미가 쉽게 이해되질 않는데요 보통 초기 W, b 값을 랜덤하게 선별하는 데, 위에서 말한 Model1에서 결정된 W1, b1값을 초기값으로 두고 Data10만을 input하여 새로운 Model2를 만든다는 개념인건가요? 이 방식이 맞다면 Model2를 만드는 과정에서 iteration 횟수를 적게하는 방식으로 overfitting을 방지하는 것인지..이 2가지 사항이 궁금합니다..	1	크로스밸리데이션에서 검증이라면 하이퍼파라메타를 의미합니다. 모델의 w, b 값은 보통 모델 파라메타라고 부르기도 합니다. 하이퍼파라메타의 예로는 학습속도, 정규화, 모델의 복잡도, 신경망이라면 히든 레이어의 수, 레이어 당 뉴런수 등등이 될 것 같습니다. 크로스밸리데이션으로 하이퍼파라메타를 튜닝하는 이유는 테스트 셋은 최종 모델의 평가에만 활용되게 하려고 합니다.	0	Training Set 으로 학습을 하고, Cross Validation Set 으로 최적의 hyperparameter 를 찾고, Test Set 으로 해당 모델의 최종 성능을 평가합니다.	0	정리해 보자면 제가 생각하는 검증과 보정이라는 개념을 합한 것이 hyperparameter를 찾는 과정을 의미하는 것이죠?  그럼 이제 hyper parameter를 구현하는 코드를 찾아봐야 겠네요. 두 분 조언 감사합니다.
21	많이 보강해서 다시 공유합니다
2	Mnist 예제를 작성해 보았습니다. 저는 여기서 추가로 제가 쓴 숫자의 이미지파일(png등..)을 테스트 해보고 싶습니다.그런데 제가 텐서플로우 초보에다 파이썬 까지 잘몰라서 어떻게 시작해야할지 감이 안잡히네요.. 이미지 파일을 어떻게 텐서플로우 모델에 인식시킬수 있는지 고수님들의 조언 부탁드립니다!	2	http://blog.naver.com/kjpark79/220783765651본 그룹의 박광재님께서 작성해주신 게시물입니다.(허락없는 태그 죄송합니다)
0	날씨도 더운데 재미있는거 해보는걸 추천해드립니다.신문에 나온 기사를 배경으로 2개의 사진이 동일인물일 확률을 예측해 보면 어떨까요?	0	tensorflow 관련 training example에 image data도 있지만 이런 데이터를 인터넷에서 수집, 동일사이즈로 변환, csv로 전환하는 full example을 직접 만들어 보는것도 좋을듯 합니다. 당연히 labeling되있어야 되니 fb친구들 이미지를 수집하는것 등 다양한 방법을 고려해야 될것 같습니다.
17	[스터디원 모집] Deep Graphical Models : 파트 1* (새로 추가/기초) 강화학습 기초, 파이선 머신러닝 기초 * (새로 추가/응용) 딥마인드 논문 읽기* (기존) 벤지오 딥러닝북, 머피 베이지안ML* 매주 수요일, 저녁 7시 - 10시 반. 강남. 무료. 8/31 시작.* 이벤트 링크 - https://www.facebook.com/events/318885331793403/* 이 스터디는 정통심리학 그룹 싸이그래머에서 진행합니다. 네이버D2의 지원을 받고 있습니다.안녕하세요, QGM에서 퀀텀컴퓨팅 파트가 종료되고 새 이름으로 바뀌어 새롭게 시작하는 스터디 DGM입니다. 절대, 참여자가 적어서 새로운 사람들을 더 많이 모아보려는 금선탈각의 수법이 맞습니다. 하지만 새로 추가된 영역들의 재미는 절대 진실입니다.-(기초) 파이썬으로 머신러닝 하기 기초, 강화학습 기초가 새로 추가되었습니다. 함께 하시죠~- (중급)벤지오 교수의 딥러닝 북 - 파트 3 : unsupervised models와 머피의 베이지안 확률모델기반 머신러닝은 그대로 이어서 합니다.- (논문) 딥마인드의 논문들을 출간 최신순으로 살펴봅니다. 누구나 함께 하실 수 있는 스터디입니다. 기초부터 중급까지 골고루 섞여 있습니다. 참여를 원하시는 분들은 링크 이벤트에 참석을 누르시거나, 댓글을 달아주시거나, 바로 스터디 장소로 찾아오시면 됩니다. https://www.facebook.com/events/318885331793403/	0	(벤지오딥러닝) http://www.deeplearningbook.org/	0	(머피ML) https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020	0	(딥마인드) https://deepmind.com/publications	0	(강화학습 기초) https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262193981	1	(파이썬 머신러닝) https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130	0	자료 & 커리큘럼 (정리중) - http://psygrammer.github.io/qgm/	0	현재 김성훈 교수님 강의 다음으로 중단 하였던 이Andrew Ng 교수님 강의를 다시 들어볼 생각을 하고 있는데 .. 아직도 ML공부 방법에 대해 확신이 안들고 있는데요. 혹시 더 좋은  학습 순서라고 생각하시는 것이 있으신지요?	1	Andrew Ng 의 강좌 + (파이썬 머신러닝) https://www.amazon.com/Python-Machine.../dp/1783555130 이 궁합이 잘 맞는 것 같습니다. 우선 이렇게 공부하신뒤에 결정해보시는건 어떨까요?
1	Input 데이터 NormalizationBinary Classification 을 응용하여 키(Height) 값으로 Winner Loser 로 분류해주는 걸 만들어보았습니다.Training Data 20 개 / Test Data 20 개 준비했구요, 데이터 구조는 Input 에 키(1XX 센티미터) 를 입력합니다. Y 는 0, 1 입니다. 입력 값이 크기 때문에 학습에 실패하고 nan 을 출력하더군요. 그래서 Input 데이터를 정규화 했고(-1.0 ~ 1.0), 같은 기준으로 Test 데이터도 정규화 해주니 원했던 결과가 나오더군요.사용한 함수는 H(X) = 1 / (1 + e^(-WX)) 이고, W 는 -1.0 ~ 1.0 의 uniform 분포의 랜덤값을 사용했습니다.정규화하지 않을 경우,nan 이 나오는데, e^ 부분이 매우 크거나 매우 작은 값이 되는데, 수학적으로 문제는 없지만 아마도 TensorFlow 내부 변수 처리 과정에서 exponential 을 잃어버릴 수 있거나 하는 등의 정밀도 문제로 nan 이 나오지 않을까 추측을 하고 있습니다. 맞는 결론일까요?	0	제 생각에 정밀도 문제로 결론지으면 위험할 것 같습니다. 단순히 말씀하신 input data normalization 문제입니다. 간단하게 Wx대신에 Wx+b로 bias 파라미터 b를 추가하고 하시면 위의 문제는 사라질 것으로 보입니다.
5	도커를 아직 초급자 수준입니다만, 어떻게 windows 에서 도커로 환경구성하여 tensorflow 환경구축까진 무리없이 진행합니다만 보통 docker에 tensorflow 올려놓으시면 windows에서 어떻게 개발하시는가요? pycharm으로 리모트 빌드 할려고하면 실질적으로 결제하고 이용해야되고.. 비주얼스튜디오는 플러그인 차찾아보아도 잘 모르겠구요. 주피터 밖에 방법이 없는건지, 혹시 windows - docekr - tensorflow로 개발하시는분들은 어떤툴로 작업하시는지 알 수 있을까요? 제가 아직 많이  몰라서 질문드립니다.	1	windows에 도커툴로 설치하는 것이, 어차피 버추어박스 설치해서 도커이미지를 가상이미지로 올려서 하는 것이니 그냥 우분투 16.04 ISO 이미지를 다운로드 받아서 새로 설치하고 거기서 텐서플로우 document 그대로 진행하는것도 나쁘지 않아 보입니다.이렇개 하면 가상머신으로 설치한 우분투에 직접 pycharm 설치해서 사용가능합니다.(pip3 버전으로 설치하여 진행)아래에 영상 그대로 따라가셔도 됩니다.https://youtu.be/CvspEt8kSIgIDE는 영상처럼 서브라임 설치해서 써도 되고요.pycharm은 커뮤니티 버전으로 우분투 안에 설치 됩니다.그럼 바로 컴파일 결과 확인 가능합니다.pycharm으로 원격으로 해보려 했더니 정식 버전 써야하는듯 보이네요.	0	저도 초반에 환경 세팅 고민 많이 했는데.. 가장 좋은 건 윈도 + 우분투 멀티부팅 환경 만드는 것 같습니다.(GPU 땜에) 저는 윈도우10 개발자 버전 + 윈도우 Bash shell + PyCharm 으로 갖고 놀고 있습니다.	0	docker 이미지 올릴실때 jupyterhub을 써서 올리셔서 jupyterhub으로 작업하시면 됩니다.	0	파이참은 교육용은 무료더군요 학생이나 학교 교직원은 사용할 수 있었어요 그런데 도커랑 파이참을 연결하는 리모트빌드 방법을 모르겠어서 포기했습니다	2	저같은 경우는 Windows 폴더쪽에 작업 코드를 놓고 sublime text 같은 걸로 윈도우로 작업하고, docker 사용할 때는 그 폴더를 마운트해서 사용하는 방법을 사용합니다. 일단 shared folder 느낌으로 작동하는지라 윈도우에서 수정해도 내용이 즉각즉각 반영되서 디버깅 하기도 그렇게 불편하지는 않구요.
31	파스칼 아키텍처 기반의 타이탄x 벤치마크 자료입니다. 이전세대 타이탄x에 비해서 약 50% 성능향상이 있네요. Nvidia도 외계인 영입했나봅니다.	1	딥러닝 벤치마크 부분은 여기 보시면 됩니다. http://quasarzone.co.kr/bbs/board.php?bo_table=qc_qsz&wr_id=18169
1	np.set_printoptions(formatter={'all':lambda x: 'int: '+str(-x)}) 이것은 무엇을의미하는 것일까요???	0	X값을 음수로 표시하라는 뜻인데
0	np.set_printoptions(precision=4)print np.array([1.123456789])이렇게 하면 "SyntaxError: invalid syntax"로 나오는데요 왜 그런걸까요	0	numpy example을 그대로 사용하신 것 같은데 앞뒤 코드를 올려주시겠어요?
59	2016 딥러닝 서머스쿨 영상이 공개되었습니다
1	안녕하세요 tensorflow를 접한지 2주차에 접어든 학생입니다.최근 tensorboard의 실행법을 숙지하게 되서 사용중인데요, sess.run(init) 관련 error가 발생하는데 해결방안을 모르겠습니다.Placeholder 지정 없이 사용하면 문제가 없다가 지정 후에 이러한 에러가 나타나고 있는 상태입니다.InvalidArgumentError: Node 'Input X': Node name contains invalid characters  [[Node: random_uniform_4/max = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1>]()]]Caused by op u'random_uniform_4/max'사용 중인 data와 코드의 형태는 아래와 같습니다. # X1 X2 Y0 0 00 1 11 0 11 1 0import numpy as npimport tensorflow as tfxy = np.loadtxt('04train.txt', unpack=True)x_data = np.transpose( xy[0:-1] )y_data = np.reshape( xy[-1], (4,1) )print x_dataprint y_dataX = tf.placeholder(tf.float32, [4, 2], name = "Input X")Y = tf.placeholder(tf.float32, [4, 1], name = "Input Y")W1 = tf.Variable(tf.random_uniform( [2,2], -1.0, 1.0), name = "Weight1")W2 = tf.Variable(tf.random_uniform( [2,1], -1.0, 1.0), name = "Weight2")b1 = tf.Variable(tf.zeros([2]), name="Bias1")b2 = tf.Variable(tf.zeros([1]), name="Bias2")with tf.name_scope("ScopeLayer1") as scope:    L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)    with tf.name_scope("ScopeLayer2") as scope:    hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)with tf.name_scope("Cost") as scope:    cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )    cost_sum = tf.scalar_summary("cost_sum", cost)    w1_hist = tf.histogram_summary("w1_hist", W1)w2_hist = tf.histogram_summary("w2_hist", W2)b1_hist = tf.histogram_summary("b1_hist", b1)b2_hist = tf.histogram_summary("b2_hist", b2)y_hist = tf.histogram_summary("y_hist", Y)with tf.name_scope("train") as scope:    a = tf.Variable(0.1)    optimizer = tf.train.GradientDescentOptimizer(a)    train = optimizer.minimize(cost)init = tf.initialize_all_variables()with tf.Session() as sess:    merged = tf.merge_all_summaries()    writer = tf.train.SummaryWriter("./logs/test14", sess.graph_def)    sess.run(init)        for step in range(2001):        sess.run(train, feed_dict={X:x_data, Y:y_data})                if step % 1000 == 0:            summary = sess.run(merged, feed_dict={X:x_data, Y: y_data})            writer.add_summary(summary, step)            print(                step,                 sess.run(cost, feed_dict={X:x_data, Y:y_data}),                 sess.run(W1),                sess.run(W2)            )	0	Input X 에서 띄어쓰기가 문제인 것 같습니다. _ 등으로 바꾸면 저 에러는 사라집니다.
39	지난 글에서 얘기한 "손으로 아무렇게나 그린 함수"를 "초간단 ANN으로 근사 시키기"를 구현 하였기에 실행 영상과 코드를 공유 합니다.https://youtu.be/SahmdQs6X74?list=PLefQdA1SdkhtRUuN_D3PdxaR2XTGQw8Ph============영상============초록색 선: 손으로 그린 그래프를 200개 포인트로 변환하고 그것들을 이은 선파란색 점: 학습용 정답 포인트 40개빨간색 점: 학습 결과 만들어진 근사 함수의 출력 포인트 100개============목표============Universal Approximation Theorem의 내용을 직접 실험해 보면서 *몸으로 느껴보기*https://en.wikipedia.org/wiki/Universal_approximation_theorem============지난 글============https://www.facebook.com/groups/TensorFlowKR/permalink/332258640448534/============ANN============지난 글에서와 마찬가지 초간단 (Deep도 아닌) ANN이고,히든 레이어 1개, 히든 노드 100개임- 입력 레이어: 노드 1개 -- x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음- 히든 레이어: 1개, 노드: 100개-- a = sigmoid(w1*x + b1)- 출력 레이어: 노드 1개-- o = w2*a + b2- 코스트 함수: Squared Error============코드============https://github.com/dgtgrade/HumanLearning/blob/master/1003.py머신러닝 프레임워크 또는 라이브러리를 사용하지 않았습니다.코드를 보면 다음과 같은 부분을 공부하는데 도움이 되리라 기대합니다.- Artificial Neural Network의 기초- Gradient Descent의 기초- Back Propagation의 기초- python에서 매트릭스 다루는 법: numpy- python에서 그래프 그리는 법: matplotlib - python에서 이미지 읽는 법: skimage- Learning Rate 변경에 따른 학습 능력의 변화- 히든 노드수 변경에 따른 학습 능력의 변화 ============실행환경============python3.5 및 numpy 등의 라이브러리가 필요합니다.처음부터 새로 설치 하려면 다음 영상을 참고 하세요.https://www.youtube.com/watch?v=pMkwjXFZdH4============실행방법============python 1003.py [이미지파일경로]마지막의 이미지 파일 경로에 data/1003_plot1.png 등을 넣어주면 됩니다.다음 git 페이지에서 제가 만든 예제 이미지들을 다운로드 할 수 있습니다.https://github.com/dgtgrade/HumanLearning/tree/master/data	0	재미있는 발상을 구현해 보여주셔서 감사드립니다. 한가지를 해보시면 어떨까 제안드립니다. 손으로 그린 선의 마지막 일정 영역을 분리해서 test라고 한다음에 나머지를 train으로 해서 학습을 한후에 test를 개발된 모델로 검증해 보시면 좋을듯 합니다.
40	GTX 1060에 Docker로 TensorFlow 설치하면서 생겼던 이슈와 설치방법 공유드립니다.Tensorflow에서 아직 Cuda8.0에 대해 정식으로 dockerfile을 지원안해서 사용 못하셨던분들에게 도움이 될 것 같습니다.틀린 부분 지적이나 질문 언제든 환영합니다!	0	Ubuntu 16.04 GTX1080 환경에서 정상적으로 설치되네요. 좋은 정보 감사합니다!	0	정성민 (SungMin Jung) Ubuntu 16.04 + GTX 1080 환경에서는 docker를 이용해서 설치하실 필요는 없습니다. 제가 설치해본 링크 첨부해드립니다.https://marcnu.github.io/2016-08-17/Tensorflow-v0.10-installed-from-scratch-Ubuntu-16.04-CUDA8.0RC-cuDNN5.1-1080GTX/아마도, CUDA 8.0과 관련된 이슈는 해결될 것 같습니다.
49	딥러닝의 최적화 해에 대한 재미있는 논문이 NIPS 2016에 있네요. MIT버전 논문의 초록을 발번역해서 올려 봅니다. Deep Learning without Poor Local Minima. -- Kenji Kawaguchihttps://dspace.mit.edu/bitstream/handle/1721.1/102665/MIT-CSAIL-TR-2016-005.pdf?sequence=1http://arxiv.org/abs/1605.07110본 논문에서  1989년에 발표한 추측을 증명했고, 또한 COLT 2015에서 발표한 open problem의 일부를 설명한다. 깊은 비선형 신경망의 예상 손실 함수에서 최근 연구들로부터 채용된 독립 가정을 전제하에 다음의 진술(statement,?)들을 증명하였다. 1) 함수는 non-convex(비 볼록 함수)와 non-concave(비 오목함수), 2) 모든 지역 최소는 전역 최소이다, 3) 전역 최소가 아닌 모든 임계점들은 안장점이다, 4) 안장점의 속성은 얕은 신경망(3층 이하)와 심층 심경망(3층 이상)은 서로 다르다. 게다가, 비현실적인 가정없이 동일한 4개의 진술은 모든 depth, 모든 넓이의 심층 선형 신경망에서도 유지된다. 결론적으로 이론적으로 심층 모델이 직접적으로 얼마나 훈련 시키기가 어려운지의 질문에 답을 할 수 있는 예시를 설명한다. 고전적인 machine learning보다 더 어렵(non-convexity 이유)지만 매우 어렵진 않다(안정점의 속성과 빈약한(poor) 지역 최적화의 비 존재성 이유). 딥러닝의 기초 이론을 진보시켰지만, 아직 이론과 실제의 갭이 존재한다.	0	ㅋㅋㅋ 날잡아서 강의한번 ㅋㅋㅋ call?
93	지난 글에서 얘기한 (단순한 함수들의 조합으로) 근사 함수 만들어 내기의 그래픽 버전을 만들어 보았기에 실험 실행 영상과 함께 코드를 공유 합니다.ANN의 기본 원리, DNN의 가능성, GD 및 BP의 원리, 그리고 무엇보다 Universal Approximation Theorem을 이해하는데 도움이 되길 바랍니다. 실제로 코드에서 학습 속도 및 히든 노드 개수 등을 조정해 가면서 돌려 보면 근사 함수를 잘 만들었다 못 만들었다 하는데, ..., 저 개인적으로는 많은 깨달음을 얻었습니다.===========지난글===========https://www.facebook.com/groups/TensorFlowKR/permalink/331870193820712/===========Universal Approximation Theorem===========https://en.wikipedia.org/wiki/Universal_approximation_theoremUAT 관련 실험의 목적 부분 업데이트:아래 댓글을 통해 한참 논의 한 이후 이 부분 업데이트 합니다. 논의 덕분에 저 스스로도 이 실험의 목적을 좀 더 명확히 할수 있었습니다. 질문 하시고 또 같이 논의해 주신 분들께 감사 드립니다.수식 t(x)는 제가 아무 곡선이나 임의로 그려 보기 위해서 사용한 도구일 뿐인 것으로 이해해야 합니다. 즉, 여기서 수식 t(x)의 식이 중요한 것은 아닙니다.그러니까 수식 t(x)의 내용을 저(문제 출제자)도 모르는 상태에서 *아무렇게나* (물론 함수로 표현은 가능하게) 제가 곡선들을 그려넣으면 단순한 ANN으로도 언제나 그 곡선이 표현 가능하다. 즉 그 곡선에 거의 딱 맞는 함수 t(x)를 (사람은 모르고, 아마 만들 낼수도 없어도) 기계가 (단순 함수 f1, f2 등의 조합으로) 만들수 낼수 있다는 것을 실험해 본 것이라고 할수 있습니다.또한 그렇기 때문에 학습한 범위 밖의 t(x)를 추정 할수 있느냐 없느냐는 여기서는 중요하지 않습니다. 왜냐하면 수식 t(x)는 범위 안의 값을 그리기 위해서 사용한 도구였으므로 사실 t(x)가 아니라 (범위 안의 출력만 일치 한다면) 수식 t2(x) 또는 t3(x)였어도 상관이 없습니다. ANN은 머신러닝을 통해서 수식 t(x)가 아니라 수식 t10(x)를 만들어 낸 것이 되겠습니다.자율운전의 이상적인 정답 함수 세트 T(x)가 존재 한다면 그 함수들은 사람이 수식으로 쓸수는 없으나(!) (운전 데이터를 통해서) 곡선 그림 t(x)를 그려주면 기계가 머신러닝으로 근사함수 h(x)를 만들어 낼수도 있지 않을까? 하는 것을 보여주는 실험으로 이해하면 될 것 같습니다.바둑의 이상적인 정답 함수 세트 T(x) 또한 사람은 그 함수들의 수식을 정리할 능력이 없습니다만 기초 학습을 위한 그림 t(x)는 (기보 데이터를 통해서) 그려줄수는 있고 알파고는 우선 그 사람이 그려준 그림 t(x)에 근사하는 h(x)를 머신러닝을 통해서 만들어 보는 것으로 시작했다고 이해 됩니다. 그 근사가 어느 정도 완료된 이후엔 자기 h1(x) vs 자기 h2(x) 싸움을 통한 학습에 들어가게 되니까 t(x)는 불필요 할테고요.제가 t(x) 없이 손으로 *아무렇게나* 곡선을 그리고 ANN이 그 곡선에 근사하는 과정을 영상으로 찍었다면 이 목적이 명확하게 전달 되었을 것 같네요. 다음에는 그렇게 해 보겠습니다.학습 데이터범위 밖은 어떻게 할것이냐 이슈에 대해서는 DongHyun Kwak님께서 VC Analysis에서 그 문제를 다루고 있다고 말씀 주셨습니다. 이 부분 추가로 공부해 볼 예정입니다.===========실험 실행 영상===========다음 3가지 함수에 대하여 실험한 영상을 첨부 하였음1. x^22. 8*x^2-X^33. 10*sin(X)+(X-4)^2-10초록색 선: 실제 함수파란색 점: 학습용 정답 데이터빨간색 점: 학습 결과 만들어진 근사 함수의 출력 데이터===========코드===========https://github.com/dgtgrade/HumanLearning/blob/master/1002.py===========ANN===========지난 글에서와 마찬가지 초간단 (Deep도 아닌) ANN이고, 히든 노드만 100개로 변경함- 입력 레이어: 노드 1개 -- x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음- 히든 레이어: 1개, 노드: 100개-- a = sigmoid(w1*x + b1)- 출력 레이어: 노드 1개-- o = w2*a + b2- 코스트 함수: Squared Error===========실행 환경 준비===========python3.5, numpy, matplotlib 이렇게 세가지만 있으면 간단히 실행할 수 있습니다.혹시 그 세가지가 설치되어 있지 않다면, 다음 영상을 참고 하여서 간단히 설치 하실 수 있습니다.https://www.youtube.com/watch?v=pMkwjXFZdH4===========목표 함수 t에 따라서 사람이 조정해야 하는 값===========1. Learning Rate: 너무 작게 하면 학습이 느리고, 너무 크게 하면 학습이 안 됨2. 히든 노드수: 너무 적으면 학습이 불가능할테고, 너무 많으면 학습이 느려질 것 같음이 두가지 외에는 사람이 조정하는 값은 없음이 두가지를 굳이 사람이 조정해야 할까? 싶은 생각도 있음. 아마 자동화 할 수 있을 것 같고, 찾아보면 관련 이론이나 팁들이 꽤 있을듯함.===========머신 러닝이란 무엇일까?===========제 개인적으로는 이 글의 주제인 UAT에 크게 감명 받아서... 머신 러닝 공부를 본격적으로 시작하게 되었습니다. GD나 BP도 감동이지만, UAT는 격이 다르다고 생각합니다. 다음은 머신 러닝이란 무엇인지 제 나름대로의 생각을 정리해 본 영상입니다.https://www.youtube.com/watch?v=3vcG61VC90c	2	훈련값들의 범위 밖에서는 어떻게 추론을 해내는지 궁금하네요. 예를 들어서 t(x) = x*x 에서  -6, -7, -8, 11, 12, 13 ... 등에서 어떻게 값을 내주는지 궁금하네요.	1	저런 그래프는 어떻게 그리나요??	1	어떤프로그램으로 그래프 그린거에요??	1	음.. Training Set과 Test Set 을 6:4로 나누고 비교해보면 Bias/Variance 를 관찰해볼 수 있을것 같습니다. Training Set 에 대한 정확도를 보는건 의미는 있지만 치팅이 아닐까싶네요.	1	감사합니다.
53	MNIST 예제에 JPEG데이터를 적용해 볼수 있도록 함수로 만들었습니다.공부하는데 도움이 되었으면 좋겠습니다.	1	감사합니다~	2	감사합니다. 데이터 입수부터 시작해서 해야 제대로 배울수 있을것 같아서 저도 지금 동일한 작업을 하고있었습니다.	0	안녕하세요 올려주신 자료 감사히 잘 보고 있습니다. 보면서 궁금한 점이 있습니다. 영상 resize를 하는 과정에서 원본 영상의 가로세로 크기가 다른데 128x128 (config.py)로 resize를 하게 되면 비율이 틀어질 것 같은데요.. 이 부분이 학습에 영향을 주진 않을까요? 사진에 얼굴이 있다고 한다면 어떤 사진은 얼굴이 상하로 길게~ 또는 좌우로 길게 resize 될 것 같거든요.
1	아래것이 무슨말인가요?The Android entries in <workspace_root>/WORKSPACE must be uncommented with the paths filled in appropriately depending on where you installed the NDK and SDK. Otherwise an error such as: "The external label '//external:android/sdk' is not bound to anything" will be reported.	0	현재 텐서플로우를 활용해 어플리케이션 개발 진행중입니다. 저희 팀이랑 비슷한 문제 겪고계셨던거 같은데 혹시 정보공유 하실 생각 있나요? 관심 있으시면 메세지 부탁드립니다!
30	믿고 보는 WildML의 TensorFlow를 이용한 RNN 포스팅입니다주제는 다음과 같습니다.* Using tf.SequenceExample* Batching and Padding* Dynamic RNN* Bidirectional Dynamic RNN* RNN Cells and Cell Wrappers* Masking the LossRNN을 처음 접하시는 분들은 작년 말에 올라온* Theano를 이용한 RNN 포스팅 (http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)* AIKorea 의 한글 번역본 (http://aikorea.org/blog/rnn-tutorial-4/)* 기본적인 LSTM 포스팅 (https://colah.github.io/posts/2015-08-Understanding-LSTMs/) 을 간단하게 살펴보신 후 읽어보시면 좋을 것 같습니다.자세한 코드는 아래 깃헙에 Jupyter notebook 파일로 실습할 수 있게 공유해 놓았습니다.https://github.com/dennybritz/tf-rnnhttp://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/
2	import tensorflow as tfimport numpy as npx_data = np.float32(np.random.rand(1, 100))W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))sess = tf.Session()print sess.run(W)print x_data	0	왜 에러가 날까요??	1	u should run "initialize all variables "\	0	세션 가동전에 모든 변수를 초기화하세여
1	의학지식은 어떤방식으로 러닝시킬까요? 문장분석하나요??	1	목표가 어떻게되는지에 따라 달라지지않을까요...우선 문제를 잘 정의하여야 하고 정의된 문제의 목표에 따라 분석방법이 달라질것같습니다.
2	y=x^2같은 함수는 로지스틱 리그리션으로 함수 찾기 힘들것 같고 딥러닝으로 함수 찾아내는 방법 아시나요?input: 1 2,3,4,5...outout : 1,4,9,16,25,...	2	제 짧은 소견으로는비선형함수의 경우 모함수의 식을 모를 경우 추정하기 상당히 힘이듭니다.(거의 불가능하다고 봐야겠지요, 모집단이 아주 많으면 어느정도 가능성이 있습니다만)딥러닝도 수리적으로는 n차식과 같으니 어렵지 않을까합니다.미니탭이나 SPSS등 상용 솔루션에서도 비선형회귀분석은 기대하는 모형을 설정하는것으로 시작합니다	1	maxout networks이라구 quadratic한 함수를 근사적으로 푸는 방법이 있는것 같습니다~https://arxiv.org/pdf/1302.4389.pdf	2	class 가 있는겨우 logistic regression 을 쓰시고요, polynomial 일때는 https://en.wikipedia.org/wiki/Polynomial_regression 쓰시면 됩니다.	1	logistic regression 용도에 대해 잘못이해하고 계신것 같습니다.	2	근데 Deep learning은 모델 자체가 기존의 함수로도 안될 경우에 쓰는 거죠. 모델이 어느정도 예상이 된다면 그냥 Optimization 만으로도 충분히 답이 나옵니다. 제 경험에는 왠간한 비선형 함수들도 거의 수학 모델 자체가 있다면 coefficient구하는데 어렵지 않습니다.	3	반갑습니다. 저 또한 DNN을 이용해서 고양이 사진 인식 함수도 만들어 내는데 x^2 함수 정도도 근사함수를 못 만들어낼까? 하는 의문을 가진적이 있습니다. 이 문제와 관련하여 공부하다 보니 "Universal Approximation Theorem"이라는 키워드를 알게 되었습니다. 짧고 거칠게 얘기하자면 간단한 NN으로 거의 모든 함수를 (일정 수준으로) 근사시키는 함수를 만들 수 있다는 것입니다. 문제는 그것을 학습시킬 수 있느냐는 것이고요. 더 상세한 내용은 다음 링크를 참조 하시고요.- universal approximators: standard multilayerfeedforward networks are capable of approximatingany measurable function to any desired degree ofaccuracy- there are no theoretical constraints for the success offeedforward networks- lack of success is due to inadequate learning,insufficient number of hidden units or the lack of adeterministic relationship between input and targethttp://deeplearning.cs.cmu.edu/notes/Sonia_Hornik.pdf제 생각에는 x^2 함수는 매우 단순한 함수이므로 입력값 x 의 범위 [-max, max]를 어떻게 정하느냐에 따라서 뉴론수 또는 레이어수를 적당히 조정 해 주고 단순한 (기본) ANN 모델로 학습 시키기만 해도  x^2를 꽤 (그러니까  | F( x ) - f ( x ) | < epsilon) 근사시키는 함수를 금방 찾아낼 수 있지 않을까 쉽네요.
9	[스터디원 모집 ] #싸이그래머 스몰마인드 : 파트 2 (DIY 나만의 딥러닝 프로젝트 만들기) + (새로 추가) 파이썬 기초/중급  - (기존) tensorflow를 이용한 딥러닝 기반 개인 프로젝트* 2주에 한번, 토요일, 오전 10~1시. 강남, 무료(유료공간사용료는 각자 결제: 1회 3천원)* 이벤트 링크 - https://www.facebook.com/events/1090635240990193/tensorflow를 이용해서 뭐 좀 만들어보자는, 개인 프로젝트형 스몰마인드입니다. 파트1에서 좀 몸을 풀고 파트2로 넘어갑니다. 사실 그냥 2달을 채워서 파트2로 이름만 바꿉니다. * (새롭게 추가된 것) 파이썬 기초/중급단, 파트2에서는 파이썬 문법 관련 돌아가며 발제를 하는 시간을 1시간 정도 가집니다. 막상 구현을 하려하니 딥러닝 이론보다 파이썬 문법에서 더 어려움을 겪는 분들이 계실듯하고, 텐서플로우 예제들이 중급의 멋진 코딩 방식이 많고 파이썬에 대한 이해도가 높은 사람들이 짠 것들이 종종 보이더라구요.교재는 한빛 미디어의 '전문가를 위한 파이썬'  http://www.hanbit.co.kr/store/books/look.php?p_code=B3316273713 으로 합니다. 이 책은 중급 정도의 난이도이지만, 대신 2시간 동안은 기초가 없는 분들은 각자 파이썬 기초 공부를 하시면 되니까, 이 기회에 파이썬도 익히는 시간이 되시라 생각합니다.----------(기존) 그리고 2시간은 자유롭게 자신의 프로젝트를 하는 것이죠. 관심있는 누구나 함께 하실 수 있는, 토요일 오전의 느슨한 취미 스터디입니다. 참여를 원하시면 이벤트에 참석을 누르시거나, 댓글을 달아주시거나, 해당 장소로 바로 찾아오시면 됩니다~	1	파이썬 교재 - http://www.hanbit.co.kr/store/books/look.php?p_code=B3316273713
35	구글 텐서플로우 엔지니어링 디렉터 Rajat Monga 팟케스트 "Software Engineering Daily" 에 나왔네요. 텐서플로우 설명, 모델링 접근 방법, 동시성, Kubernetes 사용 등등에 대한 질문에 답변합니다. 들어보니 재밌어서 공유 합니다.  	0	팟캐스트 구독해서 듣는 건데 이번주 목요일자로 올라왔네요! 정보 감사합니다.
8	안녕하세요! Tensorflow를 공부를 하고있는 학생입니다. Tensorflow를 이용해서 머신러닝을 하고, 이를 이용해 이미지 속에 있는 숫자를 인식하는 프로그램을 만들어보고 싶습니다(이미 좋은 오픈소스들도 많이 나와있지만).이를 위해 머신러닝과 Tensorflow를 공부하고 있습니다. 특히 Tensorflow는 김성훈교수님의 강의를 들으며 공부하고 있습니다. 좋은 강의 감사합니다.최근엔 간단한 숫자이미지(필기체가 아닌 숫자이미지)를 인식해보기 위해 MNIST 데이터 셋으로 트레이닝 시킨 뒤, 이미지를 입력시켜주면 어떤 결과가 나올까 궁금해서 간단한 소스코드를 추가해 보았습니다. 그런데 입력한 데이터 포맷과 튜토리얼 코드를 참고해서 만든 코드에서 필요로 하는 데이터 포맷이 맞지 않아 고생을 하고 있습니다.이미지를 MNIST 데이터 형식으로 바꾸고 싶은데 어떻게 해야할지 막막합니다.혹시 문제를 해결하는데 필요한 단서를 알고계시는 분들이 계시다면 조언을 구하고 싶어서 이렇게 글을 올리게 되었습니다.자세한 사항은 부족한 영어실력이지만 Stackoverflow에 적어놓았습니다. 질문에 대한 조언 이외에도 Tensorflow와 머신러닝을 공부하는 초심자에게 많은 조언을 부탁드립니다!	4	예전에 여기에 올렸던 JPEG image를 MNIST 형식으로 바꾸는 예제입니다.도움이 되셨으면 좋겠습니다.http://blog.naver.com/kjpark79/220783765651
0	12개의 parameter 로부터, 0(failure) 1(success)의 binary classification 모델을 구축하고 있습니다. Tensorflow org에서 제공하는 IRIS classification의 3 layer DNN 을 기반으로, 트레이닝 및 테스트를 시키고, 12개의 새로운 parameters를 피드하면, Imagenet challenge 처럼 각각의 label 별로 0~1 사이의 score를 주려고 합니다. csv 파일로 데이터를 읽어들이고, 학습을 시키는것까지는 구현을 했는데, Imagenet 처럼 레이블별로 score를 부여하는것은 어떻게 해야하는지 감이 안잡히네요. Inception v3 예제를 뜯어보고 있는 중인데 긴가민가합니다...	0	0~1 사이 값이시라면 sigmoid 나 tanh 에 NN 결과를 연결해주면 될 것 같습니다만..	0	저도 매우 궁금합니다. classify_image.py 소스를 보면 아래와 같은 부분이 있는데softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')    predictions = sess.run(softmax_tensor,                           {'DecodeJpeg/contents:0': image_data})print 해보면 [[  1.00236488e-04   2.51059479e-04   7.98703913e-05 ...,   1.00235920e-04    1.00237063e-04   1.00237063e-04]]이렇게 나옵니다. 보통 예제들은 True, False, ...이런게 batch size만큼 나와서 그걸 평균해서 precision을 구하는데 위의 softmax_tensor는 어떻게 생겼길래 리턴값이 저런식으로 나오는지 궁금합니다.
28	안녕하세요 저번에 발표자 모집 공지를 올렸던 모임이 확정되어 이곳에도 알려드립니다. TensorFlow 관련 내용이니 만큼 관심있으신 분들은 일정과 장소 아래 경로에서 확인하시고 참석신청 해주세요 :-)
16	#딥엘라스틱 딥NLP+검색엔진+신경인지언어심리학 스터디 : 파트 3 - 엘라스틱서치, 파이썬, 딥러닝(+텐서플로우)를 이용한 챗봇 만들기(+클로져)* 첫 모임 후기만 공유하겠습니다. 자료는 모두 공개&공유됩니다(정리중)* 심리/언어학+자연어처리 그룹 바벨피쉬에서 운영하는 스터디 입니다.* 네이버D2의 지원을 받습니다.<딥엘라스틱서치 파트3 후기>작성자 : 박혜웅박신홍님께서 먼저 뉴스 크롤링에 대해서 먼저 설명해 주셨습니다. 한국 뉴스들이 라이센스때문에 수집하기 어려워서 고생하신 흔적이 많이 느껴졌습니다. 공개된 사이트에서 수집하는 것을 보여주셨네요. 수집한 한국 뉴스들을 elasticsearch에 넣어서 elasticsearch HQ에서 검색하는 방법까지 알려주셨습니다.박신홍님께서 시간이 남을 것까지 대비하셔서, 감성 분석까지 발표해 주셨습니다. konlpy, gensim을 이용한 감성분석이었구요. 박은정님의 자료를 참고하셨다고 합니다. word2vec을 이용하여 감성분석하는 방법에 대해서 설명해 주셨습니다. 부족한 부분은 많은 고수님들이 챙겨주셨구요.오늘 처음 오신 김성환님은 슬랙 API를 이용한 챗봇에 대해서 설명해 주셨습니다. 먼저 자신만의 챗봇을 생성하는 부분부터 차근차근 해주셨구요. 모든 분들을 psybus.slack.com으로 초대하였지만, ipynb 파일로 실행하는 환경이 대부분 준비 안되서 실습은 못하고, 시연 위주로 진행되었습니다. 채널이나 DM에 메시지 보내고, 메시지를 받으면 "안녕, xxx님 "하면서 대답하는 것까지 보여주셨습니다. 다음에 모든 분들이 ipython notebook과 슬랙등 준비된 상태에서 다시 한번 실습하면 좋을 것 같습니다.세번째 발표는 놀러온 손님 강지훈님의 "기업을 위한 머신러닝"을 주제로 발표하셨습니다. 머신 러닝 관련 회사를 다니시는데요. 회사에서 하는 여러가지 NLP 관련 사업에 대해서 설명하셨습니다. 검색엔진 최적화 부터, 자동 응답시스템, 챗봇까지 못하시는게 없네요. 검색에 대해서 실무 위주로 설명해주셨고요. 검색 랭킹 모델에 BM11, BM15, BM25 등을 쓰면 된다고 심플하게 답을 주셨구요. 추천시스템, LDA, word2vec을 하나로 묶어서 설명해 주신 것도 귀에 쏙 들어왔습니다.마지막 발표는 송영숙님이 하셨구요. 기다리던 클로저였습니다. "joy of clojure" 라는 책의 내용으로 설명하셨구요. 클로저 역사부터 시작했구요. 클로저의 특징은 "단순성", "권한위임", "핵심에 집중하기" 라네요. 괄호가 좀 많아 보이는데 이게 오히려 명료한 표현에 필요하다고 합니다.문법적인 특성으로 넘어 갔습니다. 변수 선언부터 자료형 간단한 함수까지 클로저를 맛 보는데 즐거운 시간이었습니다.	1	http://babelpish.github.io/deep-elastic/	1	진짜 멋집니다!! 여유가 생기면 따라가보겠습니다. 공유 감사합니다!	1	감사합니다. 아직 정리 중입니다. 완전 정리가 끝나면(8월안에) 다시 공유하겠습니다~	0	이주영 정윤의	0	재밌었을 것 같네용. 다른 작업이 있어서 참석을 못했는데 아쉽습니당...혹시 이번 시즌도 저번 시즌같이 하드코어 한가용 ?	1	차근차근 기초부터 합니다~
257	안녕하세요. 블로그에 번역했던 글이 책으로 출간(예정)되었습니다. 자수하는 마음으로 공유 드립니다.^^ 혹시 나중에 서점에 가실일 있으시면 한번 들춰봐 주세욧! :-)	0	축하드립니다.^^	0	블로그를 통해 도움 받고 있었는데 책으로 출판한다니 축하드립니다.	0	축하드립니다. 하나 주문해야겠네요.	0	축하드려요!!^^	0	감사합니다. 큰 도움이 될 것 같아요.	0	축하드립니다~~^^	0	와우~ 축하드립니다	1		1	출간 축하드립니다!! 큰 일 이루셨네요	1	축하드립니다! 책 쓰는 과정이 쉽지 않으셨을텐데.. 이 책이 많은 사람들에게 도움되기를!	1	정말 수고하셨습니다	0	힘드셨을텐데 그간의 노고를 씻어내시지요. 축하드립니다..	0	이해하는것과 별개로 한글로 설명하기 쉽게 다시 풀어쓰는건 완전 다른 영역이라 생각됩니다. 고생많으셨습니다. 많은 분들에게 도움이 되겠네요!	0	번역 감사해요.사서 볼려고 합니다.	0	감사합니다~! 딱 이런 책을 원했는데 바로 주문들어갑니다~~	1	정말 축하드립니다. 많은 분들이 보시면 좋겠습니다.	0	오늘 사러가야겠내요 ㅋ	0	주문했습니다. 잘 읽어 보겠습니다.	0	관심많은 분야인데 .. 초보인 저에게도 도움이 많이 될것 같습니다. 저도 예매 했어요..^^	0	다음주에 배송 해준다는데 정말 기대가 많이 됩니다.	0	훌륭하십니다. 한 권 구매 해야겠네요. ㅎㅎ
67	파이썬 기초도 다시 잘 해보시죠강의했더니 3일간에 끝내지 못했어요
6	아래 사진이 이해가 안가는데요, 필터의 개념과 앞에 노랑판이 무엇을 의미하는것인가요?	3	5x5x3은 필터 사이즈고 여기서 3은 컬러 이미지라서 그런거 같아요. 이 예제와 같은 필터 사이즈를 가지면, 전체 이미지에서 5픽셀x5픽셀 크기의 영역이 다음레이어(노랑)에서 1x1의 사이즈가 되는거죠. 그만큼 작아지니까 오른쪽 아웃풋레이어가 왼쪽 파란색 인풋레이어보다 크기가 작은거고요.물론 사이즈가 같을수고 있습니다. Padding하고 stride값에 따라서.	2	5x5 의 한 점이 필터(위에서 붉은색)를 거치면서 1점으로 계산되구요. 전체 입력값이 아니라 5x5=25개의 neuron 으로 1개의 neuron이 만들어지기 때문에 Fully Connected Network가 아니라고 말합니다. 필터 size 만큼의 파라미터로 전체 입력값에 적용시킬 수 있기 때문에 학습시킬 파라미터 양이 획기적으로 줄어들어서 계산량을 훨씬 감소시키는 효과가 있죠. 위에 분이 설명을 잘해 주셨는데 사족을 달아 봤습니다.ㅎㅎ	1	필터는 일반적으로 이미지에 적용하는 필터라고 생각하시면 될거고, (이미지 프로세싱에 사용하는 필터) 인위적으로 어떤 필터를 적용하는 것이 아니라 라벨값을 잘 구분할 수 있도록 머신러닝으로 필터값을 조정(학습)시킨다고 보면 되죠.	0	이 뜻은.. m(x) = x, w(x) = x Mountain is mountain, water is also water 입니다. (교수님 강의 듣자마자 3분만에 조는 학생) 죄송합니다	1	보통은 2차원배열로 합성곱을 하는 예시가 많아서 그런거 아닐까요? 이건 3차원으로 합성곱을 하니까 3층(레이어)가 단층으로 되는걸 거에요이 질문이 아니었을까 한번 써봅니다	0	fileter는 입력데이터(이미지 등)의 특징을 추출하기 위한 것이고, 이렇게 추출된 특징을 오른쪽 노란색 매트릭스에 저장을 하는데 이 매트릭스를 보통 activation map 혹은 feature map이라고 합니다. 윗분들이 세부적인 걸 설명하셔서 전 개념적인 걸 설명 드립니다.
18	회사를 다니는 개발자로 ML 을 접한 짧은 단상입니다.학문적으로 기반 기술을 연구하는 분이 아니라면 Why 보다는 How to 가 더 궁금하실 것 같습니다. 그래서 돈을 만들 수 있나? 어떻게 만들 수 있나?ML 분야가 아직도 경지를 개척해나가고 있는 단계이기 때문에 How to 보단 Why 가 더 집중을 받는 단계인 것 같습니다. 그만큼 대중화가 멀었다는 뜻이고, 그것은 다가올 대중화에 Key 가 있을거란 겁니다. 웹 기술 개발/설계자로 10년 정도 일해왔고, 그간 Big Analytics 를 비롯한 많은 부분들이 이와 같은 맥락으로 Why 보단 How to 로 성과를 내오는 모습을 보아왔습니다.가까운 시일내에 웹 기술의 Spring Framework 와 같이 반제품화 되는 모델/제품들이 나오겠죠? 이처럼 도전적인 일이 오픈소스로서 활동하는 것도 개인으로서나 같은 길을 걷는 사람으로서 보람있는 일일 것 같습니다. 혹시 이처럼 보다 Field 에 가까운 활동에 Contribution 할 수 있는 곳이 있을까요? 정보 공유를 부탁드립니다.	1	누군가했는데 반갑!. 텐서도 주무르다니... 역쉬.	2	IT업종에서 개발자,분석자,영업대표 등등 많은걸 해오다가3년전부터는 데이터분석관련일을 해왔었는데 실제 빅데이터필드는하나밖에 못 만나봤습니다. 일데이터 천만건 이상 나오는 사이트가그렇게 많지는 않고 ML이 현재 이슈긴 하지만 AS-IS에서 뭐가 더나아지는지를 설득해야 됩니다. 그 효과도 증명해야 되고오늘 PAYPAL 관련 분석을 좀 해봤더니 데이터분석으로 H20를 써서효과의 구체석 수치를 확인 한 다음에 이리저리 홍보를 하더군요.그러나 어쨌든 앞으로는 이쪽으로 사업이 집중될것으로 예측(?)을조심스레 하다보니 관련 스킬을 익혀야만 될 거 같은 그런 느낌이아닐까 하네요..기업은 바보가 아니죠.ML은 왜? 혹은 하면 뭐가 좋아지는지(?)를 구체적으로 입증해야지만돈이 움직이겠죠. 이번달까지 ML로 AS-IS의 가치를 올린다는 내용으로 구체적인제안작업을 해야되는데 쉽지는 않습니다.그렇지만 트렌드라는게 있죠...돈을 움직일 결정권자도 뉴스는늘 보는거니까..
7	안녕하세요. 처음막 공부하기 시작한 학생입니다."모두를 위한 머신러닝/딥러닝" 강의를 보면서 공부하고 있습니다.공부하는 도중 궁금한게 생겼는데요. 첫번째 사진은 제가 생각한대로 결과가 잘 나왔습니다. 그런데 2번째 사진에서 x_data와 y_data를 5개로 늘려준후 보니 nan이 떠 버립니다..  4개까지는 되는데 5개부터 nan가 뜨네요.  왜이럴까여??	1	저도 아직 유튭 보는 초보입니다만, cost 잘 보시면 200번째 train 에서 inf 즉 cost 가 무한대로 발산해버렸죠? 그래서 nan 이 된 겁니다.	0	ㅎㅇㅎㅇ 텐서꿀잼임	1	입력값이 커지는 방향으로 개수가 중가하잖아요? 그래서 cost 자체가 커져서 overshoot 된게 아닌가... 조심스럽게 짐작해봅니다. 윗분 말씀대로 learning rate를 줄여보시거나 5,5대신 0,0 -1,-1등을 넣어보시면 어떨까요
32	저는 gtx1070 tensorflow 설치시 실패하여구글 검색중 바로 설치하게된 분의 방법을 공유해드립니다.cuda 8.0 설치시 계속 오류였는데, 이분 방법은 7.5이지만 그대로 따라했을때, 바로 사용할수 있게 해주네요. 혹시 잘안돼시는분 있으면 이분 방법도 유용하다고 생각드네요.바로 test 할수 있게 예제도 같이 올려주셔서 좋았습니다.정리하는 법좀 배워야할것 같네요.	2	실행후 결과도 첨부합니다	0	좋은 정보 감사합니다.안 그래도 gtx1060에다가 올려서 해볼까 했는데, 마침 좋은 정보네요.	0	좋은정보 감사합니다 :) i7-6700 GTX1080 32GB Ubuntu 16.04 에서 동일한 환경으로 셋팅을하여 deep_fizz_buzz.py 도 정상적으로 실행이 됬으나, iPython위에서 동작시 tensorflow를 import할시 No module named tensorflow 라고 에러가 나네요. 혹시 관련 설정에 관해 조언을 구할 수 있을까요?
40	https://gist.github.com/haje01/202ac276bace4b25dd3f	0	위에 링크 이해가 잘안가는데요. 제가 머리가 나빠서라기 보다는 설명이 상세하지 않고 갑자기 도약해서 그런거 같은데요. 이해하려면 어떠한 방법이 있을까요	1	김성훈 교수님의 강의 내용을 추천드립니다. 딱히 내용에 문제가 있지는 않습니다만 말씀하신 부분은 이해가 가네요. mnist를 구현하는 텐서플로 코드를 이해하시려면 나름의 테스팅이 필요합니다. 순차적으로요. (텐서플로 자체가 캡슐화된 로직이 많아서요). 조금 시간이 걸리시더라도 전체 내용을 이해하시려면 텐서플로 홈페이지만으론 부족합니다.	2	김성훈 교수님 강의는 꼭 보셔야 하구요. 아래 사이트의 내용도 도움이 될거에요.http://blog.naver.com/PostList.nhn?blogId=laonple&from=postList&categoryNo=22 머신 러닝의 기본 개념부터 모델별 비교까지 자세히 설명되어 있어요
219	파이콘에서 했던 "지적 대화를 위한 깊고 넓은 딥러닝" 발표의 슬라이드와 텐서플로우 구현 코드들을 공유합니다. 텐서플로우 코리아 밋업에서 소개하지 못했던 DCGAN, NTM, Visual Analogy 모델과 코드를 다뤘는데, 텐서플로우를 공부하시는 데 도움이 되셨으면 좋겠습니다 :)1. 이미지(사람의 얼굴 사진)을 이해하고 스스로 만드는 모델http://carpedm20.github.io/faces/https://github.com/carpedm20/DCGAN-tensorflow2. 픽셀을 하나씩 예측하며 이미지를 만드는 모델https://github.com/carpedm20/pixel-rnn-tensorflow3. Atari 게임을 화면의 픽셀만 보고 배우는 모델https://github.com/devsisters/DQN-tensorflow/4. 이미지 버전의 '왕 - 남자 + 여자 = 여왕'https://github.com/carpedm20/visual-analogy-tensorflow5. 뉴럴 네트워크로 만든 튜링 머신https://github.com/carpedm20/NTM-tensorflow6. 강화 학습 모델들https://github.com/carpedm20/deep-rl-tensorflow/7. Question Answering, Language Modelhttps://github.com/carpedm20/MemN2N-tensorflow8. Character-level Language Modelshttps://github.com/carpedm20/lstm-char-cnn-tensorflow9. Teaching Machines to Read and Comprehendhttps://github.com/carpedm20/attentive-reader-tensorflow10. Neural Variational Inference for Text Processinghttps://github.com/carpedm20/variational-text-tensorflow11. Text-based Games using Deep Reinforcement Learninghttps://github.com/carpedm20/text-based-game-rl-tensorflow12. Continuous Deep Q-Learning with Normalized Advantage Functionshttps://github.com/carpedm20/NAF-tensorflow13. Asynchronous Methods for Deep Reinforcement Learninghttps://github.com/devsisters/async-rl-tensorflow14. Neural Abstractive Summarizationhttps://github.com/carpedm20/neural-summary-tensorflow발표 슬라이드: http://www.slideshare.net/carpedm20/pycon-korea-2016	0	와 감사합니다 !!	0	재밌게 들었습니다! DCGAN 은 응용할 분야가 많아보이네요 ㅎㅎ	0	어제 발표 잘 들었습니다. ^^	0	발표  잘들었습니다  공유  감사합니다 ^&	0	감사합니다. 파이콘에서 꼭 듣고 싶은발표였는데, 못 가서 아쉽네요. 담번에 기회가 또 있기를 ^^	0	다 혼자 짜신건가요	0	공유 감사합니다!	0	누가 짠거에요??	0	좋은 발표 정말 잘 들었습니다! 공유 감사드려요 ㅎㅎ	0	좋은 자료 감사합니다. DEVSISTERS에서 딥러닝 관련 일을 하시나요?	0	태훈님 발표 들으러 사실상 pycon 참석했습니다. 재밌는 연구들 많이 소개해주셔서 감사하구요~ 발표도 잘 하셨고 코드들도 직접 짜신 것도 자극이 많이 되었습니다. 다음에 또 뵐 기회가 있길 바랍니다~	0	대박! 재밋습니다!! 감사합니다	0	DCGAN에 대해서 처음 들었는데 흥미로웠습니다!ㅎ 쉽고 깔끔한 설명 감사합니다. 근데 여기 적는게 적절한 것인가 잘 모르겠습니다만, 처음에 경찰 네트워크를 먼저 훈련할때, 데이터가 이미 가짜로 생성된 얼굴 이미지와 진짜 얼굴 이미지가 있어야하는 것 맞나요? (unsupervised learning이라 하셨으니 라벨까진 필요없겠지만) 제가 이해한게 맞다면 이 가짜 데이터가 진짜와 다른 어떤 특징을 갖느냐가 굉장히 관건일거 같은데... 당연한 질문 같기도 한데 의견을 여쭙고 싶네요	4	http://bamos.github.io/2016/08/09/deep-completion/#introduction   GAN에 대한 평가로 시작되는 아주 재밌는 포스트입니다.  carpedm20님이 언급되어 있네요.
4	형태가 불분명하며 비슷한것들 예를들어 구름과 연기를 딥러닝+@를 통하여 분류하고싶습니다. 색이 비슷한 연기와 구름을 사람은 어떻게 구분하는가 생각해봤을때, 구름은 하늘위에 떠있고, 대부분 뭉쳐있는 느낌이라면 연기는 바람에 의해 모양이 쉽게 변하며 구름에 비해 빨리 흘러가는 느낌 정도로 구분하지않을까 생각됩니다.단순한 CNN에서 연기를 학습시킨 네트워크에 구름 이미지를 테스트 해봤을때 연기 이미지와 구름 이미지를 제대로 분류하지못하는 결과를 보였습니다.MNIST와 같이 모양이 뚜렷하게 구분되는 것들은 Accuracy가 아주 높은데, 형태가 불분명한것들 불꽃, 연기, 질감 같은것들도 학습데이터의 양이 충분하다면 CNN이 적합한 네트워크가 될 수 있을까요?이러한 것을 딥러닝을 통하여 분류하고싶다면 어떤식으로 접근하여야할까요?
5	텐서플로우 공부중인 회사원입니다MNIST 문자인식 프로그램 구글예제 보고 코드 이해까지 다 했습니다근데 그림판에서 숫자를 적고 그 이미지에 있는 숫자를 판독해서 숫자 2라고 결과가 나오게 하고싶습니다구지 그림판이 아니어도 됩니다 제가 쓴 숫자를 컴퓨터가 판독해서 제가 입력한 값이 결과로 나오도록 하고 싶습니다텐서플로우 초짜라 아무리 검색해도 감이 안잡히네요유용한 사이트나 팁줌 주시면 감사하겠습니다	1	저도 초짜라 도움이 될지 모르겠는데요. 그러니까 이 머신러닝한테 공부를 시켜야죠. 내 필체를 이해시키기 위해서는 나의 필체를 찍은 여러 사진을 가지고 학습을 시켜서 일단 내 필체를 알아 먹게 해야죠. 그러니까 MINST 그 예제 코드에서 학습 데이터를 모조릭 내 필체를 찍은 이미지로 바꾸고 돌리면 머신이 러닝을 하겠죠. 그리고 내 손글씨를 찍어서 다시 물어 보는거죠. 이거 뭐라고 쓴거야?라고 그러면 이놈이 그 학습한것을 바탕으로 얼마다라고 말해주겠죠. 대충 이렇게 시나리오가 흘러가지 않을까요? MNIST는 CNN쓰지 않나요? 이미지는 다 CNN이 성능이 잘 나온다고 하던데.... 이야 얼마전까지만해도 전 CNN이 뉴스 방송국 이름인줄 알았는데.. ㅎㅎㅎ 많이 발전했네요. ㅋㅋㅋㅋ 도움이 되었길 바랍니다. 그리고 여기 계시는 많은 고수님들의 자세한 상세 설명이 이어지길 바래봅니다. 전 이만 ....	0	이미지와 input의 모양을 똑같이 맞춰주시면 됩니다Softmax라면 이미지를 일자로 늘어트린 모양 즉 flatten 함수로 이미지를 처리해주시면 될거 같고 CNN이라면 input 레이어와 실제 데이터를 같게 하기위해 reshape 함수로 처리해주시면 될거 같아요 Ps 제 git에 말씀하신 내용에 대한 소스코드가 있습니다!	4	뭔가 이상하네요.. 데이터는 mnist만 있으면됩니다. 재 필기체를 train 시킬 필요까지는 없습니다. mnist엔 이미 다양한 글씨체가 들어 있습니다. 이미 mnist를 통해 학습이 된 weight을 가지고 내가 test하고 싶어 하는 것만 새로 만들어 주면됩니다.	1	https://github.com/sugyan/tensorflow-mnist 이 url이 도움이 되셨길 바랍니다.
122	챗봇 만들기에 대한 몇가지 시도와 아이디어를 소개한 파이콘 발표자료입니다. 여러 아이디어 만드시는데 도움이 되면 좋겠네요. 다들 즐거운 여름 보내시길!https://speakerdeck.com/inureyes/building-ai-chat-bot-using-python-3-and-tensorflow#pyconapac #봇의대부분은노가답니다 #TensorFlow	0	미...미키	1	좋은 발표와 자료 감사드립니다. 시간 관계상 편집하셨다던  뒷부분 분량이 포함된 자료를 추가로 공개 해주시면 더욱 좋을 것 같습니다. (+_+)(+_+)(+_+)	0		1	호시ㅎ.. 읍읍
4	여기서  숫자 2를  그림판으로 그리고 mnist = input_data.read_data_sets("그림판 숫자 2", one_hot=True)코드를 이렇게 수정해서 학습 시켰습니다print 가 결과를 출력하는 명령어잖아요제가 학습시킨 그림판 숫자2가 컴퓨터가 판별했고print로 컴퓨터가 2라고 알았고 결과 2라고 알았다고 출력할려면 어떻게 코딩해야하나요??설명을 잘 못해서 죄송합니다....	2	으아.... 이 질문 글은 정말 한글인데 이해할 수가 없네요...ㅠ 주어가 두개 있기도 하고, '알았고'의 주체는 불명확하고, 무엇이 문제가 무엇을 알고싶은지도 불분명하고...고등학생이신 것 같은데 외람된 말씀이지만 이 문제를 해결하는 것보다 사람들에게 알기쉽게 질문을 전달하는 방법에 대해 고민해보는게 훨씬 중요할 것 같아요	0	https://github.com/y0ubat/MachineLearning_Study/tree/master/04%20-%20Image%20Classification 참고 해보세요ㅎ	0	제가 질문을 제대로 이해했는지 모르겠지만 인식 결과물을 확인하고 싶으신거라면 tf.argmax(y_,1)을 출력하시면 될거같아요
26	[서울대학교 스터디 모임] - 발표자료 공유 / 인원추가모집은 마감되었습니다. :-)안녕하세요! 서울대학교에서 대학원과정을 하고 있는 이지민이라고 합니다.이전에 서울대학교 TF 스터디 모임 관련하여 글을 올렸던 적이 있고 정말 많은 분들이 관심을 가져주셨던 것 같습니다.처음 시작하는 것이라 우선은 12명으로 모임을 시작하였고, 7월 11일부터 서울대학교에서 일주일에 한번씩 스터디를 진행하고 있습니다.스터디가 조금씩 안정되어서 이번에 추가로 6분을 더 모집하고자 합니다. 이 그룹에 계신 분들 중 혹시 스터디모임에 관심있는 분이 있으시다면 저에게 페이스북 메세지를 보내주세요. (소속, 수업/인터넷강의 수강 등의 머신러닝 공부 정도, 연구 관심 분야 등)이 밖에 궁금하신 점이 있으시면 언제든 연락주시기 바랍니다.감사합니다.- 일시 : 매주 월요일 7:30pm (7/11부터 매주 진행하고 있습니다.)- 장소 : 서울대학교 39동 강의실- 발표 주제 : 관심있는 오픈소스/파이썬문법/텐서플로우구현/머신러닝 코드 리뷰(자기 연구와 관련된 것), 머신러닝 논문 리뷰, 연구 소개 (발표 30분, 질의응답 10분)	0	참여하고 싶어요.	0	많은 분들이 연락을 주셔서 방금 모집을 마감하였습니다. (ㅠㅠ) 많은 관심 감사드립니다!!	0	아... 난 또 왜 늦는 것인가....ㅠ 아쉽습니다 ㅠ	3	혹시 발표자료나 동영상있으면 공유해주시면 정말 감사하겠습니다!!	2	https://drive.google.com/open?id=0B8z5oUpB2DysbFNEOWxfVDh5VW8저희 발표자료 공유 링크입니다! 많은 분들이 관심가져주셔서 감사드리고, 앞으로도 더 열심히 하겠습니다 :-)	1	좋은 자료 감사합니다 ㅎㅎ
1	머신러닝에 대해 공부하고 있습니다. 아직은 미숙하지만 방법을 찾질 못해 질문드리네요예를들어A 10 20B 5 10D 2 5A 10 15와 같은 데이터셋이 있을 경우에는 학습을 A는 A끼리, B는 B끼리 모아 학습을 해야 하는 건가요 아님, 같이 학습을 시키는 방법이 있나요?또, NN으로는 아웃풋이 모두 분류화된 값으로 출력하는 것이 아닌 Linear Regression처럼 수치로 출력하는 방법은 어떻게 사용해야하나요?
36	파이콘에서 Deep Learning with 파이썬 & 텐서플로우를 준비중입니다!	1	발표자료 구할수 있을까요?
4	object detection을 real-time 수준으로 구현하려고 하는데 어떤 알고리즘을 써야 할까요? 지금까지는 Faster R-CNN이 최고인거 같은데 혹시 이거 말고 다른게 있나요?	0	오픈씨브이 사용하시나요	2	YOLO (http://pjreddie.com/darknet/yolo/) ~45fps 정도 performance 나오는데, accuracy 는 Faster-RCNN 보단 떨어지는듯 합니다. 참고하세요.	4	YOLO도 시간대비 괜찮은 퍼포먼스를 보이긴 하는데 SSD (Single-shot Multibox Detector)가 더 괜찮아보입니다. (https://arxiv.org/abs/1512.02325)YOLO보다 빠르면서 거의 Fast R-CNN과 비슷한 성능을 보이는 방법론이구요.
49	SyntaxNet (https://github.com/tensorflow/models/tree/master/syntaxnet) 에서 한글이 빠져(https://github.com/tensorflow/models/blob/master/syntaxnet/universal.md)있어서  보니, http://universaldependencies.org/ 로 training하는데, 한글 말뭉치가 없습니다. 세종 말뭉치가 CC license 인데, https://github.com/UniversalDependencies/UD_Korean 에 작업하실 잉여분들 연락주세요.	2	메시지 드렸어요!	3	김혜영	0	어떤식으로 작업하실건가요???	1	페북 메세지로 협업하려 합니다. 세종말뭉치 다운 받아서 -> 맞는 포멧으로 변환 -> 깃헙에 올리고 -> pull request 로 조르면 해줄거 같아요.	0	좋은 아이디어입니다!	1	저도 참여해보고싶네요. 메시지 드렸습니다.
64	안녕하세요! TensorFlow KR의 지원을 받아 파이콘 2016에 다녀온 변성윤입니다. (지원해주셔서 정말 정말 감사합니다!!!)파이콘 스프린트/듀토리얼은 참여하지 못했지만 1,2일차 후기를 블로그에 나름 자세히 적어봤습니당 :)	3	후기 잘 봤습니다. 텐서플로우 모임의 긍정적인 영향력을 직접 볼수 있어서 좋네요 :)
17	MNIST 형식으로 JPEG image 입력을 받게 한 것에 이어 CIFAR10 형식으로 받도록 만들어 보았습니다.
0	최길용 (시인,한국문학세상)파도를 바라보면 (시)꿈이 출렁 출렁 지평선 까지끊임없이 밀려와서 가슴을덮어 주는 평안의 비단이불가진 것 다 내어놓고 평안을 누리라는 선각자의 끝없는 질책의 소리응어리진 아집의 큰 바위때리고 또 때려서 조금씩 부서뜨리는 끈질긴 승부사거품 물고 아우성치는사랑하는 사람의 한 맺힌 소리그 소리 바라보고 바위는 부서져 모래알 비단 될 때까지 떠날 수 없구나.
44	텐서플로우가... 낳은... 괴...아니 덕후니뮤ㅜ	0	링크있나요?
65	신정규님의 세션. 영어로 준비하셨다가 한국어로 진행한다고 하니 커다란 박수가.. :-) #pyconapac	0	와 !!!	1	김준기 보십시오 ㅋㅋㅋ	0	와우	1	한국어 발표 한단 소문 듣고 갔더니 문앞까지 만석이네요	0	ㅎㅎㅎㅎ	2	정규님 발표 완전 대박이었네요 ㅎㅎㅎ	2	저도 봤습니다.오늘 세션 중 감히 최고라고 얘기할 수 있습니다. 혹시 동영상이라도 올라오면 꼭 시청하시면 좋겠습니다.	0	오.... 영상 꼭 보고싶습니다!	0	ㅎㅎ완전 재밌었어요 ^^ 많이 배워갑니다
1	혹시 optimizer쓸때 model에서 tf.gather_nd를 쓰면 아직 구현되지 않았다고 에러가 나는데, 어떻게 돌려서 쓰는 방법 아시는 분 있나요? - 에러 공유 -
2	TensorFlow를 공부하는 사람입니다.다름이 아니라 python의 for문을 이용하는 과정에서tensor를 integer로 변환해야만 문제를 해결 할 수 있는 경우가 발생 하였습니다. 그래서 tensor를 integer형태로 바꿀수 있는 함수가 있나요?	1	tf.cast 함수를 참고하시면 될 것 같습니다	1	텐서플로우 실행은 1. 계산그래프 생성 2. 생성된 계산그래프 실행 이 두가지 스텝으로 나뉘는데요, sess.run 같은 명령을 실행하지 않는 이상 텐서에는 실제 값이 들어가지 않습니다. 그래서 Sung-Un Park 님이 말씀하신것과 같이 세션을 실행해서 텐서의 값을 가지고 와야하죠. 이게 어떨때는 편한데 또 디버깅할때 은근히 불편한 점이 많긴해요 ㅠㅠ
2	간단히 딥러닝으로 Face Grouping에 관한 샘플 코드나 논문이 있으면 추천 부탁드립니다.... Face Detection 및 Recognition은 있는데 Unsupervised 된 사진을 Clustering 해주는 자료를 못 찾아서..
22	안녕하세요. GDG 모임을 하고 있는 이원제라고 합니다. 이번 GDG 모임에서 ML관련해서 발표자 분을 찾고 있는데 TF KR 회원분들 중에 내용 공유해주실 수 있는 분이 계실까 글을 남깁니다. 발표자로 기술공유에 관심있으신 분들은 아래 주소로 신청해주시면 감사하겠습니다. 혹시 문의 사항이나 다른 궁금한 점 있으면 댓글이나 메세지 남겨주십시요.ps.게시글 성격이 이곳에 맞지 않는다면 삭제하겠습니다;;GDG Seoul facebook : https://www.facebook.com/groups/gdgseoulGDG 기존 행사 URL : https://festi.kr/festi/	2	하성주 (Sungjoo Ha) 님 혹시 저번에 numpy 발표하신거 여기서 다시한번 해주시면 어떨까 하네요~ :-)
99	Jeen Lee  님께 주은 텐서플로우를 이용해 오이분류기를 만든 사례 ( 복붙해옵니다. )http://kskbyt.hatenablog.jp/entry/2016/08/09/001717- TF Deep MINST for Expert 룰베이스 엔진과 영상인식을 통한 오이 구분기 구현- 수확기 하루에 8시간동안 분류작업을 해야하는데 그걸 자동화 하고 싶었다. - 학습과 계산은 외부 서버를 사용하지 않고 집 windows 데스크톱 PC1 대 (내용은 Linux )에서 실시. 학습 완료까지 2 ~ 3 일 걸린다. - test 이미지 데이터의 정확도는 95 %. 운영 데이터는 정확도 70 % 정도. - 학습에 사용한 7000개의 오이 데이터는 Github에 공개중 ( https://github.com/workpiles/CUCUMBER-9 ) - 식별기 부품은 3D 프린터를 통해 인쇄자세한 내용은 블로그를 참조해주세요.	0	ㅋㅋ 오이 분류기라 하니까 뭔가 재밌네요 ㅋㅋ	0	우아 멋지네요	0	멋집니다 현실밀착형 프로젝트
43	Windows에서 TensorFlow를 돌리기 위해서 Docker Toolbox를 많이 사용하시는데요. Docker와 Host PC의 폴더를 공유해서 사용하시면 훨씬 편합니다.Docker Toolbox가 Windows에서도 Mac에서와 마찬가지로 C드라이브의 Users 폴더 이하는 자동으로 공유되더군요. (Mac에서는 /Users 폴더 이하)$ docker run -it --name test1 -v /c/Users/{자신의 Windows 계정 폴더}/{공유할 디렉터리명}:{Docker Image에서 공유폴더와 Mount할 폴더 경로} {Docker Image 이름}Example))$ docker run -it --name test1 -v /c/Users/Heeseok/shared:/root/shared ubuntu( /c/Users 대소문자 구분하므로 주의! )Docker Quick Start 터미널로 들어가서 Docker Container에 접속해서 ll 해서 공유된 폴더를 보면 폴더 이름이 녹색 바탕으로 보입니다.이렇게 보이면 공유 설정은 정상적으로 된것이고, 쓰기 권한이 없으면 Protocol Error 가 납니다. (Users 밑에 자기 계정 폴더 밑으로 들어가면 따로 쓰기 권한을 줄 필요는 없습니다.)C드라이브의 Users 이하 폴더 말고 다른 폴더와 공유하시고자 할 때 블로그의 글을 참조해 주세요.	1	감사합니다. 정리해야했었는데 ㅎㅎ	1	< Mac 용 Docker Toolbox로 테스트 결과 >Mac은 -v 옵션만 주면 자동으로 폴더 공유가 되긴 되는데, /Users 폴더 밖을 공유폴더로 하려면 -v 옵션만 줘서는 폴더 공유가 안되더군요. Windows 처럼 다른 설정이 필요할것 같습니다.Mac에서는 /Users 밖의 폴더를 쓸 일이 거의 없고,Mac 사용자 계정으로, 도커 컨테이너를 실행시키는거니까 당연히 유저 경로내의 볼륨에 자동 연동되도록 하는게 맞을것 같다는 의견.사실 웹에서 검색해보면 Windows 도 C:\Users 폴더는 자동 공유된다고 하는데 실제로는 안되네요.http://stackoverflow.com/questions/33245036/docker-toolbox-is-there-a-way-to-mount-other-folders-than-from-c-users-windows아시는 분은 댓글 부탁드려요.사실.. 제가 Windows에서는 Docker for Windows를 설치할 수 있는 조건이 되지만 굳이 Docker Toolbox를 설치하려는 이유는... PyCharm 으로 Docker 안으로 Remote Debugging을 하려고 합니다. PyCharm 에서 Docker for Windows로는 아직 Remote Debugging 을 접속 지원 못하는것 같아요.	0	Docker Toolbox가 Windows에서도 Mac에서와 마찬가지로 C드라이브의 Users 폴더 이하는 자동으로 공유되더군요. (Mac에서는 /Users 폴더 이하)$ docker run -it --name test1 -v /c/Users/{자신의 Windows 계정 폴더}/{공유할 디렉터리명}:{Docker Image에서 공유폴더와 Mount할 폴더 경로} {Docker Image 이름}Example))$ docker run -it --name test1 -v /c/Users/Heeseok/shared:/root/shared ubuntu( /c/Users 대소문자 구분하므로 주의! )Docker Quick Start 터미널로 들어가서 Docker Container에 접속해서 ll 해서 공유된 폴더를 보면 폴더 이름이 녹색 바탕으로 보입니다.이렇게 보이면 공유 설정은 정상적으로 된것이고, 쓰기 권한이 없으면 Protocol Error 가 납니다. (Users 밑에 자기 계정 폴더 밑으로 들어가면 따로 쓰기 권한을 줄 필요는 없습니다.)C드라이브의 Users 이하 폴더 말고 다른 폴더와 공유하시고자 할 때 블로그의 글을 참조해 주세요.
3	도요타, 자율주행차·AI·서비스로봇에 잰걸음?- 작년 9월부터 현재까지 관련 MIT인공지능연구소 등 미국 유력 연구소에 800여 억원 투자
56	참고할 만한 내용 같아 공유 드립니다. 근데 오늘은 정말 더워서 잠을 못 자겠네요. ㅠ.ㅠ	0	진짜 올 여름은 너무 덮네요. 건강 유의하세요
7	DRAW(Deep Recurrent Attentive Writer) 같이 다소(?) 복잡한 형태의 모델을 Variable Length를 처리할 수 있는 형태로 구현하려면 어떤 방법이 가장 적합할까요? 논문 중에 비슷한 구조를 이용해 video 상에서 object tracking에 적용한 것을 보아서 관심을 갖고있습니다. Scan이나 dynamic_rnn을 생각하고 있는데 모델 내부에 encoder/decoder RNN 뿐아니라 attention, sampling 그리고 regularization term도 있어서 이를 rnn_cell 형태로 만들 수 있을지 잘 모르겠네요 (아직 초보라 잘 가늠이 되지 않습니다). 기존의 DRAW 구현은 이미 아래링크와 같이 공개된 것이 있어서 참고하면 될것 같은데...https://github.com/ericjang/draw/blob/master/draw.py어떤 방식으로 구현하면 좋을지 조언을 주시면 감사하겠습니다. scan이나 dynamic_rnn외에도 더 좋은 방향이 있다면 알려주시면 더욱 감사하겠습니다.
9	안녕하세요. GPU로 tensorflow를 막 돌리기 시작한 학생입니다.https://github.com/aymericdamien/TensorFlow-Examples/blob/master/multigpu_basics.py이 예제를 돌려보던 중 이해가 되지 않는 점이 있어 질문드립니다. 코드 자체는 매우 단순합니다. 처음 절반의 코드는 single gpu로 두개의 매트릭스를 각각 n번 제곱한 후 cpu에서 더하는 예제이고, 나머지 절반의 코드는 두 개의 gpu에서 각각 하나 씩의 행렬을 n 제곱한 후에 cpu에서 더하는 예제입니다.제 질문은 크게 4개로 나뉩니다.1. 상부에 주석을 보시면 작성자는  gtx 980 2개, 8 cores를 사용했다고 나옵니다. 그리고 걸린시간은 대략 11초정도 입니다. 제 경우에는 gtx 1060 2개, i5 6500(4 cores)를 사용하고 있습니다. 하지만 행렬의 크기를 똑같이(10000 by 10000)하여 수행할 경우 6분 50여초가 나오게 됩니다. 제가 알기로는 gtx980이나 gtx 1060이나 거의 비슷한 스펙을 가지고 있는 것으로 아는데 이렇게 큰 차이가 왜 일어나는 지 잘 모르겠습니다.2. 둘째는 multiple gpu와 single gpu의 시간차입니다. 작은 행렬에서 실험할 때는 두 케이스가 적절한 시간 차이를 보입니다. 하지만 행렬의 크기가 커질수록 이차이는 줄어들어 위의 (10000 by 10000)에 이르면 거의 같은 시간이 걸리게 됩니다. 정확히는 single에서 6분 50초 , multi에서는 6분 47초였습니다.  이 이유도 모르겠습니다.3. 사실 2번의 이유가 device와 host의 메모리간 병목현상 때문인 것으로 생각하고 gpu에서의 작업량을 늘려주면, 즉 행렬의 제곱수를 늘려주면 single과 multi의 수행시간의 차이가 더욱 명확해 질 것이라고 생각했습니다. 하지만 결과는 정반대였습니다. n 번 제곱한다고 했을때, n이 커질수록 수행시간의 차이(비율)는 점점 줄어들었습니다. 이는  제 예상과 완전히 반대였고 아직까지 이유를 모르겠습니다.4. with tf.device('/gpu:0'): 같은 구문 안에서도 tensorflow의 함수가 아니면 다 cpu에서 실행되는 건지도 궁금합니다. 예를 들면 예제 46번째 줄의 append같은 것이 gpu 커널로 실행되는 것인지 cpu에서 실행되는지 궁금합니다.	0	gpu가 실행되는지 확인해보시는게 좋을 것 같습니다. nvidia-smi 명령어로 현재 gpu가 사용하는 프로세스 목록을 확인가능합니다. tf의 경우 필요한 CUDA라이브러리(ex.cudnn) 등의 요구조건이 만족되지 않으면 그냥 cpu로 실행시켜버립니다. 또 1060의 경우 compute capability가 3.5(tf의 default)와 달라 gpu버젼 설치시 pip이 아닌 소스버젼으로 특정옵션을 넣어서 컴파일해야한다고 알고 있습니다. 이 두 부분 참고해보시길 바랍니다.
44	얼마 전 베를린에서 열린 ACL 2016 NMT Tutorial 강연 자료입니다최근 RNN기반 Machine Translation 및 Language Model의 발전을 한눈에 살펴볼 수 있습니다. 그림들이 정말 친절하네요ㅎㅎ발표자: Thang Luong, Kyunghyun Cho, Christopher Manning
1	[스터디원 모집] 텐서팔로우 : 파트 2- (새로 추가됨) 분산처리 프로그래밍 이론- (기존) tensorflow 프로젝트 코드리뷰 + 파이썬을 이용한 병렬처리 프로그래밍 실습* 2주 간격, 화요일, 저녁 7시 - 10시. 강남. 무료(유료공간 사용비 1회 3천원 각자 결재), 9월 6일 시작.* 이벤트 링크 - https://www.facebook.com/events/1131216840286067/* 이 스터디는 정통심리학 그룹 싸이그래머에서 진행합니다. * 자료는 모두 공개&공유됩니다 - https://github.com/psygrammer/tensorfollow텐서플로우로 구현된 코드들을 리뷰하면서, 실제 어떤 식으로 만들수 있는지 좀 감을 익히자는 취지에서 진행하는 스터디입니다. 각자 자신의 수준과 희망사항에 맞춰서, 공부하고 싶은 텐서플로우 구현체들을 찾아서 리뷰하면 됩니다. 이에 더해서 병렬/분산 프로그래밍 쪽도 기초부터 하고 있습니다. 파트2에서는 이론 책도 하나 추가되었습니다.전문가/실무자 스터디가 아닌, 배경불문 누구나 참여할 수 있는 취미 모임입니다. 함께 하실 분들은 언제나 환영합니다~	0	https://www.facebook.com/groups/psygrammer/	0	교재 1 - (병렬Py) 파이썬 병렬 처리 : Python Parallel Programming Cookbook - https://www.amazon.com/Parallel-Programming-Cookbook-Giancarlo-Zaccone/dp/1785289586	0	교재 2 - (분산이론) 분산처리 프로그래밍 이론 : Programming Distributed Computing Systems: A Foundational Approach (MIT Press) - https://www.amazon.com/Programming-Distributed-Computing-Systems-Foundational/dp/0262018985	0	커리큘럼 & 자료 - https://github.com/psygrammer/tensorfollow
0	inception v3모델로 연습해보려는데 예제로 나온 판다는 잘됩니다. 그다음 다른 이미지파일로 해보려는데 tf.app.flags.DEFINE-string과 os.path.join에서 설정해주는게 맞나요?
3	안녕하세요. TensorFlow로 Deep Neural Network를 공부하고 있습니다.MNIST 데이터 외에 제가 따로 input data를 주어서 활용하고 싶은데요.아래 캡쳐본과 같이 데이터를 입력받고 학습을 하려고하는데 shape크기와 관련된 에러가 납니다.사용할 데이터는 1*720 크기의 벡터입니다. (이미지 아닙니다.. 그냥 1차원 벡터)데이터 수는 training 290개, test 290개를 활용하려고 합니다. 그리고 4개의 클래스로 분류하려고하는 문제입니다.mnist에서는 next_batch와 관련된 함수가 있어서 그대로 썼지만,input data가 달라짐에 따라 next batch와 관련된 함수를 따로 만들어줬습니다..다음과 같은 에러가 뜨는 이유와 해결책은 무엇이 있나요?	0	placeholder에 명시된 사이즈는 None x 720인데 feed_dit에 들어가는 사이즈는 10x290 (해상도 때문에 잘 안보이네요)으로 서로 다르다고 합니다. batch_xs를 출력해서 디버깅하시면 될 것 같습니다.	0	Label도 이상하네요클래스가 네개여서 플레이스홀더에 네개를 잡으신거 같은데 Y는 Nx1인거 같아요	0	train_data = train[:,0:720] 아닐까요? train_label도 1칸이 아니라 4칸이 되도록 one hot encoding을 해줘야할 것 같네요
8	TensorFlow (TF), 딥러닝의 모든 이야기 나누어요.TF 구현 모음: https://github.com/TensorFlowKR/awesome_tensorflow_implementationsTF-KR 슬랙 가입 링크:https://tensorflowkr-login.herokuapp.com 	0	ML을 보는데 비지니스적인 내용도 좀 이야기 할 수 있나요?  이곳이 좀 그런 곳인가요?  아니면 그룹 안에 그런 곳 아시면 pointer 좀 부탁드려도 될까요?
68	모두의 딥러닝 시즌 1의 실습코드 입니다.RNN의 소스와 강의 요약이 업데이트 되었습니다.(소스는 autodrive님에게 무한한 감사를) 많은 사람들이 좀더 딥러닝에 쉽게 접근할 수있게 만들어 주신 Sung Kim 님에게 정말로 존경을!	0	굿	1	수학은 다 이해하셨나요. 실전에 적용하려면 논문 수준으로는 가능성이 없어요	2	승현님 화이팅입니다!	1	멋진데요? :) 훌륭합니다!	1	완전 멋져요!!! ^_^	1	정말 감사합니다!
2	https://www.facebook.com/groups/TensorFlowKR/permalink/325270274480704/
39	초창기에 따라가다가,의지가 박약이라 한 동안 못봤는데어느새 시즌1이 종강 했네요다시 처음부터 하루에 꼭 1개라도 따라가도록작심 해 봅니다 !!!	1	Sung Kim 너무 느무 니무 나무 감사합니다 👍👍👍👍👍	0	무려 '작심삼일'을 넘기고  꾸준히 하루 한개 강의씩,,, 4일차 강의+실습 까지 완료
7	안녕하세요, 텐서플로우로 제가 원하는 RNN 모델을 만들려는데 궁금한 점이 있습니다. DRAW (Deep Recurrent Attentive Writer?)를 조금 변형해서 구현해 보려고 하는데 이처럼 모델에 RNN 부분 뿐 아니라 다른 모듈(sampling이나 filter 등)들이 필요한 모델의 경우 Class를 이용하는 것이 좋은 접근방법인가요? Class를 이용하면 코드가 조금 깔끔해지지 않을까하는 생각에서 사용해 볼까하는데 조금 복잡한 것 같습니다. 아래 링크를 보면,https://gist.github.com/danijar/3f3b547ff68effb03e20c470af22c696데코레이터(lazy_property, staticmethod)들을 쓰고있는데 이런것들이 필수적인 것인가요?  lazy_property는 정확히 모르겠지만 computation graph가 여러번 그려지는 것을 방지하는것 같긴한데, weight 같은 파라메터들은 그냥 class를 initialize 할 때 self.weight = tf.truncated_normal([in_size, out_size], stddev=0.01)이런식으로 만들어 놓고 메소드(멤버함수?) 에서 사용하면 혹시 문제가 되나요?	1	http://stackoverflow.com/questions/3012421/python-memoising-deferred-lookup-property-decorator
18	안녕하세요. Sung Kim 교수님의 딥러닝 강의 듣고 Tensorflow 기반의 딥러닝을 응용하고자 하는 학생입니다. github에 올라와 있는 code들을 실행해 보면서 차근차근 이해하고 있습니다. 훌륭한 강의 올려주셔 감사합니다.  질문이 하나 있어, 어제 facebook에 가입하고 community에 질문을 남기려 합니다. 현재 제가 가지고 있는 데이터에 CNN 또는 LSTM을 적용하고자 하는데, 문제는 제가 사용하고 있는 데이터가 기존 것들과는 조금은 다른 데이터라서 도움을 받고자 여쭈어보고자 합니다.  제가 사용하는 데이터는 MNIST 등의 Computer vision 분야와는 다르게 임상에서 마취심도 측정을 목적으로 만들었으며, 환자에게 마취제를 투여하고 실시간으로 측정한 뇌신호입니다.  데이터의 흐름은 '그림1'과 같이 마취제 투여에 따라 의식/무의식이 반복되게 됩니다. 최근 분석 결과 환자의 의식/무의식 경계에 점진적으로 변하는 뇌 신호 패턴(or특징)을 찾아냈고, 여기에 Deep Network를 이용해보고자 하는데, labeling 부분에 있어서 고민거리를 가지고 있습니다.  아직 labeling이 되어있지는 않지만, 전환 시점을 기점으로 의식(1)/무의식(-1)로의 labeling을 한다면 1,3의 상태(완전한 의식, 완전한 무의식 상태)는 구별이 가능하나, 2,4의 상태(의식을 잃고있는/회복하는 상태)에서의 구분이 가능할지 궁금합니다. 뿐만 아니라 binary (1 or -1)가 아닌 level-dependent labeling(?) (의식의 깊이에 따른 0과 1사이의 값)을 이용하여 DNN을 학습할 수 있는지도 궁금합니다.뿐만 아니라, 지금 고민하는 두 모델 (CNN vs. LSTM) 중, 이 데이터에 어떠한 모델이 적합한지 모르겠습니다. Deep Learning 을 이용하는 computer vision 분야나 제가 사용하는 brain signal 기반의 neuroscience 분야에서 논문들을 찾아보고 있는데, 이와 유사한 패턴을 띄는 데이터를 찾지 못해, 아직까지 해답을 찾지 못하고 있습니다. 두 모델을 사용할 경우, 제가 고민해본 학습의 flow는 '그림2'와 같을 것이라고 생각합니다.얄팍한 지식으로 딥러닝을 사용해보고자 하니, 너무 어렵네요. 그림이 이해가 가지 않으시면, 수정토록 하겠습니다 ^^감사합니다.	0	마취가 되었는지 안 되었는지를 어떻게 확정해서 labeling을 하는지요?	0	CNN으로 먼저 해보시는게 어떨까요. 뇌신호를 1차원 배열의 이미지라고 생각하시고. 아웃풋 노드를 4개로 잡아서.	0	뇌 신호가 raw voltage 이면, spectrogram 으로 frequency domain으로 변형시켜 주시는것은 어떨까요?? 그걸 사진처럼 CNN 으로 처리시켜서.	0	형 글쓰셨네요	1	아무리 딥러닝이라지만 모델에 넣기 전에 feature extraction은 제대로 해 주시는게 좋지 않을까요? 마취상태의 의식/무의식과 관련된 뇌파는 주로 delta-alpha-gamma band의 frequency component의 power/phase 활동을 한정지어서 분석을 많이 합니다. 참고로 저희 연구실에서 나온 페이퍼 중 EEG에서 Unconscious <->conscious 간 transition에 대해 모델링을 한 페이퍼가 있어 공유드립니다. http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0050580	1	예전에 Ketamine, Propofol, Sevoflurane-induced patient group의 raw data로 aesthetic level 이나 sleep scoring 을 딥러닝 돌려 봤었는데 기존 방법 대비 이점이 없었습니다. 특정 필터 영역에서의 feature가 너무 뚜렷한 경우라 (숙련의들은 raw signal을 눈으로 보고도 아니까요. Sleep scoring의 경우엔 실제로 그렇게 매기고.) LSTM 등을 적용하는게 오버테크놀러지더군요... 참고되시길.
3	Hello, I have a question about distributed tensorflow. Recently I have run into a problem where my training data is too large such that it does not fit into a single machine. So, I want to run distributed tensorflow over large-scale data(possible hundreds of Gigabytes) to train a neural network model. I am not sure if I can run it on hadoop cluster because I read somewhere that distributed tensorflow is highly integrated into Google internal infrastructure, which means it only runs on Google cluster like Google Cloud. I am not sure whether or not this statement is true. I'd really appreciate any guidance you are able to give me. Thank you.	1	오랜만이네 ㅋㅋ 요걸로 안될까? https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html	0	ㅋㅋ 고마워	0	이게 맞는 지는 저도 안해봐서 모르겠습니다. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dist_test	1	https://www.hakkalabs.co/articles/fabrizio	1	The distributed tensorflow is not stick to any platform such as Google cloud. You can run it in any Linux, assuming you will utilize GPUs, and installed TensorFlow in the machines will connect by themselves. You don't need to install any other tools. And It should be a big burden installing and maintaining hadoop clusters.You mentioned that hundreds of Gigabytes. Does it mean the total size? I assume it is the data size in a single machine. In this scenario, you need to be careful in splitting the data. It should be evenly divided into machines.	1	Thank you for the info. I will try it as you suggested.
2	안녕하세요 요즘 텐서플로우로 놀고있는 학생입니당노트북으로 GPU 버전 돌리려고 하는데, GTX860M으론 cuda7.5를 지원하지 않는가 의문스럽습니다. 왜냐면 제 노트북으로 돌아가질 않거든요 ㅜㅜi7-4710HQ/GTX860M인데 역시 GPU버전은 쓸 수 없는건가요? 왜 돌아가지 않는지... 며칠을 고생했는데 결국엔 CPU버전으로 돌리니까 너무 안타깝네요...ㅠㅠ	0	컴퓨터 환경 및 에러는 무엇인가요?	0	nvidia gpu  사이트에 따르면 compute capavility가 최소 3.0이니 이론적으론 돌아가야 되는건데 말이죠...흠... 다시한번 뼈와 살을 깎는 세팅의 시간을 갖어 보심이...
11	[스터디원 모집] #바벨피쉬 딥엘라스틱 : 파트 3- (새로 시작) 파이썬/텐서플로우를 이용한 챗봇 만들기 기초 + 함수형 개념을 익히기 위한 clojure 기초- (기존에 이어서) 파이썬/엘라스틱서치 응용 실습  + 딥러닝 자연어처리 논문 리뷰 +  실제 인간의 뇌는 어떻게 언어를 처리하는가를 알기 위한 인지신경언어학* 2주에 한번 목요일, 저녁 7시 30분 ~ 10시 30분. 강남, 무료, 8/18 시작.* 이 스터디는 네이버 D2의 지원을 받으며, 바벨피쉬에서 진행합니다.딥엘라스틱 스터디가 어느새 파트3로 넘어갑니다. 취미로 대충대충하지만 호기심이 많아서 이것저것 의욕넘치게 스터디 중입니다. 전문가/실무자 모임이 아닌 관심있는 누구나 참여하실 수 있는 편안한 실습 중심 스터디입니다. 스터디 참여를 원하시면 이벤트 링크를 통해, 참석을 누르시거나, 댓글을 달아주시거나, 바로 해당 장소로 찾아오시면 됩니다.--------------- 스터디 상세 내용 --------새로 추가된 것은 파이썬(+tensorflow 포함)으로 챗봇 만드는 기초와 인공지능으로 가기 위해 한번은 거쳐야 한다는 lisp의 적자. clojure 기초입니다. 그 외에는 파트3에 이어서 하는데, 단 오픈소스 검색엔진 엘라스틱서치 스터디는 이제 기초가 아니라, 응용을 많이 할 생각입니다. 뉴스 검색 시스템 만들고, 거기에 감성분석을 붙여보는 내용으로 시작합니다. https://www.facebook.com/events/306455256355005/	1	https://www.facebook.com/groups/babelPish/	3	자료&커리큘럼은 모두 공개&공유됩니다(현재 정리중) - http://babelpish.github.io/deep-elastic/	0	스터디 참여를 위한 베이스는 최소 어느정도인지 궁금합니다.
0	-- Last week for all On-Campus Applicants living in EU/EEE countries for Autumn 2016! --Data ScienceTech Institute is honoured to have GE Digital to join its partners network and delighted for its #DataScience and #BigData MSc and Executive MSc programmes recognised by the French Government via Campus France under its prestigious "Programmes taught in English" section, for "Mathematics" and "Engineering and Technology", with all the leading French #HigherEd institutions.https://www.datasciencetech.institute/Campus France (using Flash):http://www.campusfrance.org/fria/taughtie/index.html?mfid=7http://www.campusfrance.org/fria/taughtie/index.html?mfid=4
22	우분투16에 TensorFlow 설치 가이드 입니다.
12	#QGM 싸이그래머 QGM(퀀텀 그래피컬 모델링=머신러닝의 50가지 그림자) : 파트 5 - 1회차 스터디 후기입니다.* 첫회 후기만 공유하겠습니다.* 발표자료는 모두 공개&공유됩니다(정리 중) - http://psygrammer.github.io/qgm/* 이 스터디는 네이버D2의 지원으로, 정통심리학 그룹 싸이그래머에서 진행합니다. - https://www.facebook.com/groups/psygrammer/어느새 QGM도 파트 5. 중반쯤 도달했습니다. 확률모델링 기반의 머신러닝 접근법의 책 중 하나인 머피의 머신러닝 책을 완독하는게 기본 목표입니다. 그리고 양자컴퓨팅도 끝내구요. 그 사이사이 딥러닝이 추가되었습니다. 또 심리학과 머신러닝의 관계성도 좀 보구요. 지금은 신경망 기반의 심리학인 '연결주의 접근'에 대한 책을 보고 있습니다. 이 책이 끝나면 베이지안 추론 기반의 수리인지심리학 책을 볼 것 같습니다.파트5쯤되니 새로 참여한 분들은 없었습니다. 이건 아쉽지만, 그래도 반가운 분들과 새 파트를 시작하는 것도 좋았습니다. 우선 제가 연결주의 심리학의 9. Computational models of visual selective attention: A review 를 발표했습니다. 우선 몸풀기로 심리학에서 'attention'을 어떻게 연구해왔는지 여러 이론들을 살펴봤습니다. 그 개념들 사이에서 visual selection attention이 어떤 위치쯤 있는지 맥락을 알고 싶어서였습니다. 다음 발표때 본격적으로 책의 내용을 보게됩니다. 그리고 '주의'에 대한 심리학 이론들을 살펴보면서 컴퓨터 사이언스 쪽에선 어떤식으로 도입하고 있는지도 잠깐 봤는데, 딥러닝의 '어텐션 모형'들을 보면 정말 그 창의성에 깜짝놀라게 되었습니다. 그리고 이어서 송근창 (Vicente Zumba)님이 머피의 머신러닝 책 - 11. Mixture models and the EM algorithm 를 준비해오셨습니다. EM 알고리즘에 대해서 주로 얘기했습니다. 일단 이번엔 K-means를 EM의 측면에서 봤구요, 다음 발표에 더 내용이 이어집니다. 수식가득한 책을 열심히 땀흘려가며 돌파해나가는 송근창님께 박수를.그 뒤에, 제가 벤지오 딥러닝북의 13 Linear Factor Models 를 전반부 했습니다. 이제부터 딥러닝의 unsupervised model을 본격적으로 공부하게 되는데요, 우선 generative model의 가장 간단한 형태인 linear factor model 중에서 Probabilistic PCA와 factor analysis에 대해서 살펴보았습니다. 수많은 데이터가 요구되는 상황에 도움이 되기 위해 데이터를 생성하는 확률모형을 구축하는 방식이 많이 연구되고 있는데 그 가장 간단한 모형으로 은닉변수가 관찰변수를 linear한 방식으로 generate하는 linear factor model에 대한 이야기로 벤지오 책이 시작하네요. 그 뒤에 오토인코더라던가..하는 것들이 이어서 나올 예정입니다. 일단 이번 시간엔 PPCA만 했고, 다음 발표때 ICA 등의 전통적인 linear factor model들을 좀 더 합니다. 이런 것들을 딥러닝으론 어떻게 대응할수 있는지로 이야기가 전개될 것 같습니다.마지막으로 고희연 (Heeyuen Koh)님이 양자 컴퓨팅 - 7. Quantum computers : Physical realization 부분을 발표해주셨습니다. 양자 컴퓨터를 어떻게 실제 물리적으로 구현하려는지 여러 시도를 살펴보았는데요, 이 스터디 참여인원과 목적을 고려하면 이번 7장을 심도깊게 살펴보는 것은 무리가 있는듯해서 고희연님이 일부 선정해서 발표하고 다음 8장으로 빨리 넘어갈 생각입니다. 아, 중간중간 여러 기초 수학 특강도 있을 것이구요. 양자컴퓨팅쪽을 혼자 이끌어가는 희연님께 언제나 감탄 중입니다.파트 첫날이지만, 나름 충실하게 진도를 나갔습니다. 무더위를 뚫고 스터디에 참여하신 분들 모두 감사합니다.
1	[cpu가 지원하는 28레인 vs 40레인에 따른 gtx1080 성능문의]gtx1080 2개를 사용환경에서gpu가 보드에서 PCIe 잡는 레인수가 각각- 16x + 16x로 구성할 때와 - 16x + 8x로 구성 할 때 (sli나 독립 모두 결국 8x+8x가 되나요? )차이가 많이 나는지 문의 드립니다. (병목현상에 의해 얼마나 속도가 저하되는지)이부분이 중요한 이유는, 40레인을 지원하는 cpu i7-5930k + x99 보드를 구성해야 해서 cpu 6700+z170 보다 비용이 많이 들어갑니다. 참고로 아래 동영상(gtx980, 딥러닝이 아닌 게임)에서는 별로 차이가 나지 않다고 하는군요. https://www.youtube.com/watch?v=rctaLgK5stA
4	부족한게 많은 학생이라 열심히 질문글만 올리고있습니다이번 질문은 데이터 셔플에 관한 질문인데요.예전에 신경망이론을 약간 공부할때에 어디선가 언뜻, 오버피팅의 우려로 인해 학습데이터를 셔플시켜주는게 좋다는 말을 들었는데요,지금 만들고 있는 모델에 csv를 읽어오는 과정에서읽어온 테이블을 트레이닝셋과 테스트셋으로 분리하기 전에 np.random.shuffle(array)함수를 통해 셔플을 한번 진행해줬더니10000번 트레이닝 후에 cost가 기존 0.4정도였던 것이 634수준으로 확 증가하였습니다.셔플 외에 다른 조건은 동일하구요,이론적으로는 유사한 loss로 수련하여야 할 것 같은데 그렇지 않은 이유가 있을까요? 아니면 shuffle함수가 제대로 동작하지 않는것일까요?만약 후자라면 rows를 shuffle할수있는 좋은 방법이 있을까요?	2	셔플에 문제가 있을 가능성은 적을 것 같구요,말씀하신 cost가 training 후 test set에 대한 error라고 가정하면, 2가지 가능성이 떠오르네요.1. 약간의 셔플로도 데이터셋의 특징이 크게 바뀔 정도로 데이터가 적거나(=네트워크 구조에 비해 데이터가 너무 적어서 neural net이 overfitting하고 있음)2. 뉴럴넷 트레이닝이 덜 되었거나. 1만번이라고 말씀하신 것이 세션이 돌아간 횟수를 뜻하신 거라면 stochastic gradient descent를 사용한다고 가정했을 때, global minimum으로 수렴하기에 충분한 시간이 흐르지 않은 경우일 수 있습니다. 제 경우 간단한 MNIST 예제를 적은 수의 hidden layer를 가진 CNN으로 훈련하는데도 최소 10만번 정도는 세션을 돌려야 쓸만한 결과가 나왔던 것으로 기억합니다 ㅎㅎ
2	환경적인 이슈가 있어서 문의드립니다.ubuntu 14.04(ec2)에서 jupyter를 이용해서 tensorflow를 쓰려고 하는데요. library 이슈가 있어서요.(전에도 비슷한 이슈가 있었는데.) jupyter는 library path를 아래와 같이 잡고  /home/ubuntu/anaconda2/lib/python2.7/site-packagespip 로 설치된 tensorflow는  /home/ubuntu/anaconda2/lib/python2.7/dist-packages를 보는데요. 임시적으론 "import syssys.path.append('/usr/local/lib/python2.7/dist-packages')"으로 처리해서 코드는 돌려보고 있는데 맘에 들지 않아서요.이는 anaconda나 virtualenv를 써도 jupyter에선 동일하게 발생하는 이슈입니다. 즉 jupyter가 보는 python library의 위치가 문제가 되는데요...혹시 이와 같은 경험이 있으신 분중에 해결하신 분이 있으신지 궁금합니다.(pycharm을 써야 하는건가... ㅠㅜ)	1	https://gist.github.com/yasushisakai/86da64df10581d37af709387f45f9312 여기 한번 참고해보세요
25	ubuntu 16.04에 tensorflow를 소스로 설치해봤습니다.바이너리로 설치하면 다른건 다 되는데 MNIST 예제에서 misaligned address error가 발생하더군요.http://blog.naver.com/kjpark79/220781100554혹시 저같은 분이 있다면 도움이 되길 바랍니다.
51	First Contact with TensorFlow을 번역해서 공개한 사이트입니다..
66	오늘 가능해진 Windows 10 1607 업데이트에서 CLI Ubuntu 사용이 가능해졌습니다.14.04 버전이고, 패키지 업데이트 및 업그레이드, python3-pip 인스톨 이후 리눅스와 같은 방법으로 TensorFlow를 설치한 뒤Sung Kim 님의 머신러닝 강의 코드 몇개를 돌려봤습니다.잘 돌아갑니다.	1	GPU버전도 구동되는지 알 수 있을까요?	0	lspci로 pci 디바이스가 잡히지를 않습니다ㅠㅠ	1	일단은 간단하게 윈도우에서 돌려볼 수 있는 것만으로 좋네요. ^^	1	gpu아직 안 됩니다 디바이스가 안잡혀요. cuda 가..
11	계속해서 RNN에 관련해서 질문드리게 되네요. 몇몇의 RNN 예제를 살펴보면서, Training data, Validation data, Testing data를 만드는 것에 대해서 의문이 생겨 질문드립니다.RNN은 다들 아시다시피 temporal pattern을 잡아내기 위한 목적으로 만들어진 NN 아키텍쳐입니다. 일반적인 NN는 다르게 학습하려는 데이터 자체의 순서가 중요한 의미를 가지고 있게 되고요.그럼 이때 우리가 데이터를 어떻게 나누어야 제대로 된 training, validation, testing set 으로 만들 수 있을까요?예를 들어 RNN 에게 각각의 t에서 [1,5,3,4,2,5,7,8,10,5,6,4,10,11,9] 의 데이터를 학습시키려고 한다면, 보통은 truncation step 에 따라서 ( 3이라고 가정하겠습니다) 데이터를x1 =  [1,5,3] x2 =  [4,2,5]x3 = [7,8,10]x4 = [5,6,4]으로 나누고 각각의 학습 데이터의 라벨은 y1 = [5,3,4]y2 = [2,5,7]y3 = [8,10,5]y4 =  [6,4,10] 로 만들것 일것입니다. 제가 살펴본 예제에서는 데이터를 임의로 섞지않고, 앞에서 부터, training, validation, testing 셋으로 나누었습니다. 예제1 : http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html예제2 : https://github.com/tgjeon/TensorFlow-Tutorials-for-Time-Series(질문1)허나, 이런식로 데이터를 앞에서 부터 나누게 되면 데이터를 우리가 충분히 임의로 나누었고, 모델의 일반화를 위해서 사용할 testing 셋이 그 역할을 제대로 수행할지 의문스럽습니다. (질문2)덧으로 보통은 우리가 nn를 학습시킬 때 데이터를 batch로 묶어 여러개의 데이터를 동시에 학습시키는데 이 때도 데이터를 배치로 묶을때 순서가 모델의 학습에 영향을 미칠지 궁금하네요.배치의 크기를 2로 가정하면, 첫번째 training batchBX1 = [[1,5,3],          [4,2,5]]BX2 = [[7,8,10],          [5,6,4]] 로 만들고 그에 해당하는 라벨은BY1 = [[5,3,4],           [2,5,7]]BY2 = [[8,10,5],           [6,4,10]]  로 데이터를 만들고 이 순서대로 RNN 을 학습시키고 validating 하고 또 testing 해야하는 건가요? 아니면 애초에 그런 순서는 의미가 없는 것일까요?글을 쓰며, 갑자기 생각이 든것은 우리가 truncation을 한다는 것 자체가 데이터의 dependency는 truncation step 안에서만 발생하기 때문에 우리가 나눠 놓은 데이터는 모두 독립적으로 발생한다는 것을 가정하고 모델을 훈련시킨다면 이런 모든 질문이 의미가 없을수도 있겠다는 생각이 들기도 합니다.항상 Tensorflow KR 그룹과 구성원들께 감사드립니다.박준영 드림	2	질문 1)과 2) 모두 data set을 분류 하는 방식에 대한 이슈라고 이해되는데요. 이와 관련해서는 여러가지 의견이 있습니다만 문제 발생가능성은 존재합니다.결국은 시간에 대한 관점이 중요해지는되요. 기본적으로 이를 해결하기 위한 가장 유명한 방법이 cross validation입니다. 데이터를 여러 그룹으로 나누어서 이를 각각으로 달리 배당해서 결과를 추출하는 방법입니다. 당연히 비용이 올라가는 이슈가 발생하지만 말씀하신 시간에 대한 가장 일반적인 해결방법입니다. 이는 여러 책이나 구글님께서 보다 자세히 알수 있으실 겁니다.개인적인 경험으론(워낙 오래전 일이지만..) 순차적으로(시간순으로) 데이터를 나누는것이 (정확히는 , Trainging+ validation, testing 이렇게 두가지를 시간순으로 구분)하는 것이 도움이 될때가 있었습니다. 모델 자체가 자체 보정기능을 가지고 있을 때인데요. 이전 건들을 가지고 최근  것을 평가하는 로직으로 구현된 모델이 cross validation으로 생성됨 모델보다 향후  저채 보정이 잘됩니다. 이는 어찌보면 당연한거지만 그런 상황도 있다는 것을 알려드리고 싶네요.	2	저도 몇 예를 보았는데 rnn 에서 크로스밸리데이션 하지 않고 그냥 몇 뭉터기 씩 잘라서 사용하는 것 같습니다. 말씀하신 BX1 BX2 로 표현된 방법입니다. 아마도 데이터가 충분히 많기 때문에 크로스밸리데이션할 필요를 못느끼거나 rnn 특성상 섞는 것에 부담이 있어서가 아닐까 합니다. 그래도 수십개의 배치로 나눠서 진행하면 학습시간도 좀 줄일수 있고 데이터를 섞는 효과도 약간 볼 수 있지 않을까 생각합니다. 다만 lstm의 상태 데이터를 저장하기 위한 메모리는 배치 만큼 곱으로 늘어나겠지만요.	9	안녕하세요. 우선 이와 관련된 질문은 rnn을 실제 구현해서 학습할 때 가장 실수가 많이 일어나고 헷갈리는 부분입니다.시퀀셜 데이터에서는 나이브하게 시간 축까지 랜덤으로 섞어서 트레이닝/테스트 데이터를 나눌 경우 테스트 셋이 오염되는 문제가 발생합니다.예를 들어 60초짜리 비디오에서 초당 10 프레임으로 이미지를 뽑았다면, 총 600개의 이미지가 생기는 데 이를 랜덤셔플링해서 7:3으로 트레이닝/테스트로 나누게 되면 학습에 쓴 이미지와 거의 차이가 없는 이미지가 테스트셋에 포함될 확률이 매우높습니다.이는 1초에 10장 뽑은 이미지들은 서로 거의 비슷한 정보를 담고 있는 데이터이기 때문입니다. 예를 들어 천천히 화면이 바뀌는 동영상의 경우 이 10장의 이미지는 거의 차이가 없다고 볼 수있습니다. 그런데 이 이미지들이 트레이닝과 테스트에 7:3 장씩 들어가면, 테스트 데이터가 트레이닝 데이터로부터 완전히 독립된 underlying true distribution에서 나온 샘플이라고 볼 수 없습니다. 따라서 크로스벨리데이션이 아니라 최소한 퍼센티지 스플릿을 해서 앞쪽을 트레이닝, 뒤쪽을 테스트로 써야 보다 나은 테스트 성능측정이 가능합니다.혹은 크로스벨리데이션을 하려면 시간축이 아닌 인스턴스를 기준으로 랜덤셔플링을 하시면 됩니다.예를들어 서로 독립된 동영상 10개에서 7:3 으로 크로스벨리데이션을 하는 것은 문제가 없지요.휴먼 액션 리콕니션 분야 등에서 공개된 데이터 셋 등도 모두 이런식으로 데이터를 나누고 있습니다.
12	NN를 트레이닝 시키다 보면, 다양한 형태로 loss를 정의하고는 합니다. 그 중 cross-entropy로 정의된 loss 함수의 경우는 제게 있어서 자연스럽지 않습니다. cross-entropy loss 로 loss를 정의한 경우 p(x)와 q(x)간의 엔트로피와 비스무리 한 걸 (?) 측정해서 그 것을 줄여나가려는 것을 목표로 트레이닝 시켜나가게 될텐데, 일단 NN의 출력물에서 p(x)와 q(x)를 정의하는것 조차 여간 의심스럽지 않습니다. 혹시 이부분에 대해서 아이디어를 가지고 계신 분들이 있으시다면 회신 부탁드리겠습니다. 미리 감사드립니다.	5	http://colah.github.io/posts/2015-09-Visual-Information/도움이 되실듯 하여 남겨봅니다 ㅎㅎ	2	softmax 아웃풋에서 맥시멈 로그 라이클리후드를 계산한 것이 크로스엔트로피 Loss 입니다~ 확률이론적으로 justified된 Loss라고 보시면 됩니다.
110	김홍배님과 양선희님이 공휴해주셔서 조금 보았는데 영어를 풀어쓰듯이 쓰면 python이 된다고 설명해주시네요.이번주말 5시간만 투자하시면 Python zero에서 hero로 만들어 준다는데... 한번 달려보아요~누가 TF zero to Hero 비디오 (3~5시간) 만들어도 재미있을것 같아요.	2	한국어 나레이션 판을 만들면 좋을텐데  ㅎㅎ	3	지금 들어보니 영어공부에도 매우 도움이 될듯. 천천이 말해줍니다.	1	다운로드해서 플레이시 속도를 천천히 해서 들으시면 도움이 됩니다.	5	https://mva.microsoft.com/ko/training-courses/python%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EC%86%8C%EA%B0%9C-8360?l=CrrhO0O8_6204984382  여기에 이미 한글자막제공하고 있습니다.	1	영어 영어 영어	0	감사합니다!	2	유튜브를 PC에서 보시면 속도를 빠르게 또는 느리게 설정하실 수 있습니다 ^^
37	TensorFlow를 시작하시는 분들을 위한 문서가 있어 공유드립니다~*	1	오 감사합니다!
14	텐서플로우를 공부중인 학생입니다.대용량의 csv파일(대략 600000*88)을 학습하고싶은데요, 양이 방대하다보니 loss가 너무 커서 NaN으로 표시되는것은 둘째치고라도GPU버전을 사용하다보니 OOM에러가 발생하더라구요.어떻게 학습시키는게 좋을까요?	0	sample이 60만개고 feature가 88개란 뜻이죠? 음 저정도면 design한 architecture가 복잡하지 않으면 batch size를 조절해서 oom은 피할 수 있을 것 같아요	0	일단 모델은 최대한 간단하게 설계하시고 어느정도 트레이닝이 된다는 걸 확인하신 다음에 conv이든 fc든 추가하셔야 할 것 같습니다	0	아니면 sample size가 넉넉하니 data를 10 fold로 나누시고, 10개에 대해 각각 모델을 만드신 후 최종적으로 ensemble한 방법으로 결과를 내는것도 방법일 것 같습니다	0	Dongjin Jang 아아 감사합니다. 앙상블모델을 만드는방법도 있겠군요.그런데 배치사이즈는 적용관련한 예제가 있을까요?ㅜㅜ 죄송합니다	0	텐서플로우 돌리는 환경은 어떻게 되나요? 메모리가 큰 환경으로 옮기는 게 방법일 수도 있습니다 (...)	0	배치사이즈에 질문하시는거보니 아마 full-batch를 이용해서 학습을 시키는 거 같은데요, 말씀하신대로 full-batch를 이용하면 VRAM 혹은 RAM 용량 때문에 OOM 에러가 뜨는게 맞습니다. 이를 방지하기 위해서 60만개 데이터중 **랜덤하게** 몇개를 골라서 (8, 16, 128, 256, 512..) 샘플링된 데이터만을 이용해서 학습을 시키고(mini-batch) 이 작업을 매우 많이 반복합니다. 여기서 iteration과 epoch라는 용어가 나오는데요,  쉽게 예를들어 설명하자면 만약 데이터의 개수가 100개이고 mini-batch 사이즈가 10개일때 한 epoch당 iteration의 수는 10개라고 보시면 될거 같네요. 구현을 어떻게 하느냐는 사람마다 다르긴하지만 https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py 이 예제를 참고하시면 될것같습니다.	0	그리고 배치와 별개로 loss가 NaN이 뜬다고 하셨는데 이건 아마 loss를 구할 때 tf.reduce_sum을 하셔서 그런거같네요. tf.reduce_mean을 하시면 각 데이터 loss의 평균을 구하기 때문에 모델이 diverge하지 않는이상 NaN이 뜨지는 않을거같습니다.
10	그럼 봇 개발은 어떻게 하는데.... 두번째 Bot Talk이 "봇 개발 101"이라는 주제로 8월 24일 저녁에 열립니다. 봇 개발 튜토리얼 및 개발 경험을 공유하는 자리로 마련됩니다. 이미 개발했거나 개발 중인 봇과 관련해 경험을 발표하고 싶은 분들은 댓글 남겨주세요. 참가 신청 및 자세한 내용은 아래 이미지 클릭해주세요.
10	안녕하세요, 구글 제품을 사용한 다양한 프로젝트를 전시하고 체험해볼 수 있는 Google HackFair 가 올해는 Maker Faire Seoul 과 함께 진행됩니다. 8월 19일(금)까지 참가 신청이 진행되고, 특히 TensorFlow 기술을 우대하고 있으니 재미있는 아이디어가 있으신 분들의 많은 참여 부탁 드립니다. ▶goo.gl/rYP98Y
5	안녕하세요, 이번에 tensorflow를 시작하려고 하는 학생입니다.다름이 아니라 gpgpu 환경구축부터 막힌 상태인데요, 도움을 받고자 글을 남기게 되었습니다. (cpu 이용방법은 잘 되었습니다)하드웨어 환경은 i7-6700K + gtx1060 인데요, 인터넷에 존재하는 다양한 설치방법들을 시도해 보았으나 gpu를 확인할수 없거나, 우분투 로그인 단계에서 로그인이 되지 않는 등(tty에서 실행시 역시 gpu확인불가..)의 문제가 있었습니다. 거의 6일동안 우분투만 30번은 넘게 설치한것 같아 너무 힘들어 도움을 받고자 글을 남겨봅니다...혹시 gtx10x0 시리즈로 gpu tensorflow를 성공하신 예가 있으신지요?	2	네 가능합니다. 그래픽드라이버와 쿠다설치,cudnn설치, bazel로 텐서플로 설치하면 가능하네요 (1080에서 테스트했어요)	0	ubuntu 14.04에 1080 설치를 했습니다. bazel 0.2, 0.3 모두 가능하였고 cuda 8.0, cudnn 5.0.5 사용하였습니다. 특별한 점은.. 중간에 에러가 났었는데 tensorflow/third_party/gpus/crosstool/CROSSTOOL에 "cxx_builtin_include_directory: "/usr/local/cuda-8.0/include"를 추가했더니 해결되었습니다.  http://www.pittnuts.com/2016/07/geforce-gtx-1080-cuda-8-0-ubuntu-16-04-caffe/ 여기 방법을 참고하여 설치하였습니다.	5	좀 길긴 하지만 제가 설치했던 절차입니다.도움 되시길... ^^블로그나 깃허브에 잘 정리했으면 좋았을텐데 제가 게을러서리...하시면서 문제가 되는 부분들을 공유하시면 여기 계신 분들이 도움을 드리지 않을까 싶습니다. ^^CPU: 6th i7 Skylake 6700Mother Board: Gigabyte Z170X-DESIGNAREGraphic Card: GEFORCE GTX-1080 x2Ubuntu 16.04 *After Install Linux, Upgrade the packagessudo apt-get updatesudo apt-get upgrade*Install nvidia device driversudo apt-add-repository -y ppa:graphics-drivers/ppasudo apt-get updatesudo apt-get upgradesudo apt-get install nvidia-current nvidia-settingsUbuntu Setup[System Settings]-[Software & Updates]-[Additional Drivers]+— NVIDIA Corporation:Unknown+— Using NVIDIA binary driver-version 367.35 from nvidia-367(open source)*Install CUDA and cuDNNsudo apt-get install libglu1-mesa libxi-dev libxmu-dev libglu1-mesa-devsudo sh cuda_8.0.27_linux.run –overridetar -xvzf cudnn-8.0-linux-x64-v5.0-ga.tgzsudo cuda/include/cudnn.h /usr/local/cuda/include/sudo cp cuda/include/cudnn.h /usr/local/cuda/include/sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*export PATH=/usr/local/cuda/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATHPython Module installsudo apt-get install swigsudo apt-get install python3-pipsudo apt-get install python-pippip3 install -upgrade pippip install -upgrade pipsudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-devsudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython3 ipython3-notebook python3-pandas python3-sympy python3-dev*Install bazelsudo apt-get install python-software-propertiessudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installer./bazel-0.3.0-installer-linux-x86_64.sh –userexport PATH=/home/oneway/bin:$PATHedit .bashrcadd following line to end of the filesource /home/oneway/.bazel/bin/bazel-complete.bash*Install early version of gcc/g++sudo apt-get install zlib1g-devsudo apt-get install libc6-dev <>sudo apt-get install gcc-4.9sudo apt-get install g++-4.9sudo update-alternatives –remove-all gccsudo update-alternatives –install /usr/bin/gcc gcc /usr/bin/gcc-4.9 10sudo update-alternatives –install /usr/bin/g++ g++ /usr/bin/g++-4.9 10*Compile TensorFlowbazel cleanbazel build -c opt –config=cuda //tensorflow/cc:tutorials_example_trainerbazel-bin/tensorflow/cc/tutorials_example_trainer –use_gpubazel build -c opt –config=cuda //tensorflow/tools/pip_package:build_pip_packagebazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkgsudo pip install /tmp/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whlsudo pip3 install /tmp/tensorflow_pkg/tensorflow-0.9.0-py3-none-any.whl	2	두분이 보내주신 절차를 참고하여 성공하였습니다!거진 일주일만에 성공하니 감회가.. ㅜㅜ시간이 되는대로 빌드에 성공한 방법을 공유할 수 있도록 하겠습니다.	0	혹시 docker 환경에서는 gpu로 돌릴 수 있는 방법이 없나요?
110	http://news.mt.co.kr/mtview.php?no=2013052615345024115크아아아아 ㅠㅠ문제가 된다면 삭제하겠습니다.	0	멋진 분이시지요. 딥러닝에 대해서도 아주 쉽게 기르치시고..	0	감사합니다	0	감사합니다	1	이런분이 계셔서 다행입니다유튜브강의 잘 듣고 있습니다	0	멋있습니다~ ^ ^	0	같은 경상도 분으로 자랑스럽죠 특히 그 경상도 악센트로 설명하시는게 너무 귀에 속속 잘들어와요 ㅎㅎㅎ 마치 아는 동네 형이 설명해주는듯한 느낌 ㅎㅎㅎ	0	존경하는 교수님	1	그런사연있었군요멋지십니다^^
3	안녕하세요. 최근에 텐서플로우를 공부하기 시작한 학생입니다. 처음으로 직접 간단한 연습 코드를 짜보려고 하는데 잘 안되서 질문 드립니다. TF에서 제공하는 tf.nn.rnn을 사용하지 않고 제가 scan 함수를 이용해서 rnn을 구현해 보려고 하는데요 scan 함수의 사용법이 잘 이해가 되지 않습니다. 몇몇 예제들, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functional_ops.mdhttp://r2rt.com/inverting-a-neural-net.html을 보고 이해를 하려고 하는데 잘 안되네요. lamda a,x: 이 부분도 정확히 이해가 안되고요. 혹시 TF에서 scan함수를 많이 사용해 보신분이 있으신가요? scan함수를 이해하기 쉬운 예제들이 있으면 알려주시면 감사하겠습니다.제가 하려고 하는 것은 예를들어 rnn이 1dim 의 input을 받고 batch로 학습하는 경우에x = tf.placeholder(tf.float32,shape=[batch_size,time_step,1], name= 'input')cell = tf.nn.rnn_cell.BasicRNNCell(num_rnn_h)init_state = cell.zero_state(batch_size, tf.float32)rnn_outputs, final_states = tf.scan(lambda a, xi: cell(xi, a), tf.transpose(x, perm=[1,0,2]), initializer= init_state)이런식으로 해주면 되지 않을까 했는데...(잘 이해되지는 않지만 두번째 링크의 코드를 대충 바꿔보았습니다.) 에러가 뜨네요. 뭔가 dimension이 잘 맞지 않는 것 같긴한데...  고수님들의 도움이 필요합니다. 혹시 쉽게 설명해주실 수 있는 분이 있으시면 어떻게 사용해야되는지 알려주시면 감사하겠습니다.
1	혹시, 윈도우에서 CNTK를 구동해 보신분 계신가요? 텐서와 비교했을 때 성능 측면에서 차이가 많은지요?	0	성능이라면 인식률을 말씀하신건지요? MNIST DB를 이용한 인식률에서는 정확한 수치가 기억나진 않지만 매우 비슷했었습니다.
1	Tensorflow를 공부하고있는 학생입니다.Tensorflow 로 얼굴을 식별 할 수있는 CNN 을 설계하였다면 이를 사용하여 다양한 사물이 포함된 큰 사진에서 얼굴을 인식하여 localization 해줄수있는 방법을 tensorflow 로 어떻게 구현 할수있는지 궁금합니다ㅜㅜ	1	컴퓨터비전의 object detection분야에 해당하는 기술입니다cnn이나 tensorflow 는 그 응용기술이라고 생각합니다tf가 python 기반이므로 pil이나 opencv python과 잘 섞어서 구현해볼 수있습니다Piotr dollar의 acf 등 프로젝트페이지를 추천합니다https://pdollar.github.io/toolbox/
6	안녕하세요, forward pass, backward pass 관련해서 CNN 알고리즘 기준으로 궁금한것이 있어 질문 드립니다.Tensorflow의 예제 소스 중 alexnet benchmark가 있어 실행시켜봤는데요, backward pass의 수행 시간이 forward pass보다 약 2.5배 정도 오래 걸리는데 이 이유를 잘 모르겠어서 질문 드립니다. 제가 질문을 올린 이유는 CNN에서는 forward pass에서 convolution 및 max pooling으로 많은 데이터 접근 및 연산이 일어나며 backward pass는 back-propagation을 통한 weight 값 변경 정도만 할 것이라 생각하여 전체 CNN 연산 중 backward pass의 연산 비중이 적을것이라 생각하여서입니다.(본 문장은 임재영님의 답변을 통해 수정한 내용입니다.) 알고리즘에 대한 지식이 아직 부족하여 제가 잘못 생각하고 있는것이 존재하는것 같은데, 혹시 제가 잘못 생각하고 있는 부분에 대해서 말씀해주시거나 또는 backward pass가 forward pass보다 시간이 많이 걸리는 이유(예를 들어 back-propagation에서 ~한 이유로 오래 걸림)에 대해서 아시는분이 계시면 답변 주시면 정말 감사드리겠습니다.	1	음.. backward pass로 갈수록 데이터 사이즈가 작아진다고 말씀하셨는데.. 아마 forward-backward pass 개념을 잘못 이해하고 계신듯 하네요.간단하게는 forward pass는 inference 과정, backward pass는 learning 과정이라고 말씀드릴수 있을 것 같습니다.아래의 주소에도 간략하게 설명이 있으니 확인해보세요.http://caffe.berkeleyvision.org/tutorial/forward_backward.html	1	GPU를 사용하는 경우 convolution이나 max pooling등의 연산은 매우 빠르게 가속됩니다. 아마 순차적으로 많은 데이터를 접근한다고 생각하시는것 같은데 실제로 거의 한방에 연산이 끝날겁니다. 따라서 forward prop이 backward prop보다 연산량이 많다는건 사실이 아닐 것 같습니다. 다만 저도 왜 두 배 까지 시간차가 나는지는 좀 궁금하네요.	1	cnn 에서 가장 큰 연산은 conv입니다 하드웨어 연산양따질때는 아예 conv pooling layer만 계산 하기도 하고요Backward 에도 conv연산이 들어갑니다 stride 1 conv의 transpose가 kernel을 뒤집은 conv랑 같기때문입니다Pooling은 mask를 저장했다 이전 layer error를 채워넣어야는데 gpu가 이런 indexing 처리에 적절하지 않아서 느린건 아닌가 생각도 드네요그외 normalization은 const 연산이니까 더 가벼울것 같고요Backward 에서 optimizer가 계산하는시간도 같이 들어간다면 그것도 만만찮을것 같네요Adam류의 것은 feature balance 를 고려하기위해 차원하나하나 계산하니까요(이건 다시 생각해보니 vector 연산이니 속도차이는 크지 않을 것 같네요)정확히 알진 못하고 추측만 해서 좀 자신은 없네요 ㅜ ㅜ
1	안녕하세요. 우분투설치가 안되어서 질문드립니다.USB부팅을 하면 우분투를 체험해볼 것인지 바로 설치해볼 것인지 나오는 화면 다음에 바로 Ignoring BGRT : invalid status 0 (expected 1)이 뜨면서 어떤한 커맨드도 듣지 않고 강제종료밖에 되지 않습니다.기존에 듀얼부팅으로 윈도우10과 우분투14를 사용하고 있었는데 오늘 우분투 무한로그인어 걸려 새로 설치하려 하니 저런 증상이 나타나네요. 윈도우를 깔지 않고 우분투만 설치하려 해도 윈도우를 설치하고 우분투를 깔려해도 저럽니다.우분투 부팅usb가 잘못되었나 다른 컴퓨터에서 해봐도 정상이고 새로 구워봐도 마찬가지네요.. 설치가 되던 컴퓨터인데 갑자기 이런 이유가 무엇인지 참 난처합니다. 혹시 솔루션을 아시는 분 계시나요?
7	안녕하세요. Tensorflow 관련 코드들을 매번 터미널에서 돌렸는데, 파이참에서 하면 좀 더 나을거같아서 파이참을 설치했습니다. 헌데 import tensorflow as tf 수행 시에 임포트 에러가 나네요. 구글링해서 이방법 저방법 보았으나 같은 상태네요. 해결 방법이 있을까요??	1	그룹 내 파이참 관련 글을 참고하여 해결하였습니다. virtualenv 로 텐서플로우 활성화 시킨 후에 파이참을 켜면 코드가 돌아가네요. project interpreter는 Python 2.7.6 virtualenv at ~/tensorflow 로 설정하였습니다. 혹시나 이와 같은 문제를 겪고 계신 분이 계실까봐 댓글 남깁니다~	0	혹시 docker에서 텐서플로우 이미지로 실행시킬때 파이참을 사용하고 싶은데 네트워크 컴파일인지가 필요하다고 하던데 설정방법을 아시나요?리모트 컴파일기능은 커뮤니티버젼엔 없지만 프로에는 있어서 아카데믹버젼으로 받아서 실행해보니 도커에 연결이 안되더군요 혹시 아신다면 알려주시면 고맙겠습니다
6	안녕하세요. Tensorflow를 이용한 머신러닝에 관심이 있는 학생입니다. GPU-Enabled docker container가 있던데, 윈도 상에서 이를 이용해서 tensorflow gpu버전을 실행할 수 있을까요?원래는 windows 10에서 bash를 이용하려 했으나 그 경우는 gpu를 사용할 수 없다고 본 적 있는데.... 8월2일 정식 업데이트에서는 gpu가능하게 바뀔까요	1	윈도우에선 gpu 사용이 안됩니다.	0	현재로써 윈도상에서 gpu버전은 사용 불가능합니다	0	지금이라도 운영체제는 리눅스를 메인으로 하기 위해 노력하는걸 권장합니다.	1	저도 비슷한 노력을 했다가 그냥 우분투로 돌아 섰습니다....윈도우 미워요.. T_T	0	아직 테스트는 안해봤습니다만 gpu버전의 도커 nvidia-docker 에서 tnesorflow gpu버전을 지원하는 것으로 알고 있습니다. 그부분을 찾아보시는게 어떨까요?
68	딥러닝 기술의 총아라 할수 있는 VQA의 Challenge에서 국내팀들이 선두를 다 차지하고 있다는 반가운 소식입니다. Hyunseok Min 님의 글입니다. (FB share하니  Hyunseok Min님의 글이 없어져 아래 붙여드립니다.)VQA를 돌리려면 이미지 처리와 NLP가 동시에 필요하므로 논문 한번 읽어보고 직접 구현해보시면 매우 도움이 될듯합니다.----Hyunseok Min8 hrs · Suwon올해 CVPR VQA Challenge Workshop에서 우리나라 팀(삼성 AI랩, Naver labs, POSTECH 한보형 교수님.. 현재 결과에는 삼성이 2위... 흠...)들이 2위부터 5위까지 차지하는 기염을 토했다는 소식은 다 들으셨을겁니다. 그런데 논문을 읽어보시면 아시겠지만 아이디어가 많이 비슷합니다. (물론 제가 아는게 없어 비슷하게 보이는거겠지만요..)오늘 소개 시켜드릴 논문은 그 대회에서 1위를 한 논문인... Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding (https://arxiv.org/abs/1606.01847) 입니다. 발표자료는 http://visualqa.org/static/slides/vqa_final.pdf 에 공개되어 있습니다. 다들 비슷한 알고리즘을 가지고 있는데 왜 이 사람들이 1등인지 궁금해서 -_- 기분도 꿀꿀해 읽어봤습니다.작년부터 VQA 관련 논문을 읽어보면 늘 포함되는 개념이 attention 개념입니다. 뭐 물론 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (http://arxiv.org/abs/1502.03044)과 같이 Image Caption Generation에서도 attention개념이 들어왔었죠. 단어를 볼 때 늘 전체 이미지보다는 특정 영역이 더 관계가 있으니깐요. VQA에 와서는 질문을 구성하는 요소가 하나 혹은 다수의 attention 영역과 관계가 있을 수 있어 이 관계를 더 복잡하게 분석해야 했습니다.한마디로 질문 각 요소 벡터와 영상의 attention을 표현하는 벡터들의 요소간의 관계 정보를 넘겨줘야 합니다. 그런데 보통 Deep learning에서 이질적인 두 벡터의 정보를 넘겨줄 때, 주로 쓰는 방법은 그냥... concatenate... 그냥 연결해서 넘겨주었습니다. 앞에서 어떻게든 웨이트들이 훈련되어 알아서 되길 기도하는 맘으로... 그런데 그러면 두 벡터의 요소들간의 관계가 잘 학습이 안 되어 최근 Bilinear CNN Models for Fine-grained Visual Recognition (http://arxiv.org/abs/1504.07889) 같은 논문에서는 bilinear pooling을 적용했습니다. 쉽게 말해 두 벡터를 outer product (와 비슷하게.. 정확히는 좀... 다를 수도..) 처리하였습니다. 그런데.. 두 벡터들의 관계는 자세하게 정리할 수 있을 거 같은데, 이게 사이즈가 엄청 커져버린다는 점이 문제라 VQA에서는 잘 안 쓰여졌습니다. 그런데, 올해 이 1등한 팀 연구실 옆자리 팀이 한 논문을 발표합니다. Compact Bilinear Pooling (https://arxiv.org/abs/1511.06062)이라는 논문으로 위에 말씀드린 Bilinear Pooling을 compact하게 처리할 수 있는 방법이죠. 그래서 위 논문은 질문과 영상의 관계를 더 잘 pooling할 수 있게 되었습니다. 그게 핵심 아이디어라고 논문에서는 얘기하고 있습니다. 물론 Compact Bilinear Pooling 논문을 읽어보시면 아시겠지만, kernel을 compact하게 할 때 쓰인 아이디어들이 쓰였고, 그걸 적용하기 위해 적당한 기술을 변형하긴 했습니다.뭐 우왕좌왕 설명했는데요... 이번 VQA 쪽 논문을 보면서 느낀점은...1. Deep learning기반한 영상 기술 보다는 NLP 쪽의 기술 발전, 그리고 기존 머신러닝의 전통적 기술들이 막혀 있던 한단계를 넘는데 아주 중요하게 작용했다는 점입니다. (물론...ResNet 킹왕짱!!) VQA 논문들을 읽어보면 영상쪽 특징은 그냥 ResNet.. 그것도 152계층.. (물론 location 정보가 살아있을 수 있는 적당한 계층을 써야하겠지만요..) 그 이외에 영상처리쪽에서 큰 변화는 감지하지 못 했습니다. NLP 분야 지식과 기존 ML쪽 기술들이 융합되는 모습이 더 새롭게 보였습니다.2. 올해 1등한 팀보다 더 이슈가 되기도 했고, 제 까막 눈에도 멋졌던 논문은 Neural Module Networks (https://arxiv.org/abs/1511.02799)이란 논문입니다. 예전 소개드린 Dynamic filter network (https://arxiv.org/abs/1605.09673)와 DPP Net(http://arxiv.org/abs/1511.05756)과 같이 상황에 따라 달라지는 Network라고 생각하시면 되는데 그 정도가 더 심합니다. (이 논문은 향후에..리뷰를..) 이렇듯 하나의 고정된 Network로 VQA와 같은 다이나믹한 문제를 풀 수 없기에 질문에 맞게 변형될 수 있는 방법에 대한 고민이 나왔습니다. 이러한 시도는 다른 머신러닝에도 적용될듯 합니다. 고정된 문제가 아닌 다이나믹한 문제에 적용될 때 아직 갈길이 멀기 때문입니다.3. 한보형 교수님 제자들 짱..이라는 점? 올해 2위였던 Naver에 핵심 인력 중 하나가 한보형 교수님 연구실 졸업생 남현섭씨고 (제 기억엔 VOT 2015때도 우승 먹었던 분이죠..), 삼성분들도 한보형교수님 연구실과 산학을 진행한 팀이라고 알고 있고, 노현우씨야 한보형교수님 제자로 유명하시니... -_- .. 참가한 한국팀 곧곧에 한보형교수님과 제자들이... 부...부러워요.	1	삼성에서도 이번에 좋은 결과를 냈고 지속적인 투자 중입니다. 많은 관심 바랍니다. Jihie Kim.	0	Ji Soo Yi 교수님 팀인가요? 축하 드립니다.	0	Junyoung Park
140	Yong Joon Moon 님이 소개해주신 Fluent Python책에 나온 예제들을 모아놓은 곳입니다. 한번씩 다 읽어볼만한 좋은 코드들입니다.https://github.com/fluentpython/notebooksTF를 잘 하시기위해서는 Python에 유창하시면 더 좋을수 있습니다.	4	감사합니다.교수님 2013년 인터뷰 기사보고 교수님같은 사람이되고자 오늘도 화이팅 하려고합니다.	4	저도 교수님 같은 사람이 되고 싶습니다. 방학은 제주도에서 보내고 싶습니다 T.T	6	이 책 번역서도 최근 나왔습니다. 한빛미디어 신간 <전문가를 위한 파이썬>입니다.  http://goo.gl/vVGwHl	1	감사합니다. ^^
10	안녕하세요. RNN을 공부하고 있습니다. 텐서플로우에서 제공해주는 튜토리얼 중 ptb_word_lm 이라는 예제가 상당히 괜찮아 보여서 조금 코드를 뜯어보았습니다.코드 중에서 num_steps = 20, hidden_size = 200 이 있습니다. 일단 hidden_size는 RNN의 사이즈(time_stamp 라고도 이해하고 있습니다) 를 이야기하고 있는데 num_step 이라는 파라미터는 무엇을 조정해주는 것인지 잘 이해가 가지 않습니다.num_steps가 사용되는 부분을 찾아 봤을때, 아무래도 RNN의 히든레이어를 계속적으로 feed 해줄때 사용하는 것으로 보입니다. 그렇다면 num_steps와 hidden_size가 같아야 할 것 같은데, 왜 이런 차이를 보이는지 알고 싶습니다.아래는 ptb_word_lm.py 의 코드입니다.	5	hidden size는 히든 레이어의 뉴런 갯수 입니다. num step 은 미니배치 방식에서 그래디언트를 업뎃하기 전까지 모델에 주입할 데이터의 갯수 입니다. hidden size는 num step과는 상관없고 단어를 lstm에 임베딩하는 부분에 관련되어 있습니다.	1	RNN을 막 시작한 상황이라 잘 모르겠지만 Comment를 보면- num_steps - the number of unrolled steps of LSTM- hidden_size - the number of LSTM unitsnum_steps는 unrolled(unfolded) steps이니 한번에 feed되는 sequence수(time window)에 해당되는 듯 하고, (적으신 글을 보면 생각하고 계신 hidden_size의 의미가 실은 num_steps인듯 합니다.)hidden_size는 LSTM의 Cell 내부의 memory크기를 뜻하는 것 같습니다. class BasicLSTMCell가 구현된 rnn_cell.py를 보시면 좀 더 이해가 빠르실 듯 합니다. (여기에선 hidden_size가 아닌 num_units로 사용됩니다.)https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py
63	최근 열렸던 SciPy 2016: Scientific Computing with Python Conference 발표된 92 video 들입니다.https://www.youtube.com/watch?v=oqfKz-PP9FU&index=7&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6이중 Hanna 연구원의 머신러닝관련 강의를 듣고 있는데 정말 유창하시네요. Python을  ML에 이용해야 하는 이유도 나옵니다.이 비디오 말고도 볼만한 비디오들이 정말 많은것 같습니다. 즐거운 한주가 될것 같습니다.
92	수준 높은 책이 번역되었네요메뉴얼을 찾으면서 보던 내용이 잘 정리가 되어있는 듯...
39	FYI :-)
61	파이썬을 다시 정리해서 올립니다기본도 중요해서요
7	이제 막 텐서플로우 설치하고 들어왔습니다.혹시 Mac에서 Tensorflow 개발환경은 무엇을 사용해야 하나요?기승전 Eclipse인가요?	5	기승전 Pycharm이나 Atom일지도...	0	쥬피터죠	0	또 pycharm 인가요?	4	파이참참되다	0	파이참 추천합니다.	4	vi.....	0	스파이더..	0	저는 그냥 Xcode는 에디터로 쓰고, 나머지는 command mode에서 합니다.	0	파이썬은 파이참으로!	0	jupyter 추천~~논문이나 gihub에서 소스코드 공유를 jupyter로 해줍니다	0	익숙한 개발 도구 emacs를 ...	1	처음 배울때는 jupyter가 편하다가 직접 데이터처리하고 모델 개발할 때 pycharm으로 넘어가게 되네요..	1	파이참 추천	0	Pycharm or vim with some plugins
3	안녕하세요.. 딥러닝 관련해서 보다보니.. vgg라고 되어 있는 게 있는데 정확한 의미가 무엇인지요?	0	imagenet에 참가한 팀 이름입니다. (https://arxiv.org/abs/1409.1556)	1	Oxford대학 Visual Geometry Group에서 이미지넷 참가할때 VGG팀이름으로 나갔는데, 성능이 좋아서 그때 사용된 모델이 유명해지면서 그 모델을 그냥 VGG라고 많이들 부릅니다. http://www.robots.ox.ac.uk/~vgg/research/very_deep/	1	ㅍㅎㅎ
33	이미지 분석에 꼭 필요한 딥러닝 기술을 정리한 자료입니다.Object proposals, Detection, Recognition, and Segmentation 별로 최신 기술에 대한 관련논문의 자세한 설명이 있습니다.“Deep Learning for Computer Vision, Object Analytics”, Xavier Giró-i-Nieto https://www.slideshare.net/mobile/xavigiro/deep-learning-for-computer-vision-24-object-analytics-lasalle-2016중요한 몇 개의 논문에 대한 알기 쉬운 설명자료도 있습니다. “Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition”, ByungIn Yoohttp://slideplayer.com/slide/5277459/“Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks”, Amaia Salvadorhttps://www.slideshare.net/mobile/xavigiro/faster-rcnn-towards-realtime-object-detection-with-region-proposal-networks
19	박은정 (Lucy Park) Sung Kim 슬랙 가입 관련해서 문의가 자주 오는데,https://tensorflowkr-login.herokuapp.com 을 상단이나 사이드바에 붙여 주셨으면 좋겠습니다~	0	어, 이거 뭔가요. 누르고 메일적고 봤는데...?! 무슨용도의 슬랙인가요ㅠㅠ 여기 텐서플로kr 가입자면 전부 가입해도 되는건가요?	3	가입 링크 사이드바에 추가했습니다 :)
30	스터디 하면서 수정했어요	1	감사해요^^	1	덜덜덜 2003페이지!!
56	안녕하세요. 최근에 TensorFlow와 다른 딥러닝 라이브러리 간의 속도 이슈에 관한 질문을 받아서 글을 올립니다.우선 결론부터 얘기하자면, batch_size가 작고, 모델이 단순할 수록 TensorFlow는 속도가 느려지고, 반대로 batch_size가 크고 모델이 복잡할수록 이런 속도 차이는 사라진다고 알려져 있습니다.https://github.com/tensorflow/tensorflow/issues/120https://www.reddit.com/r/MachineLearning/comments/48gfop/tensorflow_speed_questions/링크된 글을 잘 읽어보면, Theano와의 속도 비교에서 batch_size가 작을 때는 거의 5~10배 이상 느린 반면, batch_size가 커질수록 속도차이가 무의미할 정도로 사라집니다.이는 session.run()을 실행하는 데 overhead가 발생하여, session.run()을 자주 실행할 수록 이 overhead가 누적되어 상당한 속도차이를 일으키는 것으로 보입니다.다만, 실제로 의미있는 실험/연구/개발은 모두 방대한 데이터와 복잡한 모델을 사용하는 만큼, 실질적으로 이 overhead는 무시할 수 있는 수준입니다.또한 TensorFlow는 다른 딥러닝 라이브러리와 달리 Multi-gpu 환경에대한 확장성을 설계서부터 고려했기 때문에, 이러한 Multi-gpu 환경이 일반화가 되는 미래 시점에서는 TensorFlow가 속도 면에서도 더 효율적일 것이라고 예상합니다.감사합니다.	2	좋은글 감사합니다.	0	batch size 정의는 어떤것인가요?	0	Stochastic gradient descent를 위한 적절한 batch size를 알기 위해 저희 페이지의 이전글을 검색하던 중 제가 원하는 내용과 비슷한 것 같아 질문 드립니다.CPU의 메모리를 많이 사용하고자 CNN에서의 batch size를 크게 잡으려고 하는데 어느정도까지가 허용되는 범위인지 알고 싶어 질문 드립니다.인터넷에 검색을 해보면 대부분 batch size를 256을 최고값으로 두고 있는것 같은데 링크해주신 페이지에 접속해보니 theano와의 비교를 위해 batch size를 8192까지 사용하더군요.저의 경우는 batch size를 2048정도까지 사용하면 좋을 것 같은데 이 값이 타당한지에 대해서 답변해주시면 감사드리겠습니다. 만약 관련 링크 또는 논문이 있으면 첨부해주시면 더욱 감사 드리겠습니다..^^	0	감사합니다. 확실히 적은양의 데이터를 사용할 때는 batch size의 크기를 늘이니 트레이닝 속도가 엄청 빨라졌습니다.그런데 추가적인 궁금증으로 batch size를 크게 함에 따라 생기는 accuracy 값의 변화가 있는지 궁금합니다.
0	thx for accepting
9	혹시나 CUDA쓰시는 분...아직 CUDA 8.0 으로 설치하지 마시고 다시 RC버전 혹은 7.5로 다운해서 쓰세요. 어제오늘 생긴 아주 뜨끈뜨근한 버전이라 그런지 무슨 문제가 생겨도 찾아볼 자료가 n당측 자료 말고는 저~~언혀 없네요 ㅠㅠ 그리고 이전 7.5랑 8.0RC에서 돌아가던 코드가 안 돌아가는 경우도 있어요. (New) Unified memory 부분 바뀌었다는데 그 부분 더 공부하면서 자료들 나오면 시도해보는게 좋을 듯 합니다.특히 pascal 아키텍쳐 gpu 쓰시면 더더욱;;
6	구글은 TensorFlow로 어떻게 돈을 벌려고 하는 걸까요?Tensorflow나 PaddlePaddle을 모든 사람에게 무료로 공개함으로서 구글과 바이두가 얻는 이득은 뭘까요?"딥러닝의 스탠다드가 되기 위해서!"라는 답은 많이 들었는데, 스탠다드가 되어도 계속 무료로 배포하면 구글 입장에서는 돈이 안 되지 않나요?구글과 바이두는 단지 딥러닝 계의 C+, 파이썬 같은 무료 랭귀지를 만들고 싶은건가요? 많은 분들의 의견을 기다립니다~ ^^	1	진부한 의견이지만, 생태계를 잡으려는 측면도 있지 않을까요? 당장 수익으로 이어지진 않아도, 장기적인 시각에서 머신러닝 또는 딥러닝의 빅브라더로써 영향력을 행사하기 위해서? 이에 반발해서 다른 엔진들이 등장하겠지만, 메인 스트림을 주도하겠죠?	4	구글의미래라는 책을 읽어보시면 왜 구글이 대부분의 신기술들을 무료로 배포하는지 아실 수 있습니다 일단 쉽게 얘기하면 회사 마인드가 돈을 벌려고 무언갈 만드는게 아니라고 보시면 됩니다 수익은 이미 검색 광고등으로 충분히 취하고 있고요 책한번 읽어보시길 추천 드릴게요	7	구글이 tensorflow 를 공개하기전에는 내부 커뮤니티가 20개 미만이었다가 공개하니 수천개로 바뀌었고 논문들이 모두 tensorflow로 바뀌었습니다. 구글이 내부 AI 프로젝트를 수천개를 하고 있는데... 인력과 기술을 도입하는 것 엄청 쉬워졌죠. 이것의 가치는 돈으로 따질수 없죠. 다들 시간 싸움이니까요. 그러면에서 보면 바이두는 이미 졌죠. 나머지야 말할 필요없구요.	4	업계, 학계에서 널리 쓰일수록 구글은  우수한 엔지니어를 추가적인 교육 없이도 데려올수있지 않을까요. + 덤으로 공짜 오류 수정 커밋도 받고.... 결국엔 엔지니어 인력 전쟁 이니까요.	0	생태계를 구축한다 것은 당장의 매출로 얻는 빙산의 일각이 아닌 수면 아래 가려있는 무한의 힘을 갖게되고, 사실상 그 기술의 핵심이 되기때문에 중요한 비즈니스가 될 수 있습니다.	0	플랫폼 장악이 갖는 힘이 있죠. 괜히 마소나 구글, 애플이 os를 무료화하고  오픈 플랫폼 생태계를 구축하는 것이 아니죠.	0	회사가 수익 창출을 무시할수 없지만 구글의 이와 같은 배경엔 좀 더 큰 그림이 있다고 보는게 맞다고 봅니다. 예를 들어 미국이 그렇게 자연과학에 투자해서 얻은 것들을 보면 현재의 사회 전반에서 발생하는 긍정적 효과 및 자원 그리고 이를 통해서 관련 인력이 미국이나 해당 발전 국가로 향하는 결과를 낳았으니깐요. 향후 머신러닝을 비롯한 데이터 과학 분야가 사회 전반을 지배하게 되었을 때 이와 관련된 기술 원천 및 특허 그리고 분야를 선도한다면 말그대로 지배자가 되지 않을까 생각합니다. 마치 삼성 회장 가족이 단 몇 퍼센트를 가지고 몇 백조 짜리 회사를 주무르듯이요. 결국 핵심을 누가 가지고 있는냐는 싸움에서 내 바닥을 넓히겠다는 생각이 아닐까 생각됩니다.	2	구글이 tensorflow로 이미 돈을 벌고 있는건 없습니다. 따라서 무료 공개 한다고 해서 회사 수익이 줄어드는게 아닙니다. tensorflow로 deep learning 연구를 할 수록 점점 확장되겠죠. 현재 tensorflow는 많은 deep learning algorithms 중에서 일부만 가지고 있기에 확장성이 중요합니다. 물론 전문 인력 고용에도 큰 효과가 있습니다. 구글 클라우드에서 tensorflow룰 사용하면 큰 수익 효과가 있습니다.	0	initiative / data / pioneering / fostering ecosystem by contribution 정도가 되겠습니다.	0	사업모델도 없이 뛰어난 딥러닝전문가 몇명 있는게 전부인 회사였던 딥마인드를 인수한것처럼 생태계조성과 관련 인력 확보등의 투자개념이겠죠	0	딥러닝생태계 선점!!! 에 한표 입니다! 긴호흡으로 가겠죠..
28	초보지만 다른 초보님들에게 경험을 공유하기위해 올려봅니다.[Windows 10 1주년 기념판 Pro 이상에서 TF 설치하기]Windows에는 보통 Docker Toolbox(최근엔 Docker for Windows가 나옴)을 이용하는 경우 Virtual Machine위에서 실행되기 때문에 VM의 제약으로 인하여 느릴 수 밖에 없었습니다.그러나 Win 10 1주년 기념판에는 Windows Kernel 위에 Ubuntu User Mode를 올려 제공하고 있습니다.(아직은 Beta 입니다만)이렇게 해서 예제를 돌리면 윈도우 작업 관리자에 Python 프로세스가 보이고 CPU도 Docker와는 다르게 모든 Core를 사용하면서 빠르게 돌아갑니다.윈도우에서 TF를 구동하시려는 분께서는 참고하시기 바라며 설치 방법은 아래와 같습니다.- 설정 -> 업데이트 및 복구 -> 개발자용 -> '개발자 기능 사용'에서 '개발자 모드' 선택- 제어판 -> 프로그램 -> '프로그램 및 기능'의 'Windows 기능 켜기/끄기' -> 'Linux용 Windows 하위 시스템(베타)' 선택- '명령 프롬프트'를 관리자 권한으로 실행- bash 실행	0	어서 정식패치가 이루어졌으면 좋겠네요 ㅎㅎ	0	아쉬운것은 bash에서 GPU에 접근하지를 못해서 CPU로만 계산해야 하더라고요, 만약 GPU에 접근 가능하다면 그건 그거대로 편할텐데요...	1	와...MRO 전략과 동일한 스텝이군요!! 역시 발빠른 마소!! 그래도 네이티브 환경에서 사용하는 것이 여러모로  좋을 듯 합니다. 튜닝의 끝은 정품이듯이요..^^;;
5	깃헙에 누가 올려준 텐서플로 VGG19 모델을 데려다가 ILSVRC2015 classification 데이터셋으로 트레이닝 시켜보고 있는데 메모리 에러?가 나서 질문드립니다.GTX660으로 실험하고 있는데 안그래도 VRAM 부족해서 batch_size가 1로 학습시키는 중인데 한 대여섯번 iterate 돌면 에러가 나네요. 혹시 메모리를 free 해줘야하는 부분이 따로 있나요?환경은 Ubuntu 14.04 + 0.10.0rc0 입니다.VGG19 모델 코드https://github.com/machrisaa/tensorflow-vgg/blob/master/vgg19_trainable.py트레이닝 코드https://www.dropbox.com/s/0t8b63teub4yhrn/test_trainable_vgg19.py?dl=0에러로그https://www.dropbox.com/s/8tko1ymxwamdlsb/error_log.txt?dl=0감사합니다!	1	메모리 관련 문제와 별개로 사용하신 tf.nn.softmax_cross_entropy_with_logits는 쓰면 안될 것 같습니다. API document에 "WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results."라고 적혀있는데, vgg 마지막 부분에 softmax 함수를 사용하네요.그리고 트레이닝 코드 indentation도 에러로그에 뜨는 거랑 좀 다른 것 같습니다.
0	가입하자마자 바로 염치없게 질문을 드립니다. >,.<TF 튜토리얼을 받아서 실행을 해봤는데요. 아래 처럼 오류가 나네요.무슨 오류인지도 모르겠고 어찌해야 될지를 모르겠네요. ㅜㅜ해결방법 아시면 부탁드리겠습니다.('Extracting', 'MNIST_data/train-images-idx3-ubyte.gz')/usr/lib/python2.7/gzip.py:268: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future  chunk = self.extrabuf[offset: offset + size]/share_docker/TensorFlow-Tutorials-master/input_data.py:42: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future  data = data.reshape(num_images, rows, cols, 1)('Extracting', 'MNIST_data/train-labels-idx1-ubyte.gz')('Extracting', 'MNIST_data/t10k-images-idx3-ubyte.gz')('Extracting', 'MNIST_data/t10k-labels-idx1-ubyte.gz')Traceback (most recent call last):  File "07_lstm.py", line 65, in <module>    py_x, state_size = model(X, W, B, lstm_size)  File "07_lstm.py", line 44, in model    lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size, state_is_tuple=True)TypeError: __init__() got an unexpected keyword argument 'state_is_tuple'- 실행환경: Windows for Docker + b.gcr.io/tensorflow/tensorflow(도커 컨테이너)- 튜토리얼: https://github.com/nlintz/TensorFlow-Tutorials 07_lstm.py 실행	0	박해선님께서 옮겨주신 텐서플로 첫걸음에 나와있는 방법으로 설치하니 잘 되네요. >,.<Docker에 올라온 image의 문제인가 봅니다.
1	tensorflow 0.10.0을 사용하고 있습니다. 일반적으로 모델(ex. DNNClassifier, LinearClassifier)을 구성할때,  학습을 시켜 checkpoint를 저장하고,  restore하여 사용할 수 있는데..아래와 같은 형태의 커스텀 모델의 경우, 학습을 시켜 checkpoint가 저장은 되나 restore가 되지를 않습니다. 제가 보기에는 tensorflow내에 커스텀 모델에 대해 restore부분이 구현이 되지 않은듯 한데..혹시 제가 잘못알고 있는 부분이 있거나, 해결책이 있을까요??# fitLOG_DIR = './ops_logs/est_ex'classifier = learn.Estimator(model_fn=my_model, model_dir=LOG_DIR)classifier.fit(x_train, y_train, steps=700)predictions = classifier.predict(x_test)# restoreclassifier_new = learn.Estimator(model_fn=my_model, model_dir=LOG_DIR)predictions_new = classifier_new.predict(x_test)	0	https://github.com/tensorflow/tensorflow/tree/f71cc62282bf2e066f9ebd08cf3f605fc98c6e41/tensorflow/contrib/learn/python/learn#saving--restoring-models찾아보니, model_dir은 저장할 모델의 위치이지 모델이 있으면 restore한다는 의미가 아닌것 같습니다. 링크의 설명처럼 restore함수를 써서 construct해야하는것 같네요
11	안녕하세요.시스템 얘기인데요, 당연하게도 학습한 모델이 파이썬이라 RESTFul API를 만드는데 Nginx + FastCGI + Web.py (Python)로 몇 십대를 운영하고 있습니다. 하지만 전사 시스템은 온통 스프링입니다.대부분 다른 기업들도 자바기반일겁니다.조금 애로사항이 있는데요;;궁금한건.. Tensorflow든 scikit-learn이든 학습한 모델을 이기종 서비스와 연동할 때 보통 어떻게 하세요? RESTFul API로 하시는지 아니면 다른 방식으로 하시는지...저같은 경우 일종의 마이크로 서비스 아키텍쳐가 되려나요.. 스프링이 HTTP GET으로 파이썬 웹 서버에 질의하는 방식을 취하고 있습니다. 파이썬 웹서버는 몇 십대 정도 되고 L4로 묶여 있습니다.아, 그리고 학습 배치(매일 새벽)가 끝나면 모델은 SCP로 각 파이썬 웹서버로 배포가 됩니다.	3	너무 다양한 표준들이 있어서요...보통은 데이터 양이 많지 않다면 JSON으로 하고 데이터가 많다면 streambuf로 하지 않을까요?
3	안녕하세요. 딥러닝에 관심이 있어 KMOOC 강좌도듣고 KOOC 강좌도 듣고 있던 중에 Sung Kim 교수님 강좌를 접하게 되었습니다.다른 강좌는 머신러닝과 이론쪽에 치중되어 있는 강좌였는데 교수님 강좌는 이론과 실습을 병행하는 강좌라 너무 많은 도움이 되었습니다.관심있는 분야는 RNN과 그에 파생되는 모델을 이용한 주가 예측에 관심이 있습니다.TF는 처음이라(다른 것도 마찬가지로 초보지만...  ^^;;) 많은 도움 부탁드리겠습니다.
2	검색을 해봤지만 아직 적절한 방법을 찾지 못해 질문드립니다.제가 AdamOptimizer를 주로 쓰는데, AdamOptimizer의 경우 내부에 텐서플로우 변수가 따로 있어서, 이를 초기화해주지 않으면 초기화에러가 뜹니다. tf.initialize_all_variables는 기존에 트레이닝 중인 변수까지 초기화시켜버리는 문제가 있는데, optimizer 내부의 변수만 따로 초기화시키는 적당한 방법이 있을까요? 검색해서 찾은 방법들은 너무 불편하거나 복잡하네요;
2	안녕하세요. 딥러닝에 관심이 있어 sung kim 교수님 강의를 듣고 있습니다만, 문득 생각난 것이 있어 질문드립니다.. 학습 시킬 때 데이터는 모두 수치화 된 데이터인가요?	2	컴퓨터의 자료 중 수치가 아닌 것은 어떤 것이 있을지요?	1	이미지도 0~255 사이의 값을 가지는 Pixel 이며, 음성 파일도.. 그렇지요 ㅎㅎ	1	심지어 nominal value의 경우도 one-hot vector등으로 수치화할 수 있습니다	0	그렇다면 개개인마다 학습 데이터의 차이가 심하겠네요? 어떤 분은 소수 점을 사용할 수도 있고 어떤 분은 0과 1만 사용 할 수도 있고.. 제가 이해한 바가 맞나요?	0	신호처리쪽 양자화,샘플링 쪽 보시면 도움이 될것같습니다
107	학교에서 딥러닝 워크숍을 하게 되어서 이미지 분류 위주로 수업 자료를 만들어보았습니다. 기존에 하던 딥러닝 6주 수업에 사용한 자료 중에서 이미지 분류에 해당하는 부분만 편집하였습니다. 워크숍의 주된 목적이 본인이 가지고 있는 이미지들을 가지고 이미지 분류기를 학습시키는 것이기 때문에 MNIST만 사용해보신 분들에겐 도움이 될 것 같아 링크를 첨부합니다. :) AlexNet, VGG net, GoogleLeNet, ResNet을 설명하고, Logistic regression, multilayer perceptron, convolutional neural network를 구현합니다. 	2	부업만으로도 빛나는 남자...!	1	정말 감사합니다^^	1	워크숍은 학생들만 대상으로 진행하시나요? 일반인도 참가가 가능한지 궁금합니다.	1	Hwanmoo Yong	1	감사합니다 ^^	1	자료 정말 감사드립니다	3	코드 돌리시다가 이해안되시는 부분 있으면 언제듯 댓글로 알려주세요. :)	0		0	항상 잘 보고 있습니다~ ^^	0	멋지심돠~! ^^
6	안녕하세요. 텐서플로우에 입문하여 MNIST 샘플 예제를 돌려본 초보입니다. 제가 만든 샘플 (5개의 클라스)로 MNIST python 코드를 이용해서 돌려보는데까지는 성공했는데요.. MNIST는 이미지 사이즈가 28x28를 기본으로 하고 있지만 이미지 사이즈를 키워서 188x188로 해보려고 하니 에러가 나면서 돌아가지 않더군요. (https://www.tensorflow.org/versions/r0.7/tutorials/mnist/pros/index.html#deep-mnist-for-experts 샘플을 기반으로 하였습니다.)x = tf.placeholder(tf.float32, shape=[None, 784]) -> x = tf.placeholder(tf.float32, shape=[None, 35344]) 로 수정하였고,다른 값들 (Convolutional Layer 등)은 수정해주지 않았습니다.이미지 크기에 따라서 풀링 패딩 커널 사이즈 등을 수정해주어야 할까요? 너무 기초적인 질문이겠지만 답변 부탁드리겠습니다. ^^	2	어떤에러인지 몰라 정확한 답변은 드리기 어렵지만 행렬연산을 하려면 그 행렬의 앞과 뒤가 맞아야 합니다 다른 레이어도 아마 수정이 필요할거라고 생각해요	1	W_fc1 = weight_variable([7 * 7 * 64, 1024])이부분에서 앞에 7 * 7* 64가 안될 것 같습니다.188/ 2/ 2 해서  47 * 47 * 64 아닐까요 ㅎㅎ
7	딥러닝과 텐서플로를 이제 막 접한 초보입니다. CNN을 응용해서 배경 노이즈 제거 한국어 대화의 인식에 관심이 있는데  많은 강좌에서 사진을 이용한 예제는 많으나, sound나 audio의 처리는 많지 않은것 같습니다. 아무래도 FFT를 이용한 스펙트럼 분석이나 시계열 처리등이 추가로 필요할것 같은데. 관련된 논문이나 강의를 소개해주시면 감사하겠습니다.	2	얼마전에 DeepMind에서 WaveNet이라는, raw audio 관련 generative model을 발표했는데 한번 확인해보셔요.
5	일반적으로 대량의 데이터를 학습에 사용할 때 full데이터셋에서 일부를 샘플링해서 학습시키고, 이 과정을 반복하는 mini-batch를 많이 사용하시는데,MySQL, MariaDB등과 같은 RDB에 자료를 저장하고DB자체에서 지원하는 rand()와 LIMIT를 이용하면 파일을 쪼개거나 하는 과정없이 random sampling을 효과적으로 진행할 수 있을것같은데요.(여타 다른 파일들도 blob등의 형태로 저장하고 불러오면 가능할것입니다.)아직 실험해보지는 않았지만 충분히 괜찮을 것 같은데,이렇게 구현해보신분 계신가요? 많이 사용되지 않는다면 그 이유는 어떤문제일까요?	0	저도 궁금하네요~	2	음 필요하지 않아서 이지 않을까요. 미니배치를 DB에서 하게 되는건 문제가 있어 보이는데.미니배치를 하는 이유가 데이터 자체의 용량이 커서가 아니라 학습할 때 생기는 변수들과 결과값들이 차지하는 용량 때문에 그런데요.CIFAR-10 데이터 전체를 메모리에 올려도 150MB 정도밖에 안 되죠.VGGNET으로 데이터 1개에 대해서 학습을 하는데는 약 100MB ++ 가 필요하죠.  그래서 미니배치로 100개 씩 학습하려면 최소 1gb 이상 메모리가 필요하게 되고요. 100개씩 학습을하면 전체 셋 (150MB) + 미니배치(1gb++)의 메모리가 필요하구요.이정도 크기면 굳이 DB와 연동해서 가져올 필요가 없죠. 메모리에서 샘플링 하는 것이 DB에서 100개 불러오는 것보다 빠르니까요.그런데 만약에 한번에 전수를 못가져오면 DB에서 가져와야겠지만이것도 굳이 미니배치 단계에서 가져오기보다 메모리에 가져올 수 있을만큼 최대한 가져와서 메모리에서 미니배치를 돌리는게 이득이겠죠?전수 데이터 자체가 커서 컴퓨터 메모리에 못올릴정도가 되면클러스터를 구성해서 하는 여러가지 방법이 나오겠지만  일단 미니배치 작업을 굳이 느려지게 DB와 연결해서 할 필요가 없죠.미니배치 사이즈 128에 전체 50000개의 데이터가 있으면 390번을 DB에 연결해야 된다는 소리인데 안그래도 속도가 중요한데 그럴 필요가 있나 싶네요.	1	oracle 8iR2 시절 sample기능을 사용했는데 simple random sampling 결과가 별로 좋지 않았습니다.결국 sas로 id를 sampling해서 DB에서 가져오는 방식을 했습니다. 그리고 limit은 sequencial하게 제한하는것이므로 좋지 않습니다.
18	Pascal GPU + 16.04.1 + CUDA8.0 + CuDNN5.1 + Python2.7 + Anaconda + TensorFlow 0.1rc 설치 성공 후 텐서플로 작동하는것까지 확인했습니다 ㅎㅎㅎ 오늘 하루 다날렸네요	0	재부팅했더니 무한로그인에러네요....CUI상에서는 로그인 후 tensorflow mnist 예제 무리없이 잘 돌아가요xorg쪽 문제같은데 우분투에 익숙하지 않다보니 이거 참 난감하네요 ㅋㅋㅋ	0	다른 분들은 위한 자세한 설치법설명 부탁드려도 될까요? 미리 감사합니다.	0	저도 설치 성공했는데 저번주에 ㅋㅋ 저는 로그인 에러 있었는데 init 3에서 gpu 드라이버 재설치 하니 되네요	0	tensorflow에서 cuda7.5 library를 요청하던데 어떻게 8.0을 사용하시는 지요?
16	뉴럴넷과 관련한 기법들에 대해서 간단한 질문이 있어 글을 작성하게 되었습니다. 기존 연구들에서는 대체로 Drop out을 사용해왔는데, 트렌드 중 하나인 batch normalization을 사용하게 되면 drop out를 사용하지 않아도 된다는 말을 보았는데, 직관적으로 이해가 되질 않습니다. 레이어 마다 인풋의 distribution을 고려하는 기법인 BN과 단순히 특정 노드를 무효화 시켜놓고 학습시키는 drop out 기법 간 연관성이 있나요?그리고 이 두 기법은 모델 자체가 레이어 수가 많을 때만 효과가 있는 기법인가요? 제가 찾아본 문서 및 블로그에서는, BN 기법의 장점 위주로만 정보를 얻을 수 있어서 위에 작성한 부분들아 궁금해졌습니다. 감사합니다.	6	Dropout은 네트워크의 노드 일부를 0으로 만들어서 noise를 줍니다. noise로 인해 overfitting을 피하게 해주고요. (noise를 통해 regularization을 하는 예시로는 Denoising Autoencoder가 있습니다) BN은 overfitting을 피하게 한다기보다는 optimization을 돕는 거라 목적이 좀 다릅니다. 아래 링크에선, 대체로 깊은 네트워크의 경우 regularization보다 optimization이 중요해 Dropout 보다는 BN을 쓴다고 하고, 또 BN이 네트워크 내에 약간의 noise를 추가하여 regularize에도 도움을 준다고 설명하네요~ https://www.quora.com/What-is-the-difference-between-Dropout-and-Batch-Normalization	0	Overfitting의 방지는 여~러 방법을 통해 이뤄질 수 있습니다. 그것들이 서로 꼭 연결되거나 하나가 다른 것에 기초할 필요는 없죠.	0	dropout 이랑 BN 이 비슷한점은,-training noise를 더해주어서, training이 더 어렵게 되서서, stability가 올라간다고 볼수 있습니다.(발목에 모래주머니차고, 뛰는거라고 보시면 됩니다)dropout 은 ensemble 성격이 있는것 같고. peaky한 모델들 을 합치면, 둥글둥글해집니다. (다른데서도 많이 쓰니까, 자세한 설명은 생략)BN 은 sigmoid에서 ReLU 로 넘어가면서 생겨난 놈 같은데. dropout 처럼 랜돔하게 날리며는 아까우니까,데이터가 gaussian 이면 이쁘니까(골고루 퍼져있스면, 그 뉴런의 활용도를 maximum 으로), 그 모양에 맞춰 날려/고쳐 주자.라고 생각이 드네요... (저도 잘 몰라서, 약좀팔았습니다)	1	저도 하나의 의견을 드려보자면,drop out은 특정한 노드들로의 편중현상을 막기위한 목적이 큰 것으로 알고 있습니다. 만약 1000개의 노드가 있는데 그 중 10개가 결과를 내는데 너무 큰 기여를 한다면, loss에 대한 트레이닝도 그 10개 위주로 될 것이고, 다른 weight들은 원활히 업데이트가 되지 않겠죠. 이런 특정노드 의존현상을 막기위해 drop out을 사용한다고 알고 있습니다.BN도 어쩌면 비슷한 목적일 것입니다. 만약에 layer를 거친 후 만약 특정 노드의 값이 지나치게 커지게 되면 결국 그 노드가 loss에 주는 영향이 커지게되어 다른 weight의 트레이닝이 잘 안되는 현상이 발생되겠죠. 네트워크의 강력한 express power도 활용하지 못할 것이고요. 그런 의미에서 normalization을 통해 공평한 기여를 줄 수 있게 재분배하는 것이고, 따라서 drop out과 목적이 상통하는 면이 있다고 생각합니다.	1	윗분들이 얘기한데로 BN은 Regularization의 효과가 있고 다른 방식으로 Regularization 역할을 하는 Dropout이 필요없는 것 같다라고 추측한다고 BN이 소개되었던 논문에 나와있습니다. 그리고 BN의 Regularization에 대한 연구가 더 필요하다라구도 되어 있으니 연구해보시는 것도ㅎㅎ 저 개인적인 경험으로는 CIFAR 데이터에서 완전히 없애는 것보다 섞은게 더 잘되더군요."We have found that removing Dropoutfrom BN-Inception allows the network to achieve highervalidation accuracy. We conjecture that Batch Normalizationprovides similar regularization benefits as Dropout,since the activations observed for a training example areaffected by the random selection of examples in the samemini-batch.""More study isneeded of the regularization properties of Batch Normalization,which we believe to be responsible for the improvementswe have observed when Dropout is removedfrom BN-Inception."http://jmlr.org/proceedings/papers/v37/ioffe15.pdf	1	http://torch.ch/blog/2015/07/30/cifar.html BatchNorm을 사용한다고 Dropout을 사용할 필요가 없다는 이야기는 BatchNorm 저자들이 그런 것 같다고 주장한 내용인데, 꼭 그런 건 아닌 것 같다는 블로그 글이 있긴합니다.	2	드랍아웃이 선호 안되는건 원래 버전처럼 모든 층에 적용할경우 n배만큼 학습시간이 늘어서,이기도 할겁니다.그래서 최근에는 인풋에 가까운 층들에만 적용하는 케이스들이 있더군요.그런데 실험을 안 해봤는데 웨이트의 초기치를 같은걸로 줘야 드랍아웃은 작동하지 않나 싶습니다. 웨이트 초기치가 저마다 다르면, 개별 채널이 유사한 특성을 유지하는게 보장이 안 될테니까요.그리고 드랍아웃과 배치노말..의 궁합은 다른 최적화 요소와 그 설정들에도 영향받을 것이니 어떤 경우는 시너지가 날수도 있을거 같고, 특히 인풋 근접층에의 드랍아웃 적용은 아마 그럴거 같다는 생각이 듭니다.	3	BN 은 gaussian distribution 을 전제로 깔고 있고.Dropout 은 ensemble 이니까 아무 distribution 을 다 소화할수 있어서, 더 general 한 regularization 방법같은데요.input layer 쪽에서 dropout 을 사용한다는것이 직관적(?)으로는 말이 되는게,input layer에서는 mini-batch 가 꼭 gaussian일 필요는 없지만, (오히려 데이터의 natural distribution이 gaussian  아닌 상태에서 gaussian에 붙히면 않좋을거 같고)upper layer로 올라가면서 natural distribution은 없어지고, mathematical distribution 으로 변하면서, gaussian이 더 적절한 분포 + training 속도 빠름. 일까 하는데요.	0	dropout은 오버피팅은 막아주지만 속도가 느려지게 됩니다근데 비슷한 역할을 해주는 BN 은 속도를 가속화 하니dropout을 빼는 게 좋다 라는거 어날까요?	1	이안굿펠로우의 딥러닝북을 읽다보니 이와 관련된 내용이 있네요.Chapter 11. Practical Methodology p427 "Batch normalization also sometimes reduces generalization error and allows dropout to be omitted, due to the noise in the estimate of the statistics used to normalize each variable."한군데 더 있네요.Chapter 7. Regularization for Deep Learning p268 "Another deep learning algorithm, batch normalization, reparametrizes the model in a way that introduces both additive and multiplicative noise on the hidden units at training time. The primary purpose of batch normalization is to improve optimization, but the noise can have a regularizing effect, and sometimes makes dropout unnecessary."
173	한국어입니다!! :-)	4	강의 정말 잘하시는 교수님. 강추 합니다.	0	강의 말고 코드리뷰같은건 없나요??	0	나동희	3	현장에서 들었지만 카이스트로 가서 교수님 강의 청강 하고 싶을 정도의 강의었습니다.	0	ㅇㄷ
6	Tensorflow로 학습시킨 모델을 데이터베이스나 로컬에 저장해두었다가 임포트 시킬 수 있는 방법이 있나요?	9	tf.Saver을 이용하여 모델을 저장하고 그것을 다시 불러오는 식으로 가능합니다 DB를 이용하고 싶으신 경우는 PATH를 DB에 넣어놓는 방법이 이상적이라 생각됩니다
7	안녕하세요가입후 처음 글을 쓰네요. 김성훈 교수님의 강좌를 들으며, 텐서플로우 열공중인 멤버입니다. 강좌들을때는 다 이해한 것 같았는데, 막상 코드를 보니 모르는 것이 한두개가 아니라 도움을 구하고자 합니다.1. 코드의 rnn_cell=rnn_cell.BasicRNNCell(rnn_size)state=tf.zeros([batch_size,rnn_cell.state_size]) 부분에서 rnn_size(4)라는 것이 output node의 개수를 의미하는 것이 맞는지 궁금합니다. 또, 교수님께서 설명하실 때, rnn_size에 따라 state(hidden과 같은 개념 맞죠?)의 개수도 정해진다고 말씀하셨는데, 그렇다면 output node의 개수와 hidden node의 개수도 자동으로 항상 일치하게 설정 된다는 것인지 의문이 듭니다. (영상속 예시에서는 output node:4개, hidden node:3개로 표현이 되어 있었기에...)2. RNN에서 weight는 hidden이 넘어오는 값과 곱해지는 가중치와, input과 곱해지는 가중치 2가지 종류가 있다고 알고 있습니다. 코드에서는 weights=tf.ones([time_step_size*batch_size]) 라고 나오는데, input에 곱해지는 가중치들만 1로 초기화를 하겠다는 의미가 맞는지 궁금합니다. (이전state과 곱해져야 할 가중치는 어디로?, 초기값은 모두 1로?)이론과 구현의 괴리가 생겨 진도를 못나가고 있네요... 강의들으셨던 분이 계시다면 조언 부탁드립니다^^; 감사합니다.	0	1. rnn_size는 아웃풋 노드의 개수가 맞습니다. 예를들어 hello라는 글자를 얻기위해 h.e l.o 4개의 문자열을 넣게되는데, 아웃풋에서는 각각의 글자가 나올 확률(?)을 알려주므로 4개가되죠. state 개수가 자동으로 정해진다는건 h.e.l.o 글자를 한 스테이트당 하나씩 넣게되므로 아웃풋과 같은 4개가 되죠. 히든노드의 개수는 본인 마음입니다. 히든노드 수가 증가하면 복잡도가 높아져서 좀더 정교하고 좋은 결과를 나타내죠, 이건 어느 딥러닝구조에서나 마찬가지입니다.	0	2. 코딩을 할때 인풋과 히든, 히든과 아웃풋 사이의 웨이트와 바이어스는 크기는 처음에 배열의 크기를 각각 정해줍니다. 이 코드가 무엇을 하려는 코드인지 모르겟어서 저 코드에 관한 설명을 못드리겠네요ㅎㅎ	2	이렇게 보시면 이해가 좀 되시려나 모르겟네요ㅎㅎ(셀 내부에 있는 숫자는 신경쓰지 마세요)	1	rnn에서는 특히 lstm에서는 셀(뉴런)에서 나오는 두개의 출력을 히든 스테이트와 셀 스테이트라고 부릅니다. 히든 레이어의 히든이란 단어와 혼돈하지 마세요. ^^
9	안녕하세요. 2016/10/14(금) 역삼역 마루180 에서 "데이터야놀자" 라는 커뮤니티형 컨퍼런스를 준비하고 있습니다.오늘부터 참가신청 ( https://goo.gl/87NQiy )이 열러서 텐서플로우 그룹에서도 많은 참여 부탁 드리고자 글 올립니다. 프로그램 보시고 많은 관심 부탁드립니다.	0	프로그램 글씨 큰버젼
3	#마켓On : 파트 2 스터디원 모집합니다.<테마 : 딥러닝NLP와 강화학습을 위한 몸풀기>마케팅에 심리학과 머신러닝을 접목하려는 스터디 마켓On. 파트2는 파트3에서 본격적으로 진행될 주제에 대한 몸풀기입니다파트3에서는 딥러닝을 이용한 자연어처리와 강화학습 기초를 할 예정입니다.통계는 알지만 기계학습(특히 딥러닝)은 익숙치 않다, 딥러닝으로 자연어처리를 하고 싶지만 자연어처리 기초가 조금 막막하다, 강화학습을 하고 싶은데 어디에 쓰일지, 어떤 기초가 필요한지 잘 모르겠다. 싶은 분들은 파트2부터 함께 하시면 좋습니다.파트2는 다음 4가지 내용으로 진행됩니다.(마케팅NLP실습) 파이썬으로 웹 크롤링부터 시작해서 차근차근 텍스트 데이터를 다루고 자연어처리 기술을 적용하는 실습입니다.(NLP기초) 파이썬 기반 자연어처리 패키지인 nltk, konlpy를 이용해서 품사 태깅, tf/idf, 언어에 대한 확률모델링, 정보검색이론 기초 등을 살펴봅니다.(MAB) 강화학습의 사촌격인 멀티암드밴디트 알고리즘으로 웹사이트의 메뉴를 테스팅하는 내용으로 몸을 풀어봅니다.(행동경제학) 심리학의 휴리스틱 의사결정학파 연구들을 경제학에 적용한 '행동경제학'에 대해 스터디합니다.매주금요일 저녁 7시~10시 강남역 근처에서 진행됩니다.별도의 비용은 없으며 스터디 공간 이용료 3000원만 걷습니다.관심있으신분들은 많은 참여바랍니다^^https://www.facebook.com/events/1286968211314202/
15	안녕하세요.딥러닝 혹은 머신러닝을 다수의 컴퓨터에서 분산처리 할 때데이터를 각 머신에 어떻게 "잘" 나눠줄까에 대해서 연구한 웹이나 논문은 없는지 궁금합니다.예를들면, 미니배치를 만들 때 전체 데이터에서 그냥 랜덤하게 뽑아서 뿌리는 것이 아니라,어떤 직관을 기반으로 미니배치를 잘 만드는, 그래서 랜덤하게 미니배치를 만들었을때에 비해서 결과가 좋은 연구가 있는지 궁금합니다.감사합니다.	0	저도 궁금하네요.	0	일반적으로 데이터 분산 시 HASH 알고리즘을 많이 사용하는 데, 머신러닝을 해보진 않았지만 비슷하게 적용할 수 있지 않을까 싶습니다.아래는 하둡 아키텍처에 대해 구글링 해본 건데 참고가 될 수 있을까 싶네요.https://books.google.co.kr/books?id=732hAgAAQBAJ&pg=PT197&lpg=PT197&dq=%ED%95%98%EB%91%A1+hash&source=bl&ots=DMSoq01Q0_&sig=lhvD1EsGuWQXoif0UNC1HtgF7bQ&hl=ko&sa=X&ved=0ahUKEwivz-frzKLPAhXGKZQKHb28BN4Q6AEIKzAE#v=onepage&q=%ED%95%98%EB%91%A1%20hash&f=false	6	Active Learning 과 질문주신, 더 좋은 미니배치를 구성하는 방법이 어느정도 상관 있을 것 같습니다. Active Learning은 매우 데이터가 희소한 상황에서, 다음 번에 어떤 데이터 포인트를 학습하는 것이 가장 학습에 큰 도움이 되는지를 알아내는 방법입니다.https://en.wikipedia.org/wiki/Active_learning_(machine_learning)그러나 미니배치는 전체 데이터의 분포를 최대한 따르도록 샘플링해야만, 학습하는 데이터가 non-stationary한 문제를 겪지 않기 때문에, 랜덤으로 적당히 큰수의 N개 데이터를 샘플링해서 쓰는 경우가 일반적입니다. (이러한 문제를 internal covariate shift라 하며, 이를 해결하기 위해 쓰이는 방법이 batch-normalization입니다.)만약 어떤 알고리즘을 이용해서 미니배치를 더 잘 구성한다고 하더라도, 그 알고리즘을 수행하는 데에 따른 계산량이 필요하여, 오히려 불필요한 오버헤드가 더 커질 수 있습니다.별개도 분산처리하는 환경에 대한 논문으로는 구글의 Downpour SGD를 참고하시면 좋을 것 같습니다. https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf	0	그래프 데이터라고 한다면 그래프를 어떻게 잘 나눠서 머신에 나눠줄까라는 문제인거라고 이해해도 될까요?	1	하둡의 Spark를 이용한 SparkNet이라는 모델이 있긴 합니다. http://scholar.google.co.kr/scholar_url?url=http://arxiv.org/pdf/1511.06051&hl=ko&sa=X&scisig=AAGBfm1RkmXBgXqf6Io4Gfgxck5Ah7VR7A&nossl=1&oi=scholarr&ved=0ahUKEwiNlIqpsKXPAhVFI5QKHTWuARkQgAMIICgBMAA
1	안녕하세요.Tensorflow를 활용하여 DNN, CNN을 다루고 있는 학생입니다.다름이 아니라, DNN, CNN학습(또는 테스트) 중에 각 layer에 있는 node들의 값들을 출력하여 보고싶은데, 어떻게 볼 수 있을까요?DNN을 예로 들면, 5개 layer에 각각 1024개의 노드가 있다고하면,2번째 layer의 1024개 노드들의 값을 보고싶을 때 어떻게 출력을 할 수가있나요?CNN의 관점에서보면, 각각 5개의 convolution, subsampling layer가 있을 때, 3번째 convolution layer와 subsampling layer의 value들을 보고싶으면 어떻게 출력할 수 있나요...?답변 부탁드립니다.감사합니다.	0	파이썬으로 하신다면print(sess.run())괄호안에 변수 넣으시면 될것같습니다.
239	서울대학교 컴퓨터공학부 석박사과정 학생들이 진행하는 머신러닝 세미나를 유튜브에서 공유하고 있네요. 세미나 내용을 올린다는게 발표자들로서는 부담스러운 일이고, 또 촬영하고 올리는 것도 상당히 귀찮을 텐데 정말 감사합니다~ 	0	우와!	0	멋집니다!	0	대단합니다!	0	나동희	1	우와~
1	Tensorflow를 우분투에서 source로 설치했을때 업데이트 하고 지우는 적절한 방법은 무었인가요? 제가 최근에 업데이트를 하고 싶어서git fetch --allgit reset --hard origin/master후에 ./configure를 다시 하려고 했는데 에러가 나더라고요...그래서 아예 폴더를 지우고 처음부터 다시 깔아봐야지 하고rm -r ~/tensorflow했는데 그 이후에 어떤 에러메시지와 함께 우분투가 먹통이 되더니 부팅이 되지 않습니다. I/O error dev sda 이런식으로 뜨는 걸 봐서는 하드에 문제가 생긴 듯한데 이게 TF를 지우다가 문제가 발생한 건지 원래 하드웨어에 문제가 있어는데 우연히 시간이 맞아 떨어진 것인지 잘 모르겠습니다. 혹시 TF를 지울때 위와같이 지우면 안되는 것인지요?? 그리고 source 업데이트는 위와 같이 하면 안되는 것인지요??백업도 안되서 답답하네요... 답변 부탁 드립니다.	0	음 소스에서 wheel 만드시고 pip 으로 설치하시지 않았나요?
91	한국어 자막이 있는 머신러닝 기초 동영상입니다
59	안녕하세요. 모두의연구소 김승일입니다. 이웅원 연구원님께서 오랜기간 작업한 강화학습 자료가 드디어 마무리되었네요!일전에 모두연 게시판에 정리하던 내용에 새로운 내용들이 듬뿍 추가 되었습니다. 160페이지에 달하는 상당한 분량이지만 쉽게쉽게 써있어서 강화학습을 처음 연구하시는 분들께 추천드립니다!!	2	안재웅	2	모두연의 능력자 시군요^^ 감사합니다
3	안녕하세요제가 조립컴을 구매했습니다.Cpu는 내장그래픽이 없는 amd이구요그래픽 카드는 gtx1060입니다그래서 그래픽카드자체에 케이블을 연결해서OS 환경을 깔아야하는데요윈도우os는 아주 잘깔리고 아무문제 없이 사용 됩니다근데 ! 우분투os를 깔아야하는데Boot화면에서 우분투 로딩되고언어설정하는부분 전까지 화면이 뜨고해상도 지원이 안된다고 검은화면에서 19xx X xxx 숫자 뜨면서 안됩니다그래서 조립컴 사장님들한테 물어봐서Hdml케이블로도 해보고Rgb케이블에 hdml컨버터 껴서도 해봤습니다디지털지원 아날로그 지원 모두다그래도 안되서모니터 해상도가 높아서 그런가하고 옛날 작은 모니터로도 연결해서 해봤는데이번엔 1680x9xx 60hz 해상도 지원이 안된다고 하네요윈도우os는 잘깔리는데 우분투os는 왜안깔릴까요......컴퓨터 사장님들도 그냥 가꼬오라고 해주겠다고...... 해결법 없을까요???	0	Nvidia driver 문제입니다파스칼(gtx10x0)는 367이상인가설치 해야합니다안그러면 out of range같은 에러가 나더라고요Ubuntu16에서 기본(361??) 제공되는것으론 안된다고 합니다	0	혹시 모르니 xubuntu로 설치해보세요.
56	TensorFlow의 최초 TR인 TensorFlow:Large-Scale Machine Learning on Heterogeneous Distributed Systems에 대한 정식 논문이 나온것 같습니다.오는 11월 System 분야 Top-tier conference인 OSDI'16에서 발표됩니다.논문은 정식 학회전에도 볼 수 있도록, arXiv.org에 미리 camera-ready version을 올린것 같습니다.제목과 링크는 다음과 같습니다.TensorFlow: A system for large-scale machine learninghttp://arxiv.org/abs/1605.08695OSDI 2016: https://www.usenix.org/conference/osdi16/programTensorFlow의 구현 철학을 시스템관점에서 설명하고, 다른 기존 시스템 대비 TensorFlow가 다양항 응용에 대해서 얼마나 성능 향상을 보였는지를 다룬것 같습니다.보통 USENIX 소속 학회들은 발표자료와 동영상도 올라오니 학회가 끝나고 발표영상도 보면 좋을것 같습니다.
2	안녕하세요. 지난번에 질문을 올렸었는데 아직 더 궁금한 점이 있어서 추가로 글을 올립니다.  1. 약 18000개의 feature가 있을때 이중에서 8개의 feature만 뽑아서 레이어를 하나더 생성해서 진행하다가 중간에 합치는 형식으로 만들고 싶은데 이렇게 하면 이8개의 feature가 결과값을 도출하는데 좀더 많은 기여를 하게 되는게 맞는지 궁금합니다.. (제가 생각했을때는 맞는것 같은데 직접 테스트 해본 결과값이 크게 차이가 없어서 질문 드립니다.)2. 두개의 layer를 합칠때 concat함수를 이용해서 구현하는 것이 맞는지 궁금합니다. 저번 답변을 참고해서 구현했는데 정확한지는 잘 모르겠습니다. ㅠ  (아래에 코드가 있는데 한번 확인해 주시면 감사하겠습니다.)3. 마지막으로 제일 궁금한 점인데 현재와 같은 데이터(test.txt)가 있을때  노드수와 layer수를 어떻게 맞춰줘야 효율적이라고 할 수 있는지 궁금합니다. 조금씩 바꿔가면서 해보았는데 그 관계를 정확하게  모르겠어서 조언을 구합니다.데이터 수에 비해서 feature수가 너무 많은것도 안좋은건가요??;;----------        test.txt 예제       -------------# x1 x2 x3 x4 x5 x6.......... x18000    Y    1    0   0  1   0   1               1          0   0    0   1  0   1   1               0          0   0    0   0  1   0   0               1          1   1    0   1  0   1   1               1          1 여기에는 간단하게 표현했는데 실제로는 행 (데이타 갯수)은 2000개 정도이고 열(변수)은 18000개 정도인 learning 시킬 데이타입니다.그리고 아래는 작성중인 코드입니다알고리즘 부분만 첨부하였습니다.-------------------------------------------------------------xy = np.loadtxt('test.txt', unpack=True) v_data = np.transpose(xy[292:300])  #따로 뽑고싶은 x값 8개를 추출했습니다. x_data = np.transpose(xy[0:-1])   y_data = np.reshape(xy[-1], (c, 1))  # True or False(.....) V = tf.placeholder(tf.float32, name='v-input')  X = tf.placeholder(tf.float32, name='x-input') Y = tf.placeholder(tf.float32, name='y-input') drop_late = tf.placeholder(tf.float32) #### 8개만 따로 돌릴 layer ######  nw1 = tf.get_variable("N_w1", shape=[8 , 10],initializer=tf.contrib.layers.xavier_initializer()) nw2 = tf.get_variable("N_w2", shape=[10 , 10],initializer=tf.contrib.layers.xavier_initializer()) nw3 = tf.get_variable("N_w3", shape=[10, 2],initializer=tf.contrib.layers.xavier_initializer()) nb1 = tf.Variable(tf.zeros([10]), name="N_Bias1") nb2 = tf.Variable(tf.zeros([10]), name="N_Bias2") nb3 = tf.Variable(tf.zeros([2]), name="N_Bias3")    _nL1 = tf.nn.relu(tf.matmul(V, nw1) +  nb1) nL1 = tf.nn.dropout(_nL1, drop_late) _nL2 = tf.nn.relu(tf.matmul(nL1, nw2) + nb2) nL2 = tf.nn.dropout(_nL2, drop_late) _nL3 = tf.nn.relu(tf.matmul(nL2, nw3) + nb3) nL3 = tf.nn.dropout(_nL3, drop_late)  ############  8개를 따로 알고리즘을 돌립니다.  w1 = tf.get_variable("w1", shape=[18000, 2000],initializer=tf.contrib.layers.xavier_initializer()) w2 = tf.get_variable("w2", shape=[2000, 500],initializer=tf.contrib.layers.xavier_initializer()) w3 = tf.get_variable("w3", shape=[500, 50],initializer=tf.contrib.layers.xavier_initializer()) w4 = tf.get_variable("w4", shape=[52, 1],initializer=tf.contrib.layers.xavier_initializer())  b1 = tf.Variable(tf.zeros([2000]), name="Bias1") b2 = tf.Variable(tf.zeros([500]), name="Bias2") b3 = tf.Variable(tf.zeros([50]), name="Bias3") b4 = tf.Variable(tf.zeros([1]), name="Bias4") _L2 = tf.nn.relu(tf.matmul(X, w1) +  b1) L2 = tf.nn.dropout(_L2, drop_late)  _L3 = tf.nn.relu(tf.matmul(L2, w2) + b2) L3 = tf.nn.dropout(_L3, drop_late) _L4 = tf.nn.relu(tf.matmul(L3, w3) +  b3) L4 = tf.nn.dropout(_L4, drop_late) ################# 전체 feature를 가지고 layer 4개로 지나가도록 만들었습니다.   LL = tf.concat(1,[L4,nL3])   # 여기서 layer 두개를 합쳤습니다. hypothesis = tf.sigmoid(tf.matmul(LL, w4) + b4)cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1 - hypothesis))a = tf.Variable(0.1)   #learning rate optimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost) --------------------------------------------알고리즘 구성 자체는 기본적인 NN 구조를 가지고 만들었습니다. ㅠ	0	데이터 보다 피쳐가 훨씬 많으면 NN 보다는 더 단순한 모델을 먼저 테스트해보시는게 좋을것 같습니다. Logistic Regression이나 SVM 이 나을 것 같네요.	1	우선 결과가 어떻게 되었는지 공유해주실 수 있으신가요? 원론적으로 말씀드리면, network를 따로 분리한다고 해서 그 input들이 output에 항상 더 큰 영향을 준다는 보장은 없을 것 같습니다. 따로 분리하지 않아도 제대로 학습이 되면, 중요한 input에 연결된 weight들이 값이 크게 학습되면서 자연적으로 output에 영향을 많이 줄 수 있을거 같은데요.... 다만 data 수에 비해서 input dimension이 너무 크면 parameter가 많아져서 학습이 잘 안될거 같은데, 8개는 따로 빼고 나머지 input feature들을 dimension reduction 해서 사용하면 어떨까요?	1	차원 축소 관련해서  http://scikit-learn.org/stable/modules/feature_selection.html 이 부분을 참조해볼 수 있을 것 같습니다.저도 하려고하는 작업이 feature가 많고 (2500여개정도) 데이터수는 22만개정도입니다. 학습이 잘 될지 궁금하네요.	0	일단 1-2번 말씀드리면 그런 식으로 피쳐를 합치는 것은 가능하며 concat  하시거나 sum layer 를 만드시거나 아니면 같은 디멘전의 output 끼리는 dot product 도 가능합니다. 보통 어떤 피쳐들이 early stage 에 알 수 있게 되고 다른 피쳐들이 이후의 stage 에서 접근 가능 해질 때 그 feature 들을 critical path에서 빼기 위해서 이러한 일들을 하게 됩니다. 이 때 gradient descent 의 back propagation이 양쪽으로 전달되는게 맞는 방법일지 아닐지를 잘 판단해야 합니다. (구현이나 feature의 성격에 따라서 달라질 수 있습니다) 이것만 주의하시면 다른쪽 네트웍의 피쳐들이 더 도미넌트 해질 이유는 없습니다. 간단하게 말씀드려서 제 길지 않은 경험 상 피쳐의 상대적인 중요도가 문제가 되는 경우는 임베딩 때 중요한 피쳐와 중요치 않은 피쳐를 같이 임베딩 시키는 경우 외에는 없었습니다. 이 경우 임베딩 알고리즘에 따라서 성능이 갈리게 됩니다.	1	1. X 만 돌리면 어느 정도 까지 나오고, V 만 돌리면 어느 정도 까지 나오나요? X + V 같이 돌리면?8개가 2개 뭉치고nw3 = tf.get_variable("N_w3", shape=[10, 2],initializer=tf.contrib.layers.xavier_initializer())16000개가 50개로 뭉치고..w3 = tf.get_variable("w3", shape=[500, 50],initializer=tf.contrib.layers.xavier_initializer())2+ 50 => 52w4 = tf.get_variable("w4", shape=[52, 1],initializer=tf.contrib.layers.xavier_initializer())인데,8개를 42개로하고 넓히고. (넓게 빼는게, original data 가 sparse 이면 별 효력을 없다고 봄..) 여기는 널널한 고속도로.16000개를 10개 정도로 하면, 자연스레 무식한 PCA?? 여기는 시그널이 너무 뭉치서 충돌되서 정확도가 무너져서,  마지막 레이어에서, 별로 쓸모없는 데이터구나. 하고는 weight 이 줄어들고..42 +10 => 52 이렇게 합치면, 될찌 모르겟네요...
21	연휴때 쓴 EBGAN tensorflow 구현에 대한 반응이 좋아서 오늘은 OpenAI 의 GAN 논문인  "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets(https://arxiv.org/abs/1606.03657)" 을 tensorflow 로 구현 한 것을 공유해 봅니다. https://github.com/buriburisuri/supervised_infoganrepo 명에 supervised 가 들어간 이유는 원논문과 달리 supervised loss 를 추가해서 학습시켰기 때문입니다.  기존의 GAN 논문들을 보면 supervised loss 를 추가할 경우 성능이 더 나빠진다고 했는데, InfoGAN 의 경우는 트레이닝도 더 안정적이고 성능도 더 좋아진 거 같습니다.  ( GAN 은 정량 평가가 어려워서... ㅠ.ㅠ ) 개인적으로는 seed 에 따라 생성된 category 복불복 현상을 피하기 위해 트라이 해 본건데 결과가 의외로 좋은 것 같습니다. InfoGAN 구조상 supervised loss 를 추가한 것이 더 좋을 거 같기는 합니다.  그냥 실제 데이터와 구분되지 않는 그림을 생성하는 것 보다는 discriminator 가 특정 숫자로 믿게 트레이닝하게 하는 거니깐 트레이닝 속도도 빠를 수 밖에 없을 것 같고요.	1	요몇일 재미있어서 보고 있는 논문인데.  감사합니다.
11	딥러닝실습 TensorFlow심화교육 이번주 수요일까지 등록연장을 하였습니다. 좋은 교육기회를 놓치지 마세요^^	0	ㅎㅎ 비싸네용...	0	참석합니다. ^^
4	[스터디원 모집] 의사결정RL : 파트 6 (+대화형 시스템 Using RL)* (새로 추가) 강화학습을 이용한 대화형 시스템* (기존) 신경경제학 / 파이썬(+tensorflow)을 강화학습 코드 리뷰* 2주에 한번 월요일, 저녁 7시 - 10시. 무료( 공간 사용비는 각자 1회 3천원, 무료공간을 못구함). 10/17 시작.* 이벤트 링크 - https://www.facebook.com/events/1058557057591006/* 이 스터디는 정통심리학그룹 싸이그래머에서 진행합니다.* 자료는 모두 공유&공개됩니다(정리 중)사람의 의사결정 심리와 기계의 강화학습 모형을 같이 살펴보는 의사결정RL. 어느새 파트 6이 되었습니다. 파트6에서부터는 강화학습의 응용을 같이 살펴보려 합니다. (새로 추가된 것)Reinforcement Learning for Adaptive Dialogue Systems: A Data-driven Methodology for Dialogue Management and Natural Language Generation- https://www.amazon.com/Reinforcement-Learning-Adaptive-Dialogue-Systems/dp/3642439845/(기존)* 신경경제학 : 뇌해부학부터 시작해서 보상 시스템으로 이어지는 진도의 중간중간,  뇌과학에서의 강화학습 모형들도 살펴봅니다.* 파이썬 강화학습 코드 - 고전적인 Q learning 부터 DQN까지, 텐서플로우를 이용한 튜토리얼을 위주로 기초부터 차근리뷰합니다. 중간중간 응용 영역에 적용되는 강화학습 코드도 같이 볼 생각입니다.함께 하실 분들은 언제나 환영합니다. 전문가/실무자 모임이 아닌, 누구나 함께하는 취미모임입니다. 댓글 다시거나 이벤트 링크를 통해 참석을 누르시거나, 해당 장소로 바로 찾아오시면 됩니다.	0	https://www.amazon.com/Reinforcement-Learning-Adaptive-Dialogue-Systems/dp/3642439845/	0	혹시 월요일 말고 다른 요일에 추가 스터디는 불가능 할까요?	2	직접 스터디를 열어보시면 가능합니다~
6	가입했습니다. 일본에서 비즈니스 하고 있는 김지훈이라고 합니다. 요로시쿠오네가이시마스.	1	하이, 도조~
52	일본의 와세다대학에서 SIGGRAPH2016에서 발표한 러프화에서 선을 따는 기술을 웹으로 제공하네요. 정식명칭은 Neural Network-based Sketch Simplification입니다.	0	아쉽게도 웹이네요. 모델을 공개하는 줄 알았는데... 그래도 좋습니다!	1	최근의 동향을 보면 이론이나 알고리즘에 대한 개발은 미국을 중심으로 개발되고있지만, 활용은 일본쪽에서 가장 잘 하고있는 느낌이네요..(수치보단 그냥 제 체감입니다..)	0	아무래도 만화가들이 많으니까요.
13	휴가에 , 추석연휴에 약 3주 정도 멀리 했더니 파이썬, TensorFlow 매우 낯설게 느껴집니다,,처음부터 다시 시작하는 느낌 ㅠㅠ,,기초가 없어서겠지요?  오늘부터 다시시작합니다..으샤~~
6	안녕하세요. 딥러닝 초보자인 학생입니다. 이번 연휴 기간동안 사진내에 특정한 물체가 있는지를 판단하는 network를 학습시켜보았는데요, 먼저 alexnet의 마지막 layer output 숫자를 2로도 만들어 보았습니다. 학습은 굉장히 빨리 되고, 시뮬레이션 중에 나오는 test 결과도 잘 되었다고 나와 80k에서 학습을 종료하였습니다. 하지만 실제로 돌려 본 결과는 fp,tn 비율이 너무나도 높아서 쓰기 힘들정도였습니다. (거의 60%에 육박했습니다.) 다음으로는 ResNet-50을 이용하여 200k 학습을 진행하였는데요, train loss는 줄어드는것이 보이는 반면에 학습중간중간에 보여주는 테스트 결과비율은 도저히 올라갈 기미가 보이지 않았습니다.수렴은 빨리되는데 학습결과가 엉망인 네트워크, 천천히 수렴되긴 하지만 학습 test net 결과율이 올라갈 비율이 늘어나지 않는 네트워크. 제가 어떤것을 놓치고 있는것일까요? 많은 조언 부탁드립니다.	0	ResNet을 쓰시면 Batch Normalization Layer를 쓰신 건가요?	0	데이터 가 몇개 이신가요?? Overfit 되는거 같으니 regularization parameter 고치시거나 dropout 같은걸로 살짝 뿌셔주세요. Training이 힘들어지면서, validation 이 올라갈 수 도 있습니다.
5	안녕하세요. 텐서보드 사용 중 부분적인 문제점이 있어서 글을 작성하게 되었습니다.제가 참고한 코드는 https://gist.github.com/danijar/3f3b547ff68effb03e20c470af22c696입니다.현재 cost 값과 accuracy 값을 보기 위해서 각 def 안에서 tf.scalar_summary를 선언하였고,weight 및 bias 값은 tf.histogram_summary 를 통해 로그에 기록되도록 하였습니다.각 summary 를 합치기 위해  with tf.Session() as sess: 다음에merged=tf.merge_all_summaries() 를 사용하였고,바로 다음 라인에는 writer = tf.train.SummaryWriter("경로",sess.graph) 를 적었습니다.merged 또한 summary_str=sess.run(merged,feed=feed) 형태로 안에 잘 썼습니다.이후에 k스텝별 writer.add_summary(summary_str,k)도 잘 적어두었습니다.그런데 실제로 웹 상에서는 histogram 부분은 모두 잘 나오지만, scalar summary 부분은 Events 탭에서 cross_entropy만 표시가 되고 있습니다.여러 텐서보드 사용법 및 예제들을 보고 했음에도 불구하고, 단 하나의 스칼라만 표시가 되고 있는데요.혹시 해당 문제를 해결할 방법에 대해서 알 수 있을까요?
47	연휴기간 짬을 내서 최근 Facebook 의 논문인 "Energy-based generative adversarial network ( EBGAN )" (https://arxiv.org/abs/1609.03126) 을 tensorflow 로 구현해보았습니다.https://github.com/buriburisuri/ebgan생성된 샘플 이미지가 InfoGAN 에 비해 더 좋아 보이지는 않지만 트레이닝 과정은 논문대로 매우 안정적입니다. ( GAN training 악명 높죠. ^_^ )discriminator 의 loss 를 bce 에서 hinge 로 바꾸고 auto-encoder 를 도입해 discriminator 의 training 을 어렵게 만든게 (일종의 regualarizer 효과)  포인트 아닌가하는 생각이 드네요.GAN 트레이닝 과정에서 종종 나오는 collapse 현상 ( GAN 트레이닝 하다 보면 어느 순간 1, 1, 1 ... 만 그려 냅니다.  ㅎㅎ) 을 막기 위해 pull-away term 이라는 regularizer 를 추가했는데 개인적으로는 OpenAI 의 InfoGAN  보다 그 효과가 미미 한거 같습니다.
0	GPU를 듀얼로 구성한 경험이 있는 분들께 문의 드립니다.gtx1080 듀얼로 구성하려는데요.두 대를 병렬로 동시에 사용하기도 하고,한 대는 학습을 시키면서 다른 한 대는 테스트용으로 쓰기도 할 예정입니다.이런 용도로 사용할 경우1. SLI 로 구성해야 하는건가요? (아닐꺼 같긴 합니다만)2. 파워는 어느정도를 사용해야 할까요?	1	1. SLI 없어도 괜찮습니다. 1080 4개까지 병렬로 해보았습니다.2. 파워는 각각의 전압 × 2 + 약간의 여유 정도로 하시면될텐데, 저는 얼마로 했는지 잘 모르겠네요.
80	wavenet 구현버전이 벌써 나왔네요. 논문을 코드로 번역하는 머신들이....	0	VCTK-Corpus.tar.gz 받는데 한세월 걸리네요
4	CNN을 이용한 object detection을 공부하고 있는데 위치(bounding box)를 학습한다는 개념이 이해가 되지 않습니다. 자료를 찾아봐도 감이 안오네요 ㅠ 혹시 속시원하게 설명해 주실분 있나요?	1	저도 object detection에 관심 있어서 관련 자료를 찾아봤었는데...물체가 있을만한 Region(Bounding box)을 제안 받을 때 그 사각형의 위치 정보를 (x,y,h,w)(왼쪽 모서리 좌표 x,y 높이 h 너비 w)로 받게 되는데요. 이 Region 안에서 image classifier를 사용했을 때 '배경 혹은 물체 없음' 레이블을 제외한 특정 물체의 일치 정도가 일정수준 이상(threshold)으로 나오면 그 Region은 물체를 포함한 박스 인것으로 학습한다고 이해했어요,,!!	0	리그레션 문제이고 L2디스턴스로 학습을 하고 쓰레스홀드 값으로 판단을 합니다.	0	1. R-CNN supplementary materials에 자세히 설명되어 있습니다. https://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf제가 생각하기에 현재 Bounding box의 위치 및 크기를 기준점으로 삼는 Relative coordinate라는 점이 중요한 점인 것 같습니다.2. R-CNN의 경우는 따로 SVR을 붙여 사용했었는데, 요즘에는 fast R-CNN(http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)에서 사용한 조합인 Smooth L1 loss를 많이 사용합니다.
36	Windows 에서 TensorFlow를 실행하기 위해 Docker를 사용하고 계신 분들이 많으신데요.PyCharm Professional 버젼에서 Docker Toolbox로 Remote Debugging 하는 방법을 공유합니다.간단히 설명드리면PyCharm Professional 버젼에서만 Docker로 Remote Debugging 설정이 되고,Docker Container가 아니라 Docker Image에 연결해서 Remote Debugging 설정을 하기 때문에 Docker Container 안에서 Python Package를 설치한 후에 docker commit 으로 새로운 Docker Image를 만들어서 Remote Python Interpreter로 설정을 해줘야 적용이 됩니다.또 Remote Debugging 할때 동일한 python 소스 파일이 Host PC와 Docker Image 안에 있어야 하기 때문에, 소스를 수정해 가면서 디버깅을 하기 위해서는 Docker에서 공유폴더 기능(-v 옵션)을 설정해서 python 소스를 공유폴더에 놓고 사용하는 것이 훨씬 편합니다.자세한 설명은 제 블로그에 정리해 두었습니다.	1	먼가  어렵네요  ㅠㅠ 공유  감사  합니다	1	감사합니다
4	tensorflow 설치 후, jupyter notebook으로 구동하려고 하는데 문제가 있어서 도움을 구하고자 합니다. 콘솔상에서 python으로 import tensorflow as tf 하면 >>> import tensorflow as tfI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally와 같이 문제없이 잘 되는데jupyter notebook에서는 아래와 같이 cudnn.so 를 열 수 없다고 나옵니다... 혹시 해결 방법을 아시는 분 있을까요?이 상태에서 session을 열고 시작하면 커널이 죽어버리네요...(얼마전에 jupyter notebook에서 자꾸 커널이 죽는다는 팝업이 뜨신다는 분도 계셨는데 혹시 비슷한 증상이신지... 모르겠습니다)I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locallyI tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: I tensorflow/stream_executor/cuda/cuda_dnn.cc:2259] Unable to load cuDNN DSOI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally	1	저도 비슷한 문제가 있었는데, 제경우에는 LD_ LIBRARY_PATH 가 jupyter를 sudo로 실행할때 root계정 env에 등록이 안되어 있더라구요! 혹시  jupyter config에서 패스 추가 하셨나요?	1	저도 jupyterhub로 설치했을 때 같은 문제가 있어서jupyterhub_config.py 파일을 다음과 같이 설정하니 jupyterhub에서 tensorflow를 사용할 수 있었습니다.import osos.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64'c.Spawner.env_keep.append('LD_LIBRARY_PATH')저는 bazel로 tensorflow를 py2로 빌드를 했고. jupyterhub는 python3버전이라sudo python -m ipykernel install 를 통해서 python2 커널을 만들었습니다.	3	백서현 윤상덕 말씀해주신 방법으로 해결되었습니다 감사합니다^^
6	안녕하세요 Jetson TX1 보드에 텐서플로우 설치를 완료하고 나서예제 코드를 실행해봤는데 빨간색 박스에 적혀있는 문제가 발생했습니다.그리고 보드가 GPU를 제대로 사용하고 있는지도 궁금합니다.설치방법 알려주셔서 큰 도움주신 전승현씨께 감사합니다.	1	cuda 환경변수를 설정않해서 그러지 않을까요?	1	cudnn 파일을 cuda 디렉토리에 안옮기신거 아닌가요..?	1	cudnn 라이브러리 경로를 ld_library path에 추가하셔야 합니다.쿠다 홈페이지에 설치 매뉴얼에 나와 있었던 것 같습니다.혹은 cudnn을 설치하지 않으셨다면 설치해주세요	0	Jetson TX1 모니터링 관련 내용입니다. https://devtalk.nvidia.com/default/topic/901337/jetson-tx1/cuda-7-0-jetson-tx1-performance-and-benchmarks/
15	딥사이어인 : 파트 2 - 벤지오 딥러닝 + 파이썬 머신러닝 기초 + 파이썬 PGM(확률그래피컬 모델링) 스터디 * 1회차 후기만 공유하겠습니다. 자료는 모두 공개 & 공유됩니다(정리 중)* 이 스터디는 계산 사회과학 그룹 싸이지먼트에서 진행합니다.(진행 김성동)#딥사이어인 파트2-1회차 스터디 후기작성자 : 김성동후기가 늦었습니다.. 죄송합니다 ㅠㅠ이번 월요일에 힐스터디에서 파트2 첫 시간을 가졌습니다. 새로운 파트 시작 치고는 새로 오신분들이 거의 없었지만,, 오순도순 모여 스터디하고 뒷풀이까지 했습니다,,!![파이썬 ML] 은 임재성님이 발표해주셨습니다.이전 장에서 만들었던 영화 리뷰를 벡터화화여 긍부정으로 분류하는 모델을 pickle 모듈을 이용하여 저장하고 실제로 Web application에 적용하는 예제였습니다. 임재성님이 직접 장고로 프로토 타입을 만들어 오셔서 더욱 와닿았던 발표였습니다!! 많은 다른 책에서 이 부분까지는 다루지 않고 있는데요, 한참 머신러닝 얘기하다가 웹 프로그래밍이 등장해서,, 가장 외전적인 성격을 가진 챕터이면서도 어떻게 보면 정말 필요한 부분을 배웠습니다! 특히 모델이 Partial update가 가능한지 유무는 처음 머신러닝 어플리케이션을 설계할 때 아주 중요한 요소라고 합니다!![파이썬 PGM]은 제가 발표했습니다.저희 스터디의 주된 목적은 어찌됐든 벤지오 교수님의 딥러닝북을 완독하는것이기에 딥러닝북의 뒷장에 등장하는 그래피컬 모델을 이해하기 위해 이번 파트에서 짚고 넘어가기로 했습니다! Probabilistic Graphical Model이 쉬운 영역이 아니지만 수식이 아닌 파이썬 코드가,, 이해력을 높여줄거라 믿으며 이 책을 선택했습니다...! 이번 회차에서는 앞으로 그래피컬 모델을 이해하기 위해 필요한 기본적 확률에 대한 개념 설명과 함께 PGM에 대한 개념과 목적을 소개했습니다. 최신 알고리즘들이 포함하고 있는 Generative Model을 이해하기 위해서는 이 PGM에 대한 이해가 필요하다고 합니다![벤지오 딥러닝] 발표는 김태흥님이 발표해주셨습니다.지난 시간에 Optimization을 하는 전반적인 방법들에 대해 설명해주셨고 이번 회차에서는 Stochastic Gradient Descent에 대해 집중적으로 설명해주셨습니다. SGD가 가진 문제점들을 파헤치며 최적화 알고리즘들이 진화해온 과정을 설명해주셨습니다. ill-conditioned, local minimum 등의 문제와 saddle point를 벗어나는 방법 중 momentum의 원리와 그에 파생된 Advanced Gradient Descent 방법들을 알려주셨고 그 외에도 Newton method, Conjugate Gradients, BFGS, L-BFGS 등도 소개해주셨습니다. 뒤에 소개한 알고리즘들을 Approximate Second-Order Methods이라고 하는데 특히 Newton method는 이론상으로는 완벽할지라도 구현이 된 라이브러리가 없어 잘 안쓴다고 하셨고 실질적으로는 Advanced Gradient Descent를 사용한다고 합니다.파트2에서도 슈퍼파워를 갖기 위한 여정은 계속됩니다!! 화이팅!	0	감사합니다. 관심이 많이 가는데 혹시 자료는 어디서 얻을 수 있을까요? 자료라도보면 좋을것 같습니다. ^^	1	스터디 진행하시는 김성동님께서 아마 정리 중이실거에요~	1	아직 파트2는 2회차 밖에 안했지만 조만간 정리해서 공유하겠습니다!
3	간단하게 텐서플로우 예제인 MNIST MLP로 제 데이터를 돌려보는데 x feature는 7개, y는 2차원(실질적으로 1차원 로지스틱)으로 하구요activation은 relu, leaky relu를 쓰고training data 4만개, testing 2만개정도를 사용했는데배치를 training data에서 True label 값 중에서  랜덤으로 들고와서 배치 절반을 채우고 나머지는 False label 값 중에서 랜덤으로 들고와 채우는 방식으로 매번 새롭게 배치를 1:1 비율로 구성하는 식으로 잡았는데학습이 아예 되지 않고 모두 False 혹은 True 로 찍어버리는 결과만 나오는데혹시 여기서 잘못된 부분이 뭘까요 ㅠ 혹시 같은 경우에 해결해보신 분이 있으시려나요..?	0	코드를 올려 주심이...아마도 특정 layer에서(예상은 출력단) 설정이 잘못 된것이 아닐까 생각합니다.	0		0		0		0		0	신경써주신 덕분에 해결했어요 데이터가 많아서 다 들여다보지 못했는데 도중에 inf 값이 껴있어서 행 제거하고 학습하니 학습이 되네요 ㅠ 감사합니다
15	Ian Goodfellow 의 콘볼루션에 대한 발표입니다. 라이브 중계입니다.
10	국내에서도 첫번째 봇 해커톤이 열리네요. "TensorFlow + 봇"으로 개발하고 계신 분들이나 관심있는 분들이 참여하시면 좋을 것 같습니다.
1	현재 tensorflow 공부용으로 컴퓨터를 세팅했습니다.연구실에 남아있는 부품으로 끼워맞춘거라 고사양은 아닙니다.젤 중요한 gpu가 gtx 660 2G 입니다.이 사양으로 현재 ImageNet에 사용되는 model들 예를들어 AlexNet, GoogLeNet, ResNet 등을 구현가능한가요??원활하게 동작시키려면 gpu 메모리가 어느정도 되어야 할나요??	0	권장 cuda capability가 3.0입니다.660 역시 3.0을 만족하기에 구현은 가능합니다. 원활한 동작을 위한 사양은 항상 다다익선이지요 :)
1	<tf 업그레이드 질문>tf 를 git으로 다운받아 바젤로 빌드하여 0.9버전 install 했었습니다. 업그레이드하려면 tensorflow 폴더 전체를 그냥 지우고 새로운 버전을 git으로 다운받아 다시 바젤로 빌드하여 설치하면 되나요?	1	bazel은 build 개발 tool이고 git 는 개발 협업 tool이고 python pip (conda) 는 package 관리 tool입니다. (download, install, update ,remove 등 ) 일부 기능이 겹치기도 하지만 단순히 설치하실 거면 package 관리 tool로 하는 게 일반적인 방법입니다. (pip, conda 등 사용)	0	소스 업데이트는 폴더를 삭제할 필요없이 git pull 명령으로 가능합니다
2	안녕하세요. TensorFlow 공부하고 있는 학생입니다. ㅎ 인터넷으로 Tensorflow가 좋다고 하여 조금씩 공부하던 중에 '텐서플로 첫걸음' 책을 접하게 되었습니다. 이 책에서 나온 예제를 하나하나씩 따라해보고 있는데 matplotlib를 이용하여 화면에 그래프를 띄어서 눈으로 확인해보고 싶은데 전혀 보이지가 않네요 ㅠㅠ 이전 에러에는 "$DISPLAY의 변수가 정의가 되있지 않다"고 해서 matplotlibrc 파일을 찾아가 Backend 변수를 'Agg'로 정의하였는데 에러는 없어졌는데 plt.show()를 하면 아무것도 안되더라구요.. 혹시 이 에러에 대해 해결방법을 아시나요??	0	디스플레이 백엔드와 관련된 문제 같은데요. 리소스파일에 Agg 로 정의하신 것은 맞는 방법일 것 같습니다. 유사한 다른 방법으로는 맷플롯립을 임포트 하시자 마자 강제로 설정을 하는 것도 있습니다.import matplotlibmatplotlib.use('Agg')이게 잘 먹힐지는 모르겠네요. 보통 잘 안나는 에러인데요. 재현이 가능할지 모르겠지만 사용하시는 파이썬 버전(배포판 버전), 텐서플로우 버전, 맷플롯립 버전, 시스템 OS를 알려 주실 수 있을까요?	0	주피터에선 주피터에 표시하는 기능이 있었던거 같은데요 따로 창이 뜨지는 않는거 같았는데 함 찾아봐야겠습니다
18	딥러닝에 관심이 생겨서 아래 동영상을 보고 있습니다.  linear regression 정도까지 초반만 봤는데 선형보간법이더라구요. 공대 수치해석이라는 과목과 딥러닝이 어떤 연관성이 있나요? 끝까지 봐야 알겠지만 아주 비슷한것 같아서 질문드립니다. 	2	딥러닝 혹은 뉴럴네트워크를 학습하는(수렴시키는) 가장 기본적인 알고리즘이 SGD 라는 방법인데 이 방법은 수치해석시간에 그라디언트 하강법 이라는 제목으로 배우셨을겁니다. 당장 예시는 생각이 안나는데 수치해석 강의에서 배운 내용들을 많이 써먹게 되더라구요.	1	numerical한 여러 기법들은 머신러닝에서 굉장히 많이 접하실거에요!  개인적으로 생각하기에,  학부수준의 미적분학과 선형대수, 수리통계학, 해석학 등 ML의 기초가 될법한 과목들은 굉장히 많은데,수치해석이나, 시뮬레이션 과목들이 코딩적으로(?) 조금 많이(?) 가깝습니다.	2	딥러닝의 목적은 간단히 말해 예측 및 판단을 하려는 것이죠. 회귀분석은 자료의 경향을 보여주니까 이 경향을 이용하여 예측 및 판단에 이용하는 것이죠. 그래서 딥러닝과정을 공부하다보면 이거뭐야 수치해석이잔아 하는 생각이 들죠.
3	GPU를 사용해서 tensorflow를 사용하는데 문제가 있어서 문의드립니다.MNIST를 가지고 이것저것 해보고 있는데 tensorflow tutorial대로 CNN을 구성해서 돌리면 다음과 같은 에러가 뜨면서 동작을 안합니다.E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5103 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.F tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 간단한 MLP를 구성했을때는 잘 돌아갔습니다.무엇이 문제일까요??CUDA toolkit은 7.5, CuDNN은 v5를 사용하고 있습니다. 버전 문제라면 MLP도 돌아지 않아야 하는 것 아닐까요??	1	어느 GPU를 사용하셨나요?	1	이문제랑 같아보이네요https://github.com/tensorflow/tensorflow/issues/4251CuDNN v5.1로 설치하시면 돌아갈듯합니다	0	위에분 답변대로 설치 패키지를 바이너리로 할 경우에는 문서에 명시된 버전을 맞춰 주셔야합니다.다른 "해결책"으로는 소스 빌드하는 방법도 있습니다.	0	정식 nvidia 최신 드라이버, Cuda toolkit 8.0, cudnn 5.1, tensorflow 0.10 소스를 받아서 빌드해서(빌드시 설치된 cuda 라이브러리 패스 추가) 설치해서 쓰시면 문제가 없습니다.
3	np.random.seed(1)python에서 위에 명령어 의미가 뭐에요?	0	난수 하나를 만드는데 난수 시드를 1로 준다는 의미입니다.	0	모든 난수를 만드는 알고리즘은 시드라는 것이 필요한데 아무리 난수라고 해도 어떤 외부적인 요인이 없을 경우에 발생하는 난수에 규칙성이 생성됩니다. 이를 제거하기 위해 이 씨드 값이 필요합니다 그래서 이를 제거하기 위해 씨드 값으로 타임스템프를 많이 이용합니다. 써놓고 보니까 이런 것을 원하는 건 아니었을 것 같은데 요.. ㅎㅎ	1	값이 변경을 방지한 상태로 테스트하려면 ramdom 값이 고장되어야 해요 그럴때 사용하시면 되요	0	실제로 난수는 주어진 순서에 따라 생성되고 반복적으로 생성됩니다. 진정한 의미의 난수가 아닙니다. 그런데 그 순서가 시작되는 규칙을 시작하기 위해 필요한 숫자를 외부에서 주는데 이를 seed(씨앗)라고 합니다. 이 seed가 예를 들어 1로 고정되면 이 난수 알고리즘은 항상 똑같은 순서의 난수를 발생시킵니다. 난수가 꼭 필요한 상황인데 아직 디버깅 중이면 같은 결과를 얻기 위해 위의 경우처럼 seed를 특정한 값으로 정해 버립니다. 이제 디버깅이 다 끝나고 실제 production에 들어가면 seed값 자체를 자꾸 바꿔야 하는데, 가장 많이 쓰이는 seed가 한번 지나가면 다시 같은 숫자를 불러내지 못하는 시스템 시간입니다. 난수가 들어가는 루틴 앞부분에 time 어쩌고 seed 어쩌고 하는 샘플코드를 많이 보실 수 있을 겁니다.
45	이거 내용 이해하신분 계시면 간단히 설명좀 부탁드립니다 ^^	7	제가 제한적으로 이해한 것은 무궁 무진한 (조합이 가능한) 수학의 세계에 비해 (지금까지 관측 가능해왔던) 물리계는 소수의 상대적으로 단순한 법칙이 여러 단계로 hierarchy 를 이루고 있는데, (Deep) Neural Network 가 그러한 시스템을 approximate 하는데 적합한 형태를 취하고 있으며, 이것도 실은 생물의 뇌의 구조를 모방한 것이므로 (인간의) 뇌가  지금까지 성공적으로 작동했던 이유도 비슷하게 설명될 수 있지 않느냐 일지요?	9	흥미로운 이야기네요. 원래 대다수의 과학적 발견이 간단한 자연현상을 '모방'하는데서부터 시작되긴 했지요. 우주도 사실 관통하는 기본 원리는 방정식이 그리 복잡하지 않은데(굳이 polynomial function으로 치환하자면 order가 2~4정도) 그게 순차적으로 얽히고 섥히고 하면서 결과적으로는 자연현상을 만들어내듯이, 뉴럴넷도 작동원리가 간단한 뉴런을 '모방'하는데서부터 시작했는데, 이걸 여러겹 쌓아서 순차적으로 연결해놨더니 실제로 사람이 판단하는거처럼 잘하는거다 하는 이야기네요. 문득 중학교 때 과학선생님께 "과학이라는 학문은 '왜'를 파헤치는게 아니라 자연이 '어떻게' 구성되어 있는가를 파헤치는 학문"이라는 명언을 들었던 기억이 떠오르는군요.	2	좋은 글인거 같지만 전달해주는 정보만으로는 왜 그런지 알게는 해줘도 확신은 시켜주지 않네요. 물론 이것을 알려면 논문을 보고 그 과정을 봐야하지만 한번 이 사람들이 쓴 논문도 보고 싶네요. 만약 논문이 없는 그냥 지레짐작이면 호두가 뇌를 닮았으니 머리에 좋다라고 하던 사람들과 별반 다르지 않은 논리라고 생각됩니다. 뇌와 hierachy의 관계에 따른 소수이 parameter로 그 큰 범위를 포함하는 것을 완전하게 보여준 논문인지 궁금하네요.	2	그리고 계층적 구조가 deep neural network가 어떤 문제를 잘 해결하는 것이라고는 이미 대부분이 알던사실아닌가요? 그리고 이렇게 되는 많은 수학적 증명들이 있는데 무엇을 새로 밝힌건가요?	8	"Why does deep and cheap learning work so well?"이라는 제목으로 왜 딥러닝이 잘 되는가를 설명하는 물리학자들이 쓴 논문인데. 요약하자면, 물리학적 관점에서 봤을 때데이터가 가지는 대칭성, 위치 불변성 등의 성질로 인해 뉴럴넷과 같은 간단한 함수로 근사가 가능하고,자연이 가진 계층적 구조가 딥뉴럴넷의 계층적 표현에 잘 들어 맞는다는 주장입니다.그러나, 데이터의 대칭성, 변환 불변성 등은 논문에서 제시한 근거가 모두 직관적이어서 논란이 많네요.MIT Tech Review 페북 댓글 보시면 비판적 글이 많습니다...물론 Universal approximation theorem이나, deep representation 은 이미 일반적으로 받아 들여진 내용입니다.	2	개인적으로 맘에 않드네요.harvard/mit 만 아니였어서, 시작도 않했을텐데..읽다가 짜증나서 다 않읽었으나... 개인적인 생각입니다.ㅎ2 가지 컨셉을 (억지로) 섞었는데,1) (non-living) 자연의 물리학 법칙은 low-order polynomial with 2~4 degree. 이건, 우리가 살고 있는 우주가 3차원이래서 그럽니다."우주의 물리학적 법칙은 간단하다." 이 이유는 물리학자들도 모릅니다. 이유가 없고, "그냥 그렇하다." 가 더 맞는 표현이고.multi-verse  컨셉이라면, 우리가 살고 있는 우주는 간단하기 때문에, 존재한다, 정도로...여기에 뉴럴넷이 왜나오는지...2) (living) 생명체의 환경에서, 뇌를 닯은 모델이 성능이 좋은 이유는, 뇌의 진화가 살아가기 위한 decision-making에 최적화 되었가 때문입니다.evolution 을 통하여, 뇌에 최적화된 유전자의 섞임이 일어난것이며.. 그래서 얼굴모양이 생겨난것이며..여기서, 물리학은 아무런 관련이 없으며, cognitive stinginess, 즉 에너지 낭비를 싫어하는 생명체로 부터 나온것입니다.hierarchical structure 가 물리학에서만 존재한다고 하는데, 이건 logic이나 수학에 더 가까운데.. Elon 이 돈낭비했다는 생각이..
22	#텐서팔로우 텐서팔로우 : 파트 2 - (텐서플로우 코드 리뷰 & 파이썬을 이용한 병렬/분산 컴퓨팅 기초 스터디) 1회차 후기입니다. * 첫 모임 후기만 공유하겠습니다. 자료는 정리되는대로 모두 공개&공유됩니다.* 이 스터디는 정통심리학 그룹 싸이그래머에서 진행합니다.9/6 텐서팔로우 Part.2-1 후기작성자 : June Kim 텐서팔로우 part 2 첫번째 시간이 있었습니다. Part 1 내내 이용하던 “힐스터디”를 예약하지 못해 근처 강남 토즈타워 점에서 진행되었습니다.(아마도 다음번엔 다시 “힐스터디”를 이용하지 않을까 싶습니다만...) 그리고 새로운 part의 새로운 시작인지라 새로운 분들도 많이 와주셔서 스크린에 빔을 쏘는 방을 이용했습니다. (10년만에 다시 학생이 된듯한...) 더불어 간단히 치맥까지 곁들인 즐거운 시간이었네요. ^^스터디 내용에 대해서 말씀드리면 첫번째 스터디는 유남구님께서 “CNN + AlexNet”으로 Image detection에 대해서 정리하여 주셨습니다. 내용의 전개는 기본적인 CNN의 방식와 특징과 CNN을 대외에 널리알리게 된 AlexNet에 대한 설명 그리고 현재 CNN의 발전 방향을 보여주는 R-CNN, Fast R-CNN, Faster R-CNN에 대한 설명까지 더해주셨습니다.스터디 중 가장 많이 논의가 된 부분은 Relu 이용시 Local Response Nomalization(LRN)이 이점이 되는 상황과 Data augmentation의 방식 중 RGB 픽셀에 컬러 채널 밸류를 변경하는 경우의 장점과 발생할 수 있는 문제, 그리고 Dropout을 통한 "Co-Adaptaion을 피하는 효과”이란 무엇이며 tensorflow에서 제공하는 dropout에 대해서 토의했습니다.비전공자셔서 준비하시기 힘드셨을텐데 노력하신 것이 보였습니다. 진심 감사드립니다.두번째는 권준호님께서 “FCN(Fully Convolutional Networks)을 이용한 Image segmentation”이란 내용으로 저희가 자주 참조하는 "github.com/sjchoi86”에서 새로 작성된 "dl_tutorials_3rd/ppts/Week3-1a Semantic segmentations.pptx”의 내용을 기반으로 코드를 직접 작성하시고 테스트 하신 결과를 공유해주셨습니다. 특히 직접 작성하시면서 코드 내용을 통해 로직을 설명해주셔서 더욱 좋았던 것 같습니다. 그리고 Part 1 마지막 시간에 이준구님께서 발표해주신 SegNet 내용으로 보다 쉽게 이해가 가능했습니다. 주된 토의 내용은 과연 Segmentation된 결과를 어떻게 쓸수 있는가와 트레이닝과정에서 각 weight와 bias 그리고 그를 통해 나오게된 중간 결과물(?)을 다시 어떻게 보정하고 이를 이용한 결과를 이용해서 나온 정확도를 어떤식으로 봐야하는지에 대해서 였습니다. Deep learining의 구조상 중간 과정에서 인사이트를 찾기가 쉽지 않은데 비젼과 이미지 분야에선 시각적 화면으로 인지되기 때문에 일반적 관점에서 보면 해당 특징이 더욱 두드러진다라는 생각이 들었습니다.세번째로는 강희석님게서 “Python Parallel Programming Cookbook” 중 "Ch.2: Thread-Base Parallelism”을 지난 시간에 이어서 발표해 주셨습니다. 실제 코드 예제를 스터디 시간 중에 이리 저리 수정해가며 테스트 해주셔 python 코드에 대한 이해와 동작 방식을 쉽게 이해할수 있었습니다. 그렇지만 이번에도 코드에 너무 들떠서 시간을 많이 사용해서 진도가 늦어지는 결과가 나왔네요. 특히 제가 너무 많이 요청드려서....(참여하신 분들께 죄송합니다.) python GIL 이슈를 포함해서 thread vs non-thread 케이스를 여러 방식으로 보여주셨던 부분이 인상적이었습니다.네번째로는 김무성님께서 “Programming Distributed Computind Systems” 중 Ch1”을 공유해주셨습니다. 분산 시스템과 동시성에 대한 좋고 길지 않은 책이지만... 매우 어려워 보이는 책이었습니다. 컴퓨터공학을 전공하신 분들 조차 낮선 Calculus(대수) 개념에 대해서 공부하게 되었습니다... 열심히 봐야할 책인듯 합니다. 병렬화를 위한 Concurrncy, 자원 활용의 극대화를 위한 Distribution, 그리고 Mobility가 필수가 된 현재의 컴퓨팅 환경에 대해서 간단히(?) 정의하고 이를 기반으로 한 모델(lamda, pi, actor, join, 그리고 mobile ambient)들을 설명해주셨습니다 . 이를 이용하는 다영한 프로그래밍 언어에 대해서도 알려주셨는데. Lisp을 제외하곤 대부분 낮선..것들이었네요.텐서플로우를 포함하여 분산 컴퓨팅 환경을 제대로 구축해서 결과를 뽑아내고자 할때 알아두면 크게 도움이 될 내용인것 같습니다.날씨가 왔다갔다하며 어수선한 하늘만 보이는 날씨네요. 모두들 건강에 주의하시길.
24	"10월, 소프트웨어에 물들다" http://somul.kr 행사를 합니다. 전국 도서관 소프트웨어 강연 이벤트.10월 22일 (주로 어린이) 도서관 대상입니다. 홍보 / 참여 / 후원 부탁드립니다.요즘, 가장 핫한 아이템인 머신러닝, 인공지능 능력자 여러분들의 많은 '강연자' 참여를 부탁드립니다.	0		1	부족하지만 거들도록 하겠습니다. 참여신청 완료!
3	Tensorflow를 공부하다가 GPU와 함께 돌려볼려고 싶어서 TiTan X를 구입해서 설치를 하였습니다. 그런데 Ubnuntu 14.04, 15.04, 16.04를 설치를 해보았는데 생각보다 쉽지 않네요. Cuda drivers, Cuda toolkit 등 어떤것으로 설치해야하는지? 설치도 안되는것 같고 에러가 중간에 나오는데 참 어렵습니다. 혹시 이런과정을 경험하신 분이 있다면 공유해주시면 감사하겠습니다.	2	예전에 삽질하면서 정리한 글입니다http://m.blog.naver.com/kjpark79/220781100554도움이 되셨으면 좋겠습니다^^	1	처음이시라면 여러모로 14.04 추천드립니다.	1	https://github.com/JSpiner/gtx1080_tensorflow관련해서 정리해 보았습니다	2	http://flyingdcat4.tistory.com/m/76저도 열심히 삽질하면서 정리한것입니다. Ububtu 14.04입니다.
0	안녕하세요~텐서플로우를 시작한지 얼마 안되었고, 최근에 '텐서플로 첫걸음'책을 한 번 다 읽었는데요.실습을 하고 싶은데, 혹시 구글 클라우드 플랫폼에서 텐서플로우 실습할 수 있는 환경이 있을까요?
7	안녕하세요^^ 직접 구현한 fully connected NN을 이용하여 cos함수의 학습을 시험삼아 하고 있습니다. 구현하다 궁금한 점이 있어서 글 올려봅니다. 초기 weight가 모두 양수인 상황에서 layer를 깊게 구성하고 각 layer의 node수도 많이 설정을 하다보면 weight가 음수가 되지 않는 이상 layer를 지날때마가 값이 누적되어 inf값이 되는 경우가 있습니다. Activation function을 LReLU를 사용해서 더더욱 계산된 값이 커지는 것을 잡아주지 못하구요. 일반적인 학습 상황에서도 특별한 처리가 없으면 값이 발산할 수 있을 것 같은데.. 다른 분들은 어떻게 처리하고 계신지 궁금합니다. 참고로 제가 구성한 network은 아래와 같습니다.  - input 개수: 1개 (data set은 180개)  - output 개수: 1개  - hidden layer: 100개  - hidden layer의 각 node: 50개  - learning rate: 0.001  - Bias: 1.0	0	초기 weight를 모두 양수로 잡은 이유가 있나요?	0	Layer 가 100개(?)는 너무 깊은거 같는데 2layer 부터 시작하는게 더 좋을듯 하네요.	0	어떤 언어로 작성 중이세요? 마침 저도 비슷한 (여러가지 네트워크를 직접 구현하는) 실험들을 하고 있는데, 혹시 제가 익숙한 언어이고 또 소스 공유가 가능하시다면 저도 돌려 보고 어떤 문제가 있는지 살펴볼 수 있으면 좋겠습니다.	0	Weight decay를 사용해보시면 어떨까요	1	혹시... vanishing gradient(이하 VG) 문제와 반대 상황으로 이해하면 맞을까요? VG 문제는 [0,1] 구간의 값들이 여러번 곱해지다보니 점점 0에 가까워지는 것이라면 지금 겪고 계신 상황은 큰값들이 여러번 곱해지다 보니 점점 무한대에 가까워지는 것 아닐까요. 그렇다면 VG 문제를 해결한다고 나온 ReLU의 태생적인 문제로 보이는데... 이런 주제에 대해서 찾아보면 뭔가 나오지 않을까요.저도 찾아보고 나오면 공유 드릴께요.	3	Batch Normalization 에 대해서도 검토해보세요~	0	Leaky relu도 검토해보심이~	0	learning rate를 아주 작게 잡아주시면 어떨까요	1	Relu를 쓰신다면 윗분들이 얘기하신대로W=randn(in, out) / sqrt(in/2)로 초기화하시고 Batch normalization을 하셔야 됩니다.
2	안녕하세요, Intel machine에서는 gcc보다 icc(Intel compiler)로 컴파일하는 것이 속도 측면에서 좋다고 들은 적이 있어 tensorflow를 icc로 컴파일을 하려고 하는데요,현재 [TF_HOME]/tensorflow/contrib/makefile/ 폴더에 있는 Makefile을 gcc를 icc로 수정하여 보았으나 변경된 것이 없네요..혹시 intel compiler로 tensorflow를 설치하신 분이 계시면 소스코드의 어느 부분을 변경해야 하는지 조언 부탁 드립니다.감사합니다.	0	NVIDIA GPU를 사용하는 경우 결국 성능이 NVIDIA nvcc로 컴파일 된 cuDNN에 의해 좌우되는 것은 아닌지요...?
1	'텐서플로 첫걸음' 책을 보고 있는 한 학생입니다. regression을 한번 돌려보는데 plt.legend()에서 오류가 발생하는거 같습니다. 오류 코드는 다음과 같습니다. "UserWarning: No labelled objects found. Use label='...' kwarg on individual plots." 어떻게 해결하면 될까요?? 파이썬을 처음 해보는거라 잘 모르겠네요. 많은 가르침 부탁드립니다.	3	plt.legend() 라인을 주석 처리하시고 바로 plt.show() 하시면 될 듯 합니다. 원서의 코드에서 잘못된 건지 옮기면서 누락한 것인지 확인해 보고 다시 코멘트 드리겠습니다.	3	주피터 노트북으로 옮긴 버전(https://github.com/rickiepark/first-steps-with-tensorflow/blob/master/chapter2-6/chapter2_regression.py.ipynb)에는 빠져 있는데 책에는 원서에 있는 게 그대로 옮겨진 것 같습니다. 레전드를 쓰려면 plot 함수에서 plot(..., label='line 1') 처럼 레이블을 넣어주어야 합니다. 예제에서는 레이블 옵션을 주지 않아서 legend 함수에서 경고가 발생했습니다. 경고가 발생해도 프로그램이 중단되지는 않지만 좀 신경이 쓰이죠. ^^
4	Embedding관련 실험을 하고 있는데요 자꾸 텐서가 죽네요.. 이런 에러 보통 언제 나는 걸까여..	2	ipython 커널 실행한 터미널 콘솔에서 에러 확인해보세요	0	어..저는 윈도우10 배쉬에서 주피터돌릴때밖에 커널죽는걸 못봤습니다..	1	아마 컴퓨터의 메모리가 부족해서 나는 경우 아닐까 합니다.
16	GTX 1080 설치 성공했습니다.  i5 cpu로 1분 걸렸는데 4초만에 끝나네요. 이정도면 빠른 걸까요?그리고 질문이 한가지 있습니다.1080 8G 메모리를 가지고 있는데Total memory: 7.28GiBFree memory: 6.86GiB 라고 나오는데 VGA card를 하나더 설치하면 8G(7.28GiB) 모두 사용할수 있게 되는 것일까요?그리고 설치 관련해서 좋은 자료 올려주신 분들 모두 감사드립니다.	1	ECC (Error Correcting Codes) 를 꺼보세요	1	메인보드에서 igpu옵션이던가, pci 상의 GPU와 CPU의 그래픽 전부 사용할 수 있는 옵션이 있습니다. 그 옵션을 킨 후 메인보드로 모니터를 꽂으면 xwindow의 Usage는 사라질 것이라고 생각하지만... 어디까지나 생각이고 실험해보지는 않았습니다 :)	3	GPU 세팅 기념으로 Jupyter 공개합니다. ( password : dl )1080성능이 궁금하신 분들은 한번 사용해 보시길. 아마 여러명 동시에 사용하면 상태가 어찌될지 모르겠네요. 내일 아침부터는 일해야 해서 아침에 종료하겠습니다.^^http://203.233.111.89:8888/	1	바이오스에 보시면 온보드 그래픽카드로 모니터 쓸 수 있는 옵션 있을 수도 있습니다.	1	어느분이 조언해주셨습니다. GTX1080 은 cuda 8.0을 꼭 설치해야 한다고. 정말 2배이상 빠른것 같습니다. 감사합니다. 꾸벅^^
104	개인적으로 CNN에 대해서 수십 시간은 공부했고, 강의 또는 설명 영상은 열개 이상은 봤습니다. 그래도 "직관적"으로 정확히 이해 안 된 느낌이 남아 있었는데요. 그러던 중 아래의 30년전(!)에 만들어진 단 12분짜리 (파트1+2) 영상을 보고나서 그 찝찝한 느낌이 많이 사라졌습니다. CNN의 기초를 좀 더 직관적으로 이해 하고자 하는 분들께 공유드립니다.	0	OMG, 1986년 제작이라니요 !! 저도 activation이란 표현을 이제사 비로소 제대로 이해하게 된거 같슴다.	0	Deep Learning TV 라고 유튜브에 검색하시면 비슷한 방식으로 아주 짧게 잘 설명된 비디오 강의가 있더라고요. CNN에 대해서.	0	잘 보고 갑니다. 정말 직관적으로 이해가 되네요. 감사합니다!!
29	https://github.com/FuZer/Tensorflow-r0.8-on-Jetson-TX1Tensorflow r0.8을 Jetson TX1에 빌드한 경험을 공유합니다. 도움이 되었으면 좋겠습니다	1	사용해보고 싶은 디바이스 인데... 자료 공유 감사합니다.^^	1	정말 좋은 자료네요.. 감사합니다
4	Unsupervised learning에대해..텐서플로 첫걸음 이라는 책을 정독을 아무리 해봐도, Tensorflow로 unsupevised learning을 어떻게 하는지 감이 잘 안옵니다. 큰 그림이 안그려 진달까요. 현재 supervised learning으로 주어진 과제를 무리없이 잘 수행하고 결과도 잘 도출하고 논문도 곧 쓸예정입니다만, 비슷한 재료를 unsupervised learning을 한다면 cost function이나 gradient descent 알고리즘을 쓰지 않는건가요? 만약 그러면 학습이 어떻게 이루어지는건가요;; 평생 주입식 교육만 받아온 저로서는;; 이해가 안되는건지도..	7	저는 Auto Encoder를 보고 나서 느낌이 확 왔었습니다. Two Minute Papers - What is an Autoencoder?https://www.youtube.com/watch?v=Rdpbnd0pCiI	4	텐서플로 첫걸음 책에는 군집화가 unsupervised의 한 예로 나와있습니다만 뉴럴 네트워크에서는 Sedong Nam 님께서 말씀하신 오토인코더가 더 좋은 예인 것 같습니다. ^_^
1	Elva Intelligent Customer Service, Cool!
42	많은 부분 추가했어요파이썬이란게 만만한게 아니네요
2	안녕하세요, TF 설치중인데 bazel로 tensorflow_serving 빌드시 아래와 같은 에러가 발생합니다.ERROR: /root/.cache/bazel/_bazel_root/2d16d9349bff8cf3d8fc4a53d2a23056/external/org_tensorflow/tensorflow/core/kernels/BUILD:1089:1: C++ compilation of rule '@org_tensorflow//tensorflow/core/kernels:scan_ops' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer ... (remaining 102 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStat혹시 문제가 무엇인지 아는 분 계시려나요? ㅠㅠubuntu 14.04, python 2.7, cpu 모드, git 기준 최신 소스로 설치 진행중입니다.	0	음 빨리 해결되셨으면 좋겠네요 ^^:	0	그냥 develop용 container에서 빌드했습니다. centos7에서는 빌드에 문제가 있네요
1	안녕하세요. TF 단독으로는 문제없이 사용하고 있습니다만 serving은 빌드 에러때문에 아직 사용을 못해보고 있습니다.혹시 사용중인 분 계시면 성공하신 환경이나 설치형태 공유좀 부탁드립니다. ^^	0	그냥 develop용 container에서 빌드했습니다. centos7에서는 빌드에 문제가 있네요
20	서울대학교에서 열리는 딥러닝실습 TensorFlow튜토리알 . 다음주에 등록마감 예정입니다.  관심있는분들의 많은 참여 바랍니다^^	0	박준하
0	cnn 텐서플로우 이용하지 않고 파이썬으로 짠 소스 잇나요?	0	아니면 c++이나요	0	텐서플로우를 이용하지 않았다는 말은 다른 라이브러리도 일체 사용하지 않았단 의미인가요? 제가 짜본 게 있습니다마는 training 과정이 워낙 느려서 중도 포기했었지요. 잘 돌아갈런지 모르겠네요.	2	깃허브에서 스탠포드 cs 231n 과제 찾아보시면 될거 같습니다.파이썬으로 cnn짜는게 과제였거든요
6	안녕하세요. 매번 눈팅만 하다 질문 드립니다.리눅스 서버를 구축하고, 그 위에서 TF를 이용해서 LSTM을 학습 시키려고 하는데요.컴퓨터 사양 때문에 고민을 하고 있습니다.200정도의 예산으로 메인보드, cpu, 메모리, VGA를 해결해야 될 것 같은데요. 일단 결정한 사양은 아래와 같습니다.CPU : i7-6700 RAM : DDR4 32 Gb메인보드야 ATX 규격 내에서 적당히 구입하려 하는데요.문제는 VGA입니다.130만원 정도가 여유 금액인데요. 아래 옵션 중 어떤 게 가장 LSTM 학습 돌리기에 좋을까요?GTX 1080 1개 구매GTX 1070 2개 구매GTX 1060 4개 구매끝이 없는 고민입니다. 조언 부탁드립니다.	1	트레이드오프가 있으실 것 같은데요.메인보드의 pci 스펙에 따라 pcie x16 두 개를 지원하는지 확인해 보셔야 할것 같습니다. Pci 밴드위스가 충분치 않으면 그래픽 카드 두 개를 올리셔도 속도가 안나옵니다. 1070 두 개와 1080 한 개 중 어느 게 빠른지는 아마 다른 분이 답을 해 주시리라 믿고... ^^;;;	1	http://timdettmers.com/2014/08/14/which-gpu-for-deep-learning/저도 입문자이긴하지만 이 페이지를 참고로 gpu 구입했습니다. multiple-gpu에 관련된 조언도 있으니 한번 보시면 좋을것 같습니다.	1	훌륭한 답변들 감사드립니다. 카이스트 준 타니 교수님께 자문을 구해 보았는데요. 비쥬얼 정보를 다룬다면 무조건 비싼 gpu를 사라고 하십니다 ㅎㅎ 메모리가 아주 중요한 이슈라고도 말씀하셨고..병렬처리가 우선이면 1070 다수가 더 효율적일수도 있다고 하네요.	0	솔직히 1080이 좋죠.	2	pascal titanX 어떠신가요? 직구로(배송비, 세금 제외) 1200불입니다 예산에 오바가 되긴 하지만 ㅠ
5	드디어 GTX 1060을 구하고 이제 연구실컴퓨터로 tensorflow를 설치해보려고 하니... 여기저기서 에러가 속출하네요.CUDA설치시에 deb로 설치했더니 무한로그인에러에Pascal이라서 cuda8.0, cudnn5.0으로 해야하고 tensorflow도 직접 빌드해야하고...ubuntu 자체적인 설정도 해야하고...허허우분투 재설치하러갑니다 ㅠㅠㅠ	0	감사합니다. 파스칼은 cuda8.0을 해야하는군요	2	timeshift라는 프로그램을 활용하시면 편합니다. 중간중간에 날려먹어도 포맷하지 않고 이전상태로 복원할 수 있습니다. 시간도 얼마 안걸리구요.	0	저도 주문했는데 노가다가 예상 되는군요 ㅠ	3	뭐든지 설치가 가장 어려운거 같아요..	0	부럽습니다. 돈이 없어서 GPU기반으로는 나중에 해봐야겠어요	0	16.04에서는 nvidia 드라이버 설치하기가 그래도 좀 편하더라구요....	1	테스트용으로 1060으로 하나 세팅하고, 서비스 학습 용으로 1080 2개  꽂힌걸로 구매해서 사용하려는데, 서버 설정팀에서 따로 설정 안해준다면, 나중에 세팅 및 테스트 하는거 관련해서 공유 한번 하겠습니다.CPU vs 1060 vs 1080x2	0	저깉은 경우는 1070 ubuntu 16에설치했는데 설치과정은 그렇게 어렵진 읺았어요. mnist deepq 도 질돌아가네요.
4	텐서플로우 자료들을 찾다보면 필터들을 이렇게 시각화 한 것들이 있던데,따로 처리를 해주는것인가요? 방법이 있는건지요..단계별로 살펴보려고 이렇게 출력해보려고 하는데 방법을 모르겠어서질문 드립니다.	1	다양한 방법이 있습니다. 구글에서 tensorflow weight visualization 로 검색해보세요.
13	혹 엔비디아 임베디드 보드 Jetson TX1 에서 Tensorflow를 빌드해서 올려보신 분이 계시거나 하셔야 되는 분이 계신가요?이미 올려보신 분이 계시다면 성능이 어느정도 나오는지 여쭤보고 싶고 하셔야 되는 분이 계시다면 제가 빌드한 경험을 정리해서 공유하려 합니다	0	어떻게 하셨나 궁금하네요~^^	0	궁금	1	저도 TX1 보드에 Tensorflow를 빌드해야하는데 정확한 방법을 못찾았습니다.. ㅠㅠ공유해주실 수 있으신가요??
50	기초 중의 기초인 MNIST 숫자 인식기를 아주 오래된 (200년은 되었을 것 같은) 모델인 Gaussian Bayesian 확률 모델로 구현해 보았습니다. MNIST 데이터로딩부터 시작해서 학습, 테스트 과정까지 머신러닝 라이브러리를 전혀 사용하지 않고 구현하였습니다. 다음과 같은 기초적인 부분을 이해하는데 도움이 되었기에 이곳에도 공유 합니다.=================목표=================- MNIST 데이터 특성 시각적으로 이해하기- Python, numpy, matplotlib 사용해 보기- Bayesian Theorem 이해하고 구현해 보기- Multivariate Gaussian Distribution 이해하고 구현해 보기=================실험 데이터=================- 학습 데이터: MNIST 기본 60,000개- 테스트 데이터: MNIST 기본 10,000개=================실험 결과=================- Bayesian 확률 모델만으로 분류 정확도가 대략 84% 정도 나오는 것을 확인 하였음- Multivariate Gaussian 적용하니까 분류 정확도가 대략 92% 정도까지 올라가는 것을 확인 하였음=================코드=================메인 프로그램:https://github.com/dgtgrade/HumanLearning/blob/master/2001a.py- numpy, matplotlib 외에 본격 머신러닝 라이브러리는 전혀 사용하지 않았음- 머신러닝 관련 부분 대략 200줄 이하로 매우 짧음- 시각화 관련 코드 및 코멘트 등이 대략 300줄 정도임MNIST 데이터 파일:MNIST 공식 홈페이지에서 받은 그대로임https://github.com/dgtgrade/HumanLearning/tree/master/data위 디렉토리에 있는 t10k* 파일 2개, train* 파일 2개MNIST 데이터 로딩 프로그램:https://github.com/dgtgrade/HumanLearning/blob/master/mnist2ndarray.py- 로딩 부분 로직은 20줄도 안됨- python 및 numpy 엄청 편함Multivariate Gaussian 적용하지 않고 Bayesian 확률 모형만으로 돌아가는 코드: 위 2001a.py 옛날 버전https://github.com/dgtgrade/HumanLearning/blob/8e57a2b3340da3b38956b83cf24433d3a9fbd11b/2001a.py=================실험 동영상=================- 학습: 실험데이터 전체 60000개를 학습하는 과정을 보여줌- 테스트: 테스트 데이터 전체 10000개를 테스트 하는 과정을 보여줌- 테스트 과정에서 정답률은 1번 후보만으로 구했으나, 표시는 3번후보까지 하였음	1	조만간 발표한번 하셔야겠습니다 슬슬 준비하시지요 ㅋㅋㅋㅋ	0	동영상 잘 만드셨네요. 이 내용 Karpathy 수업에서도 봤던거 같네요
2	안녕하세요? inception-v3 모델을 공부하기 이전에 이미지넷의 데이터를 다운로드 받고 학습시키는 예제를 실행해 보려고 하는 학생입니다!!너무 궁금한 부분이 있어서 질문 올려보겠습니다!(사실, 주 목적은 이 부분이 아닌데 bazel 명령어 부분 관련해서 막히는 것이 있어서 간단한 예제를 올려보았습니다!)이미지넷에서 데이터를 다운로드 하는 부분입니다DATA_DIR=$HOME/imagenet-data    >> 경로설정bazel build inception/download_and_preprocess_imagenet >> inception/download_and_preprocess_imagenet 스크립트를 빌드bazel-bin/inception/download_and_preprocess_imagenet "${DATA_DIR}$">> 스크립트 실행이러한 명령 부분이 있습니다!download_and_preprocess_imagenet는 그냥 .sh 파일일 뿐인데, 그냥 chmod +x 로 권한을 주고 그냥 실행을 해도 되지 않나요?왜 bazel을 통해서 빌드를 하는지 이유가 너무 궁금합니다..bazel 빌드 툴에 대해서 여러가지 여쭙고 싶은데.. 잘 하시는 분 연락이 좀 닿을  수 없을까요 ㅠㅠ두서 없는 글 읽어주셔서 정말 감사드립니다!!!!	0	bazel 안쓰고 resnet에서 python 파일을 돌려본적이 있습니다. 오류 몇개 수정하니 잘 되었습니다. 아마도 inception도 bazel 없이 되지 않을까요? bazel 귀찮네요. pycharm에서 바로 돌리기도 함들고... 딱 맞는 답이 아니라서 죄송합니다^^;
0	신경망을 구축시 질문이 있습니다기존의 예를들어 사람이라고 하면 사람키에 관한 클래스를 나누고 신경망을 학습하여 사람키에 관한 output이 나오게 하고 사람의 몸무게라 하면 몸무게에 관한 신경망을 학습 하고 해서 Test Image를 키의 신경망에 넣어 키를 추측하고 그런다음 다시 몸무게 신경망에 넣어 몸무게를 추측했습니다 궁금한것은 이렇게 각각의 신경망이 아니라 Multi label이라고 하여 하나의 이미지에 키라벨도 붙이고 몸무게 라벨도 붙여서 학습하는 방법이 있다고 들었는데 자세한 방법을 아시는분이 계신가요?참고할만한 문헌이나 keras나 TF로 구현해본 분이 있으신가요?답변 해주시면 감사하겠습니다 !
9	안녕하세요.한국정보기술연구원  ‘Best of the Best’ (이하 BoB) 총동문회 부회장 정병연 입니다.다름아니라 10월에 열릴 학술 컨퍼런스 발표자 모집을 위해 글을 올리게 되었습니다 ^^..BoB는 화이트해커 양성을 목적으로 지난 2012년부터 현재까지 미래창조과학부의 지원을 받아 운영되고 있는 정보보안 인재양성 프로그램입니다.매년 수료생과 국내외 보안업계 관계자가 참여하는 컨퍼런스를 개최하고 있으며, 올해에는 다음의 내용으로 행사가 진행될 예정입니다...[개요] 제 2회 BISC 컨퍼런스[일시] 2016년 10월 29일 (토)[장소] 협의중 (고려대학교 혹은 강남 인근 컨벤션센터)[주제] 정보보안, 머신러닝 관련 자유주제 (최근 동향, 기술, 거버넌스 등)..위의 내용 중, 머신러닝 파트의 발표자를 Tensorflow KR에서 모시고 싶습니다. (주제와 컨셉에 제약은 없으나, 정보보안 기술과 접목 가능한 내용이면 더욱 좋을 것 같습니다)..발표자 지원을 희망하시는 분 께서는 2016년 9월 25일 자정까지 다음의 내용으로 메일을 보내주시기 바랍니다...[메일주소 : bobalumni@gmail.com ]- 이름 - 소속 - 연락처 - 발표 주제- 발표 요약(자유 양식)..발표자에게는 당일 소정의 발표비를 지급할 예정입니다.보내주신 메일을 확인 후 내부심사를 거쳐 9월30일까지 개별연락을 드리도록 하겠습니다. 감사합니다.
123	기계학습 기반의 채팅봇 만들기에 관련한 삽질을 주제로 8월 13일에 파이콘에서 발표를 했었습니다. 파이콘 한국어 발표 촬영본을 어제 올려주셔서 링크 붙여봅니다. 배우려고 보지는 마시고 머리 갑갑하실때 예능으로 보시면 좋습니다. https://www.youtube.com/watch?v=q44fefORi1k아래는 발표자료입니다.https://speakerdeck.com/inureyes/building-ai-chat-bot-using-python-3-and-tensorflow덧) 쉬는 날이 생겨야 코드 정리를 하고 업로드를 할텐데 발표날 이후로 하루가 안 비네요...
1	현재 Neural network를 이용해서 알고리즘을 구현하고 있습니다. 데이터는 xor데이터를 확장시킨 형식으로 이용하고 있습니다. x값이 1만개, 데이터 수가 1000개정도 됩니다. x값 01010... 에 대해서 y값 0 or 1 이 나오는 그런 데이터 입니다.지금 상황에서 x-input 값을 나눠서 두개의 layer로 진행하다가 중간에 하나의 layer로 합치고 싶은데 어떤식으로 합쳐야 할지 잘 모르겠습니다. 혹시 합치는 부분에 대한 함수가 따로 있나요??조언 부탁드립니다.	0	"Xor 데이터"가 무었인지 모르겠습니다. Input feature 가 10000개.  즉 10000*1000개의 0/1이 있다는건가요?두개로 나눈다는건 5000개 5000개 로 말씀이신가요??	0	v 는 xy 에서 나오는건가요?? NLP 로 보면 POS tagging 정도로 보면 되나요? 그래서 위에서 ensemble 하는 정도로 보면 되나요?	2	tflearn 프로젝트에 합치기가 구현되어 있더라구요. merge라는 함수였던 것 같습니다. 그걸 참고하실 수도 있을 것 같아요.	2	두개의 parallel한 layer의 출력이(x와 v가 통과되어 나온 출력) dimension만 동일하면 그냥 합치면 되지 않나요? 합치는 방법만 잘 정해서 예를 들어 합칠때 weighted sum을 할 것인지 단순히 concatenation할 것인지(이걸 하시려는거 같지만) 그것만 정해서 합친다음에 최종 layer에 입력으로 넣어주면 될 거 같은데요?
5	https://github.com/y0ubat/MachineLearning_Study/blob/master/05%20-%20Deep%20NN%20For%20XOR/01%20-%20Deep%20NN%20For%20XOR.py궁금한게 하나 있습니다. 모두를 위한 머신러닝 강의를 보고 Sigmoid 대신 Relu를 쓰게 되었는데, 정상적으로 결과가 출력이 되나, 3번중 1번 확률로 Cost가 0.693147에서 전혀 안바끼거나 0.4~~쯤에서 안내려갑니다. 무엇이 잘못되었을까요?..	0	Learning rate가 너무 높은것같은데요. 더 낮춰서 시도해보시면 좋을것같아요	0	Relu의 gradient exploding 과 관련있을 것 같아요해결방법은 윗분이 ...	1	감사합니다. 러닝레이트 쭐여보니 전부 다 잘나오네요 ㅎ
4	Window 10 bash shell에는 기본으로 파이썬 2.7이.설치되어 있는데요. 3.5를 쓰고 싶어서,anaconda3를 리눅스 버전으로 설치해 봤는데, 설치 폴더로 이동해서, 파이썬을 구동해도, 기본적인2.7이 구동되네요. 혹시,해 보신 분 있나요? 추가적인 환경변수 설정이 필요할 듯 한데, 조언 부탁드려요. 참, jupyter notebook도 구동해 보신 분 있는지요? 구글링을 해 보니, 결론적으로 안 된다 이던데, 혹시 성공하신분?	0	저 말씀하신것처럼 해봤는데 다른것은 전부 되는데.....jupyter notebook 커널이 죽네요.. 저만안되는게 아니었군요..혹시 되셨나요??	0	도커로 하셔요..	0	윈도우10 BASH에서 주피터노트북 커널이 자꾸 죽는문제 해결못하고 결국 우분투 깔았습니다...
101	안녕하세요. 텐서플로우   tutorial을 소개합니다. 일시: 2016년 10월 5일 장소: The-K  Hotel (서울 양재동) 프로그램 : (첨부파일) KSC2016  행사중 일부 등록비 없고, 선착순 등록     http://www.ksc2016.re.kr/index.html	0	등록 안내 페이지가 안 열리네요...^^;;;	0	아.. 왜 사전등록 페이지가 안열릴까요?	7	메뉴 링크 변하는거 보고 추측해서 갔더니 대충 맞네요http://www.ksc2016.re.kr/sub5_2.html	2	일을 대충대충하니까 그렇지요... 요즘들어 정부기관들 맘에 드는게 없네요. 전화번호는 안내부스로 안내하고, 안내부스는 이런 행사가 있는 지도 모르고.... 참, 기본이 중요한데....	0	튜토리얼만 신청했는데 등록된거겠죠? :-)	2	아이폰에선 등록 버튼이 안뜨네요 ㅜㅜㅋ	0	감사합니다. 근데 등록확인 으로는 안들어가지네요.	0	저는 사전 등록이 동작하지 않네요. :/	0	Suan Lee	0	다음에는 주말에도 좀 해주세요...ㅠㅠ 휴가 못 내는 직장인들을 위해...	1	가고싶은데 평일이라 학교가 걸리네요ㅠ	0	링크가 다른 행사로 연결되는것 같습니다.	0		0	트래픽 오버인듯하네요	0	안들어가져요	0	그런데 제가 보기에는 내용에 비해서 시간이 너무 부족해 보이네요~^^;; 실습까지 있지만 그냥 준비된 예제를 주고 실행하는 정도 일 듯	0	짧은 시간이지만 강사분들이 전달력도 좋으시고 능력자 분들이라 다행이네요~ 미리 한 번 예습하고 가시면 기본을 넓게 훓어보기에 아주  좋아보입니다 ^^	0	가고 싶은데 수업이라 맘이 아프네요ㅠ	0	사전등록이 200명이 넘어서 튜토리얼 등록은 더 이상 받지않고 있습니다. 150명 정도 참석가능하니 참고바랍니다.	0	마감이네요 ㅠ 현장 등록 150명 가능하다는 말씀이신가요?
78	David Wang 님께서 아래 글에서 y=x^2 함수를 딥러닝으로 근사 시킬 수 있을까? 질문 하셨었습니다.https://www.facebook.com/groups/TensorFlowKR/permalink/330905453917186/그리고 제가 Universal Approximation Theorem 에 따르면 아마도 간단한 ANN으로도 가능하지 않을까 생각 한다고 댓글 드렸었는데요.이론은 그런듯 한데 실제로 어느 정도 간단히 가능할지 저도 궁금하기도 했고, 어차피 이제 BP 좀 구현해 봐야겠다 하고 있던 참이기도 해서, 간단히 ANN 구현하고 x^2 근사 함수 찾기에 대해서 실험 해 봤습니다. 한줄 결론: x^2 잘 되네요. ^^두줄 결론: sin(x) 조차도 쉽게 되네요. ^^세줄 결론: Universal Approximation Theorem 이거 정말 끝네주네요.==================구현된 간단한 ANN==================- 입력 레이어: 노드 1개 -- x 그대로임. 즉, feature 로서 다항식이나 비선형 함수 사용하지 않음- 히든 레이어: 1개, 노드: 50개-- a = sigmoid(w1*x + b1)- 출력 레이어: 노드 1개-- o = w2*a + b2- 코스트 함수: Squared Error* 히든 레이어가 하나라서 DNN이라고 적지 않음* ANN 중 가장 표준적이고 기초적이라고 할 수 있는 ANN 그대로, 또는 그중에서도 가장 간단한 형태라고 보면 됨==================실험 결과==================t(x)=x^2 함수: x는 [1.0~12.0]까지 학습 시켰는데 잘 되었음추가로,t(x)=sin(x) 함수: x는 [1.0~10.0]까지 학습 시켰는데 잘 되었음또 추가로,t(x)=x^3+3*sin(x)^2-10 함수: x는 [-5.5~5.5]까지 학습 시켰는데 잘 되었음히든 노드수를 늘릴 수록 더 넓은 범위의 x 값을 커버할 수 있음을 일정 범위 내에서 확인 하였음==================코드==================https://github.com/dgtgrade/HumanLearning/blob/master/1001.py* numpy 외에 아무런 라이브러리도 사용하지 않았음* 실험용으로 대충 빨리 만들어본 코드라서 깔끔하지 않음* 게다가 python 사용한지 1주일도 안 되었고, * numpy 오늘 처음 써봐서 특별히 이상한 코드가 많을 것으로 추정됨* Back Propagation 외에 요구되는 배경 지식은 없음* 총 200줄 정도이고, 코멘트 및 디버깅용 코드등을 제외하면 150줄 이하임* python 3.5 환경에서 작성 하였고, numpy만 있으면 실행 됨==================실행 동영상==================첨부 하였음페북에서 HD 옵션 켜고 보면 잘 보임등장 단어 설명:* iteration: 학습 회수* train: 학습 데이터* test: 학습되지 않은 데이터* x: 입력* h: 학습된 네트워크의 결과* y: 정답 출력* cost: squared error	2	위 코드로 x^3+3*sin(x)^2-10 이런 함수도 되려나 해 봤는데 그냥 잘 되어 버리네요. 코드에 추가해 두었습니다.	1	근사 자체는 가능합니다. 뉴럴네트워크가 결국 엄청 복잡한 고차항 모형을 fitting하는것이니 수식으로 표현가능한 수준의 함수들은 대부분 fitting가능할것입니다다만 david wang님께서는 근사가 아니라 모함수를 찾아주는것을 말씀하셨었죠	2	추가적으로 드는 의문으로는, f1과 무한히 가깝게 근사된 함수 f2가 있다면 이것이 함수 f1와 구분이 가능한 것인가? 하는 의문이 드는데, 제가 이런 부분의 수학에 대해서 잘 몰라서... 잘 모르겠네요. 함수 말고 숫자에 대해서는, 0.9999999999... = 1 뭐 이렇다고 어디서 들었던 듯 한데... 잘 이해가...https://en.wikipedia.org/wiki/0.999...일단 위키에 의하면... 들은 기억이 맞긴 하네요. 이해는 안 되지만...	1	21번라인, float_formatter = lambda x: "%+.6f" % x 이게 무슨말인가요?	1	리포 이름이 인상적입니다	0	Sedong Nam 안녕하세요~ 문의 드리고 싶은 것이 있습니다. x^2 같은 2차 함수 학습 시 -a<x<a 와 같은 특정 구간의 데이터로 학습을 시키셨을 것 같은데.. 학습 후에 -a ~ a를 벗어나는 데이터를 입력으로 넣었을 때 출력을 x^2로 원하는 값을 얻으셨는지요? 전 학습 구간의 값을 넣으면 근사값이 나오는데 학습 범위를 넘어간 값을 넣으면 오차가 상당히 크게 나오더라구요. 다른 분들도 그러신지? 아니면 제가 놓치고 있는 부분이 있는지 궁금합니다. 네트워크는 hidden layer=2, node는 각각 100개, Activation function은 sig를 사용하였습니다.	0	실험의 목적에 좀 더 적합하게 업데이트 된 실험:https://www.facebook.com/groups/TensorFlowKR/permalink/332680743739657/
0	cnn 코드한줄 한줄 설명된 강의는 없나요??봐도봐도 이해가 안가서요코드를 분석해봐야 개발도 할수 잇을거 같은데요	0	저는 youtube의 Sung Kim 교수님 강의를 주로 애용합니다
24	http://solarisailab.com/archives/303위에 링크에서 # -*- coding: utf-8 -*-# MNIST 데이터를 다운로드 한다.from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/", one_hot=True)위에 명령어를 python에서 실행하면 어떤 파일의 확장장가 다운되나요?	0	바이너리 오브젝트라서 확장자는 없습니다
24	궁금해서 오늘 서점가서 한권 있던 책을 귀하게 구입했습니다..이 나이에 이런거에 궁금해하는것이 맞는지 모르겠지만....	0	책  난이도가  어떤가요?	0	50대라도 해야죠...ㅎㅎㅎㅎ
110	일본의 어느 오이 농가의 아들이 TensorFlow를 이용해서 오이를 자동으로 분류하는 시스템을 개발하여 부모님의 일손을 크게 덜어드렸다고
9	텐서플로우 공부중인 고등학생입니다.Sung Kim 교수님의 유튜브 강의 시즌 1을 다 보고 여러가지 CNN모델들을 제 나름대로 변형하여 네트워크를 만들고 있는데요,ResNet이나 GoogLeNet처럼 특정 레이어가 복수의 레이어로부터 인풋을 받을 때 어떻게 처리해아할지 고민입니다.그냥 더하려고 하여도 행렬의 shape이 달라서 쉽게 풀리지가 않네요첨부한 사진은 네트워크의 구상도(?)입니다.조금만 도와주십시오!!import tensorflow as tfimport numpy as npfrom tensorflow.examples.tutorials.mnist import input_dataimport timet0=time.time()batch_size = 128test_size = 256def init_weights(shape):return tf.Variable(tf.random_normal(shape, stddev=0.01))def model(X, w1, w3, w4, w5, w7, w9, w_o, p_keep_conv, p_keep_hidden):l1=tf.nn.relu(tf.nn.conv2d(X, w1, strides=[1,1,1,1], padding='SAME'))print('l1', l1)l2=tf.nn.max_pool(l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')l2=tf.nn.dropout(l2, p_keep_conv)print('l2', l2)l3=tf.nn.relu(tf.nn.conv2d(l2, w3, strides=[1,1,1,1], padding='SAME'))print('l3', l3)l4=tf.nn.relu(tf.nn.conv2d(l3, w4, strides=[1,1,1,1], padding='SAME'))print('l4', l4)l5=tf.nn.relu(tf.nn.conv2d(l4, w5, strides=[1,1,1,1], padding='SAME'))print('l5', l5)l6 = tf.nn.max_pool(l3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')l6 = tf.nn.dropout(l6, p_keep_conv)print('l6', l6)l7=tf.nn.relu(tf.nn.conv2d(l6, w7, strides=[1,1,1,1], padding='SAME'))print('l7', l7)l8=tf.nn.max_pool('''여기서 l5와 l7의 값을 합쳐서 줘야할 듯 한데 어떡하죠ㅠ''', ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')l8=tf.nn.dropout(l8, p_keep_conv)print('l8', l8)l9=tf.reshape(l8, [-1, w9.get_shape().as_list()[0]])l9=tf.nn.relu(tf.matmul(l9, w9))l9=tf.nn.dropout(l9, p_keep_hidden)print('l9', l9)pyx=tf.matmul(l9, w_o)return pyxmnist = input_data.read_data_sets("MNIST_data/", one_hot=True)trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labelstrX = trX.reshape(-1, 28, 28, 1)teX = teX.reshape(-1, 28, 28, 1)X = tf.placeholder("float", [None, 28, 28, 1])Y = tf.placeholder("float", [None, 10])w1 = init_weights([3, 3, 1, 32])w3 = init_weights([3, 3, 32, 64])w4 = init_weights([3, 3, 64, 128])w5 = init_weights([3, 3, 128, 256])w7 = init_weights([3, 3, 64, 128])w9 = init_weights([?, 625])w_o = init_weights([625, 10])p_keep_conv = tf.placeholder("float")p_keep_hidden = tf.placeholder("float")hypothesis = model(X, w1, w3, w4, w5, w7, w9, w_o, p_keep_conv, p_keep_hidden)print('hypothesis',hypothesis)cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis, Y))train_op = tf.train.AdamOptimizer(0.001, 0.9).minimize(cost)predict_op = tf.argmax(hypothesis, 1)with tf.Session() as sess:tf.initialize_all_variables().run()for i in range(10):training_batch = zip(range(0, len(trX), batch_size),range(batch_size, len(trX)+1, batch_size))for start, end in training_batch:sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end],p_keep_conv: 0.8, p_keep_hidden: 0.5})test_indices = np.arange(len(teX))np.random.shuffle(test_indices)test_indices = test_indices[0:test_size]print(i, np.mean(np.argmax(teY[test_indices], axis=1) ==sess.run(predict_op, feed_dict={X: teX[test_indices],Y: teY[test_indices],p_keep_conv: 1.0,p_keep_hidden: 1.0})))print(time.time()-t0)	2	심플하게 왼쪽도 맥스풀링 한다음에 합치는게 좋지 않을지요?	2	아니면 l3나 l5에서 stride를 2로주고 하셔도 될거 같구요~	2	GoogleNet Inception module의 경우 Maxpooling의 stride를 1로 두어서 convolution과 dimension을 맞추고 concat을 써서 두 matrix를 연결하는 방법을 씁니다. Inception module을 응용한 구조로 보이는데 max pooling의 stride를 조정해보심이 어떠신지요.	0	이진원 (Jinwon Lee), 봉희종 (Heejong Bong) 오 그런 방법이 있었군요! Maxpooling으로 shape 조절한다는 생각을 왜 못했을까요ㅎㅎ 감사합니다!!	0	봉희종 (Heejong Bong) 하나만 더 여쭤보겠습니다ㅠㅠ ResNet도 GoogLeNet처럼 2개 레이어를 건너 뛰는 값을 stride로 조절하여 concat으로 합치는 방법을 사용하나요?	0	resnet은 사이즈 줄이기 전에 합치고 그 다음에 pooling을 하기때문에 stride를 다르게 할 필요가 없습니다
3	TensorFlow의 Gradient Descent 적용하다가 잘 안되서 여쭤보고 싶어서 글을 남기게 되었습니다.x_data에는 리스트로 다우존스지수 종가값, y_data에는 리스트로 코스피지수 종가값이 들어있습니다.x_data의 범위는 대략 15500~19000 정도 y_data의 범위는 1800~2200정도 됩니다.다른 방법으로 구해본 결과 W가 약 0.07, b가 약 737.06 정도 나오는데요. Gradient Descent를 다음처럼 적용했는데 W와 b값 모두 NaN이 나옵니다.이 값을 구할 수 있는 것인지 구할 수 있다면 무엇을 바꿔야 되는 것인지 궁금합니다.감사합니다.# -*- coding: utf-8 -*-import pandas.io.data as webimport datetimeimport numpy as npimport matplotlib.pyplot as pltstart = datetime.datetime(2015,1,2)end = datetime.datetime(2016,7,22)f1 = web.DataReader("^DJI",'yahoo',start,end)f2 = web.DataReader("^KS11",'yahoo',start,end)def daterange(start_date, end_date):    for n in range(int ((end_date - start_date).days)):        yield start_date + datetime.timedelta(n)x_data = []y_data = []for single_date in daterange(start, end):        date_str = single_date.strftime('%Y-%m-%d')        try:                f1_close = f1.ix[date_str]['Close']        except:                continue        try:                f2_close = f2.ix[date_str]['Close']        except:                continue        try:                print(date_str, f1_close, f2_close)                x_data.append(f1_close)                y_data.append(f2_close)        except:                passW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))b = tf.Variable(tf.random_uniform([1], 730.0, 750.0))X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)# Our hypothesishypothesis = W * X + b# Simplified cost functioncost = tf.reduce_mean(tf.square(hypothesis - Y))# Minimizea = tf.Variable(0.01) # Learning rate, alphaoptimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost)# Before starting, initialize the variables, We will 'run' this first.init = tf.initialize_all_variables()# Launch the graph.sess = tf.Session()sess.run(init)# Fit the line.for step in range(2001): sess.run(train, feed_dict={X:x_data, Y:y_data}) if step % 20 == 0: print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W), sess.run(b))x_test = 18313.77print('2016-08-02 DOW30 : ', x_test)print('2016-08-02 estimated KOSPI : ', y_test)print('2016-08-02 KOSPI : ', 2019.03)	1	Overshooting으로 NAN이 나온것 같은데.. Learning rate를 작은 값으로 조정해 보시기 바랍니다.	1	지수값을 정규화해서, 스케일이 비슷하게 맞춰서 해보시면 좋을 것 같은데요. ^^	0	각각의 stock price(DOW30, KOSPI)를 scaling해보세요.
5	추운 겨울에 저는 노트북으로 네트워크를 돌립니다.비맞고 와서 추웠는데 이제 따뜻하고 좋네요ㅎㅎ
39	Gradient Descent를 좋아하는 모든 분들께 이 영상을 공유합니다. @ 배경음악도 있습니다. :)	0	크하 시각화된 자료를 보니 느낌이 또 다르네요. 감사합니다!
3	GT 730에 GPU 세팅 했는데 이럽니다.  CPU에서는 잘 동작하는 CNN 코드인데 이러네요. 1080을 사야하는 것인가요? 아니면 메모리가 8기가라서? 아니면 제가 뭘 잘못한 것인가요? 혹시 사야 한다면 어느 브랜드를 사야 할까요?ㅎㅎㅎ	0	GPU의 메모리가 부족한것같습니다. 해결책은 다음분이...	0	GPU 메모리가 부족해서 그런 듯 합니다. 가장 쉬운 방법은 batch size를 조금씩 줄여서 될때까지 해보세요. 입력 이미지의 사이즈를 줄인다거나, 네트워크의 레이어 수를 줄여도 메모리 사용량이 줄어듭니다.	0	gt730 스펙을 보니 메모리가 1~2기가 정도 되네요. 큰 데이터를 학습시키기엔 좀 부족할 듯 싶습니다. 1080은 개인이 사기엔 좀 비싼듯 하구요. 1060이면 충분할 듯 합니다. 개인적으로 저는 집에서 gtx960 4기가를 사용하고 있는데 왠만한건 불편없이 잘 돌아갑니다. resnet152를 돌릴때 저도 동일한 에러가 났었는데 batch size를 48 까지 줄이니까 잘 동작했습니다.	0	윗 분 말씀처럼 batch size만 줄여주셔도 training에는 문제가 없을 것 같습니다. 하지만 시간이 오래걸리며, K40 이상의 GPU 추천 드립니다	1	이X텍 1080 주문했습니다. 답변 주신 모든 분께 감사드립니다.^^
33	파이썬 버전 차이 등 많은 부분 수정했어요
35	작년 딥러닝패키지 선호도 조사였는데..올해 말에는 TensorFlow가 선호도에서 1위 할 듯..Deeplearning4J도 좋은데 4%라..딥러닝분야에는 파이썬관련이 확실히 대세인거 같긴 하군요.	0	혹시 표본이 어떻게 되는지 아시나요?
49	어제 주문해서 오늘 다 봤습니다.누적포인트가 많아서 두 권 주문해서 한권은 직원주고.책이 심플해서 하루 이틀이면 다 볼듯.간만에 한글로 된 책 봐서 좋았습니다.	0	기분 좋게 읽으셨다면 다행입니다!	0	입문자가 읽어도 될까요?	0	[질문] 저도 입문자로 현재는 텐서플로 매뉴얼과 튜토리얼을 따라하고 있는데위 책은 그 2가지와는 다른 내용으로 구성되어 있는지 궁금합니다 :)
17	저도 샀습니다 ~! 오늘부터 정독해야겠내요	0	동현님 두 책이 서로 다른 책인줄 알고 구매하셨다는 소문이...??!
4	[스터디원 모집]#딥사이어인 파트2(파이썬 머신러닝/텐서코드/ 파이썬 PGM /딥러닝)시작 : 9/5(월) 오후 7시~10시 장소 : 강남 힐스터디 (4번출구 10층 건물)필사의 각오로 시작했던 딥사이어인 파트1이 끝나고 파트2로 다시 시작합니다!! 스터디의 취지로 죽었다 살아나는 고통을 감내하며 초사이어인이 되고자 했는데요... 어렵다고 툴툴대면서도 끝까지 버틴 결과,,,!!! 지난 파트1에서 정말 많은 것을 배웠다고 생각이 듭니다!! (아직 초사이언이 되려면 10번은 더 죽어야,,,) 함께 초사이어인이 됩시다!!내용:가장 핵심이 되는 벤지오 교수님의 딥러닝북은 8장 Optimization부터계속해서 진행이 되고,파이썬 머신러닝 책도 9장부터 이어서 합니다만 5 챕터밖에 남지 않아 남은 3회분부터는 다음 파트까지 이어서 텐서플로우 코드를 리뷰하려고 합니다.기존에 진행했던 [Sergios_Theodoridis]의 머신러닝 책은 너무 수식이 많아스터디원들이 힘들어하기도 했고 베이지안과 PGM 내용을 공부하기도 전에 전반부에서 지쳐버릴듯 하여 고민한 결과 이번 파트에서는 스킵하기로결정했습니다. (아마 파트3나 파트4에서 할 생각이지만... 그때까지 스터디가 살아있다면요 ㅠㅠ)이번 파트부터 새롭게 공부하는 책은 [Building Probabilistic Graphical Models with Python] 이라는 책입니다. (링크 - https://www.amazon.com/Building-Probabilistic-Graphical-Models-Python/dp/1783289007 )딥러닝 후반부에는 PGM에 대한 이해가 필요한 것으로 알고 있는데요,, 이 책은 파이썬 코드 예제를 보며 이론을 다루기 때문에 조금은 쉽게 이해할 수 있을듯 합니다!https://www.facebook.com/events/311600652525432/	0	주말 강의는 없을까요
3	Tensorflow serving 을 좀더 쉽게 사용해보고 싶은데 튜토리얼 이외 정리된 사이트 없을까요? Docker 환경에서 Git clone 후 bazel 로 빌드 하는데 빌드 실패가 나서 다른 방안을 찾고 있습니다.
144	기존의 연구자들은 인공신경망이 암호학 분야에는 별로 적합하지 못할 것으로 여겨왔습니다. 그런데 이번에 구글의 Brain 팀에서 인공지능 기반의 암호화 알고리즘을 개발하였다는 소식을 "Learning to Protect Communications with Adversarial Neural Cryptography"라는 논문을 통해 발표하였습니다. 해당 논문을 간단히 요약하고, 리뷰하였습니다.개인적으로 암호학과 머신러닝 분야에 모두 관심이 있던터라 언젠가 이런 연구가 나오겠지 했는데, 역시 Google Brain팀이 해냈습니다. 그런데 조금 꼼꼼하게 논문을 읽다보니, 역시나 아직 완벽한 결과가 나온 것은 아니지 싶네요.결정적인 의문점은 어떻게 암호화가 진행되는지를 분석하지 못했다는 것입니다. 이는 대부분의 딥 뉴럴 네트워크가 내부에서 정확히 어떻게 일을 처리하는지 그 과정을 확인하기 어려우므로 발생한 것인데, 사실 머신러닝 분야에서는 자연스러운 이야기입니다. 하지만 암호학자들은 분명 의아해할 것인데, 왜냐하면 암호학의 근간을 이루는 일명 Kerckhoffs의 원리와 상반되기 때문입니다. 통상적으로 암호체계의 안전성은 암호화 알고리즘이 공개된 상태에서 키의 비밀성에만 의존하도록 하는 것이 그동안의 평가방법이므로, 본 논문과 같은 변칙성(?) 방법에 대해서 논란의 여지가 있을듯합니다. 어쨌거나 머신러닝에서는 Accuracy만 높으면 장땡이므로.. 모종의 성과를 이룬것임에는 틀림없습니다. 이들의 다음 연구도 기대되네요.	2	논문 arxiv : https://arxiv.org/pdf/1610.06918v1.pdf	0	상당히 이해하기 쉽게 잘 적어 주셨네요. 잘 보았습니다.	0	김정수  두개다하는데 이게연결고리가잇엇다니	0	저 같은 경우는 가끔 뜬금없는 생각을 하는데 그중 하나가 "세상에 존재하는 암호화 방법(샘플)들을 수집한 뒤, 인공신경망 기반의 인공지능에게 어떤 부분에는 어떤 암호화가 더 적합한지 와 해당 방법들을 결합해서 더 강력한 암호화를 만들어내는 학습을 시키면 어떨까?"입니다.Brain 팀에 의해 제 엉뚱한 생각이 조금 더 현실화 될 수도 있겠군요.
67	초보자가 텐서플로우(파이썬기반 딥러닝 라이브러리)를 배우기 좋은 사이트네요
55	안되는 머리 굴려서 이것 저것 정리하고 있습니다. 심심할때 혹 보시게 되면 가감없는 조언 부탁드립니다! :-)	1	기대됩니다	1	좋은 정보 감사합니다.	0	오 해킹과 관련된 머신러닝인가요??	0	아. 아닙니다. 좀 실용적인 접근으로 쓴 거라서요. ^^
7	제가 Asynchronous RL 에 관심이 있어서 인터넷에 올라온 코드(https://github.com/devsisters/async-rl-tensorflow)를 한번 돌려볼라고 하는데 돌아가질 않네요. 딱히 에러가 나진 않는데 어떤 시점에서 이후로 넘어가질 않는데 혹시 돌려보신 분 계신가요? 아래와 같이 나오고 진행이 안되는데 이유를 아시는 분은 좀 알려주세요.python main.py --ps_hosts=0.0.0.0:2222 --worker_hosts=0.0.0.0:2223 --job_name=ps --task_index=0 &I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.4 locallyI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.0 locallyI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zeroI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: name: GeForce GTX TITAN Blackmajor: 3 minor: 5 memoryClockRate (GHz) 0.98pciBusID 0000:01:00.0Total memory: 6.00GiBFree memory: 5.29GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:01:00.0)I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -> {0 -> 0.0.0.0:2223}I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:2222	0	혹시 이것 이유를 찾으셨나요 ?
22	http://devfest16in.gdg.kr"GDG DevFest Incheon 2016"11월 19일(토), 인천에서 GDG Korea의 마지막 DevFest 행사가 개최됩니다. 많은 분들의 등록과 공유 이벤트 참여 바랍니다! 많은 세션과 코드랩이 여러분을 기다리고 있습니다😆▶자세한 내용: goo.gl/Vi0K1y▶이벤트 참여: goo.gl/nhQGSH
215	[Google Cloud ML 온라인 강좌 예고]* 업데이트: 비디오 (https://www.youtube.com/watch?v=8Jkz2HexDAM)"혼이 다 빠져버리는" 이 힘든 시국에서도 나름 시간을 내어 최근 오픈한 Google Cloud ML 을 공부하고 그 내용을 이번 주말, 강의비디오를 공개할 예정입니다. 여러분들이 만든 TensorFlow Task 를 그냥 클라우드에 던지면, 이를 실행하고 결과를 구글 storage에 저장해주는 방식입니다. 별도의 최신 장비 없이도 어느정도 규모의 학습은 빨리 돌려볼수 있을듯 합니다.혹 구글 클라우드 계정이 없으신분들은 하나 준비해주시면 바로 제 강의를 따라 해보실수 있으실듯합니다.https://cloud.google.com (가입시 300 USD를 지급합니다.)	3	교수님 강의 잘보고 있습니다.  (이제 softmax 보는중입니다.) 공부해야하는 내용이었는데.. 감사합니다	0	Jonguk Kim 이거 참고하길~ 별도 컴퓨터 안 사도 됨 ㅎ	2	저도 교수님 강의 보고 있습니다. Google Cloud ML강의도 기대되네요^^	0		2	감사합니다. 시즌1 열심히 따라하다 회사업무로 잠시 쉬고 있습니다	1	감사합니다. 제 똥컴이 갓이 되나요 ㅎㅎ
136	[Google Cloud ML 예제와 함께 따라해보기]오늘 바깥에 계신분들, 추운날씨인데 고생 많으셨습니다. 여러분들의 TensorFlow job을 클라우드에 보내서 바로 실행시킬수 있는 Google Cloud ML를 간단한 예제를 통해 살펴 봅니다. 이제 고급 장비가 없어도 (나름 저렴한 비용으로) 딥러닝 학습이 가능해질것 같습니다.https://www.youtube.com/watch?v=8Jkz2HexDAM소스와 사용한 슬라이드들은 https://github.com/hunkim/GoogleCloudMLExamples 에 있습니다.(2부는 distributed TensorFlow in Cloud ML 관련 비디오로 이어집니다.)
9	안녕하세요? 질문이 있어서 글을 올려봅니다.보통 training, test, validation set가 있을 때, 그 안에서 class의 비율이 다른 경우, 즉 A,B,C를 구분하는 문제에서 A,B가 매우 많이 있는 경우 모델의 정확도 평가는 어떤식으로 하나요?그냥 test set에 존재하는 모든 데이터(A,B가 많더라도)를 사용해서 평가하는지 아니면 A,B,C의 수를 동일하게 맞추고 그 데이터로 모델을 평가하는지 궁금합니다.감사합니다.	9	1. 다수의 클래스에 해당하는 샘플들로부터 언더 샘플링2. 소수의 클래스에 해당하는 샘플을 오버 샘플링하는 방법이 있습니다. 자세한 내용은 http://www.kdnuggets.com/2016/08/learning-from-imbalanced-classes.html 여기 참고하시면 될거같아요 :)	1	partitions에서 class의 비율이 유지가 되는 걸 가정하는 거죠? 그렇다면, 특별한 이유가 없으면 그대로 사용합니다. 만약 특정 클래스의 특정 에러율이 중요한 문제라면, 위 Taegyun Jeon님이 제시하신 방법을 사용하여 어느 정도 해결할 수 있습니다.
2	[Tensorflow Serving 관련 질문입니다]안녕하세요, 얼마전 tensorflow에 입문하고 천천히 알아가고 있는 입문자입니다..!!제 주된 언어가 C#인데요, 혹시 Tensorflow Serving을 활용해서 결과 값을 내보내고, C#으로(예: TCP/IP 등의 통신...) 받는, 이런 구조가 가능할까요...?환경은 아무래도 C# 코딩 때문에 윈도우에서 docker 활용해서 tensorflow을 돌릴 계획입니다.	2	저는 grpc로 구현해 쓰고있어요Window 로 Delphi =>  C DLL 을 통해 grpc  client 구현하고Linux에서 grpc sever로 tensorflow 모델을  구현하여 사용중입니다Tensorflow serve도 grpc로 돼있지만 제한이 많아서요 직접 구현해서 사용중입니다
12	안녕하세요,저는 지방의 작은 스타트업에서 문자 인식(text recognition) 관련 개발 중인데 궁금한 점이 있어 처음으로 글을 남깁니다.제가 겪고있는 문제 상황은 다음과 같습니다.원래는 Caffe로 개발하던 것을 장기적으로 보고 Tensorflow로 넘어오는 중입니다.아키텍처는 Caffe와 Tensorflow 동일하게 구현을 하였고, 차이점은 Caffe에서는 data layer를 C/C++로 구현하였고 학습은 single GPU 사용, Tensorflow는 python으로 구현하였고 multiple GPUs 사용하는 정도입니다.Training data는 둘 다 batch마다 random하게 생성을 하여 넣고 있는데요, 생성 되는 문자 종류는 같고 variability를 위한 distribution은 최대한 비슷하게 맞추었습니다. Visualize 했을 때 크게 차이가 없는 것을 확인했습니다(outlier sample이 없음).Test data는 완전히 동일합니다.속도는 Tensorflow가 약간 느린데 문자 생성기가 python 기반이라 이해는 갑니다만, Tensorflow의 accuracy가 약 2~3% 정도 떨어집니다.Caffe는 94~95% 정도, Tensorflow는 92% 정도 나오네요..Tensorflow에서 optimizer, learning rate, regularization weight를 다 바꿔도 이 gap을 채울수가 없는데 혹시 비슷한 증상을 겪으셨거나 근본적인 원인을 아시는 분 있는지요?검색하다 다음과 같은 논문을 발견했습니다.. 아래 논문에서 Figs.6 & 9를 보면 Tensorflow accuracy가 이상하게 나오는데요, 문제가 있는걸까요..저 정도로 차이가 날 것 같지는 않은데 논문이 코드를 공개하지 않는 한 논란의 소지가 있겠네요.	1	두 라이브러리가 완전히 동일하게 작동하지는 않는다는 얘기군요! 답 못 드려서 죄송합니다만 좋은 정보를 주셨네요	4	수학적으로 같은 모델을 수행하면 수행 시간만 다를 뿐 비슷하게 나와야할 것 같은데 말이죠.	1	조금 다른 경우이지만 mxnet과 tensorflow를 똑같은 모델로 똑같은 데이터를 학습하더라도 똑같은 accuracy가 나오지 않는 것을 확인했던 적이 있습니다. 정확한 이유는 모르겠지만 동일한 모델일지라도 각각 참조하여 사용하는 라이브러리의 구현상의 차이가 아닐지 추측해봅니다.	1	모델이 같아도 weight의 초기화가 실행시마다 다를 수 있으므로 같은 accuracy가 나오지는 않겠지요. 언어의 차이로 나타나는 것은 아닌 것으로 예상합니다.	1	https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.pyTensorflow의 Cifar10 예제를 보니 왠지 Multiple GPUs와 관련이 있지 않을까 합니다. 상단 주석 부분을 보면 Multiple GPUs에서 accuracy가 2%정도 낮게 나오네요..System        | Step Time (sec/batch)  |     Accuracy1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)2 Tesla K20m  | 0.13-0.20              | ~84% at 30K steps  (2.5 hours)제가 파악하기로 Single GPU와 Multiple GPUs 차이는 weight regularization이 두 번 계산되는 것 같네요.. (저의 경우에는 regularization factor를 절반으로 했을 때도 별 차이는 없었긴 합니다만)GPU 수를 늘리는 만큼 step (저의 경우 batch size)를 줄여서 single GPU 사용할때와 처리하는 샘플 수를 같이 맞춘것인데, 정확도가 떨어지니 이상하네요..  Cifar10에서는 multiple GPUs 사용시 동일한 100k iteration후에는 정확도가 같아졌다는 거 보면.. Multiple GPUs 사용시 이점이 없는 걸까요? (예상하기로 gradient concatenation 등으로 시간 더 소비)	0	제가 링크한 논문은 여전히 의문이긴 하네요ㅎㅎ 댓글 감사합니다!
171	Dueling Network와 Double Q-learning, Prioritized Experience Replay 등으로 학습시킨 쿠키런 AI 데모 영상과 발표 자료, 관련 코드를 공유합니다.영상 아래에는 모델이 행동을 결정할 때 보는 state들과 각 state에서의 Q-value, value, advantage, reward 값들이 출력되며, 강화 학습 디버깅에 사용했던 로그입니다. 지금의 AI가 만들어 지기 전에 잘 뛰지 못했던 AI의 영상들도 같이 공유합니다 :)발표 자료 : http://www.slideshare.net/carpedm20/ai-67616630데모 영상 : https://www.youtube.com/watch?v=exXD6wJLJ6s첫번째 시도 (Deep Q-Network): https://youtu.be/XsJWbAd6rYk두번째 시도 (+ Double Q-learning) : https://youtu.be/rurJICmHfHQ세번째 시도 (+ Dueling Network) : https://youtu.be/XQJA1Rob0ng아쉽게도 쿠키런 AI에 사용된 코드는 공개할 수 없지만, 부분적으로 공개된 또는 강화 학습과 관련된 코드들은 아래와 같습니다.1. Deep Q-learninghttps://github.com/devsisters/DQN-tensorflow/2. Dueling Newtork, Double Q-learninghttps://github.com/carpedm20/deep-rl-tensorflow/3. 쿠키런과 같은 discrete action space가 아닌 continuous action space에서의 강화 학습 방법https://github.com/carpedm20/NAF-tensorflow/	1	감사합니다	2	감사합니다 TF 멀티세션 설정방법은  정말 큰 도움되었습니다	1	발표 재미있게 잘 들었어요~ 내용도 좋았어요^^	0	코드까지! 감사합니다
42	암밴드를 가지고 50가지의 헬스 운동을 92%로 구분한 저의 새로운 논문이 arXiv에 공개되었습니다![Link] https://arxiv.org/abs/1610.0703150가지 헬스운동에는 벤치프레스만 7종류, 스쿼트만 4종류일 정도로 미묘하게 다른 운동들을 포함하고 있어 이들을 하나의 IMU만 가지고 구분한다는게 쉽지 않은 일이었는데요, 기존에는 마이크로소프트에서 최대 13가지의 구분잘되는 동작들을 실험환경에서 구분했던게 전부였죠. (e.g. 운동 부위가 다른 운동들). 하지만 이번 연구에선 실제 운동선수들로부터 얻은 데이터를 가지고 (아마도 여기엔 잘못 입력된 데이터도 많을겁니다.) 좋은 결과를 낸 것이라 의미가 큽니다. 사실 전 한 일이 없고 딥러닝느님이 다 해내셨습니다;;; 내용은 너무 기초적인 CNN의 활용이라 부끄럽기까지 하지만, 많은 양의 데이터를 적절한 전처리와 함께 CNN에 넣어주기만 한다면 3 layer의 간단한 CNN 가지고도 충분히 좋은 성능을 낼 수 있음을 보였습니다. 별로 튜닝을 안한 결과인지라 조금만 더 신경쓴다면 95%도 가능하지 않을까 싶습니다.자세한 내용은 논문을 참고해주세요! 워낙 쉬운 논문인지라 딥러닝 초보자에게 추천합니다 ㅎㅎㅎ	1	Jeungmin Oh  recofit 이후 많은 발전이 있었나봄 , 이제 나왔나? ㅋㅋ
121	머신러닝 초보자의 시각으로 DEVIEW 2016 둘째날에 발표된 [딥러닝과 강화 학습으로 나보다 잘하는 쿠키런 AI 구현하기] 세션의 후기를 포스팅 해봤습니다.	1	티켓이 없어서 못갔는데 리뷰 감사합니다~	1	감사합니다	0	구서연	1	좋은글 감사합니다.	1	이 세션 재밌게 들었는데 정리 감사합니다^^
24	아래 링크에서 Back Propagation을 손으로 계산 가능한 범위에서 쉽게 설명해주더군요. 공부할 겸 ppt로 정리해보았습니다.https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/
180	저희 초대 1기 운영진이셨던 Taehoon Kim님의 이번 DEVIEW 최고 인기강의 슬라이드입니다. 우리나라 DL/AI 연구/개발자중 가장 주목할만한 분이라 생각합니다.이 내용을 다 이해하기만 해도 이미 대단한 수준인것 같습니다. 두고 보면서 논문들도 차근히 봐야할 아주 깊은 내용입니다. http://www.slideshare.net/carpedm20/ai-67616630(혹 아래 Share가 보이지 않으시는 분들은 위 링크를 참조하세요.)	2	친구공개 게시물인것 같군요... 열람이 안됩니다.	0	첨부드립니다. 신경써주셔서 감사합니다.	1	어제 보고 오늘 또 보았습니다. 굉장하다고 생각됩니다. 이 강연을 봤었어야 했는데..	2	어제 세션 들었었는데 정말 좋았어요!	13	아직 모르는것 투성인데.. 이렇게 칭찬해 주셔서 정말 감사합니다! 곧 AI가 뛰는 영상도 찍어서 공유하도록 하겠습니다 :)	1	저도 제일 만족했던 강의 중 하나였습니다.
16	안녕하세요,Deep learning을 이용한 의료솔루션 개발 스타트업!Vuno에서 병역특례 요원을 모집합니다.https://vuno.github.io/blog/recruit/2016/10/24/recruit2016.htmlTensorflowKR 멤버 여러분의 많은 지원 부탁드립니다. 감사합니다!
44	DEVIEW 2016 세션중 딥러닝 관련 많았다고 하는데 혹시 참여하신 분들 계시면 자세한 리뷰 부탁드려도 될까요? 미리 감사드립니다.	9	대화형 채팅봇 AMICA, 통역앱 PAPAGO관련 세션에 참여했었습니다. 아미카의 경우는 한국어를 메인타겟으로 하여 형태소분석에 집중했었고 파파고는 기존의 기계번역 패러다임에서 뉴럴넷을 이용한 시스템으로 바꾸어서 호응이 좋았습니다. 다만 두 세션모두 딥러닝에 대해 소개한다기보다는 각 솔루션(아미카는 봇 API, Usage / 파파고는 앱 개발중에 있던 Issue)에 집중했었던것 같습니다. 깊이 있는 QNA가 있었긴 하나 제 지식이 짧아서...ㅠ	11	오늘 오전부터 들었던 딥러닝세션에 대해서 정리해서 대전 내려가는 길에 하나씩 적어두겠습니다 :)	2	트랙 2에서 느낀것들을 정리해서 올릴께요	3	쿠키런 ai 세션과 NMT 쿠다로 직접 만드신분 세션이 젤 인상 깊었습니다. http://yujuwon.tistory.com/entry/Deview-2016	0	multi-rnn(데이터가 많아야겠지만 어쨌든 작년 이후 바로 이렇게들 응용하시는 거 보니 부럽네요)과 vqa에 residual(현재 state-of-art라고 하시더군요) 개념 넣은 세션 두 개가 제일 좋았고, 개인적 관심사로는 쿠키런 노가다가...ㅋㅋㅋ	0	알고계시겠지만^^; 데뷰 사이트 가시면 슬라이드 정도는 있던 것으로 기억합니다~
45	C++ API로 Gradient Descent Node를 만드는 방법까지는 찾지 못했지만 작동시키는 방법은 알아냈습니다.C++로 쓰실 분들은 슬슬 시작하셔도 좋을 타이밍이네요.
7	지금 Las Vegas에서 IBM World of Watson 2016 Conference가 진행중인데 혹시 참가못하셨으면 여러분께서 아래 링크를 통해 online 으로 참여하실 수 있습니다.
88	오늘 있었던 Deview2016에서 딥러닝 관련 세션을 듣고 간략히(?) 리뷰를 올려봅니다. 네이버의 다양한 시도를 엿볼수 있었구요. 대부분 텍스트마이닝과 정보검색을 기반으로 하고 있고, 딥러닝을 어디에 사용했는지 초점을 두고 보시는게 좋을것 같습니다.  그리고 초대장을 주셔서 deview2016에 참석하게 해주신 Taeung Song님께도 감사의 인사를 전하고 싶습니다.[딥러닝을 활용한 이미지 검색] 발표자료: http://www.slideshare.net/deview/222-20161024네이버에서 제공하고 있는 "텍스트 기반 이미지 검색"에 대해서 어떻게 딥러닝을 적용하여 성능을 향상 시켰는지 설명해주셨습니다."이미지 검색 성능 개선 부분"과 "이미지 검색 인터페이스 개선"에 대해 발표해주셨구요.1. 이미지 검색 성능 개선- Image-text pair generation: 이미지를 포함하고 있는 대상 문서에 나타난 단어들을 이용하여 이미지와 관련있는 단어들을 선택하여, image-text의 쌍으로 구성된 학습데이터를 만들었습니다. 이미지 주변에 있는 단어들을 우선으로 선택하고, word2vec등의 토픽 모델링을 통해 유사 의미를 분석했습니다. - Unsupervised image annotation: 질의어에 대해 네이버 검색기능을 통해 검색된 문서들에 대해 나타난 키워드들을 clustering하여 주요 키워드들을 선택했습니다. 최근 인스타그램 이미지를 통해 자동 해시태그 생성 해주는 연구와 같은 맥락입니다.  - Supervised image annotation: 15000개의 class에 대해 미리 학습된 딥러닝 모델을 이용하여 키워드 추출 하도록 했습니다.- External input manager: 학습 데이터 구축을 위한 자체 도구에 대한 설명. 2. 사용자 인터페이스 개선사람들이 관심가지는 주요 spot 선정: 식당, 미용실, 명소classification, clustering, annotation의 프로세스를 거칩니다.Feature extraction: VGG16의 최상위 레이어인 softmax를 제거하고 바로 아래 fc7레이어에서 최종 조합된 deep feature를 사용합니다.Classification: Multiclass SVM을 사용해 분류했습니다. 이후 랭킹 처리와 언어모델 처리를 하셨다고 했는데, 대부분 네이버 자체 모델을 사용했다고만 언급해주셨네요.3. 이미지 타임라인이 세션에서 제일 재밌는 파트였습니다. 언제 누가 어디서 찍던지 "같아야 하는 이미지"와 "달라야 하는 이미지"로 정의해서,항상 바뀌는 이미지에 대해 다양한 블로그, 뉴스등을 소스로 사용하여 해당 주제 및 관심 인물에 대해서 정리해서 보여주는 타임라인을 구성했습니다.Event detection: 사람들이 관심가질만한 이벤트를 정의하고, 누가 언제 어디서에 해당되는 단어들을 이미지 근처의 단어를 분석하여 채웁니다. 이미지의 유사도의 한계를 극복하기 위해 여전히 텍스트 의미도 중요함을 나타내고 있습니다. visual sumarization: 유사한 이미지를 모아서 종합하기 위해 2단계에 걸쳐 kmeans clustering을 사용하여 대표 이미지를 선정합니다. 그리고 inter/intra class distance를 다양한 지표들로 정의하여 대표 이미지를 선정했습니다. 최종 결과물은 event card (date, description, images)로 나타납니다. 이 세션은 네이버가 보유한 정보검색과 텍스트 마이닝의 기술에 덧붙여 실제 서비스에 적용하기 위해 딥러닝이 어느 요소로 적용됐는지 눈여겨 보시면 좋겠습니다. 항상 딥러닝이 만능이 아니듯, 기존 서비스와 기술을 바탕으로 서비스 품질 개선의 노력한 모습이 엿보입니다. 다만, 구체적인 기술에 대한 언급이 없어서 다소 아쉬운 점이 있습니다. 디테일한 설명이 빠졌다는 점이 다소 아쉽게 느껴졌습니다.[딥러닝과 강화학습으로 나보다 잘하는 쿠키런 AI 구현하기] 발표자료: http://www.slideshare.net/deview/ai-67608549Taehoon Kim님께서 쿠키런을 대상으로 강화학습을 적용한 과정을 조목조목 설명해주셨습니다. 잠깐 얼굴보긴했는데 발표전이라 얘기를 나눠보지 못한게 아쉽네요. 1. 전반적인 Deep Q-Network에 대한 설명: Q(s,a)를 쿠키런을 예제로 잘 설명해주셨습니다.2. 스스로 달릴수 있는 AlphaRun: AlphaGo + 쿠키런의 컨셉으로 스스로 달리는 AI. 이를 통한 게임서비스 측면에서 밸런싱, 다양한 테스트에 대한 설명을 해주셨어요. Deep Q-Network, Double Q-Learning, Dueling Network 논문 3개에 대한 내용을 간략하게 잘 정리해주셨습니다. 3. Engineering issue - 개발과정에서 경험하는 hyperparameter 튜닝을 위해 필요한 옵션을 dict로 정의하고 실험 스케쥴링하는 간략한 소스를 보여주셨구요. - 디버깅이 힘든 딥러닝 개발에서 각 state별 Q, r, s, a 값을 로그로 찍어볼 수 있는 예를 보여주고 있습니다. - 실험 계획 단계에서 비슷한 실험은 tf.saver를 이용해 단계별로 실험을 확장해보라는 조언 - 보통 최종학습된 여러 모델을 이용해 앙상블하여 다수의 의견을 종합하는 경우가 많습니다. 이를 위해 한 세션당 하나의 그래프를 유지하면서 세션 array를 실행하는 팁을 주셨습니다. 항상 열심히 재밌게 개발하시는 태훈님의 다음 쿠키런 버전을 기대해봅니다. [Backend 개발자의 Neural Machine Translation 개발기] 발표자료: http://www.slideshare.net/deview/224-backend-neural-machine-translation-67608580두 언어의 parallel corpus를 이용한 NMT의 개발 사례입니다. NMT에 필요한 기본적인 language model들과 NMT 모델을 간략히 리뷰해주셨구요.- Stacked LSTM의 기본구조를 이용하여 encoder/decoder를 입력으로 하고 decorder 결과를 이용하여 번역을 가능하게 합니다.- RNN의 RNN cell을 하나의 gpu로 할당하여 (RNN timestep + RNN depth)만큼의 계산과정을 통해 NMT가 동작하게 모델을 병렬화 했습니다.- 최종 softmax단계에서 계산량이 큰 부분을 줄이기 위해, 일부 단어들만 샘플링하여 처리하는 sampled softmax를 얘기해주셨습니다.- 그리고 마지막으로 attention layer를 추가하여, 주제어나 긴 문장에 대해서도 문맥을 유지하도록 구조를 업그레이드 했습니다.발표자 본인은 backend 개발자로 10년간 일해오면서, 해당 서비스를 개발한 것에 대해 놀랍다는 말씀을 해주셨습니다.이를 가능케 한건 기계번역 전문가 + 뉴럴넷 전문가 + 서비스 전문가 = 한 팀을 이루어 해낸 결과라고 말씀하시며, 다양한 주특기를 가진 팀의 능력을 말씀해주셨어요. 심히 공감이 가는 부분입니다. [YARN 기반의 Deep Learning Application Cluster 구축] 발표자료: http://www.slideshare.net/deview/225yarn-deep-learning-application-cluster다양한 딥러닝 프로젝트를 관리하기 위해 현실적인 시도들을 말씀해주셨습니다. 하둡v2에 해당하는 yarn을 통해 gpu cluster를 구성하는데 있어서 필요한 요소들에 대해 발표하셨습니다. 규모가 커질수록 클라우드 서비스를 이용하느냐 자체적으로 구성하느냐에 있어서 고민이 많이 생길 부분이지만,엔터프라이즈 서비스를 개발하는 입장에서 caffe, theano, torch, tensorflow, keras등 개발환경의 다양성을 보장해야하는 측면에서한번쯤 눈여겨 봐두면 좋을 발표라고 생각됩니다. 실제로 구축하는데는 많은 삽질이 필요하겠지만, 누군가 해준다면 여러사람이 편하게 연구와 개발을 할 수 있으니까요.- docker를 통해 각 언어별 환경과 구현 코드를 다루고, gpu scheduling하는 부분까지 얘기하고 있습니다. 개인적으로 해당 dockerfile들과 gpu cluster를 구성하는 기술 문서가 궁금합니다 :)	1	너무 감사합니다.	0	수준이 높은 것인지...	1	#1은 어느정도 성능이 향상되었나요?	1	3.은 재미있는데 혹시 데모버전이 있나요?	1	감사합니다. 신청도 실패했고, 애 간호하느라 움직일 수 없었는데, 요약 감사합니다. 음.. 2014년도 김정희님 발표가 거의 유일한 딥러닝 발표였던걸로 기억하는데... 2년만에 대부분의 발표가 인공지능이고 그 인공지능의 대부분이 딥러닝이 되었군요. ^^: 한편으론 아쉽네요.
35	http://kakaocorp.com/recruit/progressRecruit?uid=9884	3	"tensorflow 경험자 우대" 오오~ 좋습니다. 여기 TF전문가들 많이 있습니다.
2	질문 하나 드립니다  동영상 이나  영상 스트림을 분석 해서 어떤 상황인지 이해  할려고 하는데요  어떤 자료나 소스를 보면 될까요  참고 할 만한 자료 있을까요   ?	1	https://github.com/jazzsaxmafia/video_to_sequence이게 도움이 되실지..^^
0	설치 관련해서 질문드립니다.pip installation 방법으로 ~ 에서 설치를 했고 정상 설치를 했습니다. 하지만 이후 코드를 작성해둔 폴더에서 import tensorflow 를 치면 pywrap_tensorflow import error 가 발생합니다.사실 검색을 통해 위 에러의 원인이 tensorflow source 폴더 내에서 실행한 경우 발생하는 것이라고 하는데, 에러가 나는 폴더는 이전에 설치해서 소스코드를 작성하고 실행시키던 폴더입니다.제가 맥을 처음 사용하면서 공부하고 있어서 설정을 제대로 못 해서 인지 초기화 돼 버려서 재설치하게 되면서 에러가 발생하네요. 이짓을 자꾸 반복할 순 없어서 이렇게 도움 요청드립니다.tensorflow 설치 폴더 위치에 대한 것을 변경할 수 있나요? 아님 이 후에 PATH 설정을 따로 진행해야 하는 것인가요?tensorflow 설치 후 초기화(teminal 종료나 재시동 시)가 되지 않도록 하는 방법이 있나요?(저의 경우 두번째 경험하는 것이라....)아래는 에러결과입니다. 답변에 미리 감사드립니다.--------------------------------------------------->>> import tensorflowTraceback (most recent call last):  File "<stdin>", line 1, in <module>  File "tensorflow/__init__.py", line 23, in <module>    from tensorflow.python import *  File "tensorflow/python/__init__.py", line 49, in <module>    from tensorflow.python import pywrap_tensorflowImportError: cannot import name pywrap_tensorflow	0	만약 직접 소스 빌드한게 아닐 경우, 1. 현재 설치된 텐서플로우는 pip unistall tensorflow로 삭제하시고요.2. github에서 원하시는 텐서플로우 버전으로 소스를 다운로드 하시고요.3. bazel을 이용해서 소스를 직접 빌드하세요.4. 빌드해서 나온 패키지 파일을 pip로 인스톨 해 보시죠.참고로 tensorflow는 configure 할때, 지정한 옵션(python 버전 or CUDA 사용 여부)에 맞추어 해당 OS 환경에 맞추어 빌드가 되어서 pip로 설치할 수 있는 형태의 패키지 파일로 ~.whl 파일이 생성되고요.이 패키지 파일을 pip로 인스톨하면, 지정한 파이선 버전의 디렉토리 하단으로 tensorflow가 설치됩니다.반드시 필요한 패키지도 함께 설치가 될 것이고요. (numpy 같은)PATH 설정은 우분투 같은 경우, ~/.bashrc에 환경설정 등록하면, 터미널 실행시 자동으로 실행됩니다.	0	pip list를 sudo 권환과 일반 유저 권환 모두에서 확인해 보세요 이전 버젼이 2군데중 한군데에서 설치 되러 있을수 있습니다위에 분이 말씀 하신 것처럼 소스를 컴파일 했어도 최종적으로 pip로 설치 하기 때문에 pip 리스트를 확인해서 깨끗히 지우고 다시 설치 해보시기 바랍니다
2	안녕하세요, GPU를 사용하는 도중에 문제가 생겼습니다. :( 같은 소스코드 (CNN모델)를 CPU에서 구동할 때는 별 문제가 없는데,GPU를 사용하는 경우 최초 Session().run 실행시 상당한 시간이 소모되는 문제가 있습니다. (첫 번째 배치가 실행될 때)같은 소스코드인데, cpu환경에서 구동시에는 위와같은 문제가 전혀 없습니다.혹시 어떤 문제 때문이지 알고계신분이 있으실까요 ? 사용 환경CPU : Macbook Pro & tensorflow 0.8GPU : GTX1080 & tensorflow 0.11	0	버전때문인가..	0	멈추는 시간동안 GPU 가 풀로드 상ㅌ...	0	ㅠㅠ	0	같은 소스로 cpu 0.11버젼에서도 느리다면 버젼문제일 것 같습니다. GPU의 경우 복잡한 그래프에서는 variable intialization할 때 시간이 많이 걸리는데 GPU버젼만의 문제일수도 있을 것 같네요.	0	@이선로 gpu 드라이버를 설치 하는 방법이 여러개 이고 compute 모드 또한 설정이 있습니다아마도 gpu 드러이버가 잘못 설치 되었거나 gpu 셋팅에 문제가 있어 보입니다multi gpu가 아니라 단일 gpu면 일반적으로 문제가 없는데 드라이버를 재설치 해보시기 바랍니다
61	네이버, 인공지능 기반의 R&D 집중하며 기술 도약 가속화- ‘생활환경지능(Ambient Intelligence)’을 통한 이용자의 새로운 경험 제공	4	아주 좋고 당연한 방향이라 생각합니다.
79	윈도우, full support 곧 이라고 합니다.ㅎㅎ	1	좋은 소식이네요.	1	간곡히 기다리고 있습니다 ㅎㅎ	0	절실히 ㅎㅎ	0	와우!
1	안녕하세요.Tensorflow의 dnn을 사용해서 실험을 하고 있습니다.보통 dnn을 사용하는 경우 train과 test의 과정을 거치는데,그 이후, 다음 값을 예측하려면 처리를 어떻게 해줘야하나요 ?예를들어, 1,2,32,3,43,4,54,5,6 데이터가 학습된다면,다음 예측값(5,6,7)을 출력하도록 하고싶습니다.	2	안녕하세요. RNN의 seq2seq 와 유사한 방식을 DNN으로 해보시려는 것 같이 보이며, 이런방식은 오래전에 Time Delay NN 이라고 불리었던 방식입니다.말씀하신 질문에서 인풋데이터가 어떤 값일 때 5,6,7 이 나오는것 인가요?4,5,6을 넣으면 5,6,7 이 나오는 것이 맞다면, 그냥 4,5,6 데이터를 넣어주어 계산된 아웃풋 레이어의 값을 사용하시면 됩니다.감사합니다.
10	안녕하세요. 혹시 Tensorflow for R(https://rstudio.github.io/tensorflow/index.html) 을 윈도우에서 설치하신 분 계신가요? 제가 읽어보니 Tensorflow for R 또한 tensorflow가 기본적으로 깔린상태에서 가능하다고 나와있는데 결국에는 그럼 불가능한 것 아닌가요? 설명이 자세하게 안나와있어서 어렵네요. 혹시 설치해보신 분 있나 질문드려봅니다.
44	수학 공부하실때 sympy 모듈도 좀 알아보세요.파이썬도 심볼릭 수학을 지원합니다.
221	[Andrew Ng 의 딥러닝적용의 개요]https://www.youtube.com/watch?v=F1ka6a13S9I늘 그렇듯이 설명을 참 잘하시네요. 제가 들은 것을 두서 없이 요약하자면- 바이두에서 일한 경험을 공유- 왜 Deep Learning (DL) 지금 이렇게 유명한가? 스케일, 즉 엄청난 데이타와 엄청나게 큰 NN 이 좋은 결과를 만들어냄- 트렌드 모델들:  1. General DL: 일반적인 Fully connected nets  2. 시퀸스 모델  3. 이미지 2D/3D  4. 기타: Unsupervised/RL   * 상용화된 대부분이 1, 2, 3 사용. 4번은 미래의 AI될 가능성이 있음 (연구자는 4번에 집중하는것을 권장)- 다른트렌드 End-to-end DL: 기존 대부분의 숫자의 output: review score, sentiment End-to-end DL 이 할수 있는것  image ->  caption    audio -> transcript   english -> French (translation)  parameters -> image- 물론 end-to-end 가 모든것을 해결할수는 없슴audio -> 발음 -> transcript (기존 방법)audio -> transcript (end-to-end) 그러나 쉽지 않음. 엄청난 양의 레이블의 데이타 필요 - Automatic data synthesis (엄청난 양의 학습데이타 만들어내기) 예:  * OCR 데이타 만들어 내기   * 음성인식: clean 오디오 + 백그라운드 사운드  * NLP: end-to-end to correct grammar, 문법틀린 문장을 만들어냄 - 사람의 성능과 비교해 어떤 부분을 보충할것인가 (데이타 또는 더 큰 넷트웍) 결정 (대단한 목표!)- 마지막 중요 꼭지: What can AI/DL do? * 일반 사람이 1초만에 할수 있는 작업 * 반복되는 일의 다음 이벤트 예측 (sequence prediction)- ML/DL을 직업으로 하려면 * ML 수업듣기 (http://hunkim.github.io/ml/ 등. :-) * DL school 참여 * 박사과정 하기     1.  논문 많이 읽고, 기존의 연구결과 반복구현/실행 (replicate results) ->새로운 아이디어로 연결. 20~50개의 논문 읽으면 새로운 아이디 어 반드시 생김    2. Working on AI? Dirty work. :-) Download data, cleaning data, code, tune parameters, hack GPU kernels to make it fast1, 2를 반복하면 반드시 훌륭한 연구자가 됨.- 마지막: 박사연구로 세상을 바꾸겠다는 학생들이 많은데 DL/AI 연구하면 정말 세상을 바꿀수 있슴!	0	정리한 노트가 너무 좋습니다. 감사합니다.	3	Dirty work에서 공감되네요 ㅎㅎ	0	명료하게 요약해주셔서 감사드립니다!:)초보적인 질문일듯 싶은데, ML관련해서 end to end라는 용어를 여러차례 접했지만 정확한 정의?를 못찾지 못해 막연하게만 이해하고 있습니다. 어떤 뜻으로 해석하면 좋을까요?^^;	0	방향을 제시해주시는 글이십니다.	0	DL School은 뭔가요?
15	[딥러닝 시각화 / 보안을 위협하는 예제들 / 딥러닝 아트]Visualization for CNN / Adversarial examples / Deep learning arts에 대해 블로깅을 하려다가 바쁜 관계로 짧게 글을 남겨보았습니다. 즐겁게 읽어주시고 토론이나 피드백은 언제나 환영합니다 ^^
20	Tensorflow C++ API를 몇 일간 열심히 들여다 봤으나 C++에서 훈련시키는 것은 포기하고 조언 얻으러 왔습니다.훈련용 데이터 생성을 C++로 하는 경우에는 파일로 대용량 데이터를 저장한 후에 python에서 다시 읽어들이면서 훈련시키면 될 것 같습니다.그런데, 강화 학습 같이 훈련 후 네트워크의 변화가 데이터 생성에 즉각 반영되어야 하는 경우에는 python 과 C++ 간의 데이터 교환을 어떻게들 하고 계신가요? 예를 들면 게임엔진 속에서 강화학습을 하는 경우입니다.	0	ipc를 이용하는건 어떤가요?	1	Numpy 의 경우 c로 메모리 레이아웃이 잡혀있으니 그걸 파악하시면 파이썬으로 메모리 카피없이 데이터 교환이 가능할겁니다.	0	Boost python 으로 넘기는 방법도	0	전 grpc로 구현하여 쓰고있어요c(window) <->python (linux tensorflow)
63	딥러닝 뛰어넘는, 새로운 기계 학습 기술, '딥텐서(Deep Tensor)' 개발- 후지쯔 인공지능(AI), '진라이(Zinrai)' 진화에 진화를 더 한다.
66	[Sequence to Sequence Deep Learning 비디오]Sequence to Sequence (s2s)의 구글 대가인 Quoc Le 가 구글의  SmartReply in Inbox 중심으로 s2s를 설명합니다. 기본과 그리고 뒷 부분 나가야할 방향에 대해 이야기 합니다.제가 들어면서 막 정리한 두서 없는 노트입니다.Outline (2 parts):s2s 모델 개발s2s 의 활용영역Motivation:휴가후 508개의 unread이메일. 대부분의 답변이 yes/no의 문제.are you visiting Jeju? -> yesdid you read X -> no문장을 주면 yes/no로 답변문장을 벡터로 어떻게? bag of words       [0, 1, 0, 0, 0 ..] -> 1       [0, 1, 0, 0, 1 ..] -> 0Wx -> y, y is [Yes, No] 문제, 그런후 수학이 나옴 그런데 BOW는 많은 정보를 놓침. 예를 들어 문장의 순서가 무시됨RNN을 사용하면 순서 정보 포함예측을 위해 마지막셀의 출력을 이용 (기본적인 RNN을 이용한 classification, https://github.com/nlintz/TensorFlow-Tutorials/blob/master/07_lstm.ipynb 참조)다음단계 (친절한 응답)are you visiting Jeju? -> yes, willdid you read X -> no, I was busy.이걸 할수 있으면 응용할 부분 많음: 이메일 자동응답(auto reply), 이미지 요약, 문서 요약, 대화, 질문과 답변 등등등 어떻게 할것인가? 이건 조금 어렵지만 many to many model (Andrej의 슬라이드): sequence to sequence(s2s) 모델, RNN을 두개 연결한 모델 사용간단한 s2s 는 잘 안됨. 그래서 s2s에서 s2의 예측을 다시 RNN의 입력으로 사용 (autoregressive라 불림) 또는 이것을 encoder/decoder 라 불림 그럼 RNN을 만든 다음 실제로 어떻게 예측을 할것인가? 1.  greedy decoding: 우선 다음 단어 하나를 최고의 확률값을 가지는 것으로 예측. 이 단어를 통해 다음 최고 활률값 예측 (https://github.com/hunkim/word-rnn-tensorflow/blob/master/sample.py의 sample=0). 이건 너무 greedy2. beam search: 한 단계에서 단어를 n개 예측후 조합. 예로 한단계에서 3개의 단어를 예측, 각각의 단어를 이용 다음 단어를 3개 예측. 그런다음 각각의 조합을 묶어서 조합의 가능성이 가장 높은 것을 선택 (대부분 beam size는 3~10)질문: 첫번째 예측이 나쁘면 이 이후 다 망침? 어쩌지?이를 해결하기 위한 몇가지 알고리즘 있음: 예. Scheduled Sampling.(참여자들의 많은 질문이 이어집니다. 더 재미있는 부분있다고 질문을 자제시키고 진행. 대단한 관심입니다.)Attention에 대한 설명. 입력이 어떤 단어에 weight 을 더줄지를 학습을 통해 결정. Attention 은 TF에 구현되어 있슴(질문: attention을 output에 적용할수 있을까? 그렇수 있을듯이라 답변.)S2S with Attention 사용하면 대부분 잘 동작됨. 실제 사용을 위한 팁 3가지 tip1: use word segments or word/char hybrid instead of just wordstip2: gradient clipping to prevent explosion tip3: use GRU or LSTM이정도로 첫번째 파트를 마치고 응용에 대해 이야기 시작s2s for speech: 아직 CTC나 HMM-DNN hybrid 보다는 잘 안된다고 함질문: 번역에 얼마나 많은 데이타 사용? several wmt 데이타셋. 각각이 10 of million sentences (이게 전체 구글번역은 아닌듯하고 본인의 연구 실험인듯)다음은 진행중인 active research 에 대해 이야기함Automatic Q&A: read book, read question, then revisit all pages in the book그러나 대부분은 메모리의 사용. RNN+메모리: 메모리 넷트웍, 뉴럴터닝머신, 다이나믹 메모리 넷트웍RNN with augmented operations: Neural programmers에 대한 간단한 설명결국은 http://distill.pub/2016/augmented-rnns/ 를 읽어봐야 함.(구글이 가지고 있는 모든 책을 이용해 자동응답이 나올듯함.)https://www.youtube.com/watch?v=G5RY_SUJih4
94	[TF-KR 2차 모임 장소 공모]안녕하세요. 곧 다가오는 연말을 맞이해 TF-KR 운영진에서 2차 모임을 준비하고 있습니다.이번 2차 모임은 "연말 파티+워크샵" 컨셉으로 기획 중이며, 1차 모임보다는 편하고, 더 재미있는 자리를 만들어보려합니다.날짜는 12.17일 토요일 1시~9시로 예정되어있고, 간략한 행사 구성은 다음과 같습니다.1) 세미나 세션2) Contest3) 포스터 세션4) 저녁 식사5) 소셜 파티그런데 아직 장소를 정하지 못해, 계속해서 적절한 장소를 섭외중에 있습니다. 연말 행사가 많아, 빠른 시일내에 예약을 해야해서 이렇게 [2차 모임 장소 공모]를 하게 되었습니다그래서 예상 참석 인원 [300명]정도를 한 공간에 수용할 수 있고, 교통이 용이하며 음식물 반입등이 가능한 곳을 댓글이나 메신저로 알려주시면, 운영진에서 세밀하게 살펴보도록 하겠습니다!또한 장소 선정에 큰 도움을 주신 분들께는 2차 모임 초청권을 N장 드릴 예정이니 많은 도움 부탁드립니다.- Sung Kim 권순선 (Soonson Kwon) 김태훈 (Taehoon Kim) 박은정 (Lucy Park) Park Ricky 이지민 (Jimin Lee)	4	좋은 장소 많이 추천 부탁드립니다.	1	마루180도 괜찮은데 300명까지는 안될듯하네요.	1	서울대학교 문화관!!	4	서울 구호선 염창역 서울도시가스 강당입니다.	0	저희대학도 괜찮긴 한데. 딱 시험기간이라 애매하군요...	3	GDG DevFest Seoul 2016가 열리는 서울대학교 글로벌컨벤션플라자 (서울대학교 38동 글로벌공학교육센터 5층) 도 좋아보입니다.http://convention.gece.or.kr/convxe/index.php수용인원은 최대 1000명까지 가능하고 현재 예약도 가능한데 음식반입은 합의를 봐야 할 것 같습니다.	3	한양대학교 Hit 7층 대회의실도 300명가량 수용 가능했던거로 기억해요교통도 괜찮고 음식물반입 가능했던거로 기억하는데 대여가 가능할지를 모르겠네요	0	수고해 주셔서 감사합니다. 혹시 Live Streaming은 안 하나요? ^^	0	가고프네요 ㅋ	1	다행히 이번에는 nips랑 안겹치네요. 지난번에 icml과 겹쳐서 못가서 아쉬웠습니다 ㅜㅜ	1	가..가고 싶..어요.	1	http://yeyak.seoul.go.kr/main.web서울 공공시설물 예약사이트인데, 여기서 대강단으로 검색하면유료지만 매우 저렴한 비용으로 대관이 가능합니다.	1	https://mediahub.seoul.go.kr/archives/726086요 기사 참고하세요.
73	도저히 그냥 잘 수 없어서 조금 더 해봤습니다. Tensorflow - Python에서 모델링하고 윈도우에서 실행시키기http://blog.naver.com/atelierjpro/220830797975뭐든 훈련시킬 수 있을 것 같은 기분이 듭니다.	0	그냥ㅎㅎ리눅스에서해야겠네요	1	와..덕분에 성공했습니다정말수고하셨고감사합니다노트북을주로쓰는데 듀얼OS설치나 도커사용이 안되서 새로리눅스노트북을 구매하려다 홍정모씨가쓰신글보고 윈도우에서 사용가능하게되었습니다~감사합니다!!!	1	교수님 감사합니다^^	0	교수님혹시 tensorboard는따로 빌드하는방법을알수있을까요??그냥디렉토리에옮겼더니실행이안되네요ㅠㅠ구글링에도나오지않아서 여쭤봅니다..	1	텐서플로우 윈도우 버전에서 GPU 지원에 관한 코드가 머지 된 것 같습니다. 하지만 에러도 보고되고 있어서 잘 살펴 보셔야 할 것 같습니다. 깃허브 풀리퀘스트를 참고해 주세요.https://github.com/tensorflow/tensorflow/pull/5071
1	도커를 이용한 윈도우에서 텐서플로 설치 과정 중 에러에 대해 질문합니다.CMD에 FOR /f “tokens=*” %i IN (‘docker-machine env –shell cmd vdocker’) DO %i를 입력하면Error checking TLS connection: Could not find matching IP for MAC address 08027e1f31a가 나와서 진행할 수 없습니다. 어떻게 해결하나요?
21	혹시 텐서플로우의 공개된 코드 중 CNN의 visualization에 대한 코드가 깃헙에 있던가요? 예를 들면 다음의 Keras 코드 같은건데 순수 텐서플로우만 갖고 만든 코드 말이지요. 	0	Caffe모델 visualization하는 코드는 아는데.. Tensorflow는 아직 못 찾았습니다^^ https://github.com/yosinski/deep-visualization-toolbox	0	Dong-Hyun Lee // 네.. 저도 이 논문의 코드를 찾고있었습니다.. 이 논문의 코드를 찾는 질문 페이지만 찾았네요 ㅎㅎhttps://github.com/tensorflow/tensorflow/issues/842	2	간단하게 MNIST의 손글씨 예제 CNN코드를 Visualization한 코드입니다. TensorflowKR 그룹의 김홍배 님이 예전에 소개해 주셨던 자료입니다.  학습된 Filter와 Filter를 통과해서 보이는 이미지를 Visualization 해주는 예제입니다.https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb	1	Heeseok Kang // 감사합니다. filter와 filter 통과 후 이미지를 보여주는건 어렵지 않은데, 보통 visualization에선 각 filter를 최대로 activate하는 input을 보여주는 등 convolution의 반대방향 매핑을 주로 목표로 하는 것 같습니다. 위의 예시인 deep visualization이 그 좋은 예이고요	5	google deepdream 이 좋은 예가 될것 같습니다. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb 에서 Naive feature visualization 섹션을 보면 간단하게 잘 나와있는것 같습니다. gradient "ascent" 로 랜덤 노이즈로 시작해서 해당 layer filter를 fire 시키는 pattern 이 어떤것인지 보는 부분인데, 이걸 찾으시는 것 같습니다.	0	오..! deep dream이 코드가 있었는줄 몰랐네요 감사합니다!
73	lecun 교수팀 논문을 제가 tensorflow 로 구현한 것을 lecun 교수님이 직접 자기 페북에 올려주셨네요.경쟁사 라이브러리로 만들었음에도 불구하고...https://m.facebook.com/story.php?story_fbid=10153898604557143&id=722677142	2	르쿤 교수님께 경쟁사가 있을까요. ㅋㅋㅋ EBGAN 재밌게 본 논문 중 하나인데 돌려봐야곘네요. 감사합니다!	1	축하드립니다.
28	이제 고퀄 자료만 엄선해서 보셔요^^	1	아주 유용한 정보 감사드립니다. 최근 1년간 보니 구글, TF, 알파고 이야기가 많네요.
143	와우~!! 통 크신 사장님이시네요...
133	머신러닝에 대해 한페이지로 간략하게 Visualization하여 보여줍니다.	1	Wow! 대단하네요.	0	대단하다 진심	0	한글화가 절실합니다!	1	책으로 몇 달을 붙잡으면서 얻은 인사이트가 저 페이지로 정리가 되네요 ㅋ
0	혹시 pytagcloud로 워드클라우드 그릴 때 텍스트사이즈를 자동으로 조절해주는 옵션이 있나요??
10	Machine learning 관련해서 어느 (파이썬) 라이브러리 많이들 쓰세요? 텐서플로 튜토리얼 훑고 나서 다음에 뭐할까 궁금해서요...	2	scikit-learn (Python) 씁니다.	0	torch도 괜찮은거 같네요	0	코드 짜기 싫으시면 h2o.ai 도 괜찮습니다. 버튼 몇개만 누루면 모델 만들어집니다.	0	pandas로 데이터 정리하고 scikit-learn 써요	0	전 keras를 주로 씁니다 ^^	0	저와 같이 ADA 를 만듭니다...
2	[장비렌탈 질문]안녕하세요. 장비 렌탈 관련하여 질문 드립니다.혹시 GTX 1080급의 GPU가 장착된 PC나 서버를 대여해주는 업체가 있을까요?	3	https://aws.amazon.com/ ?? data 가 로컬이여야 하나요?	1	안녕하세요 국내 슈퍼컴퓨터 제조회사(주)코코링크에서 일하고 있는 최웅희사원입니다. 자세한 용도를 알수있을까요???
219	DeepCoding Project @Hong Kong University of Science and Technology (HKUST) 박사과정 모집저희 연구실에서 활발히 진행중인 DeepCoding (딥러닝을 이용한 소스코드 부분/sequence/patch 생성)에 같이 참여할 박사과정 학생을 초빙합니다.* 지원 자격: 학사 또는 2017년 7월 이전 학사취득 예정 (GRE, 석사가 필요하지 않습니다) + TOEFL등 영어 성적* 혜택: 4년간 매월 20,000 HKD (약 290만원) stipend 지급 (TA나 RA나 다른 산업체 프로젝트에 참여하지 않고 잡무 0.)* 연구실 철학: http://www.se.or.kr/60 참조* 연구 (preliminary) 진행결과: http://home.cse.ust.hk/~xguaa/papers/deepapi.pdf (논문), http://bda-codehow.cloudapp.net:88/ (데모) 참조* 지원방법: https://cerg1.ugc.edu.hk/hkpfs/apply.html (홍콩과기대 CSE 선택) * 지원 마감: 2016년 12월 4일 * 문의및 상담: hunkim@cse.ust.hk	0	와..	0	지원이 대단하네요.	0	유홍연 박준현	0	우와...	0	와 대박 좋네요;;	2	😍회사 다니는 것 보다...	1	국내 도입이 시급합니다 (...)	1	매우 좋은 조건이네요	0	헐.. 좋군요.. 저거 지원금 세전인가요 ㅎㅎ	0	논문만 보고 데모는 못봤었는데 실행해보니 굉장히 신기하네요.. 대단합니다!	1	헛 제가 가고 싶네요...	0	연구분야가 딥러닝이 아닌 다른 연구실이더라도, 홍콩과기대 지원자격이나 혜택은 상동인가요?? 교수님의 랩실만의 특권인가요? ㅎㅎ	1	등록금은없는건가요?	1	정말 좋은 기회네요!! 그럼 일단 졸업을... 아니 영어도... 흠.. 다음기회에	0	Tim DH Lee	0	#정윤선 도전!	0	크..	0	권오훈
6	저번 1차모임때 만난던 오상준씨 연락처 아시는 분 댓글 부탁드립니다. 오상준씨 지갑을 주으신분께서 제 명함을 보고 연락이 오셨습니다.
1	Achieving Human Parity in Conversational Speech Recognition
12	#의사결정RL 10/17, 월, 의사결정RL : 파트 6 - 1회차 스터디 후기* 1회차 후기만 공유하겠습니다. 자료&커리큘럼은 곧 모두 공개&공유됩니다(정리 중)* 이 스터디는 정통..심리학 그룹 싸이그래머에서 진행합니다.의사결정RL 스터디 파트6이 시작되었습니다. 불확실하에서의 의사결정에 대한 계산적 모형을 공부하고 온라인상의 응용에 적용해보자고 시작한 스터디였습니다. 중반쯤 알파고 사태가 터지면서 어느새 거의 딥러닝 강화학습 스터디가 되어있군요. 그래도 신경경제학이라는 뇌과학+경제학+의사결정심리 퓨전 분야도 같이 스터디 하고 있으므로 정통 심리학 스터디라고 우겨봅니다.파트6에서 테마는 '딥러닝 강화학습 응용도메인 눈팅'입니다. 그래서 딥러닝 강화학습 응용예제, 코드 등을 열심히 찾아보는 중입니다. 그리고 또 하나는, 이론과 함께 코드도 같이 보자. 입니다. 마침 텐서플로우로 딥러닝 강화학습 예제를 잘 설명하고 있는 블로그를 찾아서 잘 참고하고 있습니다.먼저 제가 발표했습니다. 원래는 금융분야에서, DQN 알고리즘을 이용해서 금융 트레이딩하는 파이썬 코드를 찾아서(Deep Q-learning for Stock Trading) 그걸로 시작하기로 했는데 발표자분이 사정이 생겨서 일단 미루고, 제가 또 딥마인드의 DNC 논문(Hybrid computing using a neural network with dynamic external memory)을 소개했습니다. 참여하신 분들 중에 attention model을 모르시는 분들이 있어서 그걸 좀 리뷰하느라 생각보다 시간이 길어졌습니다.두번째는 정해인님이 신경경제학의 '뇌과학 기초(Introduction to Neuroscience)' 부분을 발표해주셨습니다. 뉴론의 기본요소들과, 활동전위, 이온 펌프 등을 차근차근 살펴보았습니다. 시간이 없어서 뇌의 해부학적 구조와, 각 부분들의 기능과 연결은 다음 시간에 이어서 하기로 했습니다. 딥마인드 논문을 보고 나면 늘, 뇌과학 공부를 해야겠다는 의지가 솟아오릅니다...세번째는 강화학습 기반 대화형 에이전트였습니다. 제가 발표했습니다. 책을 하나 찾았는데 좀 옛날 책이었습니다(그래도 2011년 이후). 하지만 대화형 에이전트를 어떻게 문제정의하는지, 강화학습으로 어떻게 시도하는지 알수 있으리라 생각해서 골랐습니다. 오즈의 마법사 라는 HCI 연구 기법을 적용하면서, 시뮬레이션 기반의 강화학습으로 대화형 에이전트 만드는 내용이 주라고 합니다. 네번째도 제가 발표했습니다. 딥러닝 강화학습을 대화형 에이전트에 어떻게 적용하는지 트렌드를 알고 싶어서, 논문(Deep Reinforcement Learning for Dialogue Generation)을 하나 찾았습니다. 요즘 많이 나오는 Deep Learning chatbot이 seq2seq 모형인데 이걸로는 긴 대화를 처리하기가 부족하다며, 각자 일단 supervised learning으로 학습 시킨후, 서로 대화를 시켜서 강화학습으로 학습시키는 알파고 학습 전략을 사용한 논문이었습니다. 대화를 도돌이에 빠지지 않고 잘 이끌어 나가기 위해 3가지 정도의 보상 함수를 정의해서 섞어서 쓴 내용이었습니다. 다섯번째는 강희석 (Heeseok Kang)님이 텐서플로우 딥러닝 강화학습 기초 실습을 준비해오셨습니다. Q-Learning Agents를 파이썬 코드로 우선 살펴보았습니다. Q 테이블을 업데이트하는 예제였는데, OpenAI Gym의 FrozenLake-v0 를 이용했습니다. 호수위 빙판에서 놀고 있는데 구멍에 빠지지 않고 멀리 떨어진 원반 가져오는 게임입니다. 다음 시간에 이걸 DQN으로 하는 예제, 그리고 멀티암드 밴디트 예제 등을 살펴보려고 합니다. 코드도 기초부터 보고, 실제 응용 사례도 같이 보고 하니까 재밌군요. 함께 하실 분은 언제든 환영합니다~	0	함께 하고 싶습니다~ 어떻게 신청할 수 있죠?	0	씨맥스(강남역 11번 출구)로 바로 찾아오시면 됩니다~	1	https://www.facebook.com/groups/psygrammer/
0	안드로이드에서 TensorFlow를 이용하여 CNN Training/Recognizing을 하고 싶습니다.StackOverflow를 뒤져보니, 기본적인 Workflow가 나옵니다만1. Build and train Tensorflow model in Python.2. Create a new graph, and transfer all relevant nodes (i.e. not the nodes responsible for training) to this new graph. Trained weight variables are imported as constants so that the C++ API can read them.3. Develop Android GUI in Java, using the native keyword to stub out a call to the Tensorflow model.4. Run javah to generate the C/C++ stub code for the Tensorflow native call.5. Fill in the stub by using the Tensorflow C++ API to read in and access the trained/serialized model.6. Use Bazel to build BOTH the Java app, the native Tensorflow interface (as a .so file), and generate the APK.7. Use adb to deploy the APK.이것 말고는 Android용 예제 하나만 덩그러니 있는 터라 뭐부터 해야 할지 감이 안오네요. 사실 저 위에 순서도 이해가 잘 안되고요. TensorFlow를 이용하면 Android에서 CNN Training/Recognizing을 할 수 있나요?
80	저처럼 초보자들은 수학 공부도 필요해서 공유합니다	2	정말 중요한 부분인것 같습니다. 감사합니다.	1	정말 필요한 내용이네요	2	이상하게도 slideshare가 너무 느린데 혹시 ppt/pdf 파일들을 github에 올려서 관리하실 생각은 없으신가요? 그럼 더 많은 분들이 빠르게, 그리고 멋진 슬리이드들을 한디렉토리에서 관리하면서 읽으실수 있으실듯 합니다.	1	감사합니다	1	고2부터 수학놓은 수포자인데제가 저거 다 보고 차근차근 이해하게 된다면 텐서플로우를 비롯한 프로그래밍 관련 수학에 큰 도움이 될런지 궁금합니다
22	bazel 잘알못이 삽질 끝에 tensorflow 설치 했습니다.GTX1080(or TitanX), CentOS 7.2, gcc 5.3.0, cuda8.0, cudnn 5.1.5, bazel 0.3.1, python 2.7.11 에서 tensorflow 사용하는 방법입니다.(사용자의 환경에 따라 달라질 수 있으니 100% 보장은 못해드립니다.)(1) gcc 5.3.0 source file download 후 설치 (/usr/local/bin)(2) cuda 8.0 설치 (/usr/local/cuda)(3) cudnn 5.1.5 설치 (/usr/local/cudnn)(4) python 2.7.11 설치 (/usr/local/bin) (5) bazel 0.3.1 설치 ( --user 옵션 주고 설치)(6) 환경 변수 설정        export LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/cuda:/usr/local/cudnn:$LD_LIBRARY_PATH      export PATH=/usr/local/cuda/bin:$LD_LIBRARY_PATH(7) tensorflow 용 virtualenv 생성      # virtualenv --system-site-packages ~/tensorflowvenv(8) tensorflow 용 virtualenv 시작     # source ~/tensorflowvenv/bin/activate(9) 필요한 패키지 설치 (사용 환경에 따라 다름, ref 참고)     # sudo yum install swig     # pip install numpy wheel(10) tensorflow repository clone     # cd ~/tensorflowvenv     # git clon https://github.com/tensorflow/tensorflow (11) bazel cache directory 설정 (편의를 위함)     # export TEST_TMPDIR = /tmp/junseokpark/bazel/ (12) tensorflow configure     # cd tensorflow     # ./configure (다 default 로 하셔도 되나 GPU는 y, CUDA는 8.0 및 /usr/local/cuda, CUDNN 은 5.1.5 및 /usr/local/cudnn 으로 설정) (13) backup local_config_cuda     # cp -aR /tmp/junseokpark/bazel/_bazel_junseokpark/0cxxxx/external/local_config_cuda/* /tmp/junseokpark/backup/local_config_cuda  (14) bazel build    # bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package  (14-1) 위에서 build 에러날 경우 (bazel bug 인듯 함)    # cp -aR /tmp/junseokpark/backup/local_config_cuda /tmp/junseokpark/bazel/_bazel_junseokpark/0cxxxx/external/local_config_cuda/*    # bazel fetch //tensorflow/tools/pip_package:build_pip_package    # cp -aR /tmp/junseokpark/backup/local_config_cuda /tmp/junseokpark/bazel/_bazel_junseokpark/0cxxxx/external/local_config_cuda/*    # bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package   (14-2) 위에서 GLIBCXX 에러날 경우    # LD_LIBRARY_PATH 점검 (/usr/local/lib64 가 먼저와야 함)   (14-3) 위에서 as 가 없다는 에러날 경우    # ln /bin/as /usr/local/bin/as  (꼼수 -_-, 원래는 binutil 등 필요한 것들을 다시 설치해줘야 하나 귀찮아서 건너뛰었습니다)    (15) install tensorflow     # bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg    # sudo pip install /tmp/tensorflow_pkg/tensorflow-0.11.0rc0-py2-none-any.whl    (16) Test    # cd tensorflow/models/image/mnist    # python convolutional.py    (성공한 화면)즐거운(?!) 딥러닝 하세요!참고 자료 : https://github.com/tensorflow/tensorflow/issues/4705	0	혹시 rhel6나 centos6에서 설치해보신 분 계시나요? gcc, glibc등 core패키지의 버전 문제로 hell gate open인 상태인데요ㅠ역시 docker가 답인가요? 그러면 나중에 mesos가 아니라 yarn 기반 분산처리를 하게 되면 docker container와 hadoop을 어떻게 엮을 지 고민되는데요. docker를 사용하면서 hdfs의 short circuit read를 적용할 수 있을런지...ㅠ	0	맘 같아선 gcc, glibc등을 확 업글해버리고 싶은데 기존 동작하던 서비스에 어떤 영향이 있을지 예측이 안되서(리눅스를 깊이 몰라서가 맞겠죠...ㅠ) 어떻게 못하고 삽질 중입니다ㅠ	2	이런 글은 블로그나 웹에도 올라가있으면 좋겠습니다!!
0	신발 두짝이 있는 사진(한짝은 겹쳐져서 일부만 보이는)을 opencv로 edge detection 해서 라인을 추출했습니다.이 사진에서 겹쳐져서 일부만 보이는 한짝을 지우려고 합니다.이런 라이브러리나 방법이 있을까요?
95	60개이상의 Deep learning 관련 startup들을 통해 트랜드 한번 보세요.재미있는 회사들이 많이 있네요. https://www.cbinsights.com/blog/deep-learning-ai-startups-market-map-company-list/	3	혹시 우리나라 회사들의 사정을 잘 아시는 분들이 계시면 우리나라 스타트업들로 이런 map을 그려주시면 정말 좋을듯합니다.	2	한국 스타트업의 경우 스타트업 얼라이언스에서 작성한게 있습니다. http://kr.startupall.kr/startupmap/
23	Google published TensorFlow text summarization code in August. It is using a deep learning model: sequence-to-sequence with attention They didn't publish guidelines on using the code on publicly available datasets. Here is a tutorial for running their text summarization model on any dataset, including publicly available CNN and DailyMail data
59	아시는 분들도 계시겠지만 최근에 제가 취직을 했습니다. 대전에 있는 쎄트렉아이는 카이스트에서 우리별 인공위성을 개발하던 연구인력을 중심으로 설립되었습니다. 여기 와서 실제 우주로 올라가는 인공위성을 처음 봤습니다. 엄청 신기하더라고요. 근데 그건 그거고 자회사를 통해서 위성영상을 판매하는 일도 하고 있습니다. 원한다면 엄청난 양의 인공위성영상 데이터를 마음껏 활용할 수 있습니다. 전세계를 여기서 볼 수 있습니다. 데이터의 가치는 영상처리와 카메라 시스템의 끝판왕이지 않을까요? ImageNet이후의 SpaceNet을 꿈꾸고 있습니다. 지금 계획은 약 1년간의 창업준비과정을 거쳐 자회사로 분사할 계획입니다. 지금 조인하시는 분은 창업 팀의 일원이 되는 겁니다. 추석 이후 회사 들어와서 한 달간 느낀 점은, 회사가 정말 자유롭다는 점. 의사결정이 시원시원하다는 점. 회사의 안정적인 지원을 받으며 기존 업무를 수행하지 않고, 별개로 창업을 준비하고 있다는 점입니다. 궁금하신 분들은 회사를 조사해보시면 아시겠지만 <직원이 행복한 회사> 9개 대표기업에도 선정되었었죠. 저도 요즘 회사 다니는 게 행복합니다. 개인과 회사의 발전이 일방적인 구조가 아닌 긍정적인 상호 경쟁관계임을 확인하였구요.창의적이고 스스로 목표를 세우고 도전하실 분. 두 분을 모시고자 합니다. <딥러닝, 데이터분석, 영상분석>에 관심 있으신 분은 페이스북 메시지나 tgjeon@satreci.com으로 연락 주시기 바랍니다.	2	멋진분들이 모이길 바랍니다 ㅎㅎ	0	크윽 초보는 그저 지켜봅니다 ㅠㅠ
4	안녕하세요,  텐서플로우로 구현중 궁금한 점이 생겨 질문드립니다.현재 VGGNet을 이용해서 이미지에서 feature들을 뽑고 뽑아진 feature들을 입력으로 받는 네트워크를 구현하고 있는데요.feature들을 뽑고 따로 후처리를 해야 하기 때문에 VGGNet  위에 추가 레이어를 올려 하나의 네트워크로 구성하기는 어려운 상황입니다.(후처리 작업은 이미지에서 patch-wise로 feature를 뽑고 concat과 같은 연산을 하는 작업입니다)그래서 일단은 https://github.com/sjchoi86/tensorflow-101/blob/master/notebooks/cnn_customdata_vgg_finetune.ipynb의 예제와 같이 VGGNet의 출력을 tf.eval하여 numpy 형식으로 변환 후 후처리 작업을 하고 다시 session을 만들어서  다른 네트워크에 입력으로 주고 있는데 혹시 이 방법을 더 효과적으로 처리 할 수 있는 방법은 어떤게 있을지 궁금합니다. (tf.placeholder는 real value만 들어갈 수 있어서 바로 텐서를 집어 넣을수는 없더라구요..)이 방법이 가장 간단하긴 한데 지금 의문인 점은 eval을 통해 GPU  셰어드 메모리에 있는 데이터들이 모두 CPU로 전달되고,  다시 세션 만드는 시간도 추가되며 또 CPU에 있는 값들을 GPU에 전달하는 시간이 소모되기 때문에 비효율적이지 않을까 하는 생각입니다.	0	딥알못입니다만.. ㅠㅠ 후처리를 tf에 있는 연산자로 구현하면 세션하나로 되지않을까요?	0	하이 남혁 강의에서 vggnet 맨 뒷단 fc1000 빼고 아웃풋을 다른 네트웍(거기선 rnn) 에 넣어서 한꺼번에 학습시키는 예는 봤는데 도움은 안되겠지? ㅋㅋ	1	아직 구현을 하진않았지만 검색해보고 아예 다른 방향으로 하려고 하네요 ㅎㅎ 답변들 감사합니다!
18	쿠아르틸레스 교수는 “세계 모든 나라에서 SW 엔지니어를 더 많이 필요로 할 것”이라며 “SW 교육 대중화를 위해 프로그래밍 언어도 표준화할 필요가 있다”고 주장했다. 하드웨어가 표준화를 통해 가격을 낮추고 대중화된 것처럼 SW도 표준화를 통해 더 배우기 쉽게 할 필요가 있다는 얘기다. 그는 “책을 넘어 그림이나 음성으로 프로그래밍할 수 있는 도구를 개발하고 지속적으로 발전시켜야 한다”고 강조했다.	0	그림이나 음성으로 프로그래밍할 수 있는 도구를 개발하고 지속적으로 발전시켜야 한다==>이런 기술은 어떻게 개발가능한가요
129	중학교 2학년이 만든 이미지 설명 CNN 프로그램 이랍니다.	0	구글에서 제공하는 텐서플로우 이미지 앱깔아봣는데 인식 거의 안되던데요....	0	중학생이 대단하네요.	2	Taewon Kang너 나옴	0	김은주 빠른 시일 내에 코딩을 그만둘까....? 대단하다
8	텐서플로우 내용은아니지만 질문이있어 글남깁니다. Cnn으로 이미지분류를하고있는데요. 현재 사용하고있는 클래스의 개수는 5개라고하겠습니다. 이때 Cnn은 어떤이미지가들어와도 5개중하나를 지목할텐데요. 만약 5개중 어느하나에도 속하지못한다는 답을 cnn 이 줄수있나요?? 즉 5개 클래스에 사실 속하지못하는 엉뚱한 이미지른주었을때 5개중 어느하나에도속하지못한다를 어떤 방법을 통해 알수있나요?? 관련논문이나 조언 부탁드립니다	0	5개에 속하지 않는 이미지를 주더라도 5개의 점수로 구분되어 결과가 나옵니다. [0.1, 0.2, 0.3, 0.4, 0.5] 이런식으로요. 여기서 가장 높은 값에 속하는 클래스를 해당 이미지의 클래스로 판단합니다. 이 때 클래스 값이 0.5가 넘지 않으면 해당 클래스로 판단하지 않겠다는 식의 규칙을 정하면 될 듯 합니다.	0	답변감사합니다. 말씀하신방법이 해봤었는데 요. 단순확률값으로보게되면 여전히 높은값으로 5개중 하나의 클래스에속하는경우가있었습니다. 혹시 feature vetor관점이나 이런 문제를 해결하는 네트워크가 있는지 궁금합니다	4	Open set recognition 논문이 있습니다아이디어는 unknown의 정의인데, 여러 클래스에 걸쳐서 모호한거 또는 머무 멀리 떨어진거.. 이런건데요. 아래 링크 참고해 보세요https://www.google.co.kr/url?sa=t&source=web&rct=j&url=http://www.wjscheirer.com/misc/openset/cvpr2016-open-set-part1.pdf&ved=0ahUKEwjC3fLovJ3PAhVFHZQKHZNwAWkQFggjMAE&usg=AFQjCNGTl4arjF0BJIGewqWmOFr_n7AsAA&sig2=1YEzSpKbFLbS3Zyw9t3Gow	2	정상적인 경우라면 기 학습된 class가 아닌 새로운것이 투입되면 확률이 분산되어 특정 class 확률이 높지 않아 확인이 가능합니다. 5개 class 중 하나가 차지하는 비중이 높은데 그쪽으로 오분류된 사례라 생각됩니다. 그런 경우 feature를 더 추가하시면 도움이 되리라 생각됩니다.	2	저도 같은 문제에 부딪치고 있는데.training_set 이 (문제에 비해서) 작아서, 그냥 overfit 시키고 가려고 했더니,noise 를 잡아가지고, 한 클래스에다 몰빵을 시키더군요. (몰빵 않나올줄 알았는데.. competing signal 이 없어서..)1) Eric 님이 말씀하신데로, feature_set 억지로 더 많들어서 ("inception module" 참조), noise 가 한 클래스로 몰리지 않고 퍼트리거나.. (이레도.. 너무 뉴랄넷이 깊으면, noise 잡아다 한 클래스에다 붙힐거 같아요..)2) training data 의 5개의 클래스에서 사진은 똑같은 비율로 섞어서 만든, 6th class 는 어떨까요?https://namu.wiki/w/%EA%B0%9C%EC%83%88 이미지를 만들어서요. DCGAN냄새도 나는것 같은데..개인적으로 "개새" 가 나오는 논문을 보고 싶습니다!! ;)	4	이거 제가 얼마전에 ai korea에 질문했던 내용과 거의 동일하네요몇몇분들이 주신 답변중에 이런게 있었습니다위에 개와 고양이를 구분하는 예를 가지고 설명하면 개와 개가 아닌것을 구분하는 모델 1개 그리고 고양이와 고양이가 아닌것을 구분하는 모델 1개 이렇게 바이너리 클래시피케이션하는 모델을 두 개 만들어서 원숭이 사진이 들어오면 개도 아니고 고양이도 아니다라고 나오게 할 수 있을거라는 의견이 있었어요제가 해결해야하는 문제는 클래스가 30개정도 되는데 모델을 그만큼 만들긴 힘들어서 아직 해보진 못했습니다	4	학습할때 dustbin class를 만들어서 5개의 카테고리에 속하지 않는 이미지는 이 class에 속한다고 해서 학습을 하는 겁니다. 만약 이런 이미지가 없다면 아무거나 다른 이미지 구해서 학습을 해도 됩니다. 그러면 나중에 테스트 이미지가 dustbin class로 분류되면 이건 5개의 카데고리에 속하지 않는게 되겠죠. 재밌는 건 이렇게 하면 5개 카테고리 분류의 정확도도 높아질 수 있다는 겁니다. 일종의 unsupervised learning의 효과가 있는 셈인데요.. 자세한 건 이 논문을 참조하세요~ https://arxiv.org/abs/1511.03719	0	참고로 제가 했던 내용중에 개소리, 새소리, 당나귀, 닭, 등의 상황별 소리에 대한 classification 모델링을 한적이 있습니다. 생각보다 잘됩니다.
81	Augment 된 4개의 RNN 모델들에 대해 잘 정리된 문서입니다.http://distill.pub/2016/augmented-rnns/"As this has happened, we’ve seen a growing number of attempts to augment RNNs with new properties. Four directions stand out as particularly exciting:"	0	교수님이 만드는 언어를 통한 프로그래밍 자료 어디서 찾을수 잇우요?
23	네이버에서도 신경망 기반 번역 서비스를 오픈했네요.
46	유투브에서 제공하는 800만여개의 영상 데이터셋입니다. 1400만개의 라벨링이 되어 있으니 유용하게 사용하시기 바랍니다!
9	#싸이무비 싸이무비 : 파트 2 - 1회차 스터디 후기* 이 스터디는 정통..심리학 그룹 싸이그래머에서 진행합니다.* 1회차 후기만 공유하겠습니다. 발표자료는 정리중이며 곧 모두 공개&공유됩니다.심리학과 머신러닝을 이용해서 영화 데이터를 살펴보자는 취지의 싸이무비. 파트2  첫모임이 있었습니다. 파트2는 크게 '성격심리학 / 음성 데이터에서의 성격측정 / 비디오 카탈로깅 / 주로 동영상 데이터 영역에 적용된 딥러닝 논문 리뷰' 로 구성되어 있습니다.* (성격캡쳐링) (성격스피치) Personality Assessment in Psychology먼저 제가 성격측정 부분을 발표했습니다. 지난 파트1에서 Young-hwan Kim​님이 발표하시려다가 사정상 참여를 못하신 대신에, 김영환님이 작성한 자료를 가지고 제가 대신 발표했습니다. 이 책은 음성 신호에서 성격을 어떻게 측정하느냐가 주된 내용입니다. 이번 챕터는 심리학에서 성격이론들이 어떤게 있는지, 성격 특질 이론 위주로 살펴보는 내용이었습니다. 성격에 대해 5가지 요인이 안정적으로 관찰되더라라는 이론인 big five  이론으로 요약되는 챕터였습니다.* (성격심리) Chapter 2. Approach / Avoidance두번째는 성격심리학 부분을 제가 발표했습니다. 뉴로이미징을 이용해서 성격을 연구해보자는 취지의 책인데요, 지난 시간에 다 못했던 Approach / Avoidance 부분을 했습니다. 많이들 다루는 성격 검사인 빅 파이브 이론 보다 더 아래의 하위 경향성으로 내려가서 뇌의 여러 영역이 어떻게 관여하는지를 살펴보는게 나중에는 인간의 성격에 대해 더 설명력과 예측력을 높여줄 것이라는 내용이 주입니다. 접근/회피 속성은 대부분의 동물에게 나타나고 모든 성격 축에 관여하며 관찰도 쉽고 BAS/BIS 이론처럼 잘 정립된 것도 있고 해당 위계 영역에 뇌의 어떤 부분들의 관여하는지 좀 알려진게 있어서 초반부에 선택된 것 같아요. 우리가 관찰하는 행동 데이터를 이해하려면 목표, 동기, 그리고 정적/부적 자극에 대한 반응 등을 맥락에 따라, 그리고 위계적으로 조직화되는 점을 고려해야 하며, 또한 이 위계성에 뇌의 여러 부위가 어떻게 연결되는지를 approach / avoidance 속성을 통해 차례로 살펴보는 챕터였습니다. 정말 뇌과학의 세계는... * (성격심리) Chapter 3. Integrating Personality/Character Neuroscience with Network Analysis세번째는 역시 뉴로이미징 성격심리학 부분이었습니다. Hannah Song​님이 준비해주셨구요, 네트워크 분석을 적용해서 성격심리에 관여된 뇌과학 연구들을 통합해서 설명해보자는 파트였습니다. 시간관계상 챕터를 다하지는 못하고 네트워크 분석이 무엇인지, 용어와 개념들은 어떤게 있는지 살펴보았습니다. 노드, 에지, 노드의 중요성, 동질성, 강건성 등을 측정하는 여러 지표들을 살펴보았습니다. 예전에 다른 스터디를 통해서 알던 것도 있고, 좀 성격심리쪽에서 쓰려는지 살짝 강조한 다른 지표들도 있고해서 복습도 되고 책의 관점도 엿볼수 있는 좋은 시간이었습니다. 다음 시간에 이어서 뇌과학에서 네트워크 분석을 어떻게 적용하는지, 그리고 성격심리 연구에 어떻게 적용하는지에 대한 내용이 하기로 하셨습니다.* (딥무비-카탈로깅) - 책 : 3. Accelerating Shot Boundary Detection - (paper) CNN-Based Shot Boundary Detection and Video Annotation- (paper) A Deep Siamese Network for Scene Detection in Broadcast Videos네번째는 비디오 카탈로깅 부분이었습니다. 동영상 데이터를 내용 기반으로 분석하기 위해 샷 검출, 장면 검출, 의미 태깅 등을 하는 분야입니다. 이번 파트에서 새롭게 추가된 부분이구요, 교재는 2015년 비교적 최신임에도 기존의 기법을 모아 정리한 것인지라 딥러닝 부분이 빠져있어서 해당 내용에 대응되는 딥러닝 적용 논문을 함께 보는 식으로 진행하기로 했습니다. 제가 교재 3장. Shot boundary detection에 대한 내용과 딥러닝 논문 하나를 리뷰하고, Joon-ho Kwon​님이 다른 논문을 하나, 해서 총 3개의 내용을 발표했습니다. 갑작스런 카메라 전환인 CT(컷 등으로 변환되는), 점진적으로 화면이 전환되는 GT 등의 SBD의 문제정의를 살펴보고 프레임 차이 기반, 특징점 기반 등등의 기존 접근법들을 보았습니다. 그리고 제가 준비한 논문은 알고보니 장면 탐지였습니다. 샷은 추출했다는 가정하에, 이 샷들의 시각특성을 처리하는 CNN과 텍스트 특성(샷마다 텍스트 스크립트가 달려있습니다)을 처리하는 CNN을 병렬로 연결해서 유사도 스코어를 예측하게 하고 이를 모아놓은 유사도 행렬을 전통적인 클러스터링 기법으로  분류해서 장면들을 나누는 내용이었습니다. 권준호님이 준비한 논문은 제목과는 다르게 샷은 기존 프레임 차이 기반으로 분리하고, 그 샷들에 object recognition 용 CNN으로 자동 태깅을 하는 내용이었습니다. 역시, 딥러닝도 적용 방식에서 수준차이가 있구나 라는 것을 새삼 느낄 수 있었습니다. 아직까지 구글이나 딥마인드가 아니면 대부분 이미지 특징 추출기나 분류기 정도로 기존 이미지 처리 프로세스의 특정 지점을 딥러닝으로 교체하는 방식의 논문이 평균적인듯 합니다.* (딥마인드) Hybrid computing using a neural network with dynamic external memory다섯번째는 제가, 얼마전 딥마인드가 발표한 논문 리뷰를 했습니다. 스터디 커리큘럼과는 상관었지만 워낙 궁금해서. 그리고 정말 딥마인드의 천재성에 감탄할 수 밖에 없었습니다. 너무 멋진 집단인 것 같아요. 대충 다들 아시다시피 딥러닝의 신경망 가중치들이 '기억'과 '조작'에 대한 정보를 동시에 담고 있기에 규모의 한계가 있었죠. 그래서 외부에 '기억'을 담당하는 부분을 따로 만들고 이를 attention 기제를 이용해서 학습 기반으로 자동으로 조정해나가는 external memory network 기법들이 점점 등장하고 있었습니다. 그리고 이번에 딥마인드의 논문은 그런 연장선에서 기존 컴퓨터의 컨트롤러 역할을 하는 신경망과, RAM에 해당되는 외부 메모리 매트릭스를 효율적으로 연결하는 attention 기법 3 종류를 조합해서 선보였습니다. 기존에 딥마인드가 발표했던 뉴랄 튜링 머신 보다 더 효율적이고 진보된 형태인데요, 이렇게 해서 end-to-end 방식으로 데이터를 집어 넣으면 학습을 통해서 조정되는 미분가능한 컴퓨팅 시스템(DNC)이라고 주장하고 있습니다. 그리고 이 기제는 포유류의 기억을 담당하는 뇌부위인 해마의 작동방식에 영감을 얻어서 구성했다고 논문에서 밝히고 있구요. 그리고 이 시스템을 먼저 얼마전 페북이랑 몇군데서 작업해서 공개한 인공지능을 위한 QA(질문-대답) 테스트 셋에 적용해봤습니다. 그 뒤에 이런 질문-대답 과제들은 그 명제들의 관계를 그래프로 표현할 수 있으므로, 그래프 표현되는 과제들을 잘 풀면 비슷하게 이런 과제도 잘 풀수 있다며 지하철 노선도 문제, 가계도 문제에 적용했구요. 즉, 지식 그래프 상에서 추론하는 과제를 딥러닝으로 푸는 방법을 보여준 것이죠. 딥마인드가 발표하는 연구들은 정말 '인공지능'으로 가기 위한 기본적 요소들을 착실히 쌓는 것처럼 보입니다. 그리고 이런 기본 요소들을 - 특징을 추출하는 것은 딥러닝으로 처리할 수 있으니, 그보다는 이 딥러닝 레이어를 어떤 식으로 구성할 것인지 '아키텍쳐링'의 관점에서 뇌과학과 컴퓨터 과학 양쪽을 능숙하게 사용해서 '학습'기반을 가지는 시스템으로 재포맷팅하는 논문들이 나와서 늘 감탄하고 있습니다. 논문을 부라부랴 살펴봤고 모르는 부분도 많았지만 그래도 같이 사람들과 감탄하며 리뷰를 했습니다.* (딥비디오) DeepPose: Human pose estimation via deep neural networks마지막으로은 딥러닝으로 동영상을 어떻게 다루는지 좀 유명한 논문들을 살펴보는 시간이었습니다. 이재황​님이 구글의 DeepPose 논문을 리뷰해주셨습니다. 시간이 없어서 전반부만 살펴봤어요. 사람의 움직임을 뼈대모형으로 모델링하고 추적하고 추론하는 Pose estimation을 어떻게 딥러닝으로 좀 더 편하게 할지에 대한 내용이었어요. 보통 관절 포인트들을 탐지하고 그 관절을 잇는 뼈대도 그린 뒤에 그것들을 추적하는 것을, 이 논문에서는 무엇이 관절점이고 무엇이 뼈대인지도 딥러닝이 추론하면서 Pose를 탐지, 추적하는 식으로 전개되는 듯합니다. 구체적인 내용은 다음 시간에 이어서 하기로 했어요~첫날이라 너무 빡빡하게 모든 부분을 맛보기로 살펴보았는데요, 다음 시간부터는 3개 정도의 컴포넌트만 적당하게 보면서 진도를 나갈 생각입니다. 영화라는 도메인에, 심리학과 머신러닝이 어떻게 결합될수 있는지, 혹은 동영상 데이터를 딥러닝으로 어떻게 처리할 수 있는지 궁금하신 분들은 함께 스터디하러 언제든 찾아오세요~
14	아이디어가 좋네요 전 맨날 뭘 만들어볼까 고민해도 생각이 안나는데 ㅠㅠ	1	정말 멋지네요. 한국음식은 잘 안될테니 지금부터라도 누군가 데이터를 수집하면 이 회사에 팔거나 국내용으로 만들어 볼수 있을듯 합니다.	0	기사를 가장한 NVIDIA 광고처럼 보이기도 하는군요 ㅎㅎㅎ	0	이 주제에 관한 워크샵도 있습니다 http://madima.org/몇 년 전만 해도 이 워크샵은 일본 로컬 워크샵이 아닌가 싶을 정도로 일본발 페이퍼 비중이 높았는데 올해 스피커들을 보니 이젠 이 주제를 여기저기서 많이 다루나보네요.
1	안녕하세요? 어제 질문을 올렸었는데 하나 더 궁금한것이 있어서 여쭤봅니다. 데이터셋을 늘리고, class수도 함께 늘긴하였지만, random forest로 79.2% 정도 정확도가 나오는 문제를 deep learning으로 현재 96% 정확도를 얻었습니다. 현재 조건은 6개 layer, 각 layer에 1000개씩 node, xavier_initializer로 초기값을 정하였고, drop out 0.5, batch size는 memory가 허락하는한 최대로 7만개정도로 하였습니다. 그리고 training을 2000 cycle 돌린 후 정확도를 측정한 결과 입니다.저는 머신러닝전문가는 아니고, 활용?하는 정도로만 사용하는데 비교적 쉽게 정확도를 높인 것 같아 만족하고 있습니다. 이미 충분한 것 같지만, 혹시 제가 사용하는 조건에서 추가로 정확도를 더 올릴 수 있는 방법이나 시도할 수있는 것들이 더 있으면 조언 부탁드리겠습니다. 감사합니다.	0	batch size 가 너무 큰거 아닌가요?? 데이터가 2만개에서, 배치가 7만이면, 3.5배로??  (저도 잘 모름... 그냥 너무 크면, BN 에서 시그널을 잡아먹을거 같아서.. )input_feature size 가??	0	딥러닝만으로 성능의 극단을 내시려면 우선 하이퍼파라미터 및 네트워크 구조를 이것저것 바꿔보면서 튜닝을 해야하고, learning rate decay 및 여러 최신 regularization 찾아서 적용해야 할 것같습니다.그 이외 가장 보편적으로 쓰는 방법은 앙상블이나  data augmentation등이 있습니다.	0	저 96%가 Validation Acc 맞나요? 일단 정확도보단 Loss 값을 보시고 Bias Variance Tradeoff 참고하시면 어떤 방법을 취해야 할지 쉽게 판단 할 수 있습니다.
2	안녕하세요 김성훈 교수님의 Rnn 강좌를 보고 예제를 돌리다가 궁금한점이 생겨 질문드립니다. 먼저, 아래의 실습코드에서 기본 RNN모델에 적용되는 세 가지 weights matrices(인풋-히든, 히든-히든, 히든-아웃풋)를 실제로 출력하는 방법이 있는지 알고 싶습니다.그리고 학습 후에 다른 입력에 대해 예측하고 싶다면, tf.nn.rnn만 세션에 올려실행하고 outputs을 이용해 분석(소프트맥스의 결과 값일테니 가장 큰 값을 1, 나머지를 0으로 보고)하면 되는 것인지 궁금합니다.import tensorflow as tfimport numpy as npchar_rdic = ['h', 'e', 'l', 'o'] # id -> charchar_dic = {w : i for i, w in enumerate(char_rdic)} # char -> idsample = [char_dic[c] for c in 'hello']x_data = np.array([[1,0,0,0],  # h                   [0,1,0,0],  # e                   [0,0,1,0],  # l                   [0,0,1,0]], # l                 dtype = 'f')# Configurationchar_vocab_size = len(char_dic)rnn_size = char_vocab_size  # 1 hot coding (one of 4)time_step_size = 4          # 'hell' -> predict 'ello'batch_size = 1              # one sample# RNN Modelrnn_cell = tf.nn.rnn_cell.BasicRNNCell(rnn_size)state = tf.zeros([batch_size, rnn_cell.state_size])X_split = tf.split(0, time_step_size, x_data)outputs, state = tf.nn.rnn(rnn_cell, X_split, state)logits = tf.reshape(tf.concat(1, outputs), [-1, rnn_size])targets = tf.reshape(sample[1:], [-1])weights = tf.ones([len(char_dic) * batch_size])loss = tf.nn.seq2seq.sequence_loss_by_example([logits], [targets], [weights])cost = tf.reduce_sum(loss) / batch_sizetrain_op = tf.train.RMSPropOptimizer(0.01, 0.9).minimize(cost)# Launch the graph in a sessionwith tf.Session() as sess:    tf.initialize_all_variables().run()    for i in range(100):        sess.run(train_op)        result = sess.run(tf.argmax(logits, 1))        print(result, [char_rdic[t] for t in result])	2	확인하고싶은 W 매트릭스를 (RNN cell의 W 메트릭스 포함)를 eval로 출력하시면 확인이 가능합니다.test하실때는, RNN의 최종 클래스를 예측한 텐서를 sess.run으로 계산하면되고, 이때 feed_dict로 테스트 데이터를 넣어주시면 됩니다.
76	TensorFlow로 구글은 무엇을 하고 있을까요? https://www.tensorflow.org/versions/r0.11/resources/uses.html 문서를 보니 검색결과 튜닝, Smart reply, Drug Discovery등에 사용된다고 하며 상세한 정보 링크도 걸려있습니다. 앞으로 더 많아 지겠지요?	2	한국 기업도 등재될 수 있기를 희망해봅니다.	3	저기에 떡 하니 이름 하나 새겨넣고 싶네요! 노력해야죠 :)
5	안녕하세요. 저는 Tensorflow를 공부하고 있는 학생입니다.이 그룹을 통해서 많은 정보를 얻어가고있어서 정말 감사드립니다.지금 현재 구현하고 있는 논문은 Super Resolution CNN 인데요.GPU를 사용해서 50만번까지 학습을 시켰습니다.그런데 cost가 10만번 횟수 이후로 너무 적은 값으로 줄고 있어서 효율이 좋지 못합니다.● 어떻게하면 로컬미니멈에 빠지지않고 글로벌 미니멈으로 갈 수 있도록 할 수 있을까요?현재 learning rate는 0.0001 에서 0.001 로 번갈아가며 학습하고 있습니다. ( 번갈아간다는 의미는 10만번은 0.0001, 10만번은 0.001 로 변경해가며 하고있습니다. )논문은https://arxiv.org/pdf/1501.00092.pdf참고하였습니다.답변 부탁드립니다. 감사합니다.	0	추가 : 0.128057 0.128173 0.128097 이런식으로 줄어들지 않고 왔다갔다합니다	0	음 SGD로 쓰시나요? 논문들이 momentum method를 많이 써서 저도 momentum method 쓰는데 괜찮은 거 같더라구요
7	안녕하세요 저는 슈퍼컴퓨터 회사에서 근무를 하고 있습니다.GTX 1080 10장을 가지고 TensorFlow설치 및 테스트를 해보고 있는데, tf.Session()을  입력했을 때 사진처럼 에러가 납니다.그리고 한번 더 입력했을 때는 에러가 안나는데, 이런식으로 화면이 나오면 정상적으로 실행이 된건가요???조언 부탁드립니다.	2	CUDA_VISIBLE_DEVICES 를 8개까지만 설정해놓고 쓰세요. 10개는 못쓸겁니다.	1	CUDA에서 정상적으로 16개 GPU설정하셔서 테스트하셨다는데 그 테스트를 어떻게하셨는지 알수있을까요?	1	전 10개는 아니고 4개로 해봤는데, 확인을 위해 cifar10 multi GPU 예제를 활용했습니다.https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10
4	[스터디원 모집] 딥엘라스틱 : 파트 4 * 2주에 한번, 목요일, 저녁 7시 - 10시 30분. 강남. 회비없음. 10/27 시작.- (새로 추가된 것) 딥러닝을 이용한 질의응답 시스템- (기존) 딥러닝 NLP 관련 논문 리뷰 / 신경인지언어심리학 / clojure * 이벤트 링크 - https://www.facebook.com/events/692013947624210/* 이 스터디는 '인간의 언어, 기계의 언어' 스터디 그룹 바벨피쉬에서 진행합니다.딥엘라스틱 스터디가 어느새 마지막 파트입니다. 간단한 질의응답 시스템을 딥러닝으론 어떻게 하는지 텐서플로우, 논문 등으로 살펴볼 생각입니다. 엘라스틱서치 검색엔진은 따로 스터디 하지는 않고 실습 속에 포함되는 정도로 할 것 같습니다. 참여를 원하시는 분들은 이벤트에서 참석을 누르시거나, 댓글을 다시거나, 바로 찾아오시면 됩니다.전문가/실무자 모임이 아닌 취미 모임입니다. 함께 하실 분들은 언제나 환영합니다~
1	윈도우에서 도커 이용해서 주피터 노트북으로 텐서플로우를 사용하고 있는데 궁금한 점이 있습니다. 1. 주피터 노트북으로는 파일 입출력이 안되나요?2. 파라메터를 training 시킨 후 test할 수는 없나요?그 외에 윈도우에서 효과적으로 텐서플로우 사용할 수 있는 방법이 있다면 여쭤보고 싶습니다. 주피터노트북은 조금 불편하네요.ㅠㅠ	0	2번 때문에 1번 질문이 나온 거라면 Saver를 쓰시면 됩니다. 개인적으로는 jupyter notebook이 굉장히 편했는데요... 어떤 점이 불편하시죠?	0	test도 당연히 할 수 있습니다.	0	혹시 정말 죄송한데 참고할만한 자료나 사이트 좀 알 수 있을까요? command line 형식이라 어떻게 file load를 해야할지도 난감하고, 관련 자료 찾기가 쉽지 않네요..ㅠㅠ	0	saver가 텐서플로우 내장 라이브러리인 것 같은데 컴퓨터에 있는 이미지 파일 혹은 텍스트 파일을 웹에서 읽어들일 수 있나요?	0	답변 깊이 감사드립니다!
3	안녕하세요, TensorFlow로 기초부터 공부하고 있는 한 학생입니다.공부하다보니 Logisitc Classification을 구현해보려고 해서 아래와 같이 코드를 짜봤으나 learning_rate를 꽤 작게 잡고 많이 돌려봐도 일정 값을 넘어가면 nan이 떠서 처리가 제대로 안 되네요. 어떻게 해야할까요?import tensorflow as tfx_data = [1, 3, 9, 4]y_data = [0, 0, 1, 1]a = tf.Variable(tf.random_uniform([1], 1.0, 2.0))b = tf.Variable(tf.random_uniform([1], 1.0, 2.0))X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)y = tf.div(1., 1. + tf.exp(-a * X + b))loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))optimizer = tf.train.GradientDescentOptimizer(0.002)train = optimizer.minimize(loss)init = tf.initialize_all_variables()sess = tf.Session()sess.run(init)for step in xrange(1000000):    sess.run(train, feed_dict={X: x_data, Y: y_data})    if step % 100 == 0:        print step, sess.run(loss, feed_dict={X: x_data, Y: y_data}), sess.run(a), sess.run(b)	0	It's because y value from x_data=3 approach near to 1. When y becomes close to the value, tf.log(1-y) diverges which make your outcome nan.	0	log 안에 들어가는 값들을 tf.clip_by_value(y나 1-y, 1e-8, 1.0) 으로 감싸서 넣어보세요	0	import tensorflow as tfx_data = [1, 3, 9, 4]y_data = [0, 0, 1, 1]X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)a1 = tf.Variable(tf.random_uniform([1], 1.0, 2.0))b1 = tf.Variable(tf.random_uniform([1], 1.0, 2.0))a2 = tf.Variable(tf.random_uniform([1], 1.0, 2.0))b2 = tf.Variable(tf.random_uniform([1], 1.0, 2.0))y1 = tf.div(1., 1. + tf.exp(-a1 * X + b1))y2 = tf.div(1., 1. + tf.exp(-a2 * y1 + b2))cost = -tf.reduce_mean(Y * tf.log(y2) + (1-Y) * tf.log(1 - y2))a = tf.Variable(0.2)optimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost)init = tf.initialize_all_variables()with tf.Session() as sess:    sess.run(init)    for step in xrange(20000):        sess.run(train, feed_dict={X: x_data, Y: y_data})        if step % 100 == 0:            print step, sess.run(cost, feed_dict={X: x_data, Y: y_data})            print step, sess.run(y1, feed_dict={X: x_data, Y: y_data})            print step, sess.run(y2, feed_dict={X: x_data, Y: y_data})
0	Tensorflow  GPU 버전으로 설치 후,  python 으로 tensorflow를 실행하면 I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally이런 메세지가 떠야하는데>> import tensorflow 를 했을 때 오류는 안뜨는데 위와 같은 출력결과가 아니라 그냥 아무런 메세지가 출력되지 않습니다.혹시 이런 경우는 뭐가 문제가 있는 것인가요?ps.nvidia-sminvcc --version을 입력하였을때 정상적으로 잘 나왔습니다.---추가---포맷하고 다시 설치해봤지만 여전히 똑같은 상황입니다.bazel 설치를 하지않고 pip을 이용해 Tensorflow를 설치했을 때는 위와 같은 정상적인 출력 결과가 뜨는 것을 확인했습니다.혹시 Bazel 환경 설정과 관련된 문제인거 같은데.. 혹시 관련 문제에 대하여 해결방법이 없는지 궁금합니다.	0	cpu 버전으로 설치된거같은데요?	0	이후 Session() 등의 명령어는 정상적으로 호출되나요?	0	from tensorflow.python.client import device_libprint device_lib.list_local_devices()로 import된 device를 확인해 볼 수 있습니다.
11	딥마인드에서 dynamic external memory를 이용한 differentiable neural computer라고 하는 새로운 architecture를 개발했네요. (nature에 실렸습니다)https://deepmind.com/blog/differentiable-neural-computers/http://www.nature.com/nature/journal/vaop/ncurrent/full/nature20101.html	1	https://www.theguardian.com/technology/2016/oct/12/google-creates-ai-program-that-uses-reasoning-to-navigate-the-london-tube?utm_term=Autofeed&CMP=twt_a-technology_b-gdntech#link_time=1476292367
37	TF 0.11 버전으로 업그레이드 하시는 분들을 위해 남깁니다. bazel로 소스 설치 하시는 분들은 bazel을 0.3.1 버전 이상으로 꼭 업그레이드 하세요. 관련 issue: https://github.com/tensorflow/tensorflow/issues/4362그리고 다들 아시겠지만 cudnn 5.1에서는 3x3 conv가 2.7배가량 빨리 처리할수 있게 향상되었답니다. cuda8.0과 cudnn5.1.5로 소스 컴파일 다시 하시는걸 추천!	0	꿀 팁 감사합니다. 근데 3x3 conv 성능만 향상되나요? 다른 커널 사이즈는 해당이 없나요?	0	실례지만 CUDA 8.0 44빌드에서는 GCC 다운그레이드 없이 5.4로 컴파일 될까요...	3	우분투 데스크탑 16.04 + Anaconda + cuDNN 5.1 + CUDA 8.0 조합으로 컴파일한 TensorFlow whl입니다 (Python 3.5 CPU or GPU). 필요하신 분 한번 사용해 보세요~https://www.dropbox.com/sh/x50oux2q1jsjlot/AADd0es8cFcGKTBXagFAP0Zxa?dl=0
32	Windows 10 기반의 Tensorflow 빌드를 진행하면서 진행 사항을 노트하고 있습니다.기존에 공유해주신 내용을 참조해서 현재는 튜토리얼 예제와 PIP를 빌드해보았습니다.튜토리얼 예제 실행은 해보았고, PIP 설치 및 Python 예제를 작성하여 실행을 확인 하였습니다.	3	성공하시면 동영상도 하나 부탁 드립니다.	2	tf.train.Saver객체의 save와restore가 정상적으로 작동안하네요아마 윈도우 파일시스템 접근이 미완인듯합니다속도는 윈도우 네이티브라  동일 pc에서 도커보단 train시간이 25%이상 빠릅니다 참고하세요^^gpu지원도 얼마 남지않은듯합니다	1	pip빌드까지 무리 없이 완료를 하였네요... python에서 테스트를 해봐야 겠습니다.	0	pip 설치 및 Python 샘플 코드 작성 후 테스트까지 완료하고 업데이트 마무리 하였습니다. 이후에 MNIST예제를 windows10과 Macbook에서 각각 실행하여 결과 확인을 해봐야 겠습니다.
1	Gpu를 사용하고 있는지 확인하는 방법이 있을까요?? 속도가 빨라지는지 잘 모르겠습니다.	1	터미널에서 watch nvidia-smi 하셔서 점유율 체크해보시는게 제일 빠릅니다.
20	GTCx 2016 키노트에 대한 간략한 설명이 올라왔네요
200	아주 잘 쓰여진 간단하게 보는 텐스플로우인데 코드만 쓱 봐도 이해가 될정도입니다. 입문하시는분들 한번 보시면 좋을듯.1. https://medium.com/@camrongodbout/tensorflow-in-a-nutshell-part-one-basics-3f4403709c9d#.kxl6ftnfp2. https://medium.com/@camrongodbout/tensorflow-in-a-nutshell-part-two-hybrid-learning-98c121d35392#.t7vgyxvjd3. https://hackernoon.com/tensorflow-in-a-nutshell-part-three-all-the-models-be1465993930	1	전에 약 한달간 텐서플로어를 공부했었는데요..이때 손글씨 숫자(mnest?)를 인식하는 것을 여러가지 연습했습니다이때 생각난 아이디어는1) 윤관선을 추출 하면 인식률이 더 좋을 것이다.간단한방법은 특정 손글씨 숫자의  raw 데이터에서 윤곽선을 뽑아내는 것입니다.즉. raw 데이터의 첫줄 첫 데이터와 두번째  데이터를 빼거나 더해서 값을 구하고. 다음은 두번째와 세번째에 대해서 동일 하게 자업을 해서 마지막까지해서새로운 데이터 매트릭스를 만들고,또한 이번에는 첫줄 첫데이터와 두번째줄 첫 데이터를 빼거나 더해서 그 옆데이터도 동일하게 작업을하여 raw데이터 매트릭스만들고,또한 첫줄 첫 데이터와 두번째줄 두번째 데이터를 빼주거나 더하고 옆 데이터도 같은방법으로 하여 매트릭스만들어서이들 세개의 새로 만든 raw 데이터를 앙상블로 처리를 하면 인식율이 증가할 것으로 보입니다..저는 바빠서 실행은 못해보았습니다..2) raw 데이터를에서 오픈cv로 운곽선을 뽑아내어 이를 확습하면 숫자에 대한 인식율이 좋아질 것으로 생각했습니다..물론 이미지 데이터에서도 동일하게 윤곽선 데이터를 만들어 학습을 시키는 것이 인식율에 도움이 될 것으로 생각합낟.
2	안녕하세요 질문이 있어서 이렇게 여쭤봅니다.먼저 제 데이터는 우선 training set이 약 2만개 데이터, validation이 4천개 데이터로 구성되어 있습니다. 데이터를 총 27가지 class로 분류하는 무넺를 해결하려고 하고 있구요.Data 초기값은 normal distribution으로 random하게 하였고,DNN은 10개의 hidden layer로 각 500개의 node로 구성하여 테스트하였습니다.데이터가 많지 않아 training cycle은 100~2000까지도 수행되고, 어느정도 cost는 수렴하는 것 같습니다.training 후 validation set으로 검증했는데 정확도가 너무 낮게 나와서 (약 18%)나와서 training한 데이터로 예측해보니 정확도가 거의 0에 가깝게 나왔습니다. 이것저것 테스트를 하다보니 dropout을 여부에 따라서 accuracy가 달라지는 것을 확인하였는데, dropout을 0.99까지해도 위와 같은 증상이 보였으며, 아에 사용하지 않도록 하니 그나마 validation set에서 정확도가 44%중반, training set은 98~99%까지 나오는 것을 확인하였습니다. 실제 데이터로 처음 겪는 문제라 조언을 해주시면 감사하겠습니다.참고로 이 문제를 random forest로 테스트하였을 때 정확도가 76%정도 나왔습니다.	0	dropout은 DNN이 training set에 overfitting하지 않도록 regularize 하는 용도인데 validation에서 dropout layer를 활성화 하는 이유가 있나요?	0	Initialization 방법을 바꾸니 정확도가 85%로 올라가고 문제가 해결되었습니다. 좀 더 최적화해봐야겠네요.	0	궁금해서.. 그런데요...랜포 에 나무 몇그루 심으셨나요??	0	training set과 validation set에서 데이터 비중은 어떻게 하셨나요? 그 둘에서 데이터 비중이 맞게 학습하면 좀더 학습이 잘된다고 들었습니다.
1	GTX 1070 사용하시는 분 계신가요?? GTX 1080 가격이 부담스러워서 1070으로 살짝 내려볼까하는데,궁금해서 글 남겨봅니다 ^^;	0	GTX1070 사용 유저에요. 근데 질문이 뭐에요? TensorFlow는 우분투 16.04에 쿠다, cudnn모두 최신버젼으로 (텐서플로우는 소스버젼에서 설치) 잘 사용중요	0	14에서는 960으로 했었고.. 1070 또는 1080으로 가려면 쿠다 8.0이상이어야되고(파스칼 아키텍쳐 여기부터 지원) 최신버젼이어야합니다. 그런데 드라이버가 제가 찾은건 우분투 16.04지원되고 이전은 모르겠네요. 제가 틀린것일수도 있어요.	0	저도 궁금하네요. 너무 비싸서 충격받았습니다...
21	Deep Learning 기반 자율주행에 관한 코딩을 전문적으로 다루는 채널실무 엔지니어들에게는 많은 도움이 될 듯 합니다.
5	[스터디원 모집 ] 뉴로알파 : 파트 1 매주 월, 판교, 저녁 7시 30분 ~ 10시. 10/17 시작.* 이벤트 링크 - https://www.facebook.com/events/526221380915900/Dongwan Kim님이 진행하는 스터디입니다.-------------------[Neural Networks + alpha 스터디 / 월요일|판교] 오래전부터 있던 강의이긴한테 이번에 제프리 힌튼 교수님의 Neural Network 강의가 다시 시작되네요. 이 강의를 베이스로 하고, Introduction to Statistical Learning 정도 코스를 같이 붙여서 스터디를 진행해 보고 싶은데요.(참여하시는 분들 관심사에 따라 세션 구성은 물론 변동 가능합니다.) 판교에서 월요일에 진행하는 스터디! 관심 있는 분 알려주세요^^	1	https://www.coursera.org/learn/neural-networks
80	http://blog.naver.com/atelierjpro/220830743694일단 컴파일하고 예제 실행까지	0	대단하시네요. 많은 도움이 될듯 합니다.	1	와 감사합니다. ㅎㅎ	1	와.. 교수님. 멋지십니다.	1	.whl 만드는 부분 성공하신 분은 꼭 공유해주세요!	1	헐.. 고생 많으셨네요...	0	크	1	.whl 생성 및 windows python에서 import확인했습니다. 시행착오 전부 기록해 두었습니다.
33	어제, 오늘 Nvidia GTCx KOREA 2016에 다녀왔습니다오늘 있었던 conference에서 들었던 session들에 대해서 아주아주 간략히 요약해 두었는데, 혹시 관심있으신 분들이 있을까 하여 공유합니다다만 제 개인 페이지에 올린 글이다보니 개인적인 내용이 다소 들어있음을 양해 부탁드립니다	0	요야갓
2	Our Special Session listed below has been provisionally accepted for IJCNN 2017 <http://www.ijcnn.org/paper-submission>.At least six high-quality submissions (the deadline for submissions is November 15th, 2016) must be accepted in order for IJCNN 2017 to include your Special Session in the final program. Please consider to submit your paper to this Special Session if you do research in Business Analysis:1.     Title of Special SessionMachine Learning for Business Analytics2.     Brief descriptionWith the speedy proliferation of cloud usage and popularity, business models such as multimedia streaming services, commercial software, and games are available online more and more. For the sake of the online interactions of customers, enterprises easily access user behaviors and deal with behavioral or financial business analytics. For instance, enterprises are able to collect how often customers visit the service websites, how long customers stay their websites, when they start actual paying customers, and how many services customers order and so on. Developing machine learning methods to recognize customer behavioral patterns, understand business leakage of the products, classify potential customers, evaluate the current business models, and eventually propose key marketing area, strategic business marketing, or cognitively suggest the next business models to help the business growth revenue and reduce excess lose. This present big challenges to business analysis because of (1) heavy customer traffic flows, (2) the noise in user behaviors, (3) class imbalanced customer data (few paying customers vs. high numbers of freemium or trial customers), and (4) unpredictable business environments like highly sparse and dynamic. 3.     Related topics·     Modeling customer retention and churn management·     Modeling personalization and recommendation systems·     Advanced techniques for various Customer Relationship Management (CRM) functions·     Scalable techniques for big customer data·     Modeling cognitive business decisions·     Modeling potential sales lead prediction
4	안녕하세요. 텐서플로우로 머신러닝을 시작한 초보 개발자입니다.테스트로 학습을 돌리면서 궁금한게 생겨서 질문 드려요! 기초적인 부분일 수 있으나.. GPU 쪽은 아예 몰라서 질문 드립니다 ㅠ 제가 사용하는 PC 환경은 Ubuntu 16.04 / GTX1080 2개CUDA8.0, cudnn v5.1 로 세팅완료했습니다.CUDA 에는 SLI 가 적용 안된다? 라는 글을 보았는데. 지금 하드웨어상에는.. SLI 연결선 으로 추정되는 선이 두 그래픽카드에 연결되어 있습니다.이 선이 있고, 없고의 차이가 학습상에서 있을까요..? 제가 한번 뽑아보고 돌려보면 되긴 하지만..혹시 아시는 분은 알려주시면 정말 감사하겟습니다 :)	1	차이 없습니다. (꼽혀있다고 손해보는건 없으니 그냥 놔두셔도 무방합니다.)	1	CUDA는 SLI를 사용하지 않기 때문에 TensorFlow 및 CUDA를 사용하는 각종 ML 프레임워크 사용시에 SLI 연결선의 유무에 따른 성능 차이는 없지 않을까 싶습니다.그리고 SLI는 설정으로 On/Off 가능합니다. Ubuntu의 경우에는 sudo nvidia-xconfig --sli=off 이런 식으로 할 수 있습니다. reboot 해야 적용되는지 정확히 모르겠네요.	0	차이 없습니다.
5	[스터디원 모집] FinAlgML : ai finance  (파이썬 머신러닝을 이용한 금융투자 스터디)* 이벤트 링크 - https://www.facebook.com/events/228688647546478/* 매주 금요일, 저녁 7시 30~10시. 강남. 회비없음* 이 스터디는 계산금융 스터디 그룹, Ai Finance에서 진행합니다.공지가 너무 늦었습니다. 오늘 시작하네요. 괜찮습니다 자유롭게 참석해보세요. 파이썬, 딥러닝, 금융 공부를 합니다~------------------------장소 : 강남 토즈 타워점 (강남역 1번출구) 위치 : 02-3454-0116 서울 강남구 강남대로84길 24-4시간 : 2016년 10월 07일 금요일 오후 7시30분 ~10시 Ai Financehttps://www.facebook.com/groups/1707727306150009/싸이지먼트https://www.facebook.com/groups/psygement/### 내용 : - (논문초록+tensorflow code review) Classification-Based Financial Markets Prediction Using DNN- (Quantopian) VaR and CVaR - The loss to which you are exposed - (Standford cs231n) 14장 Unsupervised Learning=================분야=====================1) 논문초록 + 텐서블로우 코드 리뷰 - tensorflow 101 https://github.com/sjchoi86/Tensorflow-1012) 퀀트접근 : Quantopian - Tutorial and Best Algo reviewhttps://www.quantopian.com/lectures http://blog.quantopian.com/fundamentals-contest-winners/3) 기계학습 Book : Python Finance and Machine Learning - Python Machine Learning : https://github.com/rasbt/python-machine-learning-book- Mastering Python for Finance : https://github.com/jamesmawm/Mastering-Python-for-Finance-source-codes- 이벤트 링크 - https://www.facebook.com/events/228688647546478/	0	https://www.facebook.com/groups/1707727306150009/	1	사전신청없이 참석 가능한가요?  오늘 처음 봤습니다.	0	네, 그냥 자유롭게 찾아오시면 됩니다~	1	오늘부터 하는거였군요. ㅜㅜ 다음주 부터 참석해도 되나요?	0	네, 중간에 언제든 참여하실 수 있습니다~
128	안녕하세요. 가끔 TensorFlow 코드를 공유했던 김태훈입니다.제가 현재 학사 병특 중인 데브시스터즈에서 함께 일할 머신러닝 엔지니어를 찾고 있습니다. 저희 팀의 업무는- 딥러닝과 강화 학습으로 사람을 뛰어넘는 AI를 만드는 문제- Kaggle과 같은 대회에서의 노하우를 바탕으로 유저 행동 예측과 어뷰저 검출- 여러 agent가 오랜 시간 동안 상호 작용을 하면서 언어를 만들고 복잡한 목표를 달성하는 문제- 최신 머신러닝 연구 스터디 및 직접 구현이며, 현재는 강화 학습과 관련된 문제를 해결하는데 집중하고 있습니다. 하지만 프로젝트가 마무리 되면 NLP, Computer vision 등 다양한 분야의 흥미로운 문제를 찾아 해결하고자 합니다.병특임에도 불구하고 제가 원하는 일을 자유롭게 정할 수 있고, 압도적인 복지(쉐프의 요리, 수면실, 외국어 수업, 사택 지원 등)와 지원으로 머신러닝 문제에 집중할 수 있습니다. 저희 팀과 함께 세상을 바꿔나실 분들은 주저하지 마시고 연락주세요!지원 방법 : http://www.devsisters.com/jobs채용 문의 : career@devsisters.com지금까지 10개가 넘는 논문들을 TensorFlow로 바닥부터 구현하면서 팀의 실력을 키우고 있습니다. 아래에 저희 팀의 외부 발표자료 및 오픈소스로 공개한 코드들을 공유합니다.- 텐서플로우 설치도 했고 튜토리얼도 봤고 기초 예제도 짜봤다면 http://www.slideshare.net/carpedm20/ss-63116251- 지적 대화를 위한 깊고 넓은 딥러닝 http://www.slideshare.net/carpedm20/pycon-korea-2016- 강화 학습 기초 http://www.slideshare.net/carpedm20/reinforcement-learning-an-introduction-64037079- TensorFlow의 Deep Q-network의 구현 https://github.com/devsisters/DQN-tensorflow- TensorFlow의 Deep reinforcement learning 논문들의 구현 https://github.com/carpedm20/deep-rl-tensorflow	3	정말 멋진팀 같습니다. 많은 좋은 분들이 지원하면 좋을듯 합니다.	0	좋은 기회네요.. 많은 젊은이들이 지원하시길...	0	재밌겠네요.^^ 경력도 받아주나요? ㅋㅋㅋ	0	진짜 탐나는 기회네요~!	0	히트작 쿠키런을 만든 회사인가봐요!
14	PyData Carolinas 2016 <http://pydata.org/carolinas2016/> 에서 발표했던 Recommendation-Systems-for-Implicit-Feedback with PySpark 구현 자료를 공유합니다. Spark with Python + Recommendation 에 관심 있으신 분들은 참고 하세요.https://github.com/csung7/Recommendation-Systems-for-Implicit-Feedback/tree/master
25	어제 NVIDIA training lab에 참가했습니다. 마지막 세션에서 GPU inference engine을 소개했는데 trainig은 복잡한 네트워크에서 하고 inference 할때는 몇개의 layer를 합쳐서 inference time을 줄일수 있다고 하네요. 임베디드 장비에 올릴때 효과적일거 같습니다. 관련 논문들도 있다고 하니 찾아봐야 겠네요.
1	질문하나 드려도 될까요. binary classification을 하는 문제를 logistic regression으로 풀고 있습니다. 아래처럼 정의를 했고요. x = tf.placeholder("float", [None, n_input])w = tf.Variable(tf.random_normal([n_input,1]))b = tf.Variable(tf.zeros([1]))y = tf.placeholder("float", [None,1])계속 돌리는데 training이 안됩니다. 그런데 문제가 뭐일까 하나 하나 체크하는 과정에서 발견했는데 activation이 너무 1에 가깝게 되서 log(1-actv)에서 무한대 값이 나와서 cost값이 Nan이 나와서 문제가 생기는거 같은데 혹시 이런 문제를 해결하신 분이 있으시면 조언 부탁드립니다. 참고로 Initialization은 init = tf.initialize_all_variables() 로 했습니다. 감사합니다.	0	http://stackoverflow.com/questions/35277898/tensorflow-for-binary-classification 이거 참조하세요.  (The simplest would be to set NLABELS = 2 for the two possible classes, and encode your training data as [1 0] for label 0 and [0 1] for label 1.) 이 방법이 적용하기 쉬울듯 합니다.	0	http://stackoverflow.com/questions/24894231/what-activation-function-to-use-or-modifications-to-make-when-neural-network-giv	0	어떤 내용의 데이터와 목적은 어떤것인가요?	0	입력값이 정규화되어 있는지? w 초기값이 충분히 작게 설정되어 있는지? (랜덤으로 생성해도 feature가 많을경우는 연산 결과가 1에 가까운 경우가 많습니다)	0	learning rate값을 줄여가면서 nan이 안나는 값을 찾아 보세요  batch_size를 1로 했을때 cross entropy가 어떻게 바뀌는지도 확인해 보시구요.
6	안녕하세요. 텐서플로와 관련해서 질문이 있어서 글 작성하였습니다. confusion matrix 를 구해서 클래스 별 인식 성능을 분석하고자 하는데요. http://stackoverflow.com/questions/35365007/tensorflow-precision-recall-f1-score-and-confusion-matrix이 사이트를 참고하여, 결과에 대한 confusion matrix를 계산하였습니다. test 할 때 sess.run으로부터 구한 인식률 값과 confision matrix의 대각성분들의 평균 값이 일치하지 않네요. 해당 사이트 말고도, 텐서플로를 사용하면서 confusion matrix 를 구하는 방법이 있을까요?	0	https://www.tensorflow.org/versions/r0.10/api_docs/python/contrib.metrics.html#confusion_matrix
1	안녕하세요. FCNN으로 데이터 classification을 하고 있는데 어렵네요. NN 구조를 잡을 때 가이드 할만한 경험적인 규칙이 있을까요? input / output의 개수에 따라 hidden layer의 개수 / 각 layer의 node 개수같은.. activation function을 선택하는 것도 어렵구요.. 맨땅에 헤딩하고 있는 것 같습니다 ㅎㅎ
38	안녕하세요. TensorFlow KR 계신 분들 중, 신세계그룹 온라인 포털 SSG.COM BigData 팀 공개채용(신입) 관심있으신 분들 계시면 도전해 보시라고 정보 공유 드립니다. 제가 속한 팀이고, 저 또한 면접관들 중 한명입니다. 오랜만에 BigData팀에서도 신입들을 여럿(?) 뽑게 되었으니, 머신러닝 및 딥러닝을 사랑하시는 분들의 많은 도전 부탁드립니다. 참고로 저희가 주로 사용하는 머신러닝 & 딥러닝 프레임워크는 Spark ML , Mahout , Anaconda , Tensorflow 등 입니다. 기타, SparkR 및 RevolutionR(MS R) 도 일부 사용하고 있구요. 다양한 BigData 전처리에 있어, 약 20종의 BigData Eco System( Hadoop, Spark, NoSQL 등)을 활용하고 있습니다. (10월 6일까지로..좀 시간이 촉박합니다.)채용정보: http://job.shinsegae.com직무정보: http://job.shinsegae.com/job_intro/department/department02_0600_3.jspps. 이마트 또는 신세계 지원 후 지원직군 입력 시 S/W Development(e-커머스)을 선택하시기 바랍니다. 선택법인과 무관하게 위 직군들은 SSG.COM 으로 분류 됩니다. 세부분류는 서류전형 합격 이후 지원 하게 됩니다.	0	우선석사를졸업하고 지원해야겠군요ㅎ	0	모두 경험한 분을 뽑는건 아닙니다. 신입채용이니까요. 저희도 평가할때 빨리 두루 경험한 분들 보다는 길게보고 현재보다 더 성장 발전가능한분들에게 더 높은 점수를 줄 예정입니다.	0	박사졸업자도 신입채용 지원이 가능하려나요 ㅎㅎ;; 컴공출신은 아니고 입자물리학실험이어서 ㅎㅎ;;	0	내 지원하시구요. 채용 이후 인사팀에서 별도의 경력산정 논의를 할것입니다.	0	다시 보니까 서류전형시 세부분류도 미리하네요. BigData 개발팀 입니다 ^^.
7	혹시 최근 구글이 발표한 Show and Tell(https://research.googleblog.com/2016/09/show-and-tell-image-captioning-open.html)  관련해서 github(https://github.com/tensorflow/models/tree/master/im2txt)에서 im2txt 소스 받아서 테스트 해 보신 분 계실까요?Ubuntu 16.04, Python 3.5.2, TensorFlow r0.10 환경에서 진행중인데, 아래 단계에서 에러가 발생합니다.# Run the preprocessing script.bazel-bin/im2txt/download_and_preprocess_mscoco "${MSCOCO_DIR}"에러 발생 로그는 아래와 같습니다.혹시 트레이닝 해보신 분 있으신가요?디버깅해보니 에러나는 부분에서 이미지 메타데이터는 정상적으로 가져오는 것 같습니다.여러 에러가 거의 동일 합니다.Exception in thread Thread-15:Traceback (most recent call last):  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner    self.run()  File "/usr/lib/python3.5/threading.py", line 862, in run    self._target(*self._args, **self._kwargs)  File "/home/simplexi/.cache/bazel/_bazel_simplexi/fb24e009c029e33e77ab62feb6c3c3a2/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py", line 278, in _process_image_files    sequence_example = _to_sequence_example(image, decoder, vocab)  File "/home/simplexi/.cache/bazel/_bazel_simplexi/fb24e009c029e33e77ab62feb6c3c3a2/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py", line 214, in _to_sequence_example    encoded_image = f.read()  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/gfile.py", line 45, in sync    return fn(self, *args, **kwargs)  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/gfile.py", line 199, in read    return self._fp.read(n)  File "/usr/lib/python3.5/codecs.py", line 321, in decode    (result, consumed) = self._buffer_decode(data, self.errors, final)UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte	3	자문자답입니다.Python 3.5 환경에서는 해당 에러로 진행하기 어려웠습니다.결국 Python 2.7 환경에 맞추어 작업할 경우 문제 없었습니다.Ubuntu 16.04에서 Tensorflow r0.11 설치하여 트레이닝 중이고요.PIP3를 8.1.1 버전에서 8.1.2버전으로 업데이트 하는 순간,/usr/local/bin/pip 에 첫번째 줄이 아래와 같이 변경됩니다.#!/usr/bin/python3위와 같은 부분을 아래와 같이 수정하면 다시 2.7버전으로 사용가능하게 할 수 있습니다.#!/usr/bin/python2버전에 맞게 NumPy, NLTK 함께 pip로 설치하면 정상 동작됩니다.혹시 pip3 업데이트로 인하여 pip(2.x) 버전 못 쓰시는 분은 참고하세요.	0	꿀팁 감사합니다!!
6	*Deep learning boosts Google Translate tool*
1	안녕하세요. 혹시 예제 주위로 되어있는 서적이 있을까요? 머리가 안 좋다보니 이론만보기에는 응용이 불가능하네요.... 공부 좀 열심히할 걸....................... 한국어 서적이면 좋겠습니다.좋은 하루 되세요. ^^	0	텐서플로 첫걸음 외엔 국내서적은 못 본것 같아요.	0	예제 위주면 tensorflow.org의 Tutorial과 How to 부분으로도 충분하지 않나 싶습니다.	0	늦게 봐서 죄송합니다! 다들 답변 감사드립니다.
6	혹시 Ubuntu 16.04 OS에서,pip3(python3.5) 업데이트 이후,pip(python 2.7) 동작 안되시는 분들 계실까봐 관련 정보 남깁니다.문제 발생 시점 : $ sudo pip3 install --upgrade pip - 8.1.1 버전에서 8.1.2 버전으로 업데이트 됩니다.문제 발생 : $ /usr/local/bin/pip - 이 파일의 첫 줄이 #!/usr/bin/python 에서 #!/usr/bin/python3 으로 변경됨.문제 수정 : #!/usr/bin/python3 → #!/usr/bin/python 수정Python 2.7과 Python 3.5는 혼용 가능하며, 각각의 버전에 따라, Tensorflow github 소스코드를 Bazel의 .configure 할 때,Python Path 설정 맞추면 버전에 맞게 wheel이 생성됩니다.해당 wheel을 pip install xxx(python 2.7), pip3 install xxx(python 3.5)하시면 두 버전 모두 사용이 가능합니다.참고로 tensorflow r0.11 버전에서는 GPU CUDA 및 cuDNN 버전을 wheel 만들기 전에 지정할 수 있는 메뉴가 나오기에 좀 더 편리하게 세팅해서 만들 수 있는 것 같습니다.추가로 혹시 pip3 업데이트 하는 방법 더 스마트한 방법 있다면 공유 부탁드립니다.
28	텐서플로우 기반 ML Training/Prediction 플랫폼인 구글 클라우드 ML이 퍼블릭 베타 릴리즈 되었습니다.
5	[스터디원 모집] 알파로우 : 파트 1- 법 + 머신러닝 스터디 (+Python)* 2주에 한 번, 화요일 저녁, 7시 - 10시 30분, 강남, 무료(유료공간 이용료 각자 결제, 1회 3천 500원)* 계산사회과학 스터디 그룹, 싸이지먼트에서 진행합니다.완전 기초부터 시작하며(법, 딥러닝 자연어처리, 텐서플로우 양쪽 다) 누구나 함께 하실 수 있는 취미 모임입니다. 참여를 원하시면 이벤트에서 참석을 누르시거나, 댓글을 다시거나, 바로 찾아오시면 됩니다.	0	https://www.facebook.com/groups/psygement/	0	http://cs224d.stanford.edu/index.html
3	[스터디원 모집] 싸이무비 : 파트 2 (+ 딥러닝을 이용한 비디오 카탈로깅)- (새로 추가된 것) 딥러닝을 이용한 비디오 카탈로깅- (기존) 성격심리학 + video 도메인에서의 딥러닝 paper 리뷰 + (파이썬) 텐서플로우 코드리뷰* 2주에 한번 금요일, 저녁 7시 - 10시 30분. 강남, 회비없음(유료공간비 1회 3천 500원 각자 계산)* 이벤트 링크 - https://www.facebook.com/events/182810495490234/* 이 스터디는 정통심리학그룹 싸이그래머에서 진행합니다.영화 도메인에서 딥러닝과 성격심리학을 결합하여, 인물과 사건의 주요한 부분들을 파악하려는 싸이무비 스터디가 어느새 파트2로 넘어갑니다. 전문가 모임이 아닌 취미 모임입니다. 누구나 함께 하실 수 있습니다. 참여를 원하시면 이벤트 링크를 통해 참여를 누르시거나 댓글을 달아주시거나, 해당 장소로 바로 찾아오시면 됩니다.-------------------(새로 추가된 것) 딥 비디오 카탈로깅* 파트1에서는 실습에서는 파이썬 패키지로 기본적인 비디오/오디오 신호처리를 해보았다면, 이번에는 비디오 카탈로깅이라는 영역에서 기존에는 어떻게 접근했고, 요즘엔 딥러닝으로 어떻게 접근하는지 비교해보려 합니다. 기존 기법들이 나온 책 + 요즘의 논문 리뷰로 구성됩니다.(기존에 이어서)  * 성격심리학 - 뉴로이미징을 이용한 성격심리학 최신 연구를 스터디 합니다. / 더해서 컴퓨터 공학쪽에서 음성신호에서 성격 모델링을 하려는 시도들을 살펴봅니다.* 딥비디오 - Video 영역의 최신 딥러닝 페이퍼들을 리뷰합니다.* 텐서플로우 코드 리뷰 - 멀티미디어 데이터 영역에서 텐서플로우로 작업된 코드들을 리뷰하고 돌려봅니다.	0	새로 추가된 교재 : Video Cataloguing: Structure Parsing and Content Extraction - https://www.amazon.com/Video-Cataloguing-Structure-Parsing-Extraction-ebook/dp/B0169UYCEO
36	인공지능 위해-아마존, DeepMind-구글, 페이스북, IBM, MS. 단체 설립- AI기술로 사람과 사회에 도움이 되기 위해 기회와 과제를 해결하는 것
1	안녕하세요. cpu모드에서 샘플만 학습시켜보다가 gpu모드로 tensorflow를 돌려보려고하는데, 지포스 970 정도면 많이 느릴까요? 800 x 600 컬러 이미지 1400 장 정도 학습시켜보려고 합니다! 혹시 지포스 970 그래픽카드 사용해 보신분 계시나요..?	3	980레퍼 사용자 입니다. 무엇을 상상하시건 그 이상으로 빠르고 덥습니다..	0	970가지고 계시다면 직접 테스트해보시는게 좋고, 새로 구입하실것이라면 1060쪽이 더 싸고 빠릅니다. 참고로 970은 메모리 3.5G + 0.5G 분할 이슈가 있어서...한번 검색해 보세요
6	# 싸이지먼트 - 마켓On 9.30 스터디 후기지난번 스터디원 모집글을 올렸기에 1회차 후기까지만 남깁니다^^ 어제도 즐겁게 마켓On스터디를 했습니다~!ㅎㅎ마켓온 파트3는 마케팅분석에 필요한 자연어처리..그것도 Deep!한 자연어처리를 목표로 하고있기 때문에 일단 자연어처리에 필요한 텍스트를 모으는 것부터 시작하고 있습니다. 파트3 시작전에 자연어처리에 대한 기초를 학습하는 시간이어서 새로운들이 많이 오셨습니다. 그분들을 보면서 역시 "공부는 죽을때까지 해야하는구나" 다시한번 마음속에 깊이 새겼습니다.먼저 조용인님이랑는 저(김성근)는 지난주 파이썬으로 웹에서 텍스트데이터를 크롤링해오는 임무를 부여받았고 정태승님께서는 자연어처리에 중요한 부분인 형태소 분석 부분을 준비해오기로 하셨습니다. 정태승님은 워낙 능력이 출중하시기 때문에 MAB까지 발표를 준비해오셨습니다^^먼저 저랑 조용인님은 각각 한글, 영어 텍스트를 크롤링하되 제품리뷰와 사용자 데이터가 가장 잘 정리되어있는!! 화장품 사이트를 크롤링해왔습니다.저는 makeupalley.com이라는 싸이트를 크롤링했습니다. 사용자의 리뷰 뿐 아니라 나이, 피부타입, 눈색상, 개인별 평점, 재구매의향 등 다양한 데이터를 함께 크롤링할수 있는 사이트입니다. 파이썬의 beautifulsoup패키지를 활용해서 크롤링을 하던중...일부태그가 클롤링이 되지 않아..크롤러를 완성하지 못한채 스터디 발표를 했습니다만, 완성되지 않은 이유 정태승님께서 정확하게 짚어주셨습니다 html태그에 comment 클래스에 리뷰가 있었는데.. 제가...comment의 m을하나 빼먹고 coment라고 쳤더군요...^^;;; 이어서 조용인님께서는 한글로 된 화장품사이트를 크롤링하셨는데..미샤를 크롤링 하시려다 어려워서 이니스프리 사이트로 바꿔서 크롤링하셨습니다^^ post방식으로 되어 있어 url이 바뀌지 않고 화면이 전환되는 것을 깊게 파고 들어 결국 내부에서 url이 바뀌는 패턴까지 찾아내셨으나...알아낸 url을 기존 url에 연결할때 &로 연결했더니 안돼서 크롤러를 완성하지 못한채 오셨지만!! 정태승님께서 ?로 url을 연결하라고 알려주셔서 크롤링을 해보니 되는것을 확인하였습니다. 그렇게 저와 조용인님의 허당 발표가 마무리되었습니다.이어서 정태승님께서 텍스트 자료에 형태소를 태깅하는 내용에 대해 발표해 주셨습니다. nltk패키지에 brown코퍼스를 주로 활용한 예재를 발표해주셨습니다. 대부분의 내용이 형태소 태깅에 대한 내용이었으며, 파이썬이 왜 R보다 자연어처리에 강력하다고 사람들이 말하는지 실감 할 수 있었습니다. 기본적인 태깅방법, 태그와 단어를 확이하는 방법등을 설명해주셨고, 바이그램, 트라이그램, N그램 등을 활용해 형태소를 태깅하는 모델을 만들어 brown코퍼스에 기존에 태그와 정확도를 비교하는 내용이 있었습니다. 마켓온 스터디에서 통계전공자 그룹과 개발자그룹이 있습니다, 정태승님께서 파이썬부분에서 저희가 막힐때 항상 저희를 잘인도해주고 계셔서 ㅎㅎㅎ든든합니다!!ㅎㅎ마지막으로 MAB(멀티암드밴디트)발표를 정태승님께서 해주셨습니다. MAB는 웹사이트 최적화기법 중 하나입니다. 새로오신분들이 많아서 MAB가 뭔지 그리디 알고리즘과 몬테카를로 시뮬레이션 등 지금까지 공부해온 내용에 대해서 정태승님께서 전체적으로 설명해주셨습니다. 원래 발표하실 부분은 소프트맥스 알고리즘이었는데 전체적인 설명을 해주시느라 시간이 없어서 소프트맥스 부분은 간략하게 파이썬 코드로 설명해주셨습니다. 제가 코드에 대한 이해력이 딸려서..정확히는 모르지만....딥러닝에서 나왔던 소프트맥스 알고리즘과 같다면 여러가지 대안들중 어느것이 가장 좋은 성과를 가져올수 있는지에 대한 확률을 구하여 가장 확률이 높은 대안을 선택하는것이 아닐까 조심스레 예상해봅니다..ㅎㅎㅎ다음주부터는 파트3이 시작됩니다! 본격적인 마케팅 딥러닝 NLP의 세계로 다함께 가시죠~!! 참여는 언제나 누구나 가능합니다!!
54	다시 정리하고 있어요	1	마침 공부해서 사용해야 하는 라이브러리들이었는데 좋은 자료 올려 주셔서 즐겁게 공부중입니다. 평소에 다른 파이썬 슬라이드들도 잘 보고 있습니다. 감사합니다! :D
57	새로운 구글 번역기를 오픈했다고 하네요. 딥마인드의 기술을 사용했다고 합니다.http://arxiv.org/pdf/1609.08144v1.pdfhttp://www.msn.com/ko-kr/news/techandscience/%EA%B5%AC%EA%B8%80-%EC%9D%B4%EC%84%B8%EB%8F%8C%EA%B3%BC-%EA%B2%A8%EB%A3%AC-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%ED%99%9C%EC%9A%A9-%EB%B2%88%EC%97%AD-%EC%8B%9C%EC%9E%91/ar-BBwIRHP?li=AA523o&ocid=spartandhp	0	몇몇 언어에서는 기계가 한건지 사람이 한건지 구분이 어렵다고 하네요. ㅎ	2	중국어에 먼저 적용되기 시작했다고 하던데 평가가 나오고 있습니다.http://qz.com/795446/quartz-has-tested-googles-goog-new-ai-powered-translator-and-it-needs-to-learn-more-chinese/일상적인 언어는 잘되고 학술문장이나 시는 아직 잘 안된다는 이야기인데 일상 대화나 이야기는 잘 된다는 것에 주목할만한것 같습니다.
59	텐서플로우 윈도우버전이 나와서 드디어 멀티부팅으로 설치했던 우분투를 지웠습니다. 지우는건 한순간이네요기존에 2.7버전으로 쓰던 파이썬도 이참에 3.5버전으로 업그레이드 했습니다.(윈도우용 텐서플로우가 3.5버전만 지원해서...)대략적인 순서는-아나콘다 설치-cuda설치-cudnn설치-아나콘다 실행후 pip명령어(pip install tensorflow-gpu)로 설치하고 예제 돌려보니 잘 돌아가네요윈도우라그런지 우분투보다는 확실히 설치하기 쉽습니다.CPU버전의 경우에는 cuda 및 cudnn설치과정이 생략되니 훨씬 쉬울것입니다.또한 저는 GTX950을 사용중인데, CUDA 8.0버전도 잘 되네요	0	아나콘다라는게 그냥 여러 패키지들이 들어있는 집합체라고 보면 되나요??	2	윈도우7은 안되죠?	0	저도 지워야 할듯. 이러다 모두가 텐서플로우 쉽게하는 세상, 초딩도 딥러닝 하는 세상이 오는건 아닌지	0	좋은소식감사합니다!!매번 리눅스로가야되나 고민하며 얼른 프로젝트정리중이였는데 고민할필요가없어졌네요구굴신의 텐서플로우님 드디어영접해보러가야겠네요	0	꿀정보 감사합니다! 왔다갔다 힘들었는데 ㅜ	0	우분투 때문에 고생하고 있었는데, 잘 되었군요. 저도 지워버려야겠네요.ㅎ	0	어떻게 안전하게 우분투 지우는지 방법 좀 알려주세요~	0	노트북 스펙이 어떻게 되시나요?	0	아나콘다로 설치했더니 아나콘다 환경 외에서는 실행이 안되는건가요? visual studio 로 파이썬프로젝트 만들어서 하는데 import 부터 안되네요 ㅠㅠ	0	오오오오
0	Looking for MSc programmes in #DataScience & #BigData with a Spring 2017 entry?Data ScienceTech Institute, with leading international partners such as SAS Software & Amazon Web Services or GE Digital and programmes listed by the French Government via Campus France under its prestigious "Programmes taught in English" for "Mathematics" and "Engineering and Technology", is happy to receive your application!https://www.datasciencetech.institute/Campus France:http://taughtie.campusfrance.org/tiesearch/#/catalog?mfid=7http://taughtie.campusfrance.org/tiesearch/#/catalog?mfid=4
0	갑자기 궁금해서 질문 올립니다.노트북에다가 Ubuntu OS설치 후 Tensorflow기반 프로그램을 수행하는것은 위험한 생각인가요??노트북에 장착하는 GPU와 데스크탑에 장착하는 GPU는 같은 이름이면 성능이 어느정도 차이를 보이는지 알고싶습니다.	0	1. 가능합니다 2. 8xx 9xx 라인업의 경우 50~60% 10xx 라인업의 경우 80~90% 정도 입니다. (모바일 버전이 없기때문)	0	전혀문제 없습니다. 직접 노트북 980m 1년전에 산거 잘 쓰고 있고요. 현재 가성비 지피유 노트북 중에는 한성이 젤 난거 같습니다.	0	에일리언웨어(970M)에서 돌리고 있습니다. 생각보다 성능 빠방합니다. 비행기 소리가 좀 나는거같지만 기분탓이겠죠	0	Dell 인스피론 15 5779 로 돌리고 있습니다...960m이에요. 물론 데스크탑보다 많이 힘들어합니다.
72	엔비디아 딥러닝 컨테스트 대회 참가 목적으로 이미지 파일을 numpy 바이너리로 변환하고텐서플로우에서 쉽게 사용할 수 있게 작성하였습니다. 혹시 필요하신 분들이 있을까 해서 음식이미지 데이터셋을 공유합니다.엔비디아측과 Food 101측에는 동의를 받은 상태입니다.감사합니다.	0	어라, 혹시 여쭤보는데 딥러닝 컨테스트 대회 끝나지 않았나요(?)	1	좋네요. 담에 저걸로 쉽게 돌려 볼 수 있겠습니다.
17	Window 10에 TensorFlow GPU 설치해서 김성훈 교수님 강의에서 구현한 CNN, MNIST 돌려보니 I7보다 빠르긴 하네요. 제가 쓰는 그래픽 카드가 GTX 745 (OEM)이라 그런것 같지만..AWS EC2 K520 4개로 한거랑 비교한 결과랑 설치법 관련해서 글쓴것을 공유합니다.http://goodtogreate.tistory.com/entry/GPU-TensorFlow-on-Window-10-TensorFlow-GPU%EB%B2%84%EC%A0%84-%EC%9C%88%EB%8F%84%EC%9A%B010-%EC%84%A4%EC%B9%98
7	CNN 알고리즘은 주로 영상 인식 분야에 많이 사용되는것 같은데, 다른 분야에 활용되는 사례는 없나요? (음성 인식 분야에도 사용되는 것은 같은데,)그렇다면 일반적은 추천과 같은 시나리오에는 CNN등은 사용할 수 없고 기존의 Kmeans 등의 비 뉴럴넷 방식을 사용하는가요?	0	wavenet(tts) , bytenet(번역) 등에도 많이 쓰입니다!	3	제 생각에는 어떤 데이터든 간에, 어떤 작은 모양(=형태=패턴)이 모여서 조금 더 큰 모양을 만들고, 그것들이 또 모여서 더 큰 모양을 만들고... 하는 경우에는 모두 CNN을 적용 해 보는 것이 의미가 있지 않을까 싶습니다...만 그냥 제 추정입니다.그리고 이렇게 CNN을 적용 하는 것과 추천 시스템을 만드는 것은 별개의 얘기가 아닌가 싶긴 합니다만, 아무튼 CNN 뒤쪽에 추가로 추천 네트워크를 붙여서 "모양에 따른 추천"을 하는 것은 가능하리라 생각합니다.	0	자연어처리에서도 쓰입니다 ^^	3	포항공대 유환조 교수님 연구실에서 RecSys 16에 발표한 Convolutional matrix factorization 논문이 cnn으로 텍스트 임베딩을 추출해서 추천시스템에 적용한 사레입니다.	1	http://www.slideshare.net/deview/221-67605830 딥러닝을 이용한 지역컨텍스트 검색에서 CNN을 사용하였습니다.
8	세번째 Bot Talk이 12월 6일(화) 저녁 7시부터 "개포디지털혁신파크"(개포동역 8번출구)에서 열립니다. 발표자는 Fluenty.ai 클로즈 베타를 모집중인 Fluenty의 김강학 대표님, "TensorFlow + Python으로 챗봇 개발" 발표를 여러 컨퍼런스에서 하시고 챗봇 개발도 진행중인 래블업(Lablup)의 신정규 대표님, 배달봇 얌얌 운영중인 머니브레인의 장세영 대표님, 8퍼센트와 "에이다" 챗봇을 개발해 테스트 중인 데이터나다(DATANADA)의 존박 대표님입니다. 그리고 10여개의 챗봇을 소개하는 비디오 세션도 마련되어 있습니다. 관심있는 분들은 많이 참석해주세요. 	0	챗봇 관심있는 개발자 입니다. 아무도 모르고 혼자 참석할까 하는데 참석해도 될련지요??	0	물론이죠.
2	TensorFlow v0.12.0 RC0 를 윈도우에 설치하고 정상 작동하는 것 까지 확인했습니다.그런데 Tensorboard를 실행시키니 브라우저가 그냥 빈 화면만 뜨네요... 접속은 되는거같은데 그 소스 안에있는 파일들을 불러오지 못하는거 같네요....혹시 뭐 따로 건드려줘야하는게 있을까요?	0	브라우저는 어떤거 쓰셧나요?	0	음.. 저도 방금 확인해보니 텐서보드 작동은 되지만 크롬 및 다른 브라우저에서 빈화면만 뜨네요.. ㅜ	3	해결했습니다. 웹 리소스가 안불러져 오더군요... 그리고 자체 파일도 하나도 없어서 Cheehun Won 님이 올려주신 게시글에서 넣어주고 실행시켰습니다. 아 그리고 한가지 더 오류가 났었는데 이벤트 파일 이름에에 한글이 있으면 인코딩 오류로 이벤트파일을 못불러옵니다. 꼭 확인해보세요!
111	[TensorFlow 구현 모음]저희 그룹에서 TensorFlow로 구현된 모델을 모으고 있습니다. 더 많은 구현이 있을 것으로 생각합니다. 이 글의 댓글이나 저희 repository에 pull request를 보내 주시면 리스트를 업데이트하겠습니다.미리 감사드립니다.	0	재미있는 프로젝트가 되겠습니다.
4	tensorflow 는 하나도 모르고, https://codelabs.developers.google.com/codelabs/tensorflow-for-poets 만 겨우 따라해보고 있는 초보입니다.https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L177위 코드에서 입력 이미지를 training/testing/validation 이미지 분류를 파일명에 대한 sha1 해쉬값을 숫자로 변환해서 백분율로 나누는 데요.입력 이미지 갯수가 충분히 많다면 괜찮지만,숫자가 적으니깐 testing 으로 이미지가 하나도 분류되지 않을 때가 있네요.sha1 해쉬값없이 전체 이미지를 단순히 비율대로 validation/testing/training 으로 분류해도 괜찮을까요? 코드에는 비율이 ~10%, 10%~20%, 20%~ 더라구요.코드를 그렇게 변경해서 일단 돌려보고는 있습니다.
6	원론적인 질문인데, CNN에서 필터 사이즈와 Stride 값은 어떻게 구하나요? 이것도 Hyper parameter 튜닝으로 일일이 바꿔 가면서 데이타에 잘 맞는 값을 찾아내야 하는건가요?	6	옙.  랜덤서치나 그리드 서치로 찾습니다.  이거 하다보면 가뿐히 계절이 바뀝니다. ㅎㅎ  따라서 이런 과정을 이미 마친 유명한 모델을 갖다 쓰는게 정신 건강에 좋습니다.
14	Dropout에 대해서 고수님들께 질문이 있습니다.Dropout은 개념적으로 중간중간에, 노드를 꺼서 오버피팅을 막는걸로 알고 있는데요. Sung Kim 교수님 강의를 보면 각 레이어에서 뉴런을 랜덤하게 끄는것 처럼 설명이 되어 있는데,다른 글들을 보니, Dropout을 맨 마지막에 Fully Connected 레이어 앞에 별도의 레이어로 놓는 방법이 많이 보입니다.즉 Dropout을 구현할때1. 별도의 레이어로 구현하는 것이 통상적인지.2. 아니면 각 레이어에서 랜덤으로 뉴런을 끄는게 통상적인지질문 드립니다.	1	요샌  DO 잘 안쓰니 건너띄셔도 됩니다	1	굳이 나눈다면 fc1 fc2 에서 쓰는게 관례이고요.  정말 데이터가 없을 경우나 각 레이어 마다 넣어주기도 합니다.  하지만 이것도 올드한 얘기라서....	2	요샌 BN 과 좁고 깊은 모델로 오버피팅을 막고요.	2	augment 는 필수이고 데이터 많은게 일단 갑입니다.	3	Dropout을 FC 앞에서 별도의 레이어로 구현하는 이유는 Convolution layer의 경우 Dropout을 통한 Regularization 효과가 미미하기 때문에 Convolution layer 앞에는 사용할 필요가 없고 FC layer에만 적용시키기 때문입니다. Convolution Network가 보편화된 요즘은 거의 사용되지 않는 기법이고, Convolution Network를 Regularize하기 위해 Batch Normalization을 사용하는 추세입니다. BN 논문에서는 augment가 필요하지 않다라는 결론이 적혀있었던걸로 기억하는데 촤근에는 augment 없이 적은 양의 데이터로 효과적인 학습을 하는 Oneshot method에 대한 연구도 활발한 걸로 알고 있습니다.	0	드랍아웃이 각 레이어에서 꺼주는게 맞는데 별도의 레이어를 만들어서 해주는 게 개발할때 더 편해서 그렇습니다. 트레이닝이랑 테스트랑 다르고트레이닝때는 또 p로 나눠주는 방법으로 하기때문에 그렇습니다.oop 관점에서 따로 만드는게 더 낫죠.	11	드랍아웃이 오래되고 요새는 다른 더 강력한 레귤러라이제이션으로 많이 대체되었을지라도 그 의미를 이해하는 것은 중요하다고 생각합니다.드랍아웃은 여러 가지 의미로 해석이 가능한데, 우선 가장 널리 알려져 있는 것은 학습할 때에는 랜덤하게 선택된 작은 네트워크들로 학습하고, 테스트 시에는 이를 모두 사용하는 앙상블 메서드의 근사적인 방법으로 보는 관점이구요.그 다음은 히든 뉴런들이 서로 동일한 피쳐를 학습해버리는 co-adaptation 문제를, 랜덤으로 뉴런을 꺼버려서 다른 방향의 학습이 일어나도록 해주는 해석입니다.이런 관점에서 CNN에 드랍아웃을 적용할 때에는 뉴런이 아닌, 필터 단위로 꺼주어야하고, RNN에 적용시에도 하나의 템포럴 패턴에 대해서 동일하게 뉴런을 꺼주어야합니다.그리고 최근에는 베이지안 관점에서 드랍아웃을 해석한 논문 등이 있습니다.https://arxiv.org/abs/1506.02142	0	Dropout 을 마지막 layer 부터 거는 문제는 충분히 discriminative 해진 feature set 에 대해 sampling 을 하는게 효과가 좋기 때문이라 생각하고요, 보통 앙상블 방법에서 feature selection, data selection을 같이 섞어 쓰는것을 고려해보면 conv layer 에서 dropout 을 거는것이 feature selection, fc layer의 dropout 을 data selection 으로 볼 수 있지 않나 생각이 듭니다한편으론, fc layer 가 없는 semantic segmentation 같은 cnn 에서는 dropout 을 encoder와 decoder 사이의 conv layer 에 걸어 주는데 여기서는 conv layer 를 sliding window 를 가지는 cnn detector 로써 사용하기 때문에 꼭 fc/conv layer 를 구분해서 dropout을 거는 것은 아닌것 같습니다
1	안녕하세요. 질문이 있어서 글 올립니다.이미 한번 학습 된 모델에 데이터를 추가하려고 하려는데, 기존에 학습 된 모델을 Saver에서 Restore 한 후에 데이터 경로만 지정하고학습을 시작했더니, Loss가 들쭉날쭉하며 학습이 전혀 되지 않더라구요.제가 어떤 것을 놓치거나 잘못한 걸까요?	2	혹시 restore를 하신 후 tf.initialize_all_variables() 하지 않으셨나 확인해보셨으면 합니다.restore후 다시 초기화하면 저런 증상이 발생합니다	1	Saver되는 항목(Variable같은)의 'name'에 의한 충돌(?)은 의심하지 않아도 될까요?	2	들쭉날쭉 하는 폭이 중요합니다 들쭉날쭉하는 수치의 차이가 매우 작다면 이미 충분히 수렴이 된 상태라고 보시면 됩니다. 이미 미니마에 빠져서 허우적 거리는 것이지요만약 그런 현상이라면 최적화된 웨이트를 아주 작은 노이즈를 더해줘서 최적 파라메터를 살짝 흔들어주는 방법이 있습니다. regularization term을 살짝 바꿔주는 것도 방법입니다	0	학습할 때  random으로 사용하던 weights, biases를 저장해 두었다가 추가로 학습시킬때 읽어서 사용하면 잘 되었던 것으로 기억합니다.
0	안녕하세요. 처음으로 TensorFlow를 배우고 있는 직장인 입니다.가지고 있는 이미지를 tfrecrod로 변환을 하려고 합니다.그래서 https://github.com/tensorflow/models/blob/master/inception/inception/data/build_image_data.py에서 해당 파일을 받아 실행을 하였는데해당 디렉토리에 파일이 있는데도 불구하고 이미지를 찾지 못하네요. jpeg에 무슨 문제가 있는 건가요?tf.app.flags.DEFINE_string('train_directory', '/tmp/',                             'Training data directory') 해당 소스에서 위에 해당하는 부분을 수정하였습니다.
2	custom image를 TFRecord 파일로 변환해줄 때, build_image_data.py를 바젤로 빌드하여 변환작업을 합니다. 그런데, train_shards, validation_shards, num_threads 와 같은 옵션을 주는데, 이것이 무엇을 의미하는지 어떻게 줘야 하는지 혹시 아시는분 계신가요? (혹시 위 방법 말고, 다른 TFRecord 파일변환방법 아시나요?)	0	안녕하세요.처음으로 Tensaflow를 배우고 있는 사람입니다. 저도 비슷한 것을 하고 있는데요.  , build_image_data.py를 실행시키고 해당 디렉토리에 jpeg이미지를 넣고 python build_image_data.py를 실행시켰는데 잘되지 않네요. 그 전까지는 하신것 같아서. 질문드립니다.
0	안녕하세요.저는 컴퓨터 비전 계열은 큰 관심이 없어서 텍스트 데이터로 클러스터링, 클래시피케이션 부분을 몇 가지 아디이어를 갖고 working 모델을 만들어 보려 노력하고 있는데.. 학습 데이터를 확보하는데 어려움이 있네요. 확보를 못하면 dummy(가라) 데이터를 만들면 되는데..현실성을 모사하는 대량의 더미 데이터를 만들어내는데 좋은 의견이 있으신 분이 있을까 하여 글 남겨 봅니다.현재까지 아이디어는 다양한 조건들에 대하여 발생 확률을 정하고 확률 분포 함수에 따라 조건에 해당하는 데이터를 생성하도록 생각하고 있습니다. 수학은 공대 겨우 졸업한 수준이라 잘 모르구요.. 다만 여러 현상이나 리얼 데이터들이 정규분포를 따르는 경우가 많다는 것은 어디서 주워들었네요.. 그럼 좋은 의견 부탁드립니다.	2	우선 결론부터 말씀드리자면, 임의의 확률분포로부터 데이터를 생성해서 쓰는것은 불가능한 방법입니다.오히려 정반대로 기계학습은 현실의 데이터를 이용해서 그 데이터가 생성된 true underlying 확률 분포를 알아내기 위한 방법에 더 가깝습니다.이 진짜 분포만 알고있으면, 이상적인 옵티멀 클래시파이어를 만들어낼 수 있음이 이미 수학적으로 증명되었기 때문에, 이 분포를 안다는 것은 그 데이터에 대한 모든 문제가 풀렸다는 것과 같습니다.https://en.m.wikipedia.org/wiki/Bayes_error_rate
7	안녕하세요. TensorFlow를 공부해보려고 하는데MNIST 손글씨 예제말고 연습해볼 수 있는 데이터들을 구할 수 있는 방법이 있을까요?	1	https://research.googleblog.com/2016/09/announcing-youtube-8m-large-and-diverse.htmlhttps://research.googleblog.com/2016/09/introducing-open-images-dataset.html참고해 보시길...	0	이외에도 그냥 구글에 deep learning/machine learning dataset 쳐보시면 많이 나올거예요	0	cifar-10도 있습니다.
1	Tensorflow로 GPU 컴퓨팅 환경을 구축하려고 하는데... 현재 가지고 있는 GPU 서버가 없어서 아마존 AWS를 이용하려고 합니다.일단은 테스트 용도라..추천하는 사양이나 가격 아시는분 계신가요?(싼걸로..)	0	https://cloud.google.com/products/machine-learning/써보진 않았지만 이것도 참고해보세요 Try it free button도 잇네요	0	텐서는 GC를 한번 써보세요 ㅎㅎ 윗분 말대로!	0	아 직접 환경구축을 해보려고 해서 ㅎㅎ 이것도 코드 돌리기는 좋은거같아요	0	Google cloud 는 지금 gpu는 무료옵션에서 빠져있는 것으로 알고 있는데, 아닌가요??	0	그냥 갖고계신 PC와 중고 GTX1060하나로 시작해보시는건 어떠실까요.	1	구글 클라우드에는 GPU 보다 더 성능이 좋은 전용 텐서 플로우 서비스가 있습니다.  가입 하시면 300$ 무료 크레딧이 제공됩니다.	0	사용 방법은 https://www.youtube.com/watch?v=8Jkz2HexDAM&feature=youtu.be 에 있습니다.
0	안녕하세요. 보통 어떤 환경에서 텐서플로우를 구축하고 사용하시나요? (서비스되는 환경 제외)1. 로컬2. virtualenv3. docker4. 그 외저는 아직 초보라 사양이 낮아도 크게 지장이 없기에 virtualbox centos에서 pip인스톨해서 사용합니다. 프로젝트가 빠르게 업데이트되다 보니 어떤 방식이 유리한지 잘 모르겠네요. 다른 분들은 어떻게 사용하시나요?	1	로컬이요 ㅋㅋ gtx750 ti 고문하면서...	1	우분투 깔아서 쓰던 중인데 연구실 서버 컴을 쓸 수 있어서 서버를 자주 씁니다	1	docker에서 돌려봤어요	1	window bash shell 이요ㅋㅋ	1	저는 아나콘다 + gtx970으로요	1	GTX1080, GTX1070 두개 환경이요 :)	3	집은 gtx960 로컬, 회사는 서버에 gtx1080 x 2와 텐서플로우만 설치해서 사용중입니다.	1	다들 사양이 좋네요.. 부럽습니다 (...)	1	맥북 프로에 도커로 올려서 사용하고 있습니다.
195	안녕하세요? 머신러닝 입문자입니다. 이 그룹에 글 올리기가 제일 무섭습니다. ㅎㅎㅎ 고수님들이 많아서. 딥러닝의 기본 개념과 유례에 대해서 정리하였습니다.http://bcho.tistory.com/1147김성훈 교수님의 모두를 위한 머신러닝/딥러닝을 참고하였습니다.CNN이나 다른 개념들 빠져 있기는 한데, (dropout 등), 뉴럴네트워크의 기본적인 개념과 발전 과정을 이해하는데 도움이 되리라 기대? 해봅니다. 잘못된 내용 지적은 언제나 환영입니다.	0	오 정리 잘하셨네요.	1	엯촋	1	Yeongjin Choi	0	좋은 정보 감사합니다 :)	1	저도 입문자입니다.  블로그에 정리 잘 해 놓으셨네요. 보면 도움이 많이 될 것 같습니다.
3	안녕하세요. 구글 신경망 번역 모델과 관련해서 질문이 있어 글을 올립니다.구글에서 발표한 신경망 번역 모델에 관한 논문을 읽고 있습니다(https://arxiv.org/pdf/1609.08144v2.pdf).이 논문에서 보면 디코딩 단계에 LSTM을 쓴다고 하는데요.디코더 각 층에서의 hidden state와 memory state의 초기값의 초기화와 관련된 언급이 없는 것 같습니다.다른 모델의 경우, 디코더의 memory나 hidden state를 인코더 값과 연결을 시켜주는 것 같은데, 이 논문에서는 그런 언급이 없어서 혹시 관련 레퍼런스가 있는지 궁금합니다.
4	기계번역에서 data size는 어느정도로 정하고 시작하면 될까요?이제 시작하는터라 기본 논문을 읽고 있습니다. features의 갯수와 관련되는지요?	2	정답이 없는 문제입니다. 풀고자 하는 문제의 범위, 문제를 풀기위한 데이터의 특성 이런것 등등이 변수가 됩니다. 차근차근 시작해서 경험치를 높이세요. 많이 하다보면 '직관'이라는 게 생기고 공부를 하다 보면 더 빨리 생기게 되는게 '직관'입니다. 이런 직관 말고는 현재 답을 낼수 있는 방법은 없습니다. 괜히 논문들이 하이퍼 파라메터들을 변인통제하면서 각 경우에 따른 효율성과 정확성에 대해 실험결과를 보여주는게 아니니까요. 화이팅하셔서 좋은 결과 내시길 바랍니다 ^^	0	자세한 답변 감사합니다!
17	#Tensorflow안녕하세요 이찬우입니다.오늘도 9시에 텐서보드 사용 하는 법을 주제로 방송을 시작합니다.많은 관심 바랍니다.우선 방송만 켜놓고 강의는 9시에 시작하도록 하겠습니다.있다 뵙겠습니다 :)
106	구글 번역기가 인공신경망을 도입하더니 이젠 새로운 중간 언어까지 개발하려 하네요ㄷㄷ수정: 구글이 직접적으로 중간 언어를 개발하려는게 아니라 제로샷 번역기능을 통한 메커니즘으로 분석하니 중간 언어의 개념이 도입된 것 처럼 보인다는 연구결과를 발표한 것입니다.	0	구글이 정말로 신이 되려고 하네요 ㅋㅋㅋㅋㅋ	0	자고 일어나니 새로운것이 나오더라 라는 말이 이제는 더욱 피부로 체감이 되네요 만감이 교차합니다 ㅎㅎ	0	스ㅋㅇ넷..?	0	구글이 신이된다...	0	중간계 언어는 수십년전부터 링구이스트들이 번역의 필수단계로 조금씩 구현하고 있었건거라 새로운 발상은 아니지만 수준이 올라간 것은 확실하네요	3	중간언어를 구현했다기보다는 심층신경망 내부에서 자동적으로 그러한 메커니즘이 생겨난 것 같다는 연구결과입니다. 예를들어 영어-일어, 영어-한국어만 학습시켰는데 별도의 추가 작업 없이 스스로 일어-한국어를 번역한 것으로 보아 자신만의 인공모국어(?)를 통해 영어를 거치지 않고 다이렉트로 변환하는 것 같다는게 논지입니다.
38	안녕하세요, 8퍼센트 서비스에 딥러닝 기반 챗봇을 붙여 보았습니다. 베타 테스트 중인데요, 8퍼센트 서비스를 이용하시는 분은  https://www.facebook.com/8percentlending/ 에 메세지를 날려서 챗봇 테스트 부탁드립니다.	0	오픈 하셨군요... 축하드립니다. ^^	1	실패했습니다...	0	상담사연결 되고있는건가요?!	0	저도 상담사랑 연결되어. ㅋㅋ 재미있는 대화 예제 몇개 보여주시면 좋을듯 합니다.	1		2	밑에 2개는 어떻게 답했는지 모르겠는데, 그럴싸하게. 찾아봐도 training 에 없는데.. :o	1	동일한 답변 3게 중. 앞에 2개는 XX는 어떻게 하나요? 로 즉 명사 제외 뒷부분으로 학습한듯 하고... 마지막 1개는 탈퇴 라는 단어를 만나서 탈퇴 답변을 한게 아닐가요?
75	요새 end-to-end 놀음에 재미를 붙이고 있습니다.  음성인식 분야에도 해당되는데요 문장 음성파일과 문장 텍스트 파일만 end-to-end 로 넣고 학습이 되면 좋겠다는 생각을 늘 했었습니다.  (예전에는 음소 또는 단어 분리하고 라벨 맞추고 생각만해도  ㅠ.ㅠ )딥마인드사의 wavenet 을 이용해서 한번 구현해 보았는데 잘 됩니다.  ( end-to-end 만세 !!! )  늘 그렇듯 코딩은 하루 걸리는데 데이터 정리하고 read.me 만드는데 시간이 더 걸리네요.  ㅠ.ㅠhttps://github.com/buriburisuri/speech-to-text-wavenet제가 딥러닝 하면서 제일 문의를 많이 받은 분야가 음성 인식이었습니다.  다른 분들도 마찬가지 일거 같은데요.  누가 한국어 corpus 있으면 학습 시켜서 공유했으면 합니다.  똑같은 일 반복하기보다는 우리에겐 훨씬 더 중요하고 재미있는 연구가 많쟎아요.  ㅎㅎ 이 기회에 공개 한국어 음성 인식 프로젝트 런칭 한번 할까요?	1	한국어 음성인식 좋은 프로젝트 같습니다. 방송사들의 음성과 caption을 이용할수 있을까요?	1	이용은 할 수 있는데 결과 공개해서 공유할 때 저작권 문제가 있을 거 같네요.	1	현재 음성인식을 연구하고 있는데 end-to-end 기법에 손 댈 기회가 생길지 모르겠네요. 어휘, 음소의 정의를 별도로 해줄 필요가 없는건가요...? 어떻게 동작하는 것인지 상상이 안가네요. ㅎㅎ	1	영문은 인식률이 어느정도 되나요?	1	sugartensor를 쓰시는 이유는 뭔가요~?
35	텐서플로우 문서 번역 이벤트로 받은 티셔츠 인증샷입니다. 감사의 마음으로 수영장샷 올립니다.  photo: Won Kyu Cho이 티셔츠 입고 개발하면 생산성이 올라갈것 같습니다.^^이벤트를 만들고 진행해주신 김성훈 교수님(Sung Kim)과 박해선님(Park Ricky)께 감사드립니다.	1	멋집니다!
0	안녕하세요. 현재 임의의 데이터를 가지고 Neural Network 모델을 구성하여 regression하는 실험을 수행하고 있는데,모델을 통한 예측치를 python언어로 print하면 tensor와 op가 출력되고 실수 값은 출력이 되지 않는데 실수 값을 출력하는 방법을 모르겠습니다.또한 Neural Network 모델로 regression할때 원하는 epoch만큼 학습을 완료한 다음, 회귀식이나 회귀 계수를 알아낼 방법이 있을까요??	1	계수나 예측치가 a라는 변수면 session.run(a) 하면 리턴됩니다
62	텐서플로우 문서 번역에 참여해 주신 모든 분들께 감사드립니다.10월 한달간 번역에 참여해 주신 분들을 대상으로 텐서플로우 티셔츠를 제공하는 이벤트에 당첨되신 분들의 깃허브 아이디입니다. ^^jybaek, intelcoder, lsrock1, mingrammer, datalater, recisic, johnchoi83, iworkist, sgwassabi, DSKSD티셔츠는 XL 2개, L 3개, M 5개가 있습니다.주문 하시는 대로 선착순으로 배송될 것 같습니다.신청하시는 방법은 아래 깃허브 이슈에 코멘트로 페이스북 아이디를 알려 주세요.https://github.com/tensorflowkorea/tensorflow-kr/issues/196그리고 페이스북으로 저에게 주소와 성함, 연락처를 보내 주시면 우편으로 배송하고 회신 드리겠습니다.감사합니다.* 이벤트는 그룹의 비선(!)인 김성훈 교수님 도움으로 진행되었으며 텐서플로우 티셔츠는 구글코리아의 권순선님께서 후원해 주셨습니다.	9	모두모두 감사드리며 10분 축하드립니다.	1	정말 소소하게 참여했는데 부끄럽게도 이벤트에 당첨되었네요. 앞으로도 남은 번역에 꾸준한 기여를 하도록 하겠습니다. 감사합니다.	1	오오..까먹고 있었는데 감사합니다!! 저도 남은 번역에 계속 기여하겠습니다. 풀리퀘스트하는 법에 대해 쉽게 알려주셔서 정말 감사드립니다:)	0	Ming Kwon	0	감사합니다~	0	감사합니다!!	1	감사합니다!!	0	L사이즈는 모두 신청 완료 되었습니다. ^^	0	감사합니다. 남은 번역도 계속 기여하도록 하겠습니다. 덕분에 TensorFlow 공부도 하고 Github 도 공부하고 좋습니다.	4	열분께 모두 배송하였습니다. 다시 한번 감사드립니다. :-)	0	실례지만 Tensorflow 번역된 문서 어디가면 볼수 있나요? 혹시 있으시다면 보내주시면 감사하겠습니다. pooh0216@gmail.com
67	[얼굴로 범인 예측]이런것이 나올 것이라 예상했는데... 90% 정확도라고 하네요. (실험 방식은 문제가 있습니다. label 50-50)---(구글 번역 요약)그들의 mugshots에서 범죄자를 식별하기위한 노력은 우리가 인공 지능을 사용해야하는 방법에 대한 심각한 윤리적 문제를 제기합니다.중국 상해 Jiao Tong University의 연구자들은 범인과 비폭력 자의 얼굴을 연구하기 위해 다양한 머신 비전 알고리즘을 적용했습니다. 그들은 얼굴 털이없는 18 세에서 55 세 사이의 중국 남성 1,856 명을 여전히 찍었고 그 중 절반은 범인이었다. 연구원은이 이미지의 90 %를 사용하여 길쌈 신경 네트워크를 훈련시켜 차이를 인식하고 나머지 10 %의 이미지에서 신경 네트워크를 테스트했습니다. 신경망은 거의 90 %의 정확도로 범죄자와 비 범죄자를 정확하게 식별 할 수있었습니다. "이 매우 일관된 결과는 주제를 둘러싼 역사적인 논란에도 불구하고 범죄에 대한 자동 얼굴 유도에 의한 유추의 타당성에 대한 증거입니다"라고 연구원은 말했습니다. 신경 회로망은 분류를하기 위해 3 가지의 독특한 얼굴 특징을 사용합니다 : 윗입술의 곡률은 비 범죄자보다 범죄자에게 평균 23 퍼센트 더 큽니다. 눈의 안쪽 구석 사이의 거리. 범죄자의 경우 6 % 더 짧다. 코끝에서 입가에 이르는 두 선 사이의 각도는 범죄자의 20 % 더 작습니다. 연구원은 또한 범죄자 용 데이터가 비 (非) 범죄자 용 데이터보다 훨씬 더 큰 차이가 있음을 발견했습니다. "일반 법률 위반자의 얼굴은 범죄자의 얼굴과 비교해 볼 때 닮은 점이 많다. 범죄자의 얼굴 모양이 일반인보다 더 높다"고 결론 지었다.	10	다분히 파시즘으로 빠질 수 있는 접근입니다.	2	결국 관상까지 본다는  ㅋㅋ	4	장애인이 없다고 광고했던 북한, 아리안의 우수성을 이야기했던 나치 독일이 떠오르는 접근법이네요.	2	이건 실용화 할때 잡음이 크겠네요.	3	다양한 연구를 하는 건 좋지만 비전공자들에게는 인공지능에 대한 반감을 더 불러일으킬 수 있는 주제 같네요	2	10%의 경우, 이유없이 범죄자로 몰리는 경우가 생길 수도 있고, 몰리진 않더라도 잠재적인 범죄자라면서 마이너리티리포트 당할 수도 있겠네요...	2	관상이네요ㅋㅋㅋㅋㅋ	1	실제 사용되는 시점이 되면 좀 기분이 그렇네요...;;	2	언젠가는 나올 논문이였다고 생각합니다. 저는 다양한 입장에서의 접근 자체는 환영합니다. 모든 연구의 그 본질 자체는 죄가 없다고 생각해요.
3	맥북에 only CPU로 텐서플로우를 사용하다가 데스크탑 우분투 환경에서 use GPU로 해서 설치를 했습니다.실행을 해봤을때 제대로 GPU로 설치된걸 확인할 방법이 있을까요??	0	그냥 tensor flow 임포트하면 cuda관련 내용이 주르륵 뜹니다	1	nvidia-smi 하면 가운데 오른쪽쯤에 퍼센트가 계속 바뀌는거 있을거에요. 0~7퍼센트 사이에서 왔다갔다 하는건 화면 띄우는데 써서 바뀌는거고, 간단한 모델이 아니라면 그이상으로 올라가는게 보이면 정상적으로 돌아가는거에요ㅎㅎ	4	nvidia-smi -l 1로 하시면 1초단위로 모니터링하실 수 있습니다 :)	1	일단 실행속도가 10배이상 빠를꺼라 확실하게 체감이 될 듯 합니다. 저도 cpu에서 gpu로 옮길때 너무 빨라서 이게 gpu구나 했습니다.	2	GPU를 사용했을때 성능측정은 nvprof를 사용하시면 됩니다. CUDA사용할때 최적화된 GPU사용을 위해서 nvprof를 쓴 기억이 있네요. nvidia 프로파일러입니다.nvidia-smi에선 안나오는 코어사용률 같은 좀더 디테일한 정보를 알수있습니다
0	안녕하세요최근에 Tensorflow에 관심이 생겨서 이것 저것 리서치를 해보고 있는 대학생입니다.현재 Tensorflow를 이용하고 있는 이미지 처리에 대한 대표적인 프로젝트나 관련 학술 자료에 대해서 알고 싶은데요, 이에 대한 자세한 자료를 찾을 수 있는 곳이 있을까요? 제가 머신러닝에 대해 잘 알지는 못하는지라 초보자도 이해할 수 있는 수준이었으면 좋겠습니다..ㅠ	1	ILSVRC (대표적인 image classification and recognition 대회) 2012년도 우승자 논문(AlexNet)부터 공부해보시면 어떨까요?	0	초보자시면 stanford cs231n 강의도 좋구요
3	일본MS, MS 트랜슬레이터, 뉴럴네트워크(인공신경망) 번역 서비스 개시- 뉴럴 네트워크는 최근 기계 번역 업계에서도 활용되고 있으며, SMT기술보다 높은 번역 품질을 실현
25	안녕하세요! 지난 여름에 처음으로 텐서플로우를 공부하기 시작해서 8월 중순쯤 TensorFlow KR그룹에 처음 글을 적었었던 학생입니다.저는 Tensorflow를 이용해서 이미지 속에 있는 숫자를 인식하는 프로그램을 만들어보고 싶었습니다.현재 부족한 수준이지만 '사진1'처럼 몇가지 숫자들이 적혀있는 이미지(.jpg)를 집어넣었을때 다음과 같이 숫자가 인식되는 소스코드를 만들었습니다.(사진2 ~ 사진4)초기에 입력된 큰 이미지에서 Box size만큼  잘라서 픽셀과 픽셀을 비교해서 예측을 하는 Softmax classification을 사용하고 있습니다.그림1 같은 경우 986 X 786 픽셀 인데, 이 이미지에 대한 숫자인식이 모두 끝나는데 대략 30분 정도 걸리고 있습니다.(너무 오래걸리죠...)현재 구조에서는 이미지를 박스 사이즈로 1 픽셀씩 이동하면서 이미지 전체를 쭉 한번 훑고, 박스 사이즈를 증가시키고 다시 한 번 이미지 전체를 훑는 방식입니다.참고로 Slicing Box의 크기는 20 X 28에서 시작하여 Slicing Box의 가로나 세로의 사이즈가 원본 이미지와 같아질 때까지 약 1 pixel씩 증가합니다보완해야 할 부분이 너무도 많지만 일단 현재 구조에서 속도를 개선하고 싶습니다. 그런데 무엇을 어떻게 시작해야할 지 막막합니다.(pypy를 사용해야할까요?, pypy와 tensorflow를 동시에 사용 가능한가요?? 등등.. 아니면 C++를 이용해서 다시 코드를 짜야 할까요?)혹시 숫자 인식에 대한 정보나 속도 향상에 관한 정보 등을 알고계시는 분들께 조언을 구하고 싶어서 이렇게 글을 적었습니다.아직 부족한게 많은 학생입니다.. Tensorflow와 머신러닝을 공부하는 초심자에게 많은 조언 부탁드립니다!	1	저는 해당 주제를 잘 모르지만 숫자 위치 추정과 숫자 추정을 각각 어떻게 학습하셨는지 적어주시면 이해가 빠를것같습니다. 박스 사이즈는 어떻게 결정하시나요? 그리고 이런 내용은 상황에 따라 연구주제가 될 수도 있고 engineering의 문제가 될 것같기도 하네요.	0	저도 공부 시작할려고 하는데 ㅋㅋ 동기부여 감사합니다 :)	4	sliding window로 모든 image region을 search하면 시간이 많이 걸립니다. sliding window를 사용한다면 pyramid model을 사용해서 coarse-to-fine으로 찾아도 되고요, 추천하는 방법은 MSER을 사용해서 숫자 영역 candidate를 뽑고 이를 normalize해서 recognize하는 겁니다. MSER은 opencv에도 있고 오픈소스가 있으니 참고해 보세요.http://docs.opencv.org/3.0-beta/modules/text/doc/erfilter.html	2	object detection 쪽에서 최근 가장 괜찮은 논문은 Single Shot Detection이었던 것 같습니다. 참고해볼만하시지 않을까 싶어요	2	부끄럽지만 제가 쓴 text detection 논문도 링크를 걸어 봅니다.. 올해 CVPR에서 발표했습니다. classifier만 deep learning 기반으로 바꾸면 accuracy가 더 올라갈 거에요~ :)http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Cho_Canny_Text_Detector_CVPR_2016_paper.pdf	0	숫자별 영역 검출에 시간이 오래걸리는듯한데; 숫자 영역을 cropping하기 위해 이진화 후 component labelling을 수행하고, 각 component에 외접하는 직사각형 영역으로 숫자 영역을 지정하면 어떨까요...	0	맞습니다! 제가 하고있던 방법은 숫자별 영역 검출이라고 보기는 어려웠고 Sliding window로 모든 이미지의 부분들을 search하는 과정에서 시간이 오래 걸리는 것이었습니다. 몇가지 조건을 두어 예측위한 처리과정과 숫자추정과정을 거르고 넘어가도록 설계했지만 그래도 속도가 느렸습니다.말씀해주신 component labelling 이라는것이 제가 찾아본 connected component labeling이라는 방법이 맞나요?앞으로 나아갈 방향에 대하여 좋은 아이디어를 얻은것 같습니다! 많이 참고하겠습니다! 감사합니다ㅎㅎ	0	맞습니다.. 단 제시하신 예제처럼 배경과 숫자 영역의 밝기차가 명확하다는가정이고 노이즈 요소없이 숫자영역이 connected 된 한 덩어리여야 한다는 가정입니다.
2	텐서플로우 코드 관련질문드립니다.처리하는 데이터가x: 트리데이터 구조를 list화 시킨 것, y:one-hot-vector 형태인데 mini-batch 로 러닝하고 싶습니다.placeholder 를 list형태로 써서 batch_x = [[list1], [list2], ... ] 식으로 feed_dict에 넣고 싶은데 이게 가능한지 궁금하네요왜 궁금하냐면.. placeholder 선언시 들어가는 dtype을 어떻게 정해야하는지  모르겠어서.. 불가능한건지 ㅠㅠ 궁금합니다.nodes = tf.placeholder(tf.float32, shape=[1, None])+) 간단한 코드가 아니라 조금 복잡해지면, graph부분 쪽 코드와 실행부분을 나눠서 짜는게 쉽게 느껴지진 않네요 ㅠㅠ	0	nodes = []node = tf.placeholder(tf.float32, [dim])for _ in range(num_nodes):  nodes.append(node)원하시는게 이런 방식이신가요?
8	안녕하세요 학교 프로젝트로 annotation 없는 사진 검색 기능을 Show and tell + Doc2Vec으로 만들었는데요, 퍼포먼스를 평가할만한 metric이 필요해서 그런데 이와 비슷한 연구가 있을까요?미리 감사드립니다!
11	휴~ 이제서야 IDC에서 사용하는 서버 급 테스트 물리 장비를 여러 대 확보할 수 있어서, Log detection system을 토이 프로젝트로 해보려고 합니다. 아쉽지만, 받은 물리 장비에 GPU는 없군요.이미 아실 것 같지만, https://cs224d.stanford.edu 강좌에서 Log File Anomaly Detection (https://cs224d.stanford.edu/reports/YangAgrawal.pdf ) term paper(?)를 찾을 수 있었습니다.이런 주제로 구현되어 적용한 사례가 있을지요?
6	r0.12 리비전 작업 진행 사항을 잠시 공유해봅니다.github에서 리비전 브렌치가 생겼는데..Windows GPU 빌드를 위한 바질도 구성이 되고 있는것 같습니다.참고하세요.^^	0	원도우10 에서 빌드하여 버전확인까지 했네요.^^
10	엔비디아, NASA에 소행성 충돌 예방 연구 위한 딥 러닝 파워 제공- 미국항공우주국에 엔비디아 타이탄 X 및 파스칼 아키텍처 기반 GPU 활용한 딥 러닝 접근 방식으로
12	tensorflow 이미지 캡셔닝 가지고 이거저거 해보고 있는데요.구글포토에 있는 제 사진 몇천장을 inference 시켜봤습니다.아이폰으로 찍은 사진이 맥에서는 똑바로 서있는데 리눅스 서버로 옮겨서 파이썬으로 읽으니까 90 * n도씩 회전되어 있네요. 어떤건 뒤집어져 있고 어떤건 제대로 서 있는데 리눅스와 맥에서 이미지가 어떻게 서는지를 다르게 처리하는 기준은 뭘까요?	7	자문자답-요즘 프로그램들은 exif 태그대로 rotate시키고 예전 프로그램들은 그렇지 않아서 그렇다고 합니다.exiftran으로 exif 태그대로 rotate 시켜줄수 잇다고합니다https://linux.die.net/man/1/exiftran	2	사진 태그 정보 때문이 맞습니다. 저도 예전에 처음 볼 때는 어이가 없었습니다.
26	Sung Kim 교수님. 강의 잘 보고 있습니다.강의 중에 질문이 있어서 글 남겨 봅니다. 답변해주실거라고 믿고. :)딥러닝의 역사에서 딥한 네트워크의 문제를 해결한게 Back Propagation인데, 8강 17페이지에 http://hunkim.github.io/ml/lec8.pdf Back Propagation도 문제가 있어서 NN이 침체기에 들어가고, 이를 22페이지에 보면 2006년에 CIFAR 의 Hinton 교수님이 초기값을 잘 주면 해결할 수 있다고 해서 이게 전환기가 된것으로 강의에서 나오는데요.1. 여기서나오는 Back Propagation의 문제가 몬가요? 레이어가 깊어지면, 미분이 안되는 문제가 아닌가요? 2. 그렇다면 이건 ReLu로 풀린게 아닌가요?3. 2006년 Hinton 교수님의 해법은 RBM이었나요?초보적인 질문이지만 설명해주시면 답답한 머리를 뚫어주실 수 있을것 같습니다.	6	1. vanising gradient 문제네요. http://aikorea.org/blog/rnn-tutorial-3/ 잘 설명되어 있습니다.2,3 2006년 힌튼이 RBM을 통해 미리 unsupervised로 층 마다 pre training을 해서 해결한 건데, relu 등의 등장으로 굳이 RBM으로 pre training 할 필요 없다는게 밝혀졌지요. 여담이지만 힌튼은 뉴럴렛 침체기(vanishing gradient 는 예전부터 내려오던 문제)에도 RBM 이전에 홉필드 네트워크를 써봤는데 성능이 별로 향상 되지 않았고 이후에 RBM으로 개선했었어요. 즉 문제를 해결하기 위해 계속 노력했었지요..	0	Rbm은 생성모델로도사용가능하구요Dbn은 작은망에서는 제대로 작동은하는것같은데 망이커지면‥좀 안되네요
1	텐서플로어 최근 업데이터 r0.11을 원도우에서 빌드하여 사용해보려고,r0.11을 클론하여 빌드를 시작하는데 환경설정중에 오류가 발생이 되네요. 혹시 최신 r0.11을 원도우에서 빌드해보신분 계신가요?	0	본 작업을 오늘 r0.12 브렌치로 다시 시도를 하는데 현재 문제가 되었던 이부분은 무사히 지나갔습니다.
65	텐서플로우 관련 좋은 강의 자료가 있어 공유합니다. Tensorflow and deeplearning without at Ph.D 동영상 강의 : https://youtu.be/vq2nnJ4g6N0강의 슬라이드 : https://docs.google.com/presentation/d/1TVixw6ItiZ8igjp6U17tcgoFrLSaHWQmMOwjlgQY9co/pub?slide=id.pGitHub : https://github.com/martin-gorner/tensorflow-mnist-tutorial	2	쉽고 직관적으로 설명 잘 되어 있네요. 잘 보겠습니다.	2	와우~ 간결하면서 빠진 내용이 없는듯... ^^감사합니다.	1	강의 슬라이드 모두를 프린터 해서 보고 싶은데 한방에 프린트 하는 방법을 모르겠습니다. 혹시 아시는 분 있으시면 답글 부탁드립니다.
68	구글 코드랩스에서 TensorFlow관련 lab을 지원합니다.  Inception v3 network 을 사용하여 이미지 분류를 실습합니다. 다른 TensorFlow관련 lab들도 많이 추가 될것으로 생각합니다.https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#0(구글번역) 배우게 될 것- TensorFlow Docker 이미지를 설치하고 실행하는 방법- Bazel과 Python을 사용하여 이미지 분류자를 훈련시키는 법- 훈련 된 분류기로 이미지를 분류하는 방법	2	혹시 이런 코드랩을 만들어 올릴수 있는 open된 공간이 있나요?
37	파이썬 데이터 타입에 대해서도 이해하면 좋을 것 같아요
8	엔비디아, IBM과 세계에서 가장 빠른 딥 러닝 엔터프라이즈 솔루션 협력 발표- IBM PowerAI SW TOOL KIT, 카페(Caffe)가 적용된 알렉스넷(AlexNet )에서 2배의 성능 구현
8	[스터디 공지] 바벨보이스 : 파트 1 (음성인식/신경인지언어학/대화생성)* 격주 목요일, 저녁 7시 - 10시 30분, 강남 근처, 회비없음, 2017년 1월 5일 시작.* 이벤트 링크 - https://www.facebook.com/events/1682993951923031/* 그룹 링크 - https://www.facebook.com/groups/babelPish/안녕하세요. "사람의 언어, 기계의 언어" - 스터디 그룹 바벨피쉬입니다. 2017년 스터디 공지를 하는 날이 올 줄 몰랐습니다. 2017년 바벨피쉬 첫 스터디 이름은 '바벨보이스' 입니다. 파이썬, 딥러닝을 이용해서 음성인식, 신경인지언어학, 문장생성과 관련한 실습 + 이론 스터디를 합니다. 완전 기초부터 시작하며(텐서플로우 기본문법과 파이선 기본 문법은 조금 아셔야 합니다) 누구나 참여하실 수 있는, 취미모임입니다. 함께 하실 분은 이벤트에 참여를 누르시거나, 댓글을 달아주시거나, 스터디 장소로 바로 찾아오시면 됩니다.
39	#Tensorflow 금일 Tensorflow on air 4강 녹화본입니다.원래 4강에서 Tensorboard까지 해보려 했는데 오늘따라 많은 질문과 토론이 이어져서 더 알찬 시간이 되는 바람에 Tensorboard는 다음 주 내용으로 미뤘습니다 ㅎㅎㅎㅎ 많은 도움이 되었으면 좋겠습니다 ㅎㅎㅎ	0	감사합니다
390	유튜브에 있는 한국어로 된 머신 러닝, 딥 러닝, 텐서플로 강의 링크를 모아봤습니다. 공부하는 것만으로도 시간이 많이 소요되는데, 다른 분들을 위해 영상까지 제작해주신 분들 모두 감사합니다!- Sung Kim 교수님(홍콩과기대) 채널https://www.youtube.com/user/hunkims- Chanwoo Lee님 채널https://www.youtube.com/channel/UCRyIQSBvSybbaNY_JCyg_vA- 홍정모 교수님(동국대) 채널https://www.youtube.com/channel/UCg6IlhycdYiK_nWB3spjIqA- KAIST 응용인공지능연구실 채널 (문일철 교수님)https://www.youtube.com/channel/UC9caTTXVw19PtY07es58NDg- 서울대학교 대학원 머신러닝 스터디 플레이리스트https://www.youtube.com/playlist?list=PLzWH6Ydh35ggVGbBh48TNs635gv2nxkFI- Heesuk Son님(KAIST) 플레이리스트https://www.youtube.com/playlist?list=PLamqaOMCyiiTH8pEgdfDvyR3_ET3_7xT5	3	너무 감사합니다. 잘 활용하도록 하겠습니다.	2	여기만 파고들어도 몇 달은 바쁘겠습니다.감사한 마음입니다	2	좋은 정보 감사합니다!	1	감사합니다	3	서주영 (Daniel Juyung Seo) 올려주셧 감사합니다. 그런데 카이스트 교수님 성함이 조금 잘못되어서요. 문일철 교수님으로 수정해주시면 좋을것같습니다.	3	그동안 몰랐던 채널들도 많이 있네요. 이번 주말에 한번 몰아서 봐야겠습니다. 감사합니다.	1	감사합니다...ㅠㅠ 머신러닝 써야되는 수업때문에 막막했는데 이런 강의들이있었군요ㅠ	3	우리 그룹글 최초로 300 like가 넘을듯 합니다. Daniel Juyung Seo 님 좋은 post 감사드립니다!	2	좋아요를 누르고 게시자를 봤는데 깜짝놀랐습니다. 어제 세미나에서 정말 많은 것을 느꼈었습니다. 좋은 자료도 감사합니다!	1	와~~~ 정말 감사드려요~~	1	감사합니다
2	안녕하세요 텐서플로우를 파이썬2에서 사용하다가 파이썬3에서 사용할 일이 생겼는데 파이썬2와3에서 둘다 텐서플로우를 사용 할 수 있게 하려면 어떻게 설치해야 되나요 ??	0	한 개 머신에서 tensorflow를 python2,3으로 유연하게 운영하는 방법은 없는 것 같고 공식 문서를 참조해봤을때 virtualenv방식이나 docker를 사용하면 python2,3을 동시에 사용 가능하겠네요. 아래 링크는 관련된 텐서플로우 설치 한글 번역본입니다. https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/get_started/os_setup.html#virtualenv-installation	0	pyenv랑 virtualenv이용하시면 되요!!제가지금둘다사용하고있어요
110	최근 샌프란시스코에서 열린  ML Conf 후기입니다. 10가지 포인트인데 딥러닝 (TensorFlow) 을 이용한 구글번역을 이용해보았습니다.1. (아직도) Deep Learning에 관한 전부는 아닙니다.2. 적합한 메트릭을 사용하여 해결할 적절한 문제를 선택하십시오.3. 모델 미세 조정은 프로젝트의 5 %입니다.4. 앙상블은 거의 항상 더 잘 작동합니다.5. 개인화 경향6. 실제로 콘텐츠의 수동 큐 레이션이 실제로 사용됩니다.7. 복잡성의 저주를 피하십시오.8. 기존 선수들로부터 모범 사례를 배우십시오.9. 모두가 오픈 소스를 사용하고 있습니다.10. 임원의 지원을 받았는지 확인하십시오.원문은 아래에 있습니다.	6	모든 과제에서 10번은 항상 가장 중요한 요인이지요 :-)	1	10번이 가장 practical tip 이네용 ㅎㅎ	1	10번이 눈에 쏙 들어 오네요.ㅠㅠ	1	역시 마지막은 임원...	1	공유 감사합니다 교수님!	0	공감합니다. 10.임원의 지원
2	TF로 변수 초기화시 사용하는 truncated_normal 함수에서 stddev(표준편차)값이 학습에 어떤 영향을 주는지가 궁금합니다.. 예제들보면 다양한 값들을 쓰고 있던데 어떤 의미가있는지..최종 학습결과에 영향을 줄 수 있는 값인가요?	1	정규분포 중에서 드문 경우는 제외, penalty 주는 걸로 이해하고 이습니다.
12	인텔, 인공지능(AI) 구현을 위한 최첨단 통합 전략 공개- 스마트 공장에서부터 드론, 스포츠, 위변조 검사 및 자율 주행차 등 산업 및 사회를 위한 AI 기반 구축
30	#Tensoflow 텐서플로 Live 4강 시작합니다.
12	#Tensorflow 안녕하세요 이찬우입니다.텐서플로 Live 3강 곧 시작하겠습니다.잠시 셋팅 할 것이 있어 9시 10분 쯤 시작하도록 하겠습니다.많은 관심 부탁드립니다감사합니다 :)	0	항상 바빠서 라이브는 못보지만 잘 보고 있습니다~!
3	텐서플로에 대해 갑자기 궁금한게 생겨 질문드립니다.텐서플로에서 CPU로 학습할때 멀티 쓰레드를 사용하는 것으로 알고있는데,그렇다면, python으로 텐서플로를 사용하는 경우 GIL의 영향을 받지 않는건가요?	4	멀티쓰레드로 동작되는 부분은 python이 아니라 C++로 동작합니다. GIL 문제는 상관이 없겠네요.
1	DBN으로선행학습후 가중치를저장하고(tf.saver.save사용저장한가중치( tf.saver. restore)Gradient optimizer로 학습을시키면수렴이안되어Adamoptimizer로 학습을 시키려했는데오류가뜨네요 체크포인트를 찾을수없다고‥Gradient optimizer를 제외하고는다른 optimizer들 다안되네요‥해결방법이있을까요?	0	Dbn코드와 fine튜닝을 한번에하니 되네요Gradient decent 알고리즘을제외하고는다른알고리즘들은 제가겪은 이슈들이있는듯하네요Stack overflow에,,..
4	tensor의 특정 index에 값을 변경하고 싶은데요. 변경을 하려고 하면 에러가 나네요. 즉, scatter 연산이 불가능한가 본데... 아시는분 있으신가요?예를 들면, 아래와 같습니다.input_data = tf.zeros(shape=[10, 10])input_data[:, 0] = 1TypeError: 'Tensor' object does not support item assignment	1	tf.scatter_update 를 참고하세요	0	저의 경우 (최종적으로 원하는 벡터 - 현재 벡터)의 벡터를tf.add()로 현재 벡터에 더하는 식으로 구현하였습니다.	1	mutable tensor 즉 variable만 assign함수를 통해 값을 바꾸는 게  가능합니다. 이건 tensor op이 tensor를 지칭하는 것이 아니기 때문에 그런걸로 알고 있습니다.	0	(torch에서는 구현되어있으나...) scatter op 경우 gradient 계산이 까다로워 TF에서 지원하지 않는게 아닌가 싶습니다. scatter op를 안쓰는게 상책(?)이 결론 같네요.	3	1. update를 안하거나 (가령 input data를 저렇게 만드는건 좋지 않습니다 다른 방식이 분명 있을거에요)2. 꼭 해야한다면 Variable 을 쓰거나3. TensorArray https://www.tensorflow.org/versions/r0.9/api_docs/python/tensor_array_ops.html 를 쓰면 됩니다 (단 적절한 용도에서..)
13	인공지능이 2035년까지 선진국, 총부가가치(GVA) 두배로, 노동생산성 40% 끌어 올린다.- AI가 근본적 작업 방식을 변경하고, 비즈니스 성장을 주도하는 사람들의 역할을 강화시킴으로써
4	랩에서 나온 질문입니다.  Standard한 NN에서는, 제가 아는게 맞다면, 모든 neuron의 output이 activation function을 항상 거쳐서 나오게 되는데, 왜 CNN에서는 상대적으로 nn보다 적은 activation layer만으로 좋은 결과를 얻을 수 있게 되는 것 인지요? 혹시 참고할 만한 레퍼런스가 있다면 부탁 드리고 싶습니다.	2	http://cs231n.github.io/convolutional-networks/
5	페친님들께!강화학습 RL(Reinforcement Learning)의 오차평가 방법을 알고 계신 분은 알려 주세요.Supervised Learning의 Regression 문제와 Classification 문제는 Gradient Descent Algorithm으로 오차를 계산해 나가는 것으로 알고 있습니다.그런데, RL의 경우, 잘 이해가 되지 안네요.오차 평가 방법이 전혀 다른 것 같습니다.Policy-based RL의 경우에는 gradient descent로 parameter를 업데이트하는 것 같습니다.또한 Policy Gradients의 경우에는 score function gradient estimator가 있는 것 같습니다.Policy의 경우, gradient는 아래의 두 가지 기법에 의해서 달리 정의하는 모양입니다.ᆞstochastic policyᆞdeterministic policyDeep Q-Networks에서는 stochastic gradient descent로 오차？(MSE lss)를 줄여 가는 것 같습니다.강화학습의 경우, 오차 기울기를 평가하는 방법을 쉽게 설명해 주는 자료가 있으시면, 부탁드립니다.
3	안녕하세요.파이썬 2를 주력으로 사용해 왔는데요, 이번에 파이썬3으로 갈아타야 되었습니다.Anaconda2에 설치하던 것과 동일한 과정을 거쳐 소스를 컴파일하고, pip3을 이용하여 텐서플로를 설치하였습니다만 문제가 발생하였습니다.pip3이 Anaconda3을 인식하지 못 하는지 /usr/lib/python3 내의 기본 파이썬 패키지 경로에 패키지를 설치합니다.여러 시도를 해 보았으나 꿋꿋하게 아나콘다3을 무시해버리는데요..현업에서 종사하시는 분들께서는 파이썬3환경이 필요하신 경우 아나콘다3이 아니라 파이썬3을 그냥 사용하시는지요?Pip3에 -t /.../anaconda3/lib/site-package를 달아서 아나콘다에 설치한 경우 import가 안 됩니다.조언이 절실합니다. 부탁드립니다.추가로, 아나콘다를 왜 사용하는지도 궁금해졌습니다. pip이 정상 작동할 경우 굳이 아나콘다 없이도 잘 작동하는 것 같아 보이는데요.	1	비슷한 이유로 저는 아나콘다를 쓰지 않습니다. pyenv로 버전 관리해서 2, 3을 쓰는데 이게 더 좋더라구요.	0	python3 버전이 또 있는 듯 한데요. 파이썬은 경로가 아나콘다를 못 보는 것 같아요	0	아나콘다3설치시 pip3이 아닌 pip으로 사용하면 되었던것 같아요.	0	저는 우분투를 쓰니 그걸 기준으로 말씀드리자면일단 기본적으로 파이썬 2, 3이 모두 깔려있구요virtualenv로 가상환경 만들때 -p python3 옵션을 주면 파이썬3을 기본으로 잡습니다.그리고 이 환경 안에서 뭐든 작업을 하면 파이썬3 기준으로 잘 작동하구요.아나콘다같은 경우 얘가 시스템 기본 파이썬의 심볼릭 링크를 잡아먹는 것으로 기억합니다.꽤 불편해지죠. 그래서 저도 아나콘다 안씁니다.	0	일단 아나콘다는 여러가지 복잡한 모듈을 설치할때 자동으로 서로의 dependency를 조절해 주기 때문에 모듈을 추가하다가 생기는 오류 또는 충돌이 발생하지 않아 파이썬을 다시깔거나해야 하는 불편함을 없애줍니다. 우선 가상환경을 사용하시나요? 파이썬2에서 pip은 어떤 경로로 인스톨을 하셨는지	0	http://geek.oops.jp/2016/06/24/install-tensorflow-anaconda/	0	혹시 윈도우에서 설치하셔서 사용하시려고 하시면 http://statlearning.tistory.com제 블로그인데 제가 나중에 참고하기위해 정리한거지만 도움이 되셨으면 좋겠네요.
8	OpenCV 강의 1-7, 소개 마지막 강의 입니다.
4	윈도우10 home 에서 텐서플로를 설치(bash X)하여 예제를 돌려보고 있는데, 로지스틱이나 뉴럴 네트워크 같은 단순한 코드는 문제없이 실행이 되는데 몇몇 에러가 나타나네요. 에러가 비슷한 문제로 인해 발생한 것 같아 그중 한가지를 여쭤보려고 합니다.문제사항) tensorflow.tensorboard 가 "C:\Users\%username%\Anaconda3\Lib\site-packages\tensorflow"경로에 존재하지 않는다고 하여 봤더니 tensorboard 폴더가 생성이 안되어있네요.. 그리고 세개의 폴더밖에 없네요( _pycache_, contrib, core, python) 대신에 tensorflow 설치할때 작업폴더로 설정하고 설치하였던 "C:\Users\HAN\TFwork\tensorflow\tensorflow" 여기에는 tensorboard 폴더가 있네요.(환경변수 설정하면 해결될것 같아서 "C:\Users\HAN\TFwork\tensorflow\tensorflow"환경변수 추가 해주었는데도 안되서 혹시 저와같은 문제를 가지고 계신분이나 윈도우환경에서 아무런 문제점 없이 잘 사용하고 계신분 있으신가요?	0	아래와 같은 에러 입니다.	0	해당 경로에 들어갔더니 tensorboard가 없는 그림입니다.	0	윈도우에서 텐서플로우 설치한 경로로 가서 확인하였더니 tensorboard파일이 있는 것이 확인되어 파일을 에러가 발생한 경로에 복사하여 넣어주었습니다.	0	다시 텐서보드를 실행하였더니 다른 에러가 발생하였습니다.	0	마찬가지로 에러가난 경로에 텐서 보드가 없는것을 확인하였습니다.	0	다시 텐서플로를 설치한 경로에서 tensorboard 파일을 확인하여 에러가발생항경로에 넣어주었습니다.	0	이후 텐서보드를 다시 실행하였더니 다음과 같은 에러가 발생하였습니다. 그리고 설치파일에서도 해당 폴더나 파일을 찾을수 없어서 해결하지 못하였는데, 혹시 mac이나 우분투 사용자 분들중에서 아래와 같은 경로의 파일이 있는것을 확인해주실수 있으실까요?	0	컴퓨터를 잘 알지못하여 이렇게 밖에 시도를 못해보았는데 다른 시도해볼만한 정보를 아신다면 알려주시면 감사하겠습니다.	0	일단 시도해본것으로는 윈도우 배쉬에서 pyenv+virtualenv 로 python3 버전으로 tensorflow 설치하여 tensorboard 보는 방법은 되긴하네요.	0	텐서보드는 아직 안써봤는데 이글 참고해서 해보고 공유하겠습니다.	0	저는 일단 텐서플로 코딩이나 모델링은 윈도우내에서 아나콘다를 이용해서 하고 텐서보드결과를 볼때만 bash에서 텐서보드를 열어서 보고 있는데, bash가 아닌 윈도우내에서 텐서보드 이용에 문제가 없으신분이나 다른 좋은 방법이 있으시면 정보공유해주시면 감사하겠습니다.
3	안녕하세요텐서플로우를 공부하고자 스터디에 참가하고 싶습니다. 혹시 서울 근처에 텐서플로우 스터디 모임이 있나요? 초보자도 참가 가능한?
18	구글 딥마인드 DNC 
1	CNN (googlenet)을 이용해서 image classification을 해보고 있습니다.image dataset은 1360개 그림 17개 카테고리입니다.전체 dataset으로 했을 때 학습이 잘 안되길래 전체 dataset 중 100개를 학습, 10개를 평가하는 것으로 해봤습니다.dataset의 size가 학습에 영향을 줄 수도 있는 것인가요??
1	안녕하세요. 최근에 Faster R-CNN에 관심이 있어서 이것저것 찾아보다가 궁금한 점이 생겨서 글을 남기게 되었습니다.#1.Faster R-CNN 데이터셋을 보면 annotation이라고 해서 bounding box 정보가 들어있는 txt가 있는데, 학습 시키고자 하는 object를 box 해놓은 좌표 정보가 맞는지 궁금하네요.(학습 시킬때는 내부 알고리즘에서 이미지를 box 좌표에 맞게 crop하여 학습시키는건가요?)#2. Faster R-CNN의 데이터셋을 바꾸어서 진행해보려고 하는데요,제가 임의로 생성한 데이터로 학습을 진행하려고 합니다. (Perspective Transform하여 각도를 다르게 하여 한 2000장 정도 만들었습니다. 도로 노면 표시에 대한 데이터셋을 못찾았습니다.ㅠㅠ)문제는 .. 제가 생성한 데이터와 실제 이미지가 너무 다르다는 점인데요.. 언뜻 생각했을 때는 같은 화살표 모양이면 가능하지 않을까? 하는 생각이 들기도 하는데요..ㅠㅠ첫번째 이미지가 제가 학습시키려는 이미지이고 두번째 이미지는 제가 화살표 모양을 검출하고 싶은 이미지 입니다.#3. (2번이 가능한 경우) 학습 이미지의 구성은 검은색 배경에 흰색이 object 인데요, 이런 경우에도 bounding box 좌표를 별도로 잡아줘야하는지 궁금하네요.이미지 detection이나 classification 문제에서는 저처럼 이미지를 생성해서 학습시키려는 경우를 보지를 못했는데요(대부분 이미 있는 데이터셋을 쓰시려는 것 같아서요..), 두 이미지 자체가 너무 달라서 과연 이런식으로 접근하는게 가능한지 궁금합니다. 불가능하다면 다른식으로 접근해보려고 하는데요, 많은 분들의 조언을 부탁드리겠습니다.	1	네. Annotation은 해당 클래스의 bounding box 이구요 train할 때 crop해요. imdb랑 factory.py 보시면 잘 나와 있을겁니다.
37	엔비디아, 암 연구 가속화 AI 플랫폼 ‘캔들(CANDLE' 개발!- 美국립암연구소, 에너지부와 협력해 10년이 걸릴 암 예방, 진단 및 치료, 5년으로 단축
2	안녕하세요, translation 등에 사용되는 sequence training과 관련해서 질문이 있습니다.예를 들어, English-French translation을 한다고 하면 직관적으로는 사전 혹은 DB를 기반으로 training을 할 것인데요.이렇게 하면 training data와 유사한 test data에 대해서는 잘 동작하는 것으로 보입니다.하지만 실제 test 시에 "(1) English가 아닌 input이 들어오는 경우(숫자, 괄호, 특수문자 등과 같은 사전에 없는 문자들 & English가 아닌 다른 언어), (2) English input에 typo가 있는 경우"에도 robust하게 동작하도록 하는 방법이 있을까요? 두 경우 모두 training data와 다른 test data가 들어올 때 입니다.(1)에서는 test 시에 translation 하지 않고 그냥 내보내면 될 것 같은데, training set에 포함되지 않는 미래의 input들을 어떻게 training 시에 고려할 지 궁금합니다..(2)는 correction->translation을 같이 해야할 것 같은데요, 혹시 모델에서 RNN/LSTM 등 외에 추가로 고려해야 하는 구조가 있다면 조언 주실 분 있는지요.. (LSTM만 사용하고 training 시에 noisy data를 추가하면 잘 되는 것인지..)	0	typo를 unseen data라고 생각한다면, 이러한 문제는 character기반의 모델로 접근하면 해결이 될 것 같아요. 관련 논문 첨부할께요.http://www.di.ens.fr/~bojanowski/papers/bojanowski16alternative.pdf(호진아 오랜만이야 ㅎ)
5	오랜만에 질문 하나 드리려고 하는데요,simple한 CNN에서 각 layer의 output에 간단한 operation을 추가한 이후에 그것을 다음 layer의 input으로 들어가게 하고자 합니다간단한 예를 들면 1st conv layer의 출력이 [batch_size, 64, 64, 32]라고 하면, ( 첫번째 feature map이 64x64x32 인 상황을 가정) 이 32개의 feature map들끼리 차이를 구해서 그것을 다음 layer의 output으로 넣고 싶은데요.... (차를 구하니까 다음 단 입력은 64x64x31이 되겠지요...)어떻게 하면 될까요? 단순히 code가 아래와 같이 되어 있다고 가정하고 있습니다conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w1, strides=[1, 1, 1, 1], padding='SAME'), b1)pool1 = tf.nn.maxpool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2 ,1], padding='SAME')예상하시겠지만 x는 128x128, w1은 3x3 convolution filter 32개 입니다.pool1 다음에 어떻게 하면 원하는 operation을 추가할 수 있을지 고수님들의 도움을 구합니다 ㅠㅠ	0	import tensorflow as tfbatch_size = 1000x = tf.Variable(tf.random_normal([batch_size, 128, 128, 1]))w1 = tf.Variable(tf.random_normal([3, 3, 1, 32]))conv1 = tf.nn.relu(tf.nn.conv2d(x, w1, strides=[1, 1, 1, 1],\        padding='SAME'))pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2 ,1],\        padding='SAME')feature_difference = []for i in range(31):    feature_difference.append(pool1[:, :, :, i] - pool1[:, :, :, i + 1])print feature_difference[0].get_shape().as_list()	0	일단 이렇게 하면 difference를 계산할 수 있을 것 같은데요. feature_difference[0]부터 feature_difference[30] 까지 64x64 텐서가 저장되는 걸 확인 가능합니다.	0	64x64x31으로 만드려면 추가적으로 tensor를 합쳐주는 작업을 해야될텐데 이 역시 구글링해보시면 찾으실 수 있을 겁니다.	0	Wonseok Jeon 감사합니다~!
3	질문 삭제합니다. 제가 봐도 이해하기 어렵게 적은것 같습니다. 답변주신 분들 감사합니다.문제는 복잡하게 해결하긴 했습니다. 향후라도 tensorflow로 back-end 구현하시다가 문제 생기면 연락부탁드립니다.^^	1	Python 기반으로 back-end를 구성 하시는 건가요? 저도 시도 해보려하는데... 기대됩니다.저는 flask와 websocket을 가지고 구성을 하려고 준비하고 있거든요.	2	무엇을 하시려는지 명확히는 와닿지 않습니다. 일반적인 사항과 저의 경험만 말씀드리겠습니다. 일단 아키텍처를 supervisor + 로드발란서(nginx,play, tomcat 등) + 웹프레임워크(tornado, django 등) 으로 잡는 것이 python 쪽에서는 일반적입니다. 저 같은 경우는 python의 tornado로 로드발란서 구현/테스트 작업이 잘 안되서 java로 된 play framework를 이용해서 구현했습니다. 도움이 되셨으면 좋겠습니다.
3	안녕하세요 tensorflow, opencv를 이용한 이미지분석을 공부하고 있는학생입니다. 지식이 아직 부족하고 참고할만한 reference에 대한 정보도 부족해서 여쭤보려고 글 올립니다. 혹시 참고할만한 서적이나 강의가 있을까요?또 코세라에서 진행하는 다프네콜러 교수님의 Probabilistic Graphical Model 수업을 수강하고자 하는데 혹시 들어보신분 계신가요??
97	[Keras Tutorials] https://github.com/tgjeon/Keras-TutorialsKeras tutorial을 하나씩 만들고 있습니다. nlintz github (https://github.com/nlintz/TensorFlow-Tutorials)을 참고로 하나씩 keras로 바꿔보고 있습니다. 같이 비교해서 보시면 좋습니다. 일단 CNN까지는 소스와 노트북 파일을 업로드 했습니다. 나머지는 시간나는데로 작업해서 올려놓겠습니다. 혹시 같은 내용으로 작업중이신분이 계시면 소스 올려주시면 감사합니다 :) 실행해보기 힘드신 분들은 노트북 파일만 보셔도 됩니다. [딥러닝 용어사전] https://github.com/tgjeon/Keras-Tutorials/blob/master/DeepLearningGlossary.mdwildml.com에서 올라온 용어사전을 한글로 정리하고 있습니다. 저자인 Denny Britz의 동의를 구했습니다. 차후 tensorflor-kr 문서에 도움이 될까해서 작업중입니다. 추가되면 좋겠다 하시는 용어가 있으시다면 알려주세요. 뜻이 있으신 분들은 같이 만들어보면 좋겠습니다. * keras를 쓰면서 느낀 점1. 모델에만 집중 할 수 있다.  - 모델 작성이 용이하다.  - epoch, mini-batch를 이용한 학습이 단 한줄에! - model summary 기능이 좋습니다. (네트워크 전체 구조, 파라미터수, shape) 한번에 확인 가능. 2. TF와 섞어서 사용하기 - 새로운 레이어,  loss 함수를 구현해서 붙이기 용이합니다.3. scikit-learn 호환성 - 지금은 딥러닝 모델만 써도 성능이 탁월하지만, 다른 머신러닝 모델과 합쳐서 쓰거나, 같은 환경에서 비교해야할 경우에 좋습니다. 이부분은 따로 정리해보도록 하겠습니다.	0	이건 또 뭐야 ?  ㅠㅠ	0	감사합니다	1	keras 쉽게 참고할만한 문서나 웹사이트가 있을까요?^^	1	저도 keras가 main인데요. 워낙 간단하게 짤 수 있어서 정말 생산성이 좋은 것 같습니다. 더 널리 사용되면 좋겠습니다. ^^	1	감사합니다! ㅋ 이번 기회에 Keras를 제대로 한번 파보도록 하겠습니다 ㅋ!	1	응원합니다	1	기대하고있습니다. ㅎㅎㅎ 디텍션도 부탁드려요. :)	2	으헝헝~ 저는 주피터 노트북으로 만들고 있었는데~ 제껀 근데 다들 어디서 주워온 부분들이 많아서요 ㅎㅎㅎ 제 것도 다음주 중에 공개할게요~ 참고할 수 있는 자료가 많았으면 좋겠습니다. 화이팅!	1	tf slim보다 간결한 구조같네요	1	word2vec을 제외한 나머지는 모두 업로드 되었습니다.
21	엔비디아, 마이크로소프트와 AI 가속화 위한 협력 발표- GPU 가속 MS 코그니티브 툴킷, MS Azure에서 클라우드로, 엔비디아 DGX-1에서 온프레미스 방식으로 제공
1	CNN 학습과정에서 parameter를 잘못 넣어주면 training 할 때마다 accuracy가 떨어질 수도 있나요??	0	learning step이 충분히 작지 않으면 그럴 수도 있어요
1	안녕하세요 텐서플로우 버전 r10 (gpu) 을 아나콘다와 함께 설치해서 사용하고 있는 유저 입니다.r-11버전으로 업데이트 해야하고싶은데. 어떻게 해야할까요?다시 설치하는게 최선의 방법일까요?버전업을 하려는 이유는 아래와 같습니다.(컴퓨터2대가 있는데한대에는 r-11 gpu로 다시 설치했는데,문법적인부분에서 r-11이 바뀐 점이 좀 있더라구요(쓰는 방법만 변경된듯 합니다.)tensorboard 또 tf.summary. 이런식으로 바꼈고..).	1	릴리즈 노트에 있군요.	0	그냥다시깔러갑니다‥먼가어긋나네요?? 우분투에서 텐서플로우나Theano는 설치가쉬우니재설치ㄱㄱ	0	업데이트 하는순간 작동 안되요...
7	여기 고수분들께 물어봅니다.지방 사립대 학사과정 3학년 밟는 중인데, 최근에 머신러닝과 텐서플로우에 관심이 생겨 이리저리 알아보던 도중, 저희 학교보다 레벨이 좀 더 높은 국공립 공대 교수님과 만날 기회가 되어 텐서플로우에 대해 물어봤는데 항상 해주시는 답변이 "그런 건 대학원 가서 입문해야한다."라는 거였습니다.(여기서 반전을 말하자면, 그 교수님은 인공지능이 주 전공이셨습니다;;;)어차피 19일 부천에서 열리는 GDG DevFest 참관을 할 거지만(프로그램 중에 텐서플로우 기초 설명이 들어있더라고요^^)도대체 텐서플로우라는 녀석의 진입장벽이 얼마나 높길레 대학원을 언급하는지 궁금합니다.	6	그냥 프레임워크를 만지작하는 것은 예제나 책 강의 등으로도 충분히 가능합니다. 다만 그 이상으로 본인이 당면한 문제에 대한 해결로써 딥러닝을 적용하려면 충분한 배경적 지식이 있는것이 좋을듯합니다	2	저는 과정에 왕도는 없다고 생각합니다. 진행하다가 막히는 부분이 있다면 그부분을 채우면서 계속진행해 나가면 되지않을까요? ㅎ 정말로 재미를 느끼신다면 도전해보시는걸 추천드립니다.	0	대학원 필요없죠	0	딥러닝의 원인을 이해하는것도 물론 중요하지만 이제는 딥러닝 프레임웤도 일종의 라이브러리로써 연산이나 배경등은 라이브러리에 맞겨버리고 실용성 위주의 Usage같은걸 습득하는것도 나쁠거없다 봅니다. 사양은 말씀하신사양으로디 학습에는 문제가 없을것 같구요 클라우드상에서 돌려볼수있는 환경도 많습니다 ㅎㅎ 대학원 가서 입문할필요는 없어보입니다 ㅎㅎ 나이와도 무난하게 중고등학생들도 요즘 써먹더라구요... 전 평범함 개발자입니다만 ㅠ	0	저도 전공은 안했지만 회사 다니면서 틈틈히 공부하고 있습니다. 장비는 좋지 않지만 (GTX 960) 작은 프로젝트를 정해서 해나가기에는 충분했습니다. 딥러닝 프레임워크를 만들것이 아니라면 대학원 나오지 않아도 충분히 가능하다고 생각합니다.	1	교수님이셔서 그런 것 같은데요. 실무에서 사용하시는 분들 물어보면 그런 이야기 안 하실 듯..	0	라즈베리파이 같은 임베디드 머신에서도 도는데 돌리는데야 컴퓨터가 문제는 아니죠. CS전공하신거 같은데 친한동생이 이렇게 물어보시면 뭐라고 하시겠습니까 "형 vi가 좋아요 emacs가 좋아요? gedit가 좋아요? 아니면 요즘 가상화가 이슈라는데 vmware써서 울트라에디트 돌리는데 익숙해져야 할까요?"텐서플로우건 caffe건 torch건 머신러닝(딥러닝에 특화된) 프레임 워크뿐인데....	1	교수분은 아마도 인공지능/머신러닝/딥러닝에 대한 배경지식과 학문에 대한 세부전공을 공부할때 텐서플로우나 Caffe등의 프로그램을 다루게 되니 그렇게 말씀하신 듯 합니다. 배경지식에 대해서는 독학으로도 충분히 가능은 합니다. 요즘 서적들도 잘 나와있으니 참고해 보세요. p.s. 텐서플로우 등을 사용하기 위해 하드웨어 사양을 갖출 필요는 없습니다. 노트북으로도 개발 가능합니다. 단, 결과가 데이터양/네트웍의 크기에 따라 아주 늦게 나올 수도 있죠.	6	학부때는 배경지식을 배우고  머신러닝은 대학원에서 배우라는 교수님의 충고입니다.	1	저번주에 저도 똑같은 이야기를 서울 소재 사립대 공대 4학년 학생에게 해주었어요. 저녁에 고기사주면서..  한번 말하면 이해 못하고 반발심이 생길까봐.. 조심하면서요.	3	cnn을 돌려본 학부생이 머신러닝 책  한권 보지않았고. gpgpu가 뭔지도 모르고. linux.sql.statistics.도 배운적이 없고... 기초지식은 자바밖에 없더라고요. 어디서부터 시작하라고 해야할지 막막했죠. 근데 프로그램 만큼은 너무 잘해요. 줏어들은것도 너무 많고.	2	ㅎㅎㅎ. 파이썬 기초부터 차근차근 공부하세요.  알아야 할게 많아요	2	학부때엔 기초 수학만 해도 충분합니다. 텐서플로우는 아무때나 배울 수 있지만, 기초는 학부때 외엔 배우기 힘듭니다. 그런 툴들을 너무 일찍 접하다가 테크트리 꼬인 사람을 많이 봐서 ;;; 한 번 지나가면 다시는 되돌릴 수 없죠. 당장 현업에서 쓸 일 없다면 텐서플로우는 나중에 배우는게 낫지 않나 싶네요.	6	그 교수님에게 앞으로 묻지 마세요~	5	컴공 학부 전공하고 직장 생활 10년 다 되가는데요.. 튜토리얼을 아직도 마스터 하질 못하겠네요. 6개월쯤 했습니다. 진입장벽이 무척 높습니다. 아직 전문 학문 분야에 가까워서... 교수님 말씀도 일리가 있지만, 책을 꼭 1장 1절부터 보란 법 있습니까 ^^ 마음가는대로 멀리 돌아가더라도 돌아가면서 본 풍경들 나중에 다 뼈가 되고 살이 됩니다. 오늘 하루 이해 못한 것들 계속 파다보면 보입니다. 열심히보다 부지런히 공부하시면 길이 보일 거라 믿습니다.	10	혼란을 틈타 제가 머신러닝 공부하고 정리해놓은 블로그 링크하고 갑니다 👀저도 혼자 공부했어요http://gnujoow.github.io/category/#ML입문은 대학원가서 해야한다는 말에는 동의할 수 없지만 해당 분야에 대해 깊은 인사이트가 생기길 원하신다면 대학원도 좋은 선택지라고 생각합니다.	0	학부생 사학년으로서 유튭이랑 (제 기준) 정말 많은 영어 문서를 읽으시면- 논문에 나오는 모델들 따라 만들기- 남의 코드 조합해보기... 정도는 가능 하고- 어떤 태스크에 대해 기존 모델보다 효율이 뛰어난 모델 설계하기... 는 어렵지 않나 싶습니다기본적인건 생각보다 할만해요><	2	아마 교수님이 텐서플로우만 이야기 하신것 아닌것 같습니다. 데이터엔지니어링과 분석을 이해하고 딥러닝으로 현업에 뛰어드는 부분을 포괄적으로 이야기 해주신게 아닐까 싶습니다.저도 현업자 분들이나 멘토들께 이야기를 들으면 대학원에가라는 이야기를 많이 들었습니다. 하지만 ... ^^;	1	학사 졸업했습니다만, 실무에서 써야하는 일이 생기면... 어떻게든 씁니다	4	CS전공자는 아니나 조금은 현실적인 이야기를 해보겠습니다. 1. 대학원에서 배우는 내용이 무슨 소수의 선택받은 자들에게만 전해지는 우주의 비밀 같은건 아닙니다. 그러나 석사는 "필요한 부분을 논문으로 찾아보는법"을 배우고, 박사는 그 내용을 바탕으로 새로운 주제를 구성하는법을 배운다고 생각하시면 됩니다. 현업에서야 스택오버플로우와 깃허브만 뒤질줄 알면 뭐든지 할수 있다! 라고 하지만 의외로 저런 연습이 되지 않은 분들은 헤메는 경우가 있습니다. 2. 두번째로 지방 사립대 학부출신에게 머신러닝, 딥러닝을 제대로 다룰 기회가 주어질지 의문입니다. 네 학교이름이 아니라 실력만 있으면 되는거 맞는데요, 그 실력자체를 증명할 기회가 없습니다. 3. 반대로 텐서플로우가 핫한 툴이라고 하니 이거 하나만 잘 배워놓으면 먹고살지 않을까 생각하는 분들이 계신다면, 불과 일년여 전만해도 딥러닝의 대세가 무었이었는지 찾아보느시는것이 좋을것 같습니다. 가끔 정말 패키지 하나 사용법만 제대로 익혀도 먹고 사는 분야가 있으나, 딥러닝은 아직 너무 초기라 그런 결정판적인 툴이 없다는점. 다시한번 말씀드리고요...	1	여담이지만 결국 현업을 오래하게되면 기초가 얼마나 탄탄한가는 얼마나 고급 엔지니어로 성장해 나갈 수 있는가로도 영향을 미치게 됩니다. 기초를 배울 수 있는 시기가 지나버리면 다지기도 어렵고 가장 중요한 디딤돌 입니다. 괜히 구글같은 일류 기업에서 경력 입사 시험에서조차 서칭이나 정렬 알고리즘을 손코딩으로 시험보는게 아닐까 하네요.	0	대학 1학년 수준의 통계와 미적분, 선형 대수학을 알면... 금방 하실 수 있습니다..	1	남들이 뭐라고 하건간에 자신이 진정으로 원하는 것인지 여부가 중요하지 않을까요? http://daeson.tistory.com/category/Tensorflow 이런거 한번 읽어보시고 막히는 부분이 있으시면 그걸 또 찾아보면서 나아가는거지요..화이팅~	2	교수님 말씀은 아마 텐서플로우를 배우는게 문제가 아니라 넓게는 인공지능, 좁게는 기계학습에 대한 기초 지식이 필요하다는 말씀일 겁니다. 텐서플로우는 기계학습을 하기 위한 단순한 툴일 뿐입니다. 툴을 배우는걸 목적으로 하시면 안되죠. 기본 백그라운드가 있으면 텐서플로우든, 카페든 어떠한 툴들이 나오더라도 사용법만 익히면 쉽게 적용가능 한거죠. 넓게 보셔야 합니다.	0	관련된 지식이 너무 많아서 관련 기초부터 잘 쌓으시는게 중요한것 같아요.  정말 정확하게 이해해야 코딩을 할수있다고 생각하거든요. 저는...	2	개인적으로 통계, 고급통계분석, 데이터마이닝 기초부터 탄탄히 해 두시기를 추천드립니다.  몇몇 분들은 통계는 머신러닝에서 필수가 아니라는 말에도 동감합니다만 알아두면 편리할 때가 많습니다. 문제해결을 위해  Neural network만 사용하실 것은 아니니까요.	2	관심이 있으면 주도적으로 공부하시길 추천합니다. 물론 지금 배우고 있는 과목들 탄탄히 공부하는 것도 매우 중요합니다. 그렇지 않으면 나중에 깊이 들어갈 때 막혀서 어차피 다시 공부해야되요. 머신러닝에 대해 알고 싶으시다면, coursera 등의 오픈렉쳐 수업으로 기초를 미리 공부하고 툴 하나 정해서 튜토리얼 따라해보고, 새로운 데이터 수집해서 새로운 모델도 만들어보세요.	1	텐서플로우가 문제가 아니라 딥러닝 이론을 제대로 이해하는 것이 선과제 입니다. 도구는 도구일뿐 원리를 모르면 아무 소용이 없습니다. 비전공자가 딥러닝 이해하기 쉽지 않습니다.
4	1. tensorflow로 작업하실 때 ipython notebook vs pycharm  뭘 더 주로 쓰시나요?? 궁금해서 올려봅니다~!!2. tensorflow와 같이 쓰시는 라이브러리 (sugartensor 같은)게 있다면 추천부탁드리겠습니다	1	1. matplotlib로 figure를 그려야할 때는 Jupyter notebook, 그 외에는 pycharm 사용합니다.2. scikit-learn, pandas, numpy, matplotlib	1	keras요!	2	v.....i......	1	양쪽모니터에 둘다 켜놓고 주피터는 코드잠깐잠깐 확인용으로씁니다Numpy matplotlib 등등 을씁니다	1	Vim!	1	pycharm에서도 .ipynb 파일을 볼 수 있더군요. 실행, 자동완성이나, 변수참조 점프 같은것도 되고	0	저는 sublime text !!
111	얼마전 모 대학에서 CNN ( 그 외 약간 더 ) 에 관해 강의했던 슬라이드 공유 드립니다.  ( 한 학기 분량을 2시간만에 할려니 힘들더군요. ㅠ.ㅠ )	1	Yohan Jeong	1	모대학에 와 주셔서 감사드립니다.	0	초보자들에게 진입장벽의 높이를 줄여줄 수 있으 훌륭한 자료인것 같습니다. 이거 음성 설명이 첨부되어 배포된다면 좋을 것 같습니다. 언제 시간되시면 부탁드립니다.  ^^
1	안녕하세요, 우분투와 텐서플로우를 사용한지 얼마 안된 학생입니다.고수님들께 여쭤보고 싶은 것이 있어 글을 게시합니다.현재 컴퓨터에 anaconda로 jupyter notebook 서버를 설치한 뒤, 원격으로 jupyter notebook을 사용하고 있습니다.jupyter notebook을 이용하여 원격으로 텐서플로우로를 사용하고 싶어서 pip 방식으로 텐서플로우를 설치하였는데, 설치가 되지 않아 anaconda 방식으로 설치를 하게 되었습니다. 그런데 기존의 jupyter nootbook에서 import가 되지 않아 어떻게 해야 jupyter nootbook에서 사용할 수 있는지 여줘보기 위해 글을 게시합니다.감사합니다.(제가 초보자라 혹시 추가 작업 관련 자세한 자료를 알고 계시다면 링크를 부탁드립니다.감사합니다.)	1	jupyter는 jupyter 커널 스펙에 명시된 커널만 사용하는데 명시된 해당 커널에서 설치하신 python package 를 참조 하지 않는것 같습니다. 해당 커널에 설치하신 python package 를 링크하거나 커널위치를 바꾸시면 될것 같습니다.
8	Resnet 50을 이용해 ensemble을 구현해 봤습니다. 정말로 잘되는지 궁금했는데 효과가 있네요.
41	https://www.youtube.com/watch?v=YOyYghuXvU0http://bi_matrix.blog.me/220743649568제가 2년 전에 동료분들과 만든 R 기반 데이터 마이닝 분석 툴입니다. work flow를 작성하면 내부적으로 R 코드를 생성 및 실행하여 그 결과를 UI를 통해 볼 수 있습니다. 최근 tensorflow를 접하다 보니,아래 솔루션과 같이 작업을 work flow 형식의 그래프로 그리고, 작성한 그래프에서 tensorflow 파이썬 코드를 생성하고 실행시키면 좋겠다는 생각을 해봅니다 .
2	안녕하세요. 시리나 기타 챗봇같은 것들을 보면 질문에 대해서 가지고 있는 정보로 문장을 매끄럽게 만들어서 답을 해주던데 여기서 정보를 바탕으로 문장을 만드는 것(작문?)에 대한 검색키워드, 논문이나 책, 혹은 사이트에 대한 정보좀 알려주시면 감사하겠습니다. 언어는 한글과 영어 둘 다 할 생각입니다	1	http://pt.slideshare.net/mobile/inureyes/chat-bot-making-process-using-python-3-tensorflow	1	Generation Factoid Questions With Recurrent Neural Network The 30M Factoid Question-Answer Corpus이번 ACL2016에서 발표된 논문으로 Freebase정보를 통해 질의를 만들어주는 내용의 논문입니다. 이거와 같은 방법으로 하시면 꽤 도움이 되실듯 하네요.	0	답변달아주셔서 감사합니다!
0	안녕하세요! 그룹에 가입하고 첫 질문이네요!이번에 제가 선형회귀분석 코드를 짜면서 퍼포먼스를 조금이나마 높혀보려고 텐서플로에 있는 멀티스레드 옵션?을 써 봤습니다.s = tf.InteractiveSession(config=tf.ConfigProto(intra_op_parallelism_threads=4))그런데 그냥 s = tf.InteractiveSession() 이렇게 세션을 생성한 것 보다 훨씬 더 느리게 작동을 합니다혹시 왜 더 느리게 작동하는지 이유가 무엇일까요??   ㅠㅠ참고로 tensorflow는 r0.11 - cpu only 버전 입니다	1	텐서플로우는 원래 디폴트로 멀티쓰레드를 사용하는걸로 알고있습니다. 제 컴퓨터가 우분투16.04에 14코어 28쓰레드인데 코드를 실행하면 터미널에서 htop으로 쓰레드를 확인하면 전부 사용되더라구요. 원래 쓰레드보다 더 적게 사용해서 그런건 아닐까요?
1	[스터디 공지] 딥베이직 : 파트 1 - 2회차- 딥러닝을 위한 완전 기초 스터디* 일시 : 11월 22일 화요일 저녁, 7시 - 10시 30분, 강남 * 공간 이용료 있음(4회 공간 이용료 한꺼번에 걷을 예정입니다. 자세한 내용은 이벤트창 참조)*스터디 내용(네트워크분석 기초) 5 Effective Network Graphic Design / 6 Advanced Network Graphics(파이썬 기초) 3 파이 채우기: 리스트, 튜플, 딕셔너리, 셋 / 4 파이 크러스트: 코드 구조 (딥러닝+tensorflow 기초) Logistic (Regression) Classification / Softmax Regression (Multinomial Logistic Regression) / ML의 실용과 몇가지 팁(파이썬 ML 기초) Ch6: Learning Best Practices for Model Evaluation and Hyperparameter Tuning- 완전 기초부터 시작하며(파이썬 기초, 머신러닝 기초, 네트워크 분석 기초, 모두의 딥러닝+텐서플로우) 누구나 함께 하실 수 있는 취미 모임입니다.- 참여를 원하시면 이벤트에서 참석을 누르시거나, 댓글을 다시거나, 바로 찾아오시면 됩니다.이벤트창 : https://www.facebook.com/events/223638108058788/
7	시만텍, 인공지능(AI) 탑재한 ‘시만텍 엔드포인트 프로텍션 14’ 출시- 방대한 데이터 분석에 기반한 머신러닝으로 탐지 성능 효율화
14	머신러닝에서 요즘 핫하고 퀄리티 좋은 해외 원서 추천부탁드려요 :)https://www.amazon.com/Real-World-Machine-Learning-Henrik-Brink/dp/1617291927/ref=sr_1_1?ie=UTF8&qid=1479102749&sr=8-1&keywords=real+world+machine+learning몇개 아마존에서 찾아봤는데, 이 책 어떤가요..?	5	이 책 좋습니다. - https://www.amazon.com/gp/product/1783555130/
2	음성인식 시스템 구현 및 적용을 위한 전문가 과정 세미나 개최- 'AI 대화형 음성인식(시리) 시스템 개발기술', '음성인식을 통한 IoT 제어기술 및 지능화 서비스' 등
2	음성인식 시스템 구현 및 적용을 위한 전문가 과정 세미나 개최- 'AI 대화형 음성인식(시리) 시스템 개발기술', '음성인식을 통한 IoT 제어기술 및 지능화 서비스' 등
143	안녕하세요 ㅎㅎ TensorFlow KR에는 글을 처음 써보네요! 제가 듣는 대학원 수업에서 발표한 TensorFlow Tutorial 슬라이드와 소스코드 공유합니다 ㅎㅎ내용은 거의 "텐서플로 첫걸음" 책을 요약한 것입니다 ㅎㅎ 소스 코드도 거의 책의 예제 코드에서 가져왔구요.슬라이드의 특징은:- MNIST CNN 예제 코드를 그림으로 이쁘게 그림!- TensorFlow의 MNIST CNN 예제 코드와 동일한 NN을 TFLearn를 사용하여 구현해봄!이렇게 두 가지 정도입니다 ㅎㅎ누군가에게 도움이 되었으면 좋겠습니다. 감사합니다.SlideShare:http://www.slideshare.net/JunKim22/tensorflow-tutorial-68885890Jupyter Notebook source code:https://github.com/uosdmlab/tensorflow-tutorial	1	와우! 감사합니다 ~~	1	최근에 텐서플로 첫걸음을 읽고 있는데~ 도움이 되겠네요^^	2	후배네요. ^^ 자료 잘 봤습니다.	1		0	이거 타이틀 글씨체 뭔지 알수있을까요~?
14	혹시 실제 서비스 중인 모바일 앱에서 텐서플로우를 활용하여 앱의 기능을 향상시키거나 새로운 기능을 추가해서 좋은 결과 혹은 재미있는 결과를 내신 분 계신가요? 추천도 좋습니다~ 답글 혹은 메시지 부탁드립니다. 좋은 일이 있을 것입니다. :-)	0	안드로이드에서도 '된다'라는 글은 간혹 보았는데 정말로 서비스 운영까지 정상적으로하시는 분이 있는지 저도 정말 궁금합니다.	0	내앱찾기 라는 앱에서 영어앱이름을 한글로 검색할 수 있는 기능을 텐서플로우로 활용해서 만들었습니다.
3	안녕하세요. LSTM 을 이용한 모델을 하나 구현하고 있습니다. 다름이 아니라. LSTM에서의 model evaluation 에 대한 궁금증이 있습니다. 어떻게 LSTM 모델에 initial state 를 feeding 할것인가에 대한 이야기입니다. official tutorial 에서는 cell.zero_state 를 이용해 처음 initial state를 설정하고 dynamic_rnn 에 initital_state에 해당 zero_state 를 넣어주고 있습니다.대략 코드는 다음과 같습니다.cell = tf.nn.rnn_cell.GRUCell(hidden_size)cell = tf.nn.rnn_cell.MultiRNNCell([cell]*self.num_layers)self.init_state = cell.zero_state(self.batch_size, tf.float32)state = self.init_stateoutput, state = tf.nn.dynamic_rnn(cell, x, dtype= tf.float32, initial_state = init_state)이제 제가 지정한 time_step 만큼 dynamic_rnn 이 unroll과 inner cell multiplication 을 끝내면 state 변수에 마지막 hidden 값을 리턴해줄것입니다.여기서 제가 알고 싶은것은 tf에서 권고하는(혹은 일반적인) 새로운 initial_state를 feeding 하는 방법입니다. 가령 training 시기에는 batch_size가 1보다는 큰 어떤 정수일것입니다. 다만 validation 이나 testing 의 경우에는 배치의 크기가 1인 형태로 바꾸어야 할것이고. 이경우에 모델에 어떻게 피드를 하는것이 가장 일반적인 방법인지 궁금합니다. 제가 구현한다면, 저는 아마도 init_sate = cell.zero_state(1,tf.float32)로 다시 선언하고 dynamic_rnn 에 다시 부어줄것 같습니다.	1	feed 의 배치사이즈 디멘션을 None으로 만들고 tf.shape(tensor) 를하면 만든 텐서의 차원이 리스트로 나옵니다. 배치의 디멘션이 0이었다먼 tf.shape(tensor)[0] 를하면 0차원의 크기 텐서가 반환되며 zero_state 함수에 인풋으로 넣어줄 수있습니다.위와같이하시면 모델은 어떤 배치사이즈도 받을 수 있습니다.
3	안녕하세요. 머신러닝에 관심이 많은 개발자 입니다.요즘 Tensorflow로 seq2seq 를 테스트하고 있는데요 궁금한 점이 해결되지 않아서 조언을 부탁드리고자 합니다.날씨데이터가 사회에서 발생하는 이벤트와 무관하지 않다고 생각을 해서  특정이벤트와 날씨를 결합하여 데이터셋을 만들어서 모델을 생성하면, 내가 원하는 날씨의 조건을 입력하면 특정 이벤트에 대한 결과를 받아볼 수 있지 않을까라고 가정을 하고 테스트를 하고 있습니다.회귀나, 베이지안을 이용하는 통계적 기법류를 테스트를 생각해 볼 수 있다고 판단하지만, 딥러닝을 이용해보고 싶기도하고, 해결할 수 있을 것이라 생각하고 진행하고 있습니다.그런데, 테스트를 하다가 가만히 생각을 해보니, 기온과 온도와 같은 숫자형 데이터는 순서대로 나열하여 트레이닝을 한다고해도 의미를 가질 수 없겠다는 생각이 들더라고요. 이렇게 기온이나, 습도등 값이 중요한 의미를 가진 경우에도 seq2seq를 적용하는 것이 적절할까요?조언 부탁드립니다.고맙습니다.	2	그냥 생각일 뿐이니 참고만 하시길... 습도는 온도와 이슬점에 의해 결정되는 값이기 때문에 기온과 습도의 경우 국소적으로는 다른 데이터 같지만 거시적 관점에서 보면 correlation이 굉장히 강한 값입니다. 연주기를 갖고 있는 특징도 있고요. 그래서 그 데이터만으로 학습시키면 재미있는 결과는 덜 나올듯 하고요, 다른 조건을 더 넣어보시면 재미있는 결과가 나올 수도 있겠다는 생각이 듭니다.
5	간단한 것 같지만 갑자기 알쏭달쏭해져서 여쭈어봅니다. 저는 data augmentation에 관심을 가지고 있었는데요,Tensorflow CIFAR-10 example에서 data augmentation 목적으로, training image를 읽어올 때 translation (cropping), horizontal flipping, 그리고 아래를 수행합니다.,distorted_image = tf.image.random_brightness(...)distorted_image = tf.image.random_contrast(...)float_image = tf.image.per_image_standardization(distorted_image)random_brightness와 random_contrast은, 제가 이해하기로는, 랜덤한 delta를 뽑되, 결국 모든 픽셀에 delta를 더하는 것 같습니다.이어지는 per_image_standization은 zero mean 과 unit variance 를 만드는 과정인데, 상수값을 모든 픽셀에 더하는 앞의 과정은 결국 전혀 영향이 없을 것처럼 생각됩니다. 제가 무엇을 놓치고 있는건가요?	1	tensorflow 공홈의 설명을 보면 contrast_factor를 랜덤하게 뽑은 후에 아래 식으로 계산합니다. (x - mean) * contrast_factor + mean. 단순히 상수를 더하는 과정이 아니네요^^	0	안녕하세요! 잘 지내시죠 :) 네- 제가 contrast 는 읽어보지 못하였네요. 죄송합니다 ㅠ 곱하는 과정이 있어도 unit variance 부분이 역시 또 영향을 없게 만들지 않나 생각해보고 있습니다. 여전히 개운치가 않아서 한번 해보고 말씀드려야겠네요 ㅎ 감사드립니다!
15	안녕하세요 딥러닝 입문하는 학생입니다.머신러닝에 대한 기본지식을 가진 채로 딥러닝 입문책을 사려하는데 두 가지를 고르게 되었습니다만 지갑사정으로 한 가지만 사야할 거 같아서 이 커뮤니티 멤버분들의 추천을 부탁드리게 되었습니다텐서플로 입문 예제로 배우는 텐서플로(http://book.naver.com/bookdb/book_detail.nhn?bid=11185338)그리고 텐서플로 첫걸음 회귀분석, 군집화, 합성곱 신경망까지 딥 러닝 제대로 입문하기(http://book.naver.com/bookdb/book_detail.nhn?bid=10961940)이 둘중 하나라도 읽어보신분들의 추천을 부탁드리겠습니다!	3	중수야 잘지내지?ㅋㅋ아래책은 https://tensorflowkorea.wordpress.com/2016/04/28/first-contact-with-tensorflow/ 에서 책과 완전히 같지는 않지만 한글화해놓은 문서가 있는데 훑어보고 괜찮다 싶으면 책을 사도 될듯~~	0	헉 잘 지내고있습니다 ㅋㅋ 가끔 페북에서 소식 보고있습니다 감사합니다	1	둘다 아닙니다. 내년 2월에 새로운 책들이 나오니 조금 더 기다리셔도 될 듯 합니다.	2	3달을 공부안하고 기다리는 것보다 입문이라도 한글문서로 한 다음부턴 원어라도 문서를 찾아서 공부하는게 나을거 같아서 그렇습니다 ㅎㅎ 답변 감사합니다	0	이쪽으론 까막눈인데 입문해보려고 두번째 책으로 보고 있는데 일단 책이 얇아요.코드에대한 자세한 설명이나 지도는 별로 없어요.그래도 첫 입문서로써 별 두개는 주고 싶네요.	0	머신러닝에 대한 기본 지식이 있으시다고 하면 두번째 책은 텐서플로우를 다루는 기본을 알기위해서는 괜찮다고 생각해요. 물론 딥러닝에 대한 입문서로는 부족할수도 있을것 같고http://hunkim.github.io/ml/저는 andrew 교수님 수업듣고 위의 강의가 도움이 많이 되었습니다.	1	텐서플로에만 초점을 맞춘다면 위에서 언급한 2가지 선택이 있으실 것 같은데 만약 딥러닝에 대한 입문이 목적이시라면 그 2권보다는 <딥러닝 카페> 나 <딥러닝 제대로 시작하기>가 더 나을 것 같아요.물어보신 2권은 사실 텐서플로 홈피 튜토리얼 참고해도 될 것 같아요.	0	
2	안녕하세요. 딥러닝을 공부하는 학생입니다. 홍콩과기대 김성훈 교수님의 youtube 영상을 보며 공부중인데, regularization은 구부러진 decision boundary를 펴기위해 사용한다고 들었습니다. 강의 내용과 함께 수식을 설명해주셨는데 cost 함수에 (lambda * 시그마 * W^2)을 더하는 형태로 regularization을 적용한다고 나왔있었습니다. 여기서 뒤에 더하는 부분이 어떤 원리로 적용되어 구부러진 decision boundary가 펴지는지 궁금합니다.	4	가설이 y = w*x^2인 경우로 예를 들어 설명드리겠습니다! 이 경우 w가 커질 수록 더욱더 구부러진 형태의 이차함수가 되겠죠? 그런데 말씀하신 것처럼 L2 regularization(w^2)을 cost function에 추가하면, 알고리즘은 w^2를 최소화하기 위해 노력합니다. 그 결과 w^2가 작아지고, w의 절대값 크기가 작아져 이차 함수 곡선은 덜 구부러진 형태를 띄게 됩니다 ㅎㅎ 가설의 식이 복잡해질 경우도 위와 마찬가지입니다 ㅎㅎ	0	오차를 loss = W*X 라고하면 오차는 입력과 가중치에 대한 함수가 되고 이를 최소화 하는 것이 학습입니다.
0	CNN (GoogLeNet)을 이용해서 image classification 하는 것을 구현해보고 있습니다.dataset은 Oxford 17 categroy flower dataset을 사용합니다.1000번 training 하고 매 training마다 test를 해보고 있습니다.그런데 첫번째 epoch에서 0.05정도의 정확도가 나오고나서 그 뒤로 그 정확도에 고정되어버립니다.보통 이럴때는 어떻게 해결해야하나요?? 전 learining rate 문제라고 생각해서 learning rate을 바꿔보았는데도 마찬가지입니다.	0	아예 시작도 못한걸로 봐서 초기값에러 아니면 구현에러 아닐까 싶네요.	0	학습 속도를 혹 크게 잡으신 건 아닐지 모르겠습니다.
34	#Tensorflow 오늘 방송의 녹화본입니다.방송 일정은 일요일 밤 9시로 Fix하는 것으로 했구요.녹화본은 Live가 끝나는대로 이렇게 공유 드리겠습니다.오늘 참여해주신 분들 정말 감사드립니다.많은 분들의 도움이 되었으면 좋겠습니다.편안한 밤 되세요!
31	#Tensorflow 안녕하세요 이찬우입니다.Tensorflow Live 시작합니다.앞으로도 이 시간을 이용하게 될 것 같습니다.많은 관심 부탁드리겠습니다 ㅎㅎㅎㅎ 어서오세요~
74	오늘은 일요일이기도 하고 어제의 기분 좋음이 계속되기도 해서 코드 하나 투척합니다. ^_^얼마전 DeepMind 에서 발표한 ByteNet 을 사용해 프랑스어->영어 번역하는 tensorflow 구현 코드입니다.  https://github.com/buriburisuri/ByteNetByteNet 은 dilated CNN 과 causal CNN 으로 RNN 을 대체한 모델입니다. (논문 : https://arxiv.org/abs/1610.10099)  당연히 트레이닝 속도도 빠르고 결과도 좋은편입니다. 논문에서는 character 단위 language model 과 machine translation 을 시도했는데 LM 은 다른 사람이 구현한게 있어서 저는 machine translation 을 구현해보았는데, character level 로 번역이 꽤 잘되는거 보고 저도 놀랐습니다.  PixelRNN 과 WaveNet 에서 보듯이 요새 RNN 을 causal CNN 으로 대체하는게 추세인 듯 싶네요. ( 이러다가 RNN 은 조만간 씨가 마를 것 같습니다.)이제까지 GAN ( Generative Adversarial Network ) 관련 코드만 올렸었는데 오늘은 조금 생뚱 맞은 코드 올려봅니다.  ^_^
15	즐거운 강의가 기다려집니다 ;)	0	엇. 오셨었군요. 부족한 발표 들어 주셔서 감사드립니다. ^_^
13	회사에서 지원받아서 딥러닝 실습교육 다녀오신 분들 계시면 의견을 여쭙고 싶습니다.딥러닝 실습교육 (http://www.ikosmo.co.kr/?view=dynamicPage&code=lecture_list_2_1&view_mode=view&id=78) 이런 종류의 실습을 다녀보신분들 어떠셨나요? 3일짜리 실습 프로그램이 60만원 가량인데 실제로 수강해보신 분들은 많이 도움이 되셨나요..?	7	제가 이런거 좀 다녀봤는데^^ 별로 도움이 안되었습니다. 아예 도움이 안된 건 아닌데 가성비 면에서 만족스러운 경우가 거의 없었어요. 진짜 도움이 되려면 해결해야할 것들이 몇가지 있을거 같아요.	2	회사교육은 아니고 패스트캠퍼스 10주짜리 제돈내고 주말마다 듣고 있는데, 도움 됩니다..	0	독학으로 좀 효율적인 방법은 없을까요?	1	S대 빅데이터 강의를 들었습니다. 분석가랑 엔지니어 두파트였는데 전 엔지니어링 파트를 들었습니다. 인당 200정도의 7회차(주말만)으로 기억합니다. 결론 부터 말씀드리면 초보자에겐 조금 어렵고 숙련자에겐 실습이 부족한 살짝 애매한 내용이었습니다. 정리차원에선 좋습니다만. 바로 실전에 도입될 정도로 도움이 되진 않았습니다. ^^	0	전 1회차라 현재 차수에선 조금 다를수도 있습니다.
35	Hi, just to share that my new book on Tensorflow is about to be released, and can be pre ordered at a discounted price.It was designed to be suitable to beginners trying the library for the first time, so all concepts are explained with few math and provide more information in the form of graphics and schemes, in addition to many practical analytical examples.Many thanks.
1	CNN ensemble을 해보려고 합니다. 복수개의 모델에서 feature map을 만든후 (output shape이 같은) 평균해서 softmax에 넣으면 되나요?	2	일반적으로는 소프트맥스 결과에 대해서 majority voting 등으로 앙상블을 할 것같습니다.
2	텐서플로우  GPUGTX960을 사용해서학습중인데요GTX1060을 달면 뭐 좀더 빨라진다거나 그런게 있나요CUDA CORE는 같은거 같은데?	0	돈 좀 더 보태서 1070을 사는게 어떨까요? 1060은 좀 애매한거 같아요. 1070은 써보니 괜찮았습니다	0	960과성능차이가크나요?	0	960사용하다가 1070으로 넘어온 유저입니다. 빨라요. 그리고 메모리가 많아서 몇개씩 한꺼번에 돌릴수도 있고요. 체감 성능차이 많이남..	0	비교해 본적은 없지만, geforce 홈페이지로 가시면 성능비교 그래프가 있어요http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-960/performance	1	http://www.phoronix.com/scan.php?page=article&item=nvidia-gtx-1070&num=4http://timdettmers.com/2014/08/14/which-gpu-for-deep-learning/	0	쿠다코어 이외에도 다른것들이  영향을 주나보네용ㅎㅎ1080 가지고싶당
8	pycon apac 2016에서 신정규님이 발표하신 챗봇 한번 따라해보고 싶은데 코드를 어디서 볼수 있을까요?
10	YOLO에서 gray image를 training 할수 있도록 수정해봤습니다. cfg 파일에서 channels=1로 바꿔서 trainig과 test를 하면 됩니다.Raspberry Pi3 에서 돌려볼려고 계속 모델을 줄이다 보니 어쩌다 직접 구현하게 됐네요.Tiny model을 trainig한 weights 파일 링크입니다.https://drive.google.com/open?id=0B8AJ1FOXWIi5NGhVRVV3YTFqUlE	0	Tiny 예제에서는 그래픽 카드 없이 2010맥북에서 FPS 0.5정도 밖에 안나오던데, 모델을 줄이고 Raspberry Pi에서 돌리게 되면 몇 FPS정도 나오나요?
3	안녕하세요 기존에 cpu만 이용해서 학습을 시키다가 기회가 되어 gtx1080 정도의 gpu를 살려고 하는데,cpu나 메인보드를 어느 정도  쓰면 좋을 지 고수님들 추천 해 주세요 !!	0	본인이 하려는 분야와 데이터셋, 예산을 알아야 추천이 가능하겠지요..
28	안녕하세요.전 자연어 처리를 딥러닝으로 처리하는 것을 기초로 프로그래밍 코드를 학습시켜보려고 합니다.근데, 텐서플로 학습과 예제들의 대부분 이미지에 집중돼 있어 자연어 처리에 대한 공부가 어렵습니다.그래서 이를 공부하기에 좋은 자료가 있는지, 그리고 딥러닝으로 자연어 처리를 한 괜찮은 논문들은 무엇이 있는지 조언을 구하고싶습니다.부탁드리겠습니다. 감사합니다.	1	Stanford에서 cs224d라고 강의가 있습니다. ^^	3	현재 NYU에 계시고 utoronto에서 박사후 과정을 하신 조경현 교수님이 NLP 쪽으로 가장 활발히 연구하십니다. RNN, LSTM 쪽으로 공부하시고 조경현 교수님 논문들 참고하시면 좋을 것 같습니다.	0	와드좀 하겠습니당 ㅎ.ㅎ	0	필요했던 질문감사합니다 ㅋㅋ 챗봇에 관심이생겼었는데 논문찾기가힘드네요	1	자연어처리는 먼저 규칙기반으로 시작하고 딥러닝으로 보완해야합니다. 안 그러면 계속 도도리표예요.	0	저도 와드	0	저도 와드좀 박겠습니다	0	저도 와드좀 할게요 ㅎㅎ	0	와드!	1	질문하신분이야 잘 아시겠지만, KoNLP, word2vec, syntaxnet 관련 재밌는 예제가 많이 있는것 같습니다	0	와드!
10	안녕하세요. 저는 뤼이드 - Riiid에서 백엔드 개발자로 일하고있는 김한기입니다.다름이 아니라 저희가 머신러닝에 관심있으신 분들을 찾고 있어서 이렇게 글을 올리게되었습니다...저희는 머신러닝 기반으로 문제를 추천해주는 서비스를 기획/개발하고있습니다.현재 실제 사용자들이 쌓은 데이터가 상당하여 그 데이터를 기반으로 여러가지 시도를 해보고있는데요,실제 data로 이것저것 해보고싶은 분들의 많은 관심 부탁드립니다!(혹시 카이스트나 그 근처에 계신분들은 아래 포스터에 나온 장소로 가시면 더 많은 정보를 얻으실 수 있습니다.)감사합니다.
15	인공지능(AI)으로 혈압 정확히 측정 한다!- 강화학습과 개념과 유사한, 데이터 강화기법인 '부트스트랩알고리즘'을 고안하였다
3	링크에 광고가 떠서 다시 올립니다.tensorflow 설치문서 업데이트 했습니다.업데이트내용:-그래픽카드 드라이버는 cuda 안속에 있는거 까는게 안정성이 좋네요-docker는 host pc 안속에 그래픽카드랑 쿠다랑 버전 다 맞아야 gpu 사용 가능-나머지 잡다한 링크랑 오타 수정	1	참고할게여 감사합니다.
38	또 일손이 안 잡혀서 ( 요새 일손 안 잡히는 설마가 많이 생기네요. ㅠ.ㅠ ) 논문 몇 편 소개하고 구현 코드 투척합니다.오늘 소개할 논문은 Google Brains 에서 몇 일전에 내놓은 "Conditional Image Synthesis With Auxiliary Classifier GANs"(https://arxiv.org/abs/1610.09585)  라는 논문입니다.GAN training 할 때 기존 라벨을 활용해서 classification 도 같이 하면 더 좋다는 논문인데요.  읽고 보니 제가 InfoGAN 가지고 놀다가 9월에 이미 했던 것과 완전히 똑같더군요. ^_^  ( 과거글 링크 : https://www.facebook.com/groups/TensorFlowKR/permalink/347047655636299/?match=6rmA64Ko7KO8)논문에서는 더 다양한 데이터셋에 대해 테스트를 진행했고, 128x128 이미지 생성까지 도전했습니다. ( 이건 아직 갈길이 남은 듯 싶네요.. )가장 좋았던 점은 실험을 통해 왜 더 잘되는지를 설명하는데요(제 과거글에 써 있듯이 저는 그때 왜 잘되는지 정확히 몰랐습니다. ^_^), 세분화 시키면 생성하는 이미지의 다양성이 줄게 되고 그래서 트레이닝이 더 잘되는 것 같다는 것을 실험으로 보여 주었습니다.논문의 주장이 맞다면  InfoGAN 의 factor 를 대폭 늘려줘도 동일한 효과가 생기지 않을까 하는 생각이 드는데요 역시 실험을 해봐야겠죠.어쨌거나 저자가 제공한 코드가 없으니 저의 코드 리팩토링 해서 소개 드립니다. ( 기존의 supervised infoGAN 과 동일합니다. )https://github.com/buriburisuri/ac-gan한편, "Generative Multi-Adversarial Networks"(http://openreview.net/forum?id=Byk-VI9eg) 의 논문을 보면 discriminator 를 여러개 두고 ensemble 로 구성하는 방법이 소개되었는데 fancy 해보입니다.(이것도 실험을 해봐야 할 듯...)또한, 그저께 페북에서 나온 "Unsupervised Cross-Domain Image Generation"을 보면 GAN 을 style transfer  에 적용했는데 매우 근사해 보입니다.  (이건 일손 안 잡히는 설마가 나오면 그때 코딩해서 투척하겠습니다.  ^_^)몇개월 전만 해도 training 잘 안되서 사람들의 눈밖에 있던 GAN 이 최근에 논문도 많이 나오고 사용 영역도 넓혀가고 있다는 느낌입니다.  참 빠른 것 같다는 생각이 드네요.	1	GAN 처음볼때 가능성이 상당히 많아 보였는데 빠르게 다양한 방법으로 현실화 되니 느낌이 신선합니다. 올려주시는 구현 잘 보고 있습니다 :)
2	neural network에서 bias의 역할이 무엇일까요? and or xor 분류기에서 bias를 빼면 결과가 제대로 나오지 않는데요 MNIST에서는 bias가 없는데도 결과가 잘나오더라구요	1	and or xor를 bias 없이 직접 풀어보시면 바로 이해가 되실 듯 합니다. 더하기 없이 곱하기만 가지고는 풀어지지가 않습니다. mnist는 보통 dnn이나 cnn을 사용하기 때문에 layer가 많고 layer가 많으면 더하기인 bias가 없어도 별 상관 없는듯 합니다. and or xor도 dnn으로 학습시키면 bias 없이도 가능하지 않을까요? 제 설명이 맞는지는 모르겠습니다. 틀린 답변이면 고수분들 조언 부탁드립니다.	1	Feature detecting상황에서 bias는 threshold 값으로 사용됩니다. bias가 없으면 , threshold가 항상 0인 상황으로 절대로 최적화된 학습이 일어날 수 없습니다.아마도 MNIST에서는 값이 거의 항상 일정하게 들어오는 픽셀의 weight가 마치 bias처럼 동작했을 것으로 추측합니다.	1	일단 and or xor 이 bias가 있어야 한다는 것을 전제로 직접해보면 bias가 필요하다는것은 알수있는데요 문제는 입력 데이터에 바이어스가 필요한지 안한지 알수있는 방법은 없을까요? 혹은 dnn으로 했을경우에는 바이어스가 필요하지 않다면 왜 필요하지 않은지도 알수있을까요?  https://www.quora.com/In-artificial-neural-networks-what-actually-is-bias-unit 여기에서 설명은 하고 있지만 실제로 어떤입력데이터를 보고  바이어스가 필요한지 안한지에 대해서는 어떻게 알수있는지 잘 모르겠습니다.	2	문제를 단순화시켜서 1차함수로 생각하면 weight는 기울기고 bias는 y절편이지요 둘 다 있어야 1차함수로 fitting 가능합니다	5	bias는, output value에 직접적이고 one-shot으로 보정을 해주는 철학을 담은 offset 입니다. 그런데 이 bias는 그 점때문에 weight matrix내에 들어가야할 교호작용(latent factor의.)에는 아무 영향을 못 미치죠. 그래서 '효과는 빠르지만 불완전한 최적화 수단'이라고 할 수 있습니다. 그렇기 때문에 weight의 delta가 충분히 역할을 한다면 bias는 사실 없어도 됩니다.
47	잠시 짬이 나서 윈도우 10 우분투 Bash에 텐서플로우 개발환경을 구축하는 팁을 정리해봤습니다. pandas나 seaborn 같은 그래픽 라이브러리도 호스트 윈도우에 X-Server를 깔아서 실행가능하게 했으니 도움되시면 좋겠습니다.	0	CPU까지만 지원 되는건가요? ㅎㅎ 아무튼 고맙습니다!	0	오우 이거 이거 제가 필요하던건데.감사합니다	0	X-WIndow까지 깔 수 있나보군요...감사합니다
87	Ming Kwon 님이 올려주신대로 TensorFlow의 First Year! 축하합니다. 아래 재미있는 예를 포함하여 많은 곳에서 사용되었다고 합니다:- 호주 해양연구소에서 수만장의 사진에서 멸종 위기인 해우(sea cows)를 찾아내고 그 수를 관찰하는데 사용- 일본의 오이분류기: 크기, 모양, 그리고 특징에 따라 오이 분류- 의료 스캔화면을 이용해 파키슨병의 가능성이 있는지 판단- 로즈베리와 같이 사용하여 칼트레인 (베이지역의 교통수단) 추적재미있는곳에 많이 사용되었네요.https://research.googleblog.com/2016/11/celebrating-tensorflows-first-year.html	1	AI의 일반화에 선구적으로 나눔을 만든 1주년을 진심으로 감사드립니다. ^^	1	이런 공간을 만들어 주셔서  감사합니다  ^^
66	TensorFlow 1주년이래요!
27	딥러닝(Deep Learing) 저소비전력으로 실현하는 뇌형 프로 세서 개발- 디바이스 상에서 고성능 딥러닝 기술을 구현하는 IC	0	구글 TPU나 IBM neuromorphic chip과 다른 게 뭔지 궁금하네요
56	요즘 업데이트된 tensorflow 0.11버전 설치 문서 만들어봤습니다. 	1	안그래도 Gpu 난감했는데 감사합니다	1	참고하겠습니다. 감사합니다.	1	Nvidia docker를 사용하면 GPU연계가 수월한것 같아요.^^
2	저 질문드립니다Keras LSTM 을 사용중인데요continuous한 숫자형 feature를 넣는 법을 알겠는데혹시 discrete 한 카테고리같은 피쳐는 어떻게 넣을 수 있나요?model = Sequential()model.add(LSTM(4, input_dim=123))	1	One hot encoding 같은걸 사용해보시면 어떨까요?	0	keras example을 확인해 보세요. https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py	0	감사합니다 :)	0	문상우 np_utils에 to_categorical 함수 써주면 one hot encoding 바꿔주넹 ㅎㅎ	0	그럼 트레이닝 데이터에 continuous, one hot encoding 피쳐를 동시에 넣으면.. (숫자, 숫자, [0,0,1]) 이렇게 데이터셋 행렬이 될거 같은데 맞나요? 해보고 다시 질문드릴게요
29	Sung Kim 교수님 강의를 보면, 딥러닝이 발전한 계기가 2006년 CIFAR Hinton 교수님과 Bengio 교수님이 학습을 할때 초기 w값을 잘 설정하면 깊은 뉴럴네트워크도 학습이 가능하다는 이론으로 실용화 된것으로 이해하는데요.근데 딥 러닝은 대부분 CNN이나 RNN을 사용하는것 같은데, CNN은 1980에 나온 알고리즘인데, 그렇다면 이 CNN이 실용화 된 것이 2006년의 어떤 개념에 의해서 바뀐건가요?예제들에는 w값의 초기값을 잘 설정하는 방법은 없는것 같은데, 어떤 알고리즘이 추가되서 CNN이 실용화 되었는지 궁금합니다.	6	아마도 Relu와 Dropout, GPU일듯 합니다	0	2006년이라면 Restricted Boltzmann Machine (RBM)을 말씀하시는 것 같네요. 지금은 잘 사용되지 않는 것 같습니다만.. 이 논문을 참고해보셔요 http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf딥러닝의 개괄적인 설명(한국어)은 여기를 참고해보시면 좋을 것 같네요 :)  http://t-robotics.blogspot.kr/2015/05/deep-learning.html	10	초기 weight를 잘 설정해보자 하는 아이디어를 실현시켜준 것이 윗 분이 말씀하신 RBM입니다. pre-training과정이 한 번 들어가서 완전 random initialize되어 있는 weight들을 인풋데이터의 특성에 맞게 적당히 윤곽을 잡아주는 과정이라 할 수 있겠습니다. 이러한 과정을 거쳤더니 학습성능이 월등히 좋아졌고 cost 수렴도 빨라졌습니다. 기존에 신경망을 안쓰는 이유 중 가장 큰 문제를 해결해준 셈이지요.	3	요즘은 weight 초기화 방법으로 2010년에 나온 Xavier initialization을 많이 쓰는 것 같습니다 (아니라면 누가 댓글로 혼내주세요...ㅎㅎ) tensorflow에 이미 구현되어있습니당https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.layers.html#xavier_initializer	0	뜬금없지만 블로그 잘보고있습니다 감사합니다
7	안녕하세요. TensorFlow에서 word2vec을 이용하여 유사한 단어 및 오탈자를 찾아보려고 합니다.예를들어 맥도날드,멕도날드,맥도널드,마그도나르도가 같은 의미의 단어라고 찾고 싶은데 혹시 참고할만한 자료가 있을가요?다른 사례를 찾아보니 암살이란 영화 관련 기사 데이터를 가지고 분석하면 출연배우인 전지현과 이정재가 관련있다라고 나오고, 전지현과 "미모"와 같은 단어도 관련이 있다고 나오는데 이 것과는 다른 상황인 것 같아서요.도움 부탁드리겠습니다. 감사합니다~	1	저도 word2vec에 관심이 있어서 여러가지 자료를 찾아보고 있는데요 Elastick 5.0에 대한 기능설명을 보면서 도움이 되지않을까 올려봅니다http://www.popit.kr/bm25-elasticsearch-5-0%EC%97%90%EC%84%9C-%EA%B2%80%EC%83%89%ED%95%98%EB%8A%94-%EC%83%88%EB%A1%9C%EC%9A%B4-%EB%B0%A9%EB%B2%95/	1	http://www.slideshare.net/deview/242-52779038도 참고할 만한 것 같습니다.	0	재민님 제가 찾는 것과 비슷한 것 같아요. 다시 한번 봐야겠네요~ 감사합니다!!
22	한국마이크로소프트, 머신러닝과 인공지능 융합된 보안 솔루션 발표- 보안에도 머신러닝·AI 기술 적용, 해킹, 멀웨어 등 잠재적인 위협 한발 앞서 방지
25	https://github.com/airbnb/knowledge-repo에어비엔비에서 데이터 관련 Knowledge를 포스트 형식으로 기록하고 공유할 수 있는 플랫폼을 제공하네요.
3	Deep learning applications have a complex multi-layer architecture. This article describes a typical AI technology stack with a few layers from bare metal to high-level application code.
0	이 기술도 머신 러닝이나 딥러닝을 이용한 것일까요?
83	공부할겸 LSTM을 소개하는 영문 블로그 글을 번역했습니다 ㅎㅎ아직 저도 초보라서, 틀린 표현이 있을수 있으니 양해부탁드립니다 ^^;
8	[스터디원 모집] 싸이랭 : 파트 4 (알파고 이후의 영어공부)* (새로 추가된 것) 영어쓰기 / 딥러닝 기계번역 이론 (+파이썬 구현 실습 포함)* (기존) 영어 말하기 / 파이썬 기초* 2주에 한번 토요일, 오전 10-11시. 무료(공간이용료는 각자 계산), 2017년 1월 7일 시작.* 이벤트 링크 - https://www.facebook.com/events/1826534294248090/* 이 스터디는 - 외국어 공부 그룹 싸이랭 - https://www.facebook.com/groups/psylang/- 계산적 언어학 접근 그룹 바벨피쉬 - https://www.facebook.com/groups/babelPish/에서 진행합니다.* 파이썬과 tensorflow 실습이 있습니다.영어 공부와 코딩공부를 같이 하는 싸이랭. 이번에는 기계번역 이론/실습을 포함합니다. 스터디 시간은 3 부분으로 나눠지는데, 2개는 영어회화/쓰기, 나머지 1시간은 딥러닝을 이용한 기계번역 기초를 합니다. 전혀 아무것도 모른다는 가정하에 시작합니다. 왜 이렇게 요상하게 영어공부를 하느냐? 그런 시대이기 때문입니다. 기계번역이 점점 사람 수준에 다가가는 시대에, 그 작동법을 알면서 영어공부를 하는게 꽤 유용하고 재밌지 않을까요? 누구나 함께 하실 수 있습니다. 이벤트에 댓글을 달거나, 참여를 누르시거나, 바로 찾아오시면 됩니다.	1	* 기계번역 강좌 - http://mt-class.org/	0	기계 학습 이 아니라, 기계 번역인 것이죠 ?
0	안녕하세요. 저번에 우분투 설치로 문의를 드렸었는데 그 문제는 해결을 하게 되었습니다. 지금은 무선랜 드라이버를 설치하고 있는데 영 안되네요.. broadcom 리눅스용으로 받아서 압축해제후 그 터미널에서 폴더로 이동하여makesudo make install 진행했는데 아무런변화가 없습니다. 유선랜 연결해보아도 잡지못하여 tensorflow 설치를 못하고 있습니다. 혹시 무선랜 드라이버 설치법이나 인터넷을 연결하지않고 tensorflow 를 설치할수있는 방법을 알려주시면 감사하겠습니다. 아나콘다와 파이참 설치파일은 모두 가지고있어서 tensorflow만 설치하면 되는 상태입니다!	0	도움이 도실지 모르겠지만.. 소스로 컴파일 하는 경우 의존성 문제를 수동 해결해야하는 등 골치가 많이 아픕니다. apt-get 명령으로 설치 시도 해보셔요. 패키지 이름은 잘 모르겠지만 잠깐 구글링 해보니 bcmwl* 로 해보시면 어떨까 하네요.
5	cifar-10을 예로 기본적인 질문을 좀 드리고 싶습니다. cifar-10은 텐서플로우 기본 튜토리얼에서도 잘 정리되어 있는데요, data augmentation 목적으로 랜덤 cropping, brightness, contrast 를 조정하게끔 되어있습니다.Krizhevsky et al. (2012) 논문에는 이에 사실 한가지 트릭이 더 있는데요, RGB컬러를 PCA를 통해서 약간 변환하게끔 되어있습니다. 디테일을 논하려는건 아니지만 어쨌든 컬러값 분포의 eigen vector/value를 구해야하는 것으로 보입니다.이정도 변환을 해야한다면, 순수 텐서플로우 코드로는 어려울것 같습니다. 제 질문은, tensor에 어떤 연산을 하고 싶은데 순수 API로는 부족하다면 어떻게 하시나요? 제 생각에는 sess.run으로 numpy 로 받아서 파이선 레벨에서 필요한 연산한 다음에 다시 placeholder 로 넣어주야만 할것 같습니다. 이렇게 하는게 맞는건가요? 약간 broken flow같은 느낌이 들어서 여쭈어봅니다. 더 나은 방법이 있을까요?즉, 대략적으로 말해서, 원래 코드가 아래라면,images, labels = cifar10.distorted_inputs()logits = cifar10.inference(images)...l = sess.run(logits)좀더 심오한 변환을 위해서는,images, labels = cifar10.distorted_inputs()images2 = tf.placeholder(tf.float32, ..같은 사이즈)logits = cifar10.inference(images2)...img = sess.run(images)img_cus = do_something_with_numpy(img)l = sess.run(logits, feed_dict={images2:img_cus})라는 방법 외에는 저로서는 생각할 수가 없습니다. 혹시 관련해서 조언을 좀 주실수 있으신가요?	1	여기를 한번 참조해보세요. 되긴되는데, 아무래도 코드가 쫌 복잡해지는 경향이 있더군요. http://stackoverflow.com/questions/34594198/how-to-prefetch-data-using-a-custom-python-function-in-tensorflow	0	아 관련있는거 같네요! 일단 감사부터 드립니다 :)
3	안녕하세요 tensorflow를 공부 시작한 학생입니다. tensorflow 관련 책들을 찾아보면서 공부하고 있습니다. 개인적으로 카메라 또는 CCTV를 설치하고 실시간으로 사람을 인식하는 것을 해보고 싶은데 그래픽쪽으로는 공부를 많이 하지 못해 여기 있으신 분들의 조언을 얻고 싶습니다.이와 비슷하게 카메라에서 실시간으로 인식을 해보신 분들 어떤 카메라를 가지고 하셨는지 궁금합니다. 비싼 카메라는 학생이라는 여건상...ㅠㅠ많은 조언 부탁드립니다 ㅎㅎ	3	Google DeepMind에서 실시간 영상 사물 인식과 관련해 Single Shot Detector라는 논문(을 발표한 적이 있습니다. 논문은 구글링하시면 아카이브 등에서 쉽게 구하실 수 있을거고 밑은 저자 Wei Liu가 Github으로 공개한 Caffe 소스코드입니다. 실시간 사물 인식이 되는 동영상이 무척 인상 깊었습니다. https://github.com/weiliu89/caffe/tree/ssd	0	Usb카메라로도 가능합니다. 진행해보았구요
10	텐서플로우로 evaluation 하는 과정에서 IndexError: list index out of range위와 같은 에러를 겪어보신분 계신가요??mnist+CNNdmf 사용하는 예제를 다른 image data set으로 바꾸고 GoogLeNet을 적용해보았는데 mnist의 경우에는 동작을 하는데 제가 다른 image data set으로 바꿔서 적용을 하니까 마지막 줄에서 위와 같은 에러가 나옵니다.코드는 http://pythonkim.tistory.com/56 에서 참고했습니다.	0	input shape과 input을 받는 layer의 shape 또는 output layer와 마지막 hidden layer의 shape을 비교해 보셨나요?
23	글이 올라간 김에 한 가지 여쭈어보고 싶습니다.시간대에 대한건데요...전 토요일 9시나 일요일 9시 일정으로 매주 라이브가 나갈 것 같은데어떤쪽 시간이 좋으신지 댓글로 말씀들을 해주시면 거기에 좀 맞춰보도록 하겠습니다.영상이 깁니다..... ㅎㅎ...많은 도움이 되었으면 좋겠습니다!	1	일요일여..	1	일요일에 한 표 던집니다~	0	일요일이요 :)
16	#알파로우 10/25, 화, 알파로우 : 파트 1 - 1회차(법률분석+딥러닝 자연어처리) 스터디가 있었습니다.* 실습은 파이썬/텐서플로우로 진행됩니다.* 1회차 후기만 공유하겠습니다. 자료는 모두 공개&공유됩니다.- 자료&커리큘럼 링크 - https://github.com/psygement/AlphaLaw* 이 스터디는 싸이지먼트와 바벨피쉬에서 진행합니다.- 싸이지먼트 - https://www.facebook.com/groups/psygement/- 바벨피쉬 - https://www.facebook.com/groups/babelPish/ 법 영역에 머신러닝을 적용해보자는 취지의 취미모임 스터디입니다. 법을 공부하고 싶은 개발자와, 머신러닝 / 특히 이번 파트에서  진행하는 자연어처리에 관심이 있는 법학도 분들이 함께하셨습니다. 먼저 제가 K-MOOC의 민법학 강의 제 1강을 발표했습니다. 민법이란 무엇인가, 권리관계, 민법 기본원리, 권리의 변동 등에 대한 내용이었습니다. 민법의 기초 개념들을 알수 있어서 개인적으론 좋았습니다. 두 번째는 Semantic Processing of Legal Texts 라는 책을 소개했습니다. 자연어처리 기법을 법률 텍스트에 어떻게 적용하려는지 논문들을 모아놓은 책입니다. 첫장 Legal Language and Legal Knowledge Management Applications를 살펴보았습니다. 이 책의 입장은 결국 온톨로지를 구성해서 온톨로지 추론까지 가자는 좀 옛스러운 방식을 얘기하고 있습니다. 그리고 책이 나온지가 꽤 되어서 자연어처리의 올드한 기법들로 접근하구요. 그래서 참고 슬라이드를 찾아서 보강을 했습니다. 세번째는 법률텍스트에 딥러닝을 적용하는 논문을 같이 봤습니다. 이런쪽으로 논문이 많이 없더군요. Gov2Vec: Learning Distributed Representations of Institutions and Their Legal Text 라는 논문을 찾았는데, doc2vec 기법에서 doc부분을 해당 법률문서나 공식문서가 나온 기관의 아이디로 대체해서 작업을 했더니, 꽤 의미있게 토픽분류를 하더라..라는 내용이었습니다. 그리고 마지막으로 앞으로 어떤 분야,법률텍스트를 타겟으로 실습을 진행해야할지 서로 의논을 했습니다. 전공자분들의 분야지식과 조언을 들으며, 역시나 용기를 내서 스터디를 시작한게 다행이라는 생각을 했습니다. 앞으로 점점 재밌을 것 같습니다. 같이 공부하고 싶으신 분들은 언제나 찾아오시면 됩니다~
15	Tensorflow에 contractive autoencoder 구현이 왜 없나 했더니, Jacobian matrix계산이 매우 불편하네요.tf.gradients(f, x)를 부르면, f와 x가 벡터일 때 행렬이 나오는 것이 수학적으로 자연스러울텐데요. (x도 매트릭스라면 3차원 텐서가 나와야 되겠죠?) 텐서플로우에서는 x의 각 성분별로 Jacobian을 합친 값만을 return합니다. 관련된 이슈가 깃헙에도 올라왔었는데, 현재의 텐서플로우에서 Jacobian에 대한 자연스러운 구현은 어렵다고 하네요. 관심있으신 분들 참고하셔요 :)
5	안녕하세요. 텐서플로우 작업중에 막혀서.. 질문 남깁니다!우선 Ubuntu에서 Tensorflow 로 LSTM을 이용한 BidirectionRNN 모델을 학습하고, 그래프를 export 시켰습니다. Windows10에서 Visual studio2015로 C++버젼 텐서플로우를 빌드하고, python에서 export한 그래프를 읽어서 윈도우 버전의 디코더를 개발하려고 합니다. //홍정모 님의 블로그 글에 도움을 많이 받았습니다 :) 관련 예제를 제가 많이 찾지 못해서 버벅대고 있는데요.. 혹시 C++ 테스트용 관련 코드나, tf.placeholder 처럼 데이터를 넣는 경우 C++에서 어떻게 넣어줘야되는지 아시는분 있으신가요? ㅠ C++에 익숙하지 않아서인지 텐서플로우 API문서가 어려운건지 제가 원하는 자료를 찾기가 어렵습니다 ㅠ	0	홍정모 님의 블로그에 Gradient Descent Test 글을 보고 참고해서 지금 테스트 중입니다!	1	힘내세요! 결과 나오면 공유 부탁드립니다.	1		1	블로그에 있는 내용이지만 정리하면 python에서 placeholder 만들 때 사용한 문자열 이름에 맞춰서 c++ api에서 run 호출할 때 input으로 넣어주면 되는 것을 확인했었습니다.	1	트레이닝 끝난 후에 forward prop하는 것은 이정도도 될 텐데 여러 데이터를 자동 feed 하면서 훈련시키는 방법은 아직 못찾았습니다.
6	#딥사이어인 파트3 1회차 스터디원 모집* 일시 : 11/7(월) 오후 7~10시* 장소 : 강남 힐스터디(4번 출구 10층 건물)* 내용 :(딥러닝) 12 Applications 김태흥(강화학습) 1. Introduction to Reinforcement Learning 임재성(파이썬 챗봇) 1. DEEP LEARNING FOR CHATBOTS, PART 1 – INTRODUCTION, 실습환경 구축 김성동* 교재(강화학습)교재 1. (David Silver's RL) http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html동영상강의 https://www.youtube.com/watch…보조교재1. (모두의 연구소 강화학습 튜토리얼) https://dnddnjs.gitbooks.io/rl/content/(딥러닝)교재. (벤지오) Deep Learning - http://www.deeplearningbook.org/(파이썬 챗봇)튜토리얼, 블로그, 논문, 공개강의 이용------------------------------------------------------------------------------딥사이어인 파트3 커리큘럼입니다.!딥러닝은 벤지오 교수님의 책을 12장부터 이어서 보고요.Deep Reinforcement Learning의 대세를 따라가기 위해 강화학습 기초를 David Silver의 강의와 모두의 연구소에서 공개해주신 튜토리얼을 보며 공부할 계획입니다! (유튜브 강의에 영자막도 공개가 안되어있지만,,, 한글 튜토리얼의 힘을 빌려 ㅠㅠ)그리고 마지막 파트를 정말 고심 끝에 파이썬 챗봇이라는 이름으로 결정했는데요. 조금 다른 점은 파이썬 기초와 NLP 기초를 다지고 차근차근 가기보다는 실전적인 프로젝트 형태로 자신만의 봇을 업그레이드 해나가는 형식으로 진행하려 합니다. 물론 파이썬 기초와 nlp 기초, 지식들을 이를 위해서 습득해야겠죠!! 기초적인 내용도 커버할 생각이니 많은 참여바랍니다~~파이썬의 기본 자료구조(리스트, 딕셔너리), 형태소 및 개체 태깅/추출, 의도파악, 워드 임베딩, RNN을 이용한 분류, seq2seq 등 챗봇의 필수적인 구성요소들을 중점적으로 배우면서 확장해 나갈 계획입니다. 이를 이용해 스크립트(룰) 베이스드 챗봇을 프로토타이핑한 후 다음 파트에서는 강화학습을 챗봇에 적용하여 대화할수록 말을 더 잘하게 되는?? 그런 챗봇을 만들어 볼 수 있을지 고민해보려고 합니다.https://www.facebook.com/events/1155892427833471/
41	Lunit에서 함께 큰 문제를 풀어나가실 분들을 모십니다.아래 참고하시어 많은 지원 부탁드립니다.	2	어제 헬스케어 이노베이션 포럼에서 인상깊게 보았는데...멋있네요
3	질문있습니다. Tensorflow 예제 코드들을 보면, 모델을 만들고 학습하는 과정에서 대부분의 경우 training_epoch 를 주고 for 문 안에서 sess.run(optimizer) 를 통해 학습하더군요. 이 부분을 저는 반복을 통해 더 많이 학습시켜서 성능을 높이려는 트릭으로 이해했는데, 이러한 경우 데이터 셋의 양을 증가시킨게 맞는건지 궁금합니다. 성능은 물론 반복할수록 향상됩니다. 기존의 연구와 성능 비교를 수행해야 하는데, training epoch 를 설정하고 학습시킨 모델의 성능을 비교하는게 유의미한 비교가 아닐 것 같아서요.. 의견 부탁드립니다.	2	Overfitting 문제를 고려한다면 충분히 유의미하다고 생각합니다 :) 극단적으로 10개의 데이터 샘플을 가지고 10000번 돌린다고 성능이 향상되는 것이 아니거든요..데이터셋과 분류모델에 따라 Overfitting을 최소화하는 epoch를 찾는 것도 또다른 문제입니다	1	일단 epoch을 여러번 돌린다고 데이터 셋의 양이 증가한 것은 아니구요.. training epoch은 하나의 hyper-parameter로 tuning의 대상입니다. valid set에서 제일 성능 잘 나오는 것을 선택해도 되고, dropout등으로 overfit이 생길 염려가 별로 없을때는 그냥 충분히 돌려서 convergence를 확인만 하면 몇 번 돌렸는가가 크게 중요한 것 같진 않습니다.	0	감사합니다. 많은 도움이 되었습니다.
6	질문있습니다.Tensorflow GPU 사용 중입니다.소스코드 한번 실행할때마다 GPU의 메모리를 사용하는데,Ctrl + z로 실행 취소하고 다시 실행하려면 CUDA_ERROR_OUT_OF_MEMORY라는 오류 메시지가 뜹니다.어떤 현상이고, 해결 방법이 있는지 알고싶습니다.	3	Ctrl Z는 실행취소가 아니라 일시정지하고 백그라운드로 프로세스를 보내는 명령어입니다. 프로세스를 취소하시려면 Ctrl C를 쓰시면 됩니다.	2	봉희종님께서 잘 설명해주신 것 같습니다! 여기에 한가지만 추가하자면, 가끔 텐서플로우를 실행한 python process가 제대로 종료되지 않고 백그라운드에 남아있는 경우가 있습니다. 그런경우 nvidia-smi 로 gpu를 사용중인 프로세스의 id를 확인한 후 kill 명령어로 종료해주시면 됩니다~
60	간만에(일손도 안 잡히고 해서...) 코드도 하나 올리고 논문 소개도 하겠습니다.오늘 소개할 코드는 SISR ( single image super-resolution : 쉽게 저해상도 이미지를 고해상도 이미지로 바꾸는 거 )에 관한 겁니다.요새 SISR 에도 CNN 을 많이 적용하고 있고 결과도 좋은편 입니다. 주로 ground-truth image 와 pixel-to-pixel L2(MSE) loss 를 사용합니다.  auto-encoder 가지고 놀아보신 분들은 아시겠지만 L2 loss를 사용할 경우 생성된 이미지가 blurry 해지는 단점이 있습니다. GAN(Generative adversarial network)를 이용하면 더 선명한 고해상도 이미지를 만들 수 있지 않을까? 하는 아이디어가 생겼고 한번 해보았습니다.  호오~~ 잘 됩니다.  tensorflow 코드는 아래 링크에... https://github.com/buriburisuri/SRGAN구현상 약간 어려운 점이 있었다면 L2 loss 를 GAN 으로 대체하기만 해서는 training 이 안된다는 점입니다. 원래 GAN 이라는게 discriminator 만 속이면 되는거라서 주어진 저해상도 image 를 무시하고 discriminator 만 속이는 방법으로 학습을 할 수도 있기 때문입니다.  따라서 이를 방해하는 방법을 찾아야 하는데 저는 저해상도 이미지와 생성된 고해상도 이미지를 쌍으로 해서 discriminator 에 넣어주는 방법을 사용하였습니다.누가 더 잘해 놓은게 없을까 하고 검색 해보니 이번달에 트위터에서 같은 주제로 논문을 발표 하였더군요. 기본 아이디어는 제 생각과 동일합니다.https://arxiv.org/abs/1609.04802논문 저자들은 GAN loss 에 기존 super-resolution에서 사용한 L2 loss(논문에서는 content loss 라고 얘기함)를 추가해서 joint learning 하는 방법으로 학습을 시켰습니다.  제 생각에는 이 부분을 걷어내면 더 깨끗한 이미지를 만들 수 있을 거 같기도 하지만 실험해봐야 겠죠.  어쨌거나 GAN 을 써서 SISR 분야의 state-of-the-art 를 만들어 냈다고 합니다.마지막으로 제 구현 코드에서는 deconvolution 대신에 sub-pixel CNN(ESPCN) 을 썼는데요 이 방법은 아래의 논문을 참조하시면 됩니다.http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf위 논문은 요새 이름부터 논란이 많은 deconvolution 의 문제점을 아주 깔끔하게 해결한 논문인데요.  실행시간도 빠르고 구현도 간편하고 표현력도 더 좋습니다. de-convolution 쓸려면 kernel size 와 stride 조정에 신경을 많이 써야해서 architecture 설계에 제한이 많았는데 이 논문 때문에 여러 문제들이 시원하게 날라간 거 같습니다.  참고로 deconvolution 의 문제점을 잘 설명한 글은 아래의 링크를 참조하면 됩니다.  ( 이유만 보시고 해결법은 pass 하면 됩니다.  sub-pixel CNN 쓰면 해결되니깐요. ^^)http://distill.pub/2016/deconv-checkerboard/	0	Wonderful !	3	일손이 안 잡히는 시기인데도 상당하십니다. 이런것은 바로 서비스로 만드셔도 많은 분들이 사용할듯 합니다.	0	감사합니다.	1	DRCN과 같이 CVPR 2016에 발표된 VDSR 논문과는 비교 하지 않았네요. 좋은 자료 감사합니다 :)	2	GAN으로 바꿔보고 싶었는데 벌써 해보셨네요. SugarTensor는 쓰시기 편한가요?	1	제가 만든거니 저야 편하죠 ㅎㅎ
12	multiple gpu 사용 관련 문의드립니다.서버 한대에 gtx 1080 두개를 세팅했습니다.(참고로 리눅스는 centos 7 입니다. 회사에서 우분투를 사용할 수 없는지라..)sli는 사용하지 않았구요. (nvidia-xconfig 설정값에 sli 값이 없습니다.)그리고 텐서플로우를 사용해서 gpu를 0번만 쓰게끔 코딩하고 학습을 시작했는데 nvidia-smi로 보면 두개의 gpu가 사용되는걸로 확인이 됩니다.혹시 관련해서 따로 설정해야 하는게 있거나 경험이 있으신 분은 조언 부탁드립니다.gtx 960과 gtx 1080의 속도차이는 약 2~2.7배 정도 차이가 났습니다.가격이 4배정도 차이나는데 제 기대보다 빠르진 않더군요.2배만 빨라져도 엄청나긴 하지만CPU 쓰다가 gtx960를 쓰고 13배 이상 속도가 빨라졌을때의 기분 때문인지 기대감이 컸던것 같습니다. ㅎㅎ	0	질문있습니다.GPU0번만 쓰게 하려면소스코드에서 어떻게 작성해야 하나요??	0	with tf.device(['/gpu:0’):	0	Sli bridge 장착 상태인가요?	0	Sli는 한몸 처럼 쓸 수 있게끔 해주는걸로 알고 있습니다만, 자세한건 아래사이트에서 확인해보시고 (SLI - http://kr.nvidia.com/object/sli-technology-overview-kr.html) 제가 볼땐 CUDA 메모리 공유 때문에 그렇게 올라가고 연산은 1장으로 하는 것 같습니다만..	0	제가 sli 쪽을 몰라서 궁금한게 있는데요. sli bridge라는게 sli를 사용할때 그래픽카드 간에 하드웨어적으로 뭔가를 추가 장착하는 건가요? 그게 맞다면 sli bridge를 장착한 상태에서는 텐서플로우 코드단에서 gpu를 한개만 사용하도록 설정해도 무조건 gpu 두개가 같이 돌게 되는걸가요?	3	기본적으로 TensorFlow는 세션을 선언할 때(sess = tf.Session() 하면서) 사용가능한 모든 GPU에 메모리를 할당합니다. 이를 막기 위해서 실행하기 전에 export CUDA_VISIBLE_DEVICE=0 과 같이 사용할 GPU를 환경변수로 지정해주시면 됩니다.	0	(1) 저는 1080 4개를 사용하는데, 굳이 SLI는 필요없는 것 같습니다.(2) test 코드를 어떤 걸 쓰셨는지 모르겠는데, 저 같은 경우는 tensorflow cifar10 multigpu 예제를 활용했습니다.	0	제가 좀 두서없이 질문을 남긴 것 같아 다시 남깁니다.1. gpu 두개가 sli로 설치되어 있는지 모르는 상태입니다. 2. gpu 두개를 각각 따로 별개로 학습을 시키고 싶습니다.3. 근데 tensorflow에서 하나의 gpu만 사용하도록 /gpu:0으로 설정하고 실행해도 gpu 두개의 메모리 모두 사용되는걸로 나옵니다.4. 그래서 혹시 sli로 gpu가 연결되어 있으면 tensorflow에서 /gpu:0으로 하나만 사용하도록 지정해도 gpu 두개가 모두 사용되는지 궁금합니다.	1	댓글 달아주신 분들 감사드립니다!정리입니다.1. gpu 두 개가 설치된 서버에서 gpu를 각각 따로 돌리려면첫번째 프로그램을 실행하기 전에 환경변수 세팅export CUDA_VISIBLE_DEVICES = 0두번째 프로그램을 실행하기 전에 환경변수 세팅export CUDA_VISIBLE_DEVICES = 1이런식으로 실행하면 됩니다.이때, 소스 상에서는 /gpu:0 으로 하던, /gpu:1로 하던 관계 없습니다.무조건 환경변수에서 세팅된 GPU가 돌아가게 됩니다.2. gpu 두 개를 병렬로 돌리려면export CUDA_VISIBLE_DEVICES = 0,1이렇게 환경변수 세팅하고 multiple gpu 소스를 실행하면 됩니다.multiple gpu 튜토리얼: https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py	1	gpu를 따로 사용하는 방법으로텐서플로우에서 지원하는 with tf.device(['/gpu:0’): 이 방법은 먹히지 않았습니다.제가 사용하는 서버의 세팅이 잘 못 됐을수도 있지만gpu:0으로 세팅하고 사용할때는 gpu 하나만 돌아가는데gpu:1로 세팅하고 사용하면 gpu 두개가 모두 돌아갑니다.드라이버와 텐서플로우 모두 재설치하고 다시 테스트해보고 싶지만엄두가 나질 않네요;;
7	안녕하세요. 텐서플로우 사용을 위해서 외장ssd에 우분투설치를 하려고 하는데, 혹시 부트로더를 외장ssd쪽에 설치해주면 외장연결을했을때만 우분투가 실행되도록 할수있을까요? 맨처음에 부트로더 설정없이 설치했을때는 외장ssd 연결을 안하면 노트북윈도우가 부팅이 안되는 현상을 겪었습니다. (외장ssd 연결시에는 멀티부팅 선택화면이 나오고 우분투와 윈도우 를 선택하여 실행할수있었습니다!)	0	노트북과 외장에 각각 부트로더 포함해서 설치하신 후, BIOS 순서를 USB - HDD로 해두시면 아마 외장하드가 꼽혀있지 않으면 자동으로 윈도가 부팅될 겁니다	0	우분투가 외장 USB에도 설치를 지원한다면, 메인하드를 잠깐 빼놓고 설치한다음에  안태우님 말씀대로 USB-HDD순으로 부트순서 정해놓으면 필요없을때 USB빼놓으면 윈도우는 부트로더 없이 바로 부팅 가능합니다	0	Ssd보다는 ram을 넉넉히 구매하시고 mount -t tmpfs -o size=4096m tmpfs /media/ramdisk/렘디스크 잡아서 쓰세요.리눅스는 한 10기가 파티션 잡아서 최소설치로 하시면 돼구요데이터는 부팅시 복구 셧다운시 백업하시면 최소비용으로 만족스러운 결과를 얻으실수 있을겁니다. ^^
43	텐서플로우 0.11.0 RC1이 릴리즈 되었습니다주요 개선사항으로는 CUDA8.0+CUDNN5.1 기준PIP설치용 바이너리 파일의 지원......(털썩)복길이 님을 비롯하여 Bazel로 소스 컴파일하느라밤을 하얗게 새우신 분들께 심심한 위로를보내며응용에 더욱 매진하셔서 좋은 결과 거두시길 기원합니다 :)p.s RC0 버전은 저 말고도 아나콘다 환경에서 설치시 문제를 호소하신 분들이 계셨는데, 이점도 해결되었다는것 같습니다(미확인)	0		1	0.11rcp0에서 텐서보드에서 그래프가 검은색으로 나오는 버그도 고쳐졌을까 궁금하네요. 지금 휴 이 버그때문에 텐서보드를 쓰는 의미가없습니다 ㅠㅠ	0	털썩..	0	털썩	1	예전에 Jetson TX1에 텐서플로우를 올리는 예제를 보여주신 분이 계신데. 이후 JTX1용 우분투 16.04+CUDA8.0 환경에서 텐서플로우 0.9RC를 돌아가게 만든예제가 있어 같이 소개드립니다. 도대체 뭘 먹으면 수천개의 소스파일중에 저런 포인트들을 잡아낼수 있는지 모르겠습니다만^^;;;http://stackoverflow.com/questions/39783919/tensorflow-on-nvidia-tx1/	0	릴리즈 된지 좀 되지 않았나요? 전 저번주에 설치 했는데 아니콘다 패스 연결시 설치 이상있었습니다.	0	털썩...
42	다시 정리중	1	정말 잘보고있습니다^^
13	[스터디원 모집] 딥베이직 : 파트 1- 딥러닝을 위한 완전 기초 스터디- 딥러닝과 신경과학의 결합 * 매주 화요일 저녁, 7시 - 10시 30분, 강남 * 공간 이용료 있음(이용료 각자 결제, 1회 3천 500원)* 싸이그래머와 바이오스핀에서 진행하는 스터디입니다.- 완전 기초부터 시작하며(파이썬 기초, 머신러닝 기초, 네트워크 분석 기초, 모두의 딥러닝+텐서플로우) 누구나 함께 하실 수 있는 취미 모임입니다. - 격주로 신경과학 및 임상심리에 관한 스터디도 함께합니다. - 참여를 원하시면 이벤트에서 참석을 누르시거나, 댓글을 다시거나, 바로 찾아오시면 됩니다.이벤트 주소 https://www.facebook.com/events/212996225796807/	0	혹시 여기에서도 비디오 촬영하시나요?	0	아뇨 교수님 영상으로 공부합니다~
4	지능형 스마트홈, 말 알아듣는 가전제품, 주인 알아보는 아파트가 현실로- SK텔레콤, ‘머신러닝 기반 지능형 서비스, 음성인식 통한 가전 통합 제어 미래형 주거 문화 제시
7	안녕하세요. 다들 텐서플로우를 어떤방식으로 사용하고 계신지 궁금합니다.  GPU 잘 이용해서 사용하고 계신건가요? 부끄럽지만 컴퓨터를 산 지 몇달이 지났지만  아직 텐서플로우를 제대로 설치도 못하고 있네요.GTX1060에 CPU는 6700인데 제대로 된 설명 가이드라인이 없으니 깔았다 지웠다 하면서 아직 제대로 깔아본 적이 없습니다. 한 번 성공하여 예제를 돌린적이 있었지만 다음에 켜보니 무한로그인에 빠졌고 결국 해결못하고 포맷해버렸었네요.멀티부팅가 가능한지 우분투만 설치하는 것이 나은지, 우분투의 버전은 무엇으로 해야되는지 CUDA는 무슨버전으로 CUDNN은 어떤 버전으로 깔아야되는지 많은 분들이 올려주시지만 다들 환경이 달라 따라해보다가 중간에 막히면 구글링 해보고 해결책을 못찾으면 끝이네요.. 컴퓨터 전공자가 아니라 그런지 이러한 시행착오에서 느껴지는 좌절감이 상당하네요..지금까지 정말 100번가까이 우분투를 깐 것 같네요. 물론 조금의 발전은 있었던 것 같습니다. NVIDIA 드라이브 설치 시 무한로그인을 막으려면 어떻게 하는지 등에 대해서요.. 근데 오늘은 결국 CUDA 8.0깔면 무한로그인 되는것은 해결할 수 없었네요..사소한 설정때문에 혹시 설치가 되지 않을까 하여 기존의 멀티부팅환경을 포맷하고 우분투만 깔아서 밤새 해보다 포기하고 다시 윈도우10까는 중입니다... 다들 이런 어려운 문제를 어떻게 해결하셨는지 알 수 있을까요? 너무 힘드네요...ㅠㅠ	0	음 제가 해봤을 때 16.04, GTX 970 기준으로 다 최신 소프트 받고 드라이버는 가능하면 .run 형식을 다운받아서 직접 설치하고 듣기로는 여기서 opengl 설치할거나 하면 이건 무시하라고 하더군요	1	저도 이번에 6700K + GTX1070 에 설치하였습니다. 우선 우분투의 멀티부팅을 좋아하지 않아, 하드디스크를 하나 더 달아서, 우분투용으로만 설정을 하고 해당 하드디스크에 설치하였습니다.	0	무한 로그인의 원인은 주로 그래픽 드라이버이니 드라이버를 많이 시도해보시는게 중요할 듯 합니다	1	아마도 위에 이야기하신 분들처럼 그래픽 드라이버 문제로 판단되어집니다. 우분투 설치하시고, nvidia site에서 linux 드라이버를 받으신 후 sh ./NV....run 을 실행하시면 드라이버를 설치할 수 있습니다. 문제는 우분투 데스크탑을 설치하시게 되면, 드라이버 설치가 되지 않아서, CLI 모드(구글링해보세요)로 전환을 하셔야 합니다. 저는 "sudo service lightdm stop" 만 종료하고, 외부 노트북에서 해당 서버에 SSH로 접속하여 실행(설치)하였습니다. 그후 CUDA toolkit(저는 8.0 설치하였습니다.) 을 설치하고, 인터넷에 나와있는 방법대로 하니까 정상 동작하는거 확인했습니다.	3	저는 GTX1070+6700K였는데 이렇게 해결했습니다. 1. 별도 HDD를 준비해서 우분투만 설치(UFEI설치X, 멀티부팅 사용 X)2. 1070GPU를 아예 메인보드에서 뽑아버리고 CPU내장그래픽으로 우분투 16.02LTS를 설치한 후, NVIDIA 드라이버 설치(레파지토리 설정후 PPA로 설치하며 openGL설치 금지, 문제발생시 CLI로 부팅하야 설치후 리붓)3. 그래픽 카드를 재설치하고 CUDA8.0+CUDNN5.1 설치진행(CUDA가 패치되어 우분투 16.02에 기본 설치된 GCC5.2로 빌드가능, GCC4.8로 설치하면 에러발생)아래 깃허브 링크를 위주로 나머지 사이트의 설치방법들 참조하세요, https://github.com/JSpiner/gtx1080_tensorflow/blob/master/README.mdhttp://m.blog.naver.com/kjpark79/220781100554https://www.google.co.kr/amp/s/alliseesolutions.wordpress.com/2016/09/08/install-gpu-tensorflow-from-sources-w-ubuntu-16-04-and-cuda-8-0-rc/amp/제 경험을 적어보면 아래와 같습니다1. 링크에는  CROSSTOOL파일을 열어 빌드경로룰 수정하라고 되어있는데 저는 CROSSTOOL.tpl 파일이더군요 2. CUDNN은 아래와 같이 설치후에 파일을 카피+권한설정해보시길$ sudo tar -xzvf cudnn-8.0-linux-x64-v5.1.tgz$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*3. ./configure 실행시 설치된 경로나 드라이버 버전을 시스템기본값(엔터)으로 넘기지 말고 일일히 적어보세요 , 특히 gpu compatibility 어쩌고 부분에서 1060은 1070/1080과 넣어줘야할 값이 다릅니다기타 anaconda나 pyENV는 설치하면 경로에러가 나서 그냥 파이썬2.7로  깡통으로 설치했습니다저도 하도 설치가 안되서 (빌드부분 에러) 텐서플로우 HW구성, 설치해주는 대행업체를 하나 차려볼까 고민해봤을 정도입니다. 건투를 빕니다	0	저도 같은 문제로 한.. 5번은 우분투를 재설치했었어요. 저는 UEFI 설정을 해제하고 CUDA 8.0 설치했더니 무한로그인 문제는 해결됐었습니다.	1	멀티부팅으로 윈도우 10과 우분투에서 GPU 잘 사용하고 있습니다 :)	0	저는 우분투 16.04, GTX 970 (nvidia 그래픽 드라이버를 따로 설치하지 않고 우분투에서 자동으로 잡아주는 드라이버 사용)인데요. 이 환경에서 공식 가이드라인 (cuda 8.0, cuDNN v5, pip install)대로 설치하였습니다. 이 과정에서 우분투에서 잡아주는 드라이버가 업데이트 (361.42 -> 367.48)되었던것 같고, TensorFlow를 실행하니 그래픽카드를 못 찾는 현상이 발생했습니다. 어떻게 해야하나 고민하다가 우분투를 한번 재부팅했더니 해결되더군요. 도움이 되셨길 :)	1	그래픽 드라이버를 직접 nvidia사이트에서 설치하시지마시고 우분투 레파지에 있는걸로 혹은 ppa추가하셔서 설치하셨을 때, 터미널에 nvidia-smi치시고 결과 나오는지 부터 확인하셔야해요. (그래픽 카드 정상 설치 여부 확인) nvidia-smi 명령어를 인식하지 못한다면 바이오스 셋팅에서 UEFI boot에서 Security boot를 disable 하셨나요?	1	저는 그래픽드라이버를 따로 설치하지 않고 CUDA 툴킷을 받아서 설치하는데 쿠다 툴킷 설치할때 드라이버도 같이 설치되더라구요. 그리고 무한 로그인 문제는 쿠다 설치할 때 opengl도 같이 설치하냐고 묻는데 *절대로* opengl은 설치하시면 안됩니다.	1	참고로, 셋업 다 해서 멀쩡히 사용하다가 os관련 이런 저런 자동 업데이트 이후에 갑자기 또 무한 로그인 문제 생길 수도 있는데, 그 때는 cli에 가서 드라이버 다시 설치해주시면 보통 해결됩니다.	1	다음에 다시 인스톨하게되면 Unity를 쓴 일반 우분투 배포본 말고 Gnome으로 한번 설치해보시면 어떨까요. 저는 GTX760(Cuda7.5)을 씁니다만, 비슷하게 숱한 재설치에 지쳐서 한번 깔아 본 우분투 그놈(14.04)을 쓴 이후로 두어 달 재설치질은 안하고 사는군여. 아마도 그놈(!)의 데스크탑이  상대적으로 nvidia드라이버와 충돌이 적은 탓이 아닌가 생각하고 있슴다.	0	저도 예전에 가끔 그런일이 있어서 요즘에는 docker씁니다. 기능은 다 되면서 여차하면 그냥 docker만 다시 만들면되니 훨씬 간편하기도 하고 시간절약도 되서요	0	복길이  저 밑에글 찾아보면 우분투 16.02에러  cuda 8.0+CUDNN 5.1+ananconda 환경에서 빌드한 wheel파일을 공유하신분이 있습니다. 그걸 한번 설치해 보시지요	1	저같은경우는 이방법을 그냥 따라서 설치했습니다. tf version 0.11의 경우 anaconda를 이용해서 설치 해보려고 노력했지만 오류가 뜨더군요... 그냥  python으로 설치하실경우 아래 주소에서의 순서대로 할경우 그냥 바로 실행됩니다.  http://qiita.com/sunfankong123/items/8df412236e0494cc32c2
4	안녕하세요. RNN 튜토리얼 하고 있는데, 각각 파라메터값들에 대해 내부적으로 어떤 개념인지 궁금하여 질문 드립니다. git에 sherjilozair/char-rnn-tensorflow 코드를 기반이구요.Q1-----------------------------num_batches : 2batch_size : 5 seq_length : 6이라고 한다면, 데이터는 //num_batches_1[array([[sq1,sq2,sq3,sq4,sq5,sq6],    //batch_1_1         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_1_2         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_1_3         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_1_4         [sq1,sq2,sq3,sq4,sq5,sq6]])    //batch_1_5//num_batches_2,[array([[sq1,sq2,sq3,sq4,sq5,sq6],    //batch_2_1         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_2_2         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_2_3         [sq1,sq2,sq3,sq4,sq5,sq6],     //batch_2_4         [sq1,sq2,sq3,sq4,sq5,sq6]])    //batch_2_5이런 형태의 데이터가 되겠죠. 그러면, batch_1_1행의 데이터가 하나의 입력데이터개념으로 트레이닝이 되는건가요? 아니면, num_batches_1에 속한 array가 모두 하나의 입력데이터개념으로 트레이닝이 되는건가요? 아니면, sq1이 하나의 입력데이터 개념으로 트레이닝 되는건가요?Q2------------------------------sherjilozair/char-rnn-tensorflow 여기는 저런식으로 트레이닝 후, 하나의 단어 즉, 위의 데이터로 치면 sq1이나 sq2... 중 하나의 데이터를 입력으로 하여 이 후에 나올 값들을 예측을 하게 되는데 출력 값의 길이를 3개로 한다면, sq1을 입력으로 넣게 되면 s2,s3,s4를 출력하게 됩니다. 즉, 1-to-n 방식이 되는 것 같은데요. 저는 n-to-m, 예를 들면 2개의 입력, 3개의 출력을 하고 싶다면  s1과 s2를 입력하고 출력 값의 길이를 3개로 한다면, s1 -> s2,s3,s4s2 -> s3,s4 ,s5이렇게 따로따로 출력이 되게 구현했는데 이게 제가 원하는 n to m인가요?처음에는 트레이닝 단계에서 이미 학습을 했기 때문에 저렇게 하면 되겠지..라는 생각으로 했는데 지금 보니 1-to-n 구조를 2번 실행시킨 결과라는 생각이 자꾸 들어서요..입력 데이터를 모두 연관성있게 넣을려면 어떻게 해야 될까요??	0	Q1. num_batches_1의 행렬이 행렬곱 연산으로 진행됩니다.	0	Q2. rnn구조에서 하나의 시점을 t라고 하면 x_t를 넣었을 때 나오는 y의 값이 출력가능한 n개의 배열로나옵니다. 이것을 argmax를 통해 최대 확률 하나만 출력하게 하는 것인데, 원하시는 n to m이 예를들어x_1=사과는 x_2=무슨 x_3=색입니까?를 입력으로 넣었을 때y_1=빨간색 y_2=입니다.이런것이 나오게 하는것이면 n to m이 맞는것같은데 저 부분은 각 t에서 여러개 나오게 구현한 것 같습니다.
7	Yann LeCun 교수님의 Udacity Talk 이 진행중입니다.	0	Youngduck Choi
5	Tensorflow 공부가 생각보단.. 어렵네요. Tensor객체 디버깅하는게 은근 까다로워서... 혹시 Tensor 객체 디버깅하는 팁같은거 있으신가요?https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html#evaluate-the-model페이지에 있는 tf.equal 함수의 return된 객체가 어떻게 생겻나 보려다가... 답답해서 한번 올려봅니다
8	[스터디원 모집] 텐서팔로우 : 파트 3 + 분산딥러닝 / 동시성 프로그래밍* 2주에 한번 화요일, 저녁 7시 - 10시 30분, 강남, 회비(공간사용료 각자, 1회 3천 500원), 11/15 시작.* 이벤트 링크 - https://www.facebook.com/events/208236069603153/* 이 스터디는 정통..심리학 그룹 싸이그래머에서 진행합니다.* 자료는 모두 공개&공유 됩니다(정리 중)안녕하세요, 텐서플로우 코드 리뷰 위주로 공부하는 스터디 텐서팔로우입니다. 이번에는 분산환경에서의 딥러닝과, 동시성 프로그래밍이 추가되었습니다. 함께  하실 분들은 언제나 환영합니다~----- 상세정보 -----(새롭게 추가된 것)* 분산 딥러닝 - (교재) Distributed TensorFlow -  https://www.tensorflow.org/versions/r0.11/how_tos/distributed/index.html- 그외 여러 자료들* 동시성 프로그래밍- (교재) 7가지 동시성 모델 - http://www.hanbit.co.kr/store/books/look.php?p_code=B3745244799(기존)* 파이썬 병렬 프로그래밍- (교재) Python Parallel Programming Cookbook - https://www.packtpub.com/application-development/python-parallel-programming-cookbook* 텐서플로우 코드 리뷰- 각자 코드 찾아서.
1	안녕하세요 :) 이제 막 머신러닝공부를 시작했는데요. 사진을 입력으로 넣었을때 사진에서 적당한 다섯가지 색의 조합을 갖는 컬러팔래트를 추출해주는 것을 만들어보려고 합니다.  하고자하는것이 regression에 가깝다고 생각했고 마침 교수님 강의를 cnn까지봐서 막연히 softmax대신에 logistic cost fuction을 넣으면 비슷하게라도 나오겠거니 시도해봤는데 아무리 rate를 조정해도 cost값이 nan이 나오네요 ㅠㅠ(이건 tensorflow예제의 mnist코드에서 softmax부분만 logistic cost function으로 바꾸어봐도 역시나 발산하더군요) cnn을 regression에 사용(?)할 경우 어떻게 접근해야 할까요? 기초가 부족한것 같은데 막막합니다.	2	안녕하세요. regression을 하신다면, output layer에 softmax나 logistics가 아니라 그냥 weighted sum을 쓰셔야 합니다. 즉 액티베이션 함수가 없어야합니다.
118	지난 일요일에 텐서플로 1강을 녹화했습니다방송 형태로 컨텐츠를 제작하고 있고요 시간은 매주 일요일 심야시간대에 게시글로 공지 하고 스터디를 진행하고자 합니다관심 있으신 분들은 같이 와서 좋은 이야기 많이 나눴으면 좋겠습니다Sung Kim 교수님의 추천으로 용기를 갖고 가입했습니다잘 부탁드립니다 :)	4	동영상 강의 잘 보았습니다. 강의 잘하시네요. 저를 포함하여 많은 분들에게 큰 도움이 될듯 합니다. 앞으로의 강의도 기대하겠습니다.	3	잘 챙겨 보겠습니다. 감사합니다.	3	도움이 될것 같습니다 감사합니다!!	2	정말 감사합니다!	1	감사합니다~~	3	저도 영상 잘 챙겨 보고 있습니다. 좋은 자료 감사합니다 ^^	3	방송하실 때 여기에도 공지해주세요~	2	우와 인기 짱이네요	4	재미있게 봤습니다. :)	3	유튜브에 머신 러닝 강의 올리시는 분들이 다 모이신듯 ^^	0	재밌게 잘 봤습니다!!ㅎㅎ	0	오우예압 감사합니다
33	NEC, 인공지능으로 100만명의 얼굴에서 특정인물 10초이내 가려낸다!- CCTV 등 영상을 해석 특정 인물을 고속·고 정밀에 검색하는 AI소프트웨어 출시	0	장동인 선배님 Nec에서 이런게 나왔다고 합니다^^
10	최근 딥러닝을 공부하기 시작한 학부생입니다. Tensorflow 공식 홈페이지에서 CNN을 공부하다가 신기한걸 발견했습니다 ㅎ예제 마지막 부분에 Congratulations! 링크가 걸려있길레 뭐지 하고 들어가봤더니 싸이-강남스타일 유튜브로 가지네요 ㅋㅋㅋㅋ그리고 혹시 저희 학교 교수님께서 찍으신 딥러닝 강의를 유튜브로 올리게되면 여기에 링크 올려도 되는지 여쭙고 싶네요~	0	유튜브에 올려주세요 ^^ (링크 올려주시는건 상관 없을듯요)	1	오왕	1	물론입니다. 관련된 자료, 비디오 모두모두 환영합니다.
2	텐서플로우를 통해 mnist를 해보았는데 그럼 이거를 이용하여이미지파일을 입력하여 학습된 결과로 수자로 출력하는 형태로 프로그래밍을 해보고 싶은데어떻게 해야하나요?	0	이미지 파일은 이미지내에 숫자가 군데군데있는형태인가요??	0	예 그렇습니다.	0	tensorflow기본으로 제공되는 코드쓴거면 모델이다릉거에요
196	[2017년 새해 복 많이 받으세요!]TensorFlow를 공부하기 위해 2016년 3월 26일부터 모이기 시작한 TF-KR그룹이 이제는 7,638 분들이 재미난 정보를 "공유"해주시고 함께 "소통"해주시는 정말 신나는 커뮤니티가 되었습니다. 한 해 동안 가입해주시고 자주 찾아주시고 또 열심히 활동해주신 모든 분들에게 감사드립니다.2017년에도 우리 그룹에서 재미있는 공유와 신나는 소통이 이어지기를 기대하며 여러분 한분 한분에게도 만복이 깃드는 새해가 되기를 소망합니다.- TF-KR 운영진 Lucy Park, Jimin Lee, Soonson Kwon, Sung Kim, Park Ricky, and Donghyun Kwak 드림 PS - 저희 그룹이나 그룹운영에 건의 사항이 있으시면 댓글로 또는 저희 운영진에게 메시지등으로 알려주세요. 항상 귀기울이겠습니다.	2	감사합니다	3	덕분에 많은 것을 알아가고 있습니다. 즐거운 연말 보내시고 앞으로도 잘 부탁드립니다!	4	정말 감사합니다~.~ 2017년에도 화이팅!! 저도 내년에는 python & tensorflow 파보려구요 ㅎㅎ잘 부탁드립니다 ^^모든 분들!! 새해 복 많이 받으세요~	2	새해 복 많이 받으세요. 감사합니다^^	2	김성훈교수님과 운영진께 감사드립니다. 좋은 자료와 최신 자료를 모두 공부할 수 있도록 노력하시는 분들 덕분에 저를 비롯한 많은 분들이 큰 도움을 받고 있을거라 생각됩니다. 새해 복 많이 받으세요!!	3	TF-KR 그룹이 2017년 한 해 더욱 소중한 공유의 장이 되기를 기원합니다! Sung Kim 교수님 및 운영진 여러분 새해 복 많이 받으세요~!!	1	새해 복 많이 받으세요^^	1	이제 시작하는 사람입니다. 교수님 강의에 힘을 얻고 있습니다. 새해 복 많이 받으세요.	1	EBS에서 봤습니다. ㅎㅎ 모두 즐거운 새해 맏이하십시오.	1	교수님께서도 새해 복 많이많이 받으세요..	1	한해동안 수고 많이 하셨습니다 그리고 감사합니다	0	교수님 수고하셨습니다 2017년도 화이팅입니다
2	안녕하세요? 텐서플로우 공부 중에 궁금한 점이 있어서 질문 드립니다.현재 Style Transfer 관련하여 파이썬으로 구현된 코드를C++ 로 옮겨서 테스트 해 보고 있는데요~C++에서는 tf.nn.conv2d 같은 함수를 사용할 수가 없어서파이썬에서 freeze_graph 를 이용하여 체크포인트 파일과 그래프 파일을하나로 묶어서 사용하는 것으로 알고 있는데요..Style Transfer 같은 경우 인풋 값이 이미지이기 때문에 placeholder의 shape 값이 (4, 256, 256, 3) 이런식으로 그래프에 attr 로 고정이 되어있는데요..인풋으로 넣는 이미지의 크기가 제각각일 수 있는데, 이 attr 값을 c++ 에서 바꿀 수 있는 방법이 있을까요??? 혹은 c++에서 tf.nn.conv2d 같은 함수를 사용할 수 있는 방법이 있을까요?? 고수분들의 답변 부탁드립니다~~	0	nn_ops.h에 class Conv2D가 정의되어 있는데도 사용이 안되나요?
55	완전 이론보다는 비지니스 적용에 관심있다보니 이번 nips에서 가장 인상깊은 발표 3개중에 하나가 "MODELDB: A System for Machine Learning Model Management" 였습니다.꼭 딥러닝이 아니더라도 분석 모델들이 많이 생성될텐데 그때마다 개인이 에버노트 혹은 노트북으로 관리하는게 아니라(물론 텐서플로우 서빙과 같은 좋은 툴도 있고..), 실험 혹은 현업 적용하면서 도움이 되는 오픈소스가 될 것 같습니다. 사실 이와 유사한 것을 저희 회사에서도 시도를 했었는데 너무 파편화되어서 제대로 되지 못했습니다^^; 논문 발표자와 이야기를 하고 데모도 같이 봤는데 spark, scikit-learn, r 등도 지원하고 있어서 통합 관리할 때 도움이 될 듯 합니다. 연구자 분들께서도 이런쪽이 잘 발전되면 쓰실 의향이 있으신지 혹은 좀 더 고도화된 비슷한 사례가 있는지 궁금합니다.참고로 이 분은 현재 mit 연구실에 있고 ms, google, facebook에서 일한 경험이 있다고 합니다. ㄷhttps://cs.stanford.edu/~matei/papers/2016/hilda_modeldb.pdf
36	머신러닝 전문가들이 2016년의 빅 이슈들과  2017년 전망에 대해 짧은 메시지들을 남겼네요 - by KDNUGGETS
1	Class imbalance 관련 도움될만한 논문이나 메소드가 있을까요?제가 알고 있는 방법은 Class의 weight를 조절하거나 Sampling (SMOTE나 Under sampling) 정도가 있는데 다른 메소드나 관련 논문이 있으면 알려주시면 감사하겠습니다.
4	http://pythonkim.tistory.com/71#recentTrackback이거 보면서 설치중에이런 에러가 낫습니다 어떻게 해결아나요 ㅜㅜ	0	docker 사용하심이 어떠실런지요... (nvidia-docker, 다른 방법이 있는지는 잘 모르겠지만 저는 이렇게 ubuntu box에 설치했습니다.)	0	그냥 0.12를 바이너리로 설치하세요 cuda8.0도 바이너리 설치 가능해요
26	기계학습법을 활용해서 천체물리학 데이터분석을 하는 연구자입니다. 좋은 정보 공유 부탁 드립니다. ^^ (물론 저도 유용한 정보가 생긴다면 기꺼이 공유하겠습니다. ㅎㅎ)	0	오늘 기사에 Pan-STARRS 가 올라왔는데 데이터량이 페타바이트 단위이더군요. 머신러닝이 천체물리학에 어떤 Insight 를 줄지 기대가 많이 됩니다.
0	https://www.facebook.com/byunlisa/posts/1186058261471814
53	안녕하세요.tensorflow와 openAI의 gym을 활용하여 강화학습 알고리즘들을 설명하고, 구현해놓은 블로그가 있어서 소개드립니다.https://medium.com/@awjuliani/latest강화학습 외에도 AI전반에 대해 다루고 계신 분이신데,내용 및 코드에 대한 설명이 친절하게 잘 되어 있네요.강화학습 쪽 목차는 다음과 같습니다.Part 0 — Q-Learning AgentsPart 1 — Two-Armed BanditPart 1.5 — Contextual BanditsPart 2 — Policy-Based AgentsPart 3 — Model-Based RLPart 4 — Deep Q-Networks and BeyondPart 5 — Visualizing an Agent’s Thoughts and ActionsPart 6 — Partial Observability and Deep Recurrent Q-NetworksPart 7 — Action-Selection Strategies for ExplorationPart 8 — Asynchronous Actor-Critic Agents (A3C)Part 4만 잠시 봤는데, double DQN까지도 다루셨더군요.	2	저도 지금 이거 보며  공부하는 중입니다. 4파트까지 한번 읽어보고 다시 처음으로 돌아가서 코드를 하나씩 따라해보고 있어요.	1	교과서 보면서 애매했던 부분을 모두 해소해주는 글들이네요. 소개해주셔서 감사합니다.	2	이 아티클이 Multi Armed Bandit 문제를 풀어가는데요, 저는 MAB를 처음 접해봐서 이 글도 참고를 했습니다. http://sanghyukchun.github.io/96/
6	안녕하세요. 마크 저커버그가 만든 인공지능을 보고 문득 이해가지 않는 부분이 생겨 질문드립니다..사용된 기술은 음성 인식, 자연어 처리라고 알고있습니다만.. 이 두 가지 기술로 어떻게 자기가 해야 할 행동을 학습하는 건가요?사용자가 토스트를 만들어줘 라고 했다면, 자연어 처리를 통해만들어줘 -> 해야 하는 행동이렇게 예측하는 건가요?또.. 해야 하는 행동으로 예측을 한다면, 학습 데이터는만들다 -> make뛰다 -> run이런 식으로 학습해야 할 것 같은데..제가 생각하고 있는 부분이 맞나요?시간 내주셔서 감사합니다.	1	자연어처리 대화모델링에 화행(speech act)분석이 있습니다.이 방법론을 통해 한듯하고 본문에 적으신대로 단어와 class의 쌍이 아닌 문장 전체를 보고 파악하는 방법으로 많이들 사용합니다.	1	인공지능이 특이한건 아닙니다사람이 어떻게 말을 배우는지 생각해 보시면 쉽지요기술적으로는 음성을 문자로 바꾸고 나서, 문자를 이해하고 행동한다 인데요약간 교육받은 작은 뇌가 있다고 생각하시면 됩니다
3	아마존, 인공지능 스피커 '에코 닷' 후반기 휴가 시즌, 최고 히트 상품- 에코와 에코닷은 아마존 AI 음성비서인 알렉사(Alexa)를 탑재한 스피커로 수백만대	0	skt의 nugu도 있어서 사용중인데 아직 기능이 많이 부족하네요ㅎㅎ..
5	윈도우에서  TensorFlow   GPU 버전 설치가 있던데 우분투에서  GPU 버전 깔았을때랑 비교시 성능 차이는 없나요?? ---------------------------------------------------------------------------------------------제가 지금 GTX 1060을 달고 있는데내장 그래픽이 없는 cpu를 달아서 윈도우os는 설치가 되는데우분투나 리눅스os는 설치가 안됩니다.....컴퓨터가게도 가보고 이곳저곳에서 다 물어봤지만 대답은... 내장그래픽이있는 cpu를 사서 다는법이라고......	0	1060 우분투1604위에서는 잘돼는걸로알고있는데 안돼시나요	4	윈도우 tensorflow gpu 버전 리눅스와 속도차이 거의 없습니다굳이 리눅스버전 써야할이유 아님 윈도우버전 쓰는게  정신건강상 좋습니다^^참고삼아 저는 1080에 윈도 ,리눅스 동시 사용중입니다	1	우분투 설치화면 자체가 먹통이죠? 저도 겪은 일인데 해결을 못 했습니다	1	저는 i7에 gtx1070두개 설치해서 우분투에서 진행하다가 윈도우버전 깔았는데 처리속도가 두배정도 느려졌습니다. 리눅스에는 50000번 epoch가 도는동안 약 2분걸렀다면 윈도우에서는 5분정도 걸리더라구요. 최신버전을 깔지는 않아서 업그레이드 해볼예정이예요.	1	아직까지는 리눅스가ㅎ	0	ubuntu가 설치 안되나요? i7-6700k이지만, gtx980ti 에 모니터 연결해서 설치해서 사용하고 있습니다	2	파스칼 아키텍쳐(gtx10x0)에서만 벌어지는 문제입니다	2	위에 무한로그인 문제 언급하신 분들이 많으신데, bios setting에서 UEFI boot security 체크 시 OS를 window가 아닌 것으로 설정하면 대부분 해결되던데요. 이런 식으로 해결하신 분은 없으신가요? 도움이 될까해서 남깁니다
1	가입승인 감사드립니다!아직 인공지능에 대해 잘 모르는 부분이 많지만, 좀 더 공부해서 TenserFlow 꼭 제대로 돌려보고 싶습니다 :)잘부탁드립니다~
12	로크웰오토메이션, 머신러닝 기반 '예측 유지 보수 솔루션'으로 가동 중단 시간 감소- 강력한 기계 학습(Machine Learning) 알고리즘과 예측 분석 소프트웨어를 결합
3	승인 감사합니다~ 최근(실은 조금씩 관심이 있긴 했지만... 넘사벽이라 생각하고 살짝살짝만 봤네요..) 머신러닝에 관심을 갖게 됐고, 내년 목표를 TensorFlow 탄탄한 입문으로 잡았습니다. 앞으로 잘 부탁드립니다.
9	CNN 연구하다가 궁금한 것이 있어서 질문 드려 봅니다ㅠㅠ예를 들어 AlexNet에는 몇 개의 convolution layer가 있고, 각 layer에는 많은 convolution filter들이 있죠.그리고 직관적으로 생각해보면, 모든 filter들이 다 동일하게 쓸모가 있을 것 같지는 않습니다. 어떤 filter들은 정확도 향상에 많이 기어햐는 반면, 어떤 filter들은 별 존재감이 없을 수도 있을 것 같아요. 제 질문은... 이런 CNN filter들의 상대적 중요도? 공헌도? 에 대한 주제를 다루었던 논문이 있는지 궁금합니다. 감사합니다.	7	https://arxiv.org/abs/1602.07360질문하신게 이거랑 관련있는건지는 모르겠네요, 결국 학습데이터에 따라 filter(output node)를 과하게 잡았을 경우에 나타나는 sparse한 공간을 quantize하는 방식입니다. 의미있는 필터(상대적 중요도)들을 인덱싱하고 아닌 경우에 과감히 내쳐서 의미있는 필터들만 보유하게 함으로써, 정확도에서도 약간의 증가를 보일 뿐더러 공간적 이득을 많이 보게하는 논문입니다. GPU 머신에서 문제점인 메모리와 하드웨어 설계쪽(H/W설계는 저도 잘 모릅니다 ㅠㅠ)의 한계를 극복하기 위한 방법을 제시한 것 같은 논문입니다. 저도 자세힌 안읽어봐서... 한번 확인해보세요.	0	필터를 하나씩 날렸을때, 정확도가 가장 많이 떨어지면, 중요한 필터. 정확도가 쪼금만 떨어지면, 별로 않중요한 필터.	0	Given only a few weight values for each feature it is possible to accurately predict the remaining values.https://arxiv.org/abs/1306.0543
5	딥 러닝을 학습할 땐 많은 데이터를 필요로 하는데 만약 소규모의 데이터를 학습하고 예측할땐 어떻게 해야하나요? data augmentation을 통해서 수집하는 방법이 있지만 또 다른 방법이 존재하나요? 또한 데이터의 변화가 별로 없는 경우 어떻게 해야하나요?	1	pre-trained model을 사용해서 fully-connected layer 만 학습하는 방법도있습니다	0	간접적으로나마 해결할수 있는 방법이 gan 아닌가요?	0	data augmentation 의 한 갈래라고 할 수 도 있지만 http://web.mit.edu/cocosci/Papers/Science-2015-Lake-1332-8.pdf 이런 방법도 있습니다. 여기선 시계열 데이터에만 적용했긴 하지만요.
73	최근 인공지능 관련 책들이 많이 출간되어 드디어 이 주제로도 제법 구색을 갖춘 맵을 만들 수 있었습니다.대부분 아시는 책들이겠지만, 신간도 몇 권 있으니(제가 번역한 책도..^^) 가볍게 함 훑어보세요.앞으로도 좋은 신간들이 나오면 지속해서 추가할 겁니다.(제 번역서를 리뷰해주신 분들 모두 정말 감사합니다. 따로 연락드릴게요~)	0	감사합니다.	2	딥러닝>프레임워크/라이브러리 부분에 의견 있습니다. 제가 읽은 바로는 '가장 빨리 만나는 딥러닝 with Caffe'가 '텐서플로 첫걸음' 보다 선행이 되어야 할 것 같습니다. Caffe 책 읽어보면 아시겠지만 전체적인 머신러닝/딥러닝의 개념을 쉽게 설명하고 Caffe는 맛보기로 조금 나오는 수준입니다. 그리고 '텐서플로 첫걸음' 다음에 '텐서플로 입문' 이 나오는게 좋지 않나 합니다. 도서정보는 (http://book.naver.com/bookdb/book_detail.nhn?bid=11185338) 입니다.	0	멋지네요. 감사합니다.
2	안녕하세요~ 눈팅만 하다가 질문 올립니다.다름이 아니라 제가 nvidia gpu가 있는 macbook pro(El capitan)를 사용하고 있는데요. 혹시 tensorflow-gpu를 설치법이 잘 설명된 자료나 설치법을 알고 계신분이 있으신가요?구글링해보니 security 이슈가 있어서 cuda 설치가 어렵다는 글을 본거 같은데 혹시 가능한지 알고 싶습니다.아시는 분 있으시면 댓글 부탁드립니다. 감사합니다.	1	http://m.blog.naver.com/hms4913/220757210405사실 OSX는 써본 적도 없고 써볼 예정도 없어서 알려줄 게 없네 ㅇㅇ...	0	맥북은 gpu지원 안되는걸로 알고 있는데 혹시 제가 잘못알고 있는건가요?	0	옛날 gpu 신가보네요. 지금은 고장나서 없지만, 기능했었습니다. 그리고 현재 맥북은 외장 그래픽 카드이용하면 설치 가능합니다.	1	헌데 현지 cuda를 옛날 gpu믄 이제 지원 안할겁니다.	0	맥프로에 gpu를 교체하지 않는한 맥북에서는 안되는 것 같아요.	0	저는 맥북 프로 NVIDIA GeForce GT 750M 2048 MB으로 잘 쓰고 있는데요. 문제는 CPU보다 특별히 빠르지 않은 게 문제고요. CUDA는 그냥 설치하면 되던데... 무엇이 문제인가요?	0	그냥 문서보고 설치하면 됩니다. 몇 가지 에러가 발생하는 경우가 있는데, 해결방법이 텐서플로 공식 사이트 문서에 다 있습니다. :-)
9	안녕하십니까? 공부 중 궁금한 점이 있어 여쭙습니다.기본적인 것이라 여쭤보기가 민망하지만 놓치고 있는 부분이 있는 것인지 이해가 어렵습니다.도서 텐서플로 첫걸음의 부록에 있는 RNN관련한 질문입니다.tensorflow tutorial rnn과 동일한 것으로 알고 있는데요.코드는 다음 링크에 있습니다.https://github.com/rickiepark/first-steps-with-tensorflow/tree/master/rnn_ptbreader.py와 ptb_word_lm.py을 확인하시면 됩니다.제 질문은tensor dimension 진행을 보면처음 데이터 [929589] -> 20개의 batch로 나눠져 [46479, 20] -> num_steps = 20 통해서 mini batch 화해서 [20, 20] -> 여기에 embedding 작업을 통해서 200개의 특성이 붙어 [20, 20, 200]-> 그래서 최종적으로 cell에 입력 되는 것은 하나의 batch 에서의 [20, 200] 인데요여기서 궁금한 부분이 cell에 [20, 200] 이 입력되게 되는데 hidden_layer=200이기 때문에 embedding 통해서 나온 각 data의 feature도 200개고 cell도 200개 라고 이해하고 있는데요.그런데 이런 경우 한 cell에 들어가는 것이 한 단어의 feature가 아니라 20개 단어의 첫 번째 feature, 그다음 feature 이런식으로 200개의 cell에 대입되게 되는데요.이런식으로 동작하는 경우 각각의 hidden state가 어떻게 출력되는 것인지요?다시 말씀드리면 첫번째 cell에 [20, 1] (data, feature from embedding)이 들어가는데 이것으로 각 단어에 대한 예측값인 y가 나올 수가 있는지요?20개의 단어가 들어가면 20개의 y값이 나와야 할텐데 어떤 방식으로 구동이 되는 것인지 궁금합니다.제가 놓치고 있는 부분이 있다면 말씀 부탁드립니다.감사합니다.	2	안녕하세요. 말씀하신대로 셀에 입력이 20x200 으로 들어가게 됩니다. 그런데 셀이란 단어에 혼돈의 여지가 있습니다. 텐서플로우 코드에서 cell 이라 함은 전체 RNN 네트워크를(마지막 FC를 뺀) 나타냅니다. 흔히 우리가 뉴럴 네트워크를 그릴 때 하나씩 그리는 뉴런도 가끔 셀이라 표현하기 때문에 혼돈이 될 수 있습니다. 뉴럴 네트워크 코드는 보통 뉴런단위 보다는 레이어 단위로 행렬연산이 되기 때문에 전체를 퉁쳐서 생각하시면 좋습니다. cell 에 입력되는 값이 20x200 이고 이의 출력 값도 20x200 이 됩니다. 타입스텝 20 번에 걸쳐 셀 출력을 그대로 누적해서 outputs.append(cell_output) 에 차곡차곡 쌓습니다. 결국 셀에서 나온 최종 출력은 20x20x200 이 됩니다. 예측 값은 마지막 소프트 맥스 함수를 거쳐서 20개 배치, 20개 타임스텝에 대한 10000 개의 단어에 대한 확률을 출력하게 됩니다. 셀 스테이트와 히든 스테이트는 20 개 배치에 200 개의 히든 유닛(뉴런)이 있으므로 20x200 이 됩니다. 도움이 되셨는지 모르겠네요... 음 근데 깃허브 프로필 사진이 이렇게 대문짝만한게 나오는 건 정말 민폐네요.  본의 아니게 안구를 혼탁하게 해드려 죄송합니다. ㅠ.ㅠ	1	rnn 에서는 cell 을 뉴런 하나로 보지 마시고 히든 레이어 전체로 보셔야 혼돈이 되지 않습니다. 실제 구현된 코드도 그렇게 되어 있거든요. 즉 히든 레이어에서 나오는 출력(히든 스테이트)이 200개(유닛 개수가 200개 이므로)입니다. 물론 셀 상태는 다음 타임스텝으로 쓰기 위해서 따로 저장됩니다. :-)
0	안녕하세요. 얼마전에 텐서플로우를 알게되서 공부하고 있는데요. 가장 어려운게 정보의 부재입니다..100개의 랜덤한 점의 위치를 생성해서 Tensorboard로 보려면 어떻게 해야 할까요?tf.random_uniform([10,2],-10,10) 이런 식으로 10개의 점을 만드는것 까진 했는데 이걸 어떻게 Tensorboard로 가시화할지 모르겠어요.. summary? 이걸 어떻게 잘 비벼야하나요? 아무리 찾아봐도 안나와서 질문 드립니다. 감사합니다.
62	텐서플로우 사이트의 MNIST Beginner 내용을 다시 정리한 내용입니다.원래 문서에서 설명이 빠진 부분을 좀 보강하고, 수학적으로 복잡한 부분은 별도 이해없이 넘어갈 수 있도록 하였습니다. :)	0	y = tf.nn.softmax(tf.matmul(x, W) + b) 부분을 궁금해하신 (저도 마찬가지) tf.matmul 만 하도록 하시면 가이드에 나오는 대로 92% 까지 결과를 얻으실 수 있습니다. 저는 그래서  tf.nn.softmax_cross_entropy_with_logits 과의 양립 여부를 전에 댓글로 답변 드렸던거구요. 도움이 되시면 좋겠습니다. 저도 이유에 대해선 구글신이 알려주지 않더군요 ^^	0	어짜피 Softmax는 결과값을 1.0으로 normalization하는 것이라, softmax를 쓰지 않더라도 트레이닝이나 예측에는 상관이 없을듯 합니다. 확률로 보기 좋게 1.0으로 맞추는 개념이라고 알고 있습니다.
3	안녕하세요. 최근 뉴럴네트워크와 딥러닝에 대해 공부하고 있는 대학원생입니다.저번에 몇번 질문을 올렸는데, 답변 해주셔서 항상 도움을 받고 있습니다. 감사합니다!최근 (사실 저번부터) 궁금한 사항이 몇가지 있는데뉴럴네트워크 구조를 디자인할 때 어떤 방식으로 Layer 개수나,사이즈를 결정하는지에 대한 구체적인 방법론이 존재하나요??제가 아직 하수인지라,접했던 연구들은 가장 성능이 좋은 구조를 찾아 몇개 레이어,몇개 사이즈로 결정했다~~이런식으로 가볍게 서술하는 식이 많더라고요..Neural Network Construction 등의 키워드로 찾아보긴 하였는데,1차 트레이닝 후,사이즈를 키워가며 추가된 뉴런들을 트레이닝 하던가,큰 사이즈로 트레이닝 후,성능에 큰 영향이 없는 수준까지 개수를 줄인다던가하는 방법들은 조사하고 학습하였으나구체적으로 레이어 수,사이즈 등을 결정하는 엄밀한 방법이나 가이드라인이 있나요?(특히,모델 안에 다양한 네트워크들이 동시에 사용될 경우,이에 대한 검증이 중요해보여서요..)Batch size, Batch Num과 관련해서도 같은 질문이 드네요..제가 아직 체계적으로 모든 개념들을 차근차근 밟아오지 않아,부족하거나 어리석은 질문일 수 있지만답변해주신다면 학습과 연구에 큰 도움이 될 것 같습니다!!	0	현재는 크게 어려 부분을 바꿔본 후 성능가장 좋은 모델을 찾아가는 식으로 Model Construction을 해나가고 적용하고 있는데,현재 모델이 엄밀한 방법으로 구성되어있나 하는 질문이 계속 들어서요..ㅠㅠ	1	제가 알기론 정형화된 방법론은 아직 없고 애드혹한 접근이 이루어지고 있습니다.. 연구자나 실무자들의 경험치가 트라이얼을 줄이는 방법이라 합니다.	1	흠...가장 최적인 파라미터 설정 같은건 아직 없는 것 같아요. 다만 실험하시는 분들이 휴리스틱하게 얻어낸 것들을 가지고 모델을 구성하는 것같습니다. 이미지넷에 우승한 모델들이 그런 기준을 가지고 구성한 것이니 그것을 보고 자신의 데이터에 맞게 조절하면 될 듯 합니다.
6	텐서플로우 구동시킬 os 리눅스가좋나요? 윈도우즈가 좋나요?? 이유도 말해주시면 감사드리겠습니다 !!	1	Linux요. 사견	1	저도 리눅스라고 '생각'합니다.	2	윈도우에서도 GPU 돌릴 수 있어서 이젠 리눅스가 아니어도 상관없는것 같아요	1	얼마전까진 리눅스만 되어서 선택의여지가 없긴 했죠...편한거 쓰세요	4	전 개인적으로 가상머신에 우분투올리고 환경세팅하는게 편해서 우분투에 합니다	3	나중에 포맷하거나할때 가상머신이미지만 백업하면 되서 편하더라고요	1	텐서 플로우가 윈도우도 잘 지원해요. 그래서 익숙한 환경이 내게 가장 잘 맞는 것이 아닐까요?	2	원래 리눅스에서밖에 지원을 안해서 리눅스에서 사용하다가, 윈도우로 넘어왔더니 너무 편하네요...설치부터 사용 환경까지 모두요....	2	리눅스죠	2	Linux	1	처음 한다면 윈도에 한 표! 이런저런 귀찮은 세팅 없이 편하게 텐서플로를 즐길 수 있습니다 ^^	1	윈도우가 편해서 윈도우 표 던집니다	0	window와 linux의 차이를 모르겠으면 도커를 사용보세요.	1	전 우분투 추천 합니다	1	GPU를 사용하실거면 리눅스 ...	0	전 도커에 텐서플로우 이미지 올려서 사용합니다.
318	[Reinforcement Learning with TensorFlow & OpenAI Gym] 강의 예고ATARI 게임들을 자동으로 학습하여 사람보다 잘하고, 이세돌 선수를 이겨버린 알파고의 핵심인 강화학습! TensorFlow와 OpenAI Gym 를 이용한 강화학습 강의가 2월 1일 부터 공개됩니다.아래가 대략적인 주제이며 lab과 함께 최소 12강에서 15강으로 이루어질 예정입니다. (아직 강의를 다 만들지는 않았으니 혹시 추가해야할 중요한 주가 주제가 있으시면 알려주세요.)강화학습강의를 위한 선수 과목으로 "모두를 위한 딥러닝" ( https://www.inflearn.com/course/기본적인-머신러닝-딥러닝-강좌/ 또는 https://hunkim.github.io/ml/) 필수 입니다!	4	Double DQN, Dueling Network, A3C 등에 대해서는 다루지 않으실 예정이신가요?	1	기다리고 있었습니다! 좋은 강의 감사합니다	1	선수과목 다 들었습니다.  :) 2월까지 손꼽아 기다려야겠네요~	1	강화 학습 한글 자료의 부족함을 느끼고 있었는데좋은 강의 감사합니다!	0	와 드디어!!!!!!!!! 혼자서 강화학습 내용 찾아가면서 openAIgym 낑낑대고 있었는데 강의를 해주시면 정말 이해가 잘될거같습니다!!!!!!	0	사랑합니다 교수님!!	0	교수님 최고 ^^	0	매번 유튜브에서 강의 잘 보고 있습니다!! 넘나 감사합니다..	0	기대중입니다!	0	또 한번의 명 강의 기대 하겠습니다.. 교수님 강의 듣고 많이 배우고 있습니다.	0	우와 엄청 기대되네요!!	0	기대됩니다~~^^	0	최고의 기대작!	0	와 대박 기대됩니다.	0	기대됩니다. 미리 감사드립니다	0	기대합니다	0	오!! 다른 분야는 너무 어려워서 오픈짐 통한 강화 학습 자습하던 중이었는데 너무 반가운 소식이네요!! Torcs 로 강의 하실 계획은 없으신지요?	0	강화학습 개념이 넘 어려운데요..기대하고 응원드립니다!!!	0	너무 기대됩니다! 감히 따라갈 수 없는 열정에 경의를 표합니다!!	0	기대하고 있습니다 ^^	0	기대됩니다	0	감사합니다!!!	0	오.. 기대됩니다.	0	멋져부러요~
68	며칠 전, 애플이 최초로 arXiv에 업로드한 논문인 'Learning from Simulated and Unsupervised Images through Adversarial Training'를 PT 형식으로 제 나름대로 정리해보았습니다.http://www.slideshare.net/JungHoonSeo2/paper-reading-learning-from-simulated-and-unsupervised-images-through-adversarial-training원 논문 링크 : https://arxiv.org/abs/1612.07828
77	어제 브로드캐스팅 개념이 헷갈려서 다시 정리해봤습니다.	0	numpy와 pandas에 기본 개념도 브로드캐스팅과 벡터화...
146	오늘 많은 분들이 와주셔서 정말 감사합니다. 오늘 발표했던 내용 슬라이드 올려드립니다. 프로시딩이랑 차이가 많아서 이걸 보시는게 도움이 될거같습니다. 	2	좋은 말씀 잘 들었습니다. 조심해서 내려가시고 아이도 빨리 낫길 바랄께요! :-)	1	상당히 잘 만들어진 자료 잘 읽어 보았습니다. 강의를 듣지 못해 매우 아쉽습니다.	1	잘 들었습니다 다음에  또 뵙겠습니다  자료는 소중하게  보겠습니다 ^^	2	저도 오늘 강의 정말 잘 들었습니다!! 대전 조심히 가세요 :-) 다음 모임 때 뵙겠습니다!!^^	1	강의 잘 들었습니다. 수고 많으셨습니다.	3	오늘 수고가 많았어	1	강의 정말 잘 들었습니다! 감사합니다!	1	좋은강의 잘들었습니다:)	1	현장감 있는 강의 잘 들었습니다 감사합니다 ^^~	1	잘 듣고 왔습니다. 고맙습니다~~	2	훌륭한 강의였습니다. 자료까지 공유해주셔서 감사합니다.	1	좋은 자료 감사드립니다!	0	감사해요 잘 볼께요^^
198	오늘 과학기술회관에서 발표했던 자료 공유합니다.딥러닝을 처음 접하는 분들을 위한 자료입니다~~	0	공유해주셔서 감사합니다~^^	0	설명이 깔끔하네요~~	3	http://capp.snu.ac.kr/main.php  연구들이 재미있네요	2	자료 감사합니다~ 제목과 후기 듣고 꼭 한번 보고 싶었어요~ 근데.. CAPP 학생이세요? 저도 거기.. ㅎㅎ	3	시간이 허락하면 따로 강의로 만들어서 올려보도록 하겠습니다~(언제가 될 지는 모르겠지만요ㅠ)	1	잘 정리된 슬라이드 재미있게 보았습니다.	2	오늘강의정말감사합니다~!	1	오늘 강의 잘 들었습니다 감사합니다	2	아주 명확하네요. 몇달 전에 이것저것 찾아보며 공부할때는 이런 설명이 없어서 코드 부여잡고 머리를 싸맸는데...좋은 자료 감사합니다!	2	강의 너무 잘 들었습니다. 오프라인에서 뵈어서 반갑습니다.^^	1	신청하고 못가서 아쉽습니다..ㅜㅜ..자료잘보겠습니다~	1	오늘 강의 잘 들었습니다. 감사합니다^^	1	원더풀 !  수고 많으셨습니다.	2	아  오늘  발표  잘  들었습니다  발표  잘하시더라두요 ^^	1	수고 많으셨어요.내용도 내용이지만 발표 너무 잘 하시던데요? ^^	1	고퀄 자료 감사합니다!	1	오늘 너무 재밌게 잘 들었습니다:))	1	너무 좋은 강의였습니다. 자료까지 배포해주시다니, 정말 감사합니다.	1	감사합니다~ 자료 잘 받았습니다~!!!	1	a-z 설명 매우 감사합니다. 혹시 악기데이터와 안구데이터 돌리신 github 주소를 알 수 있을까요?
46	애플도 첫 논문을 공개했네요
13	텐서플로우 MNIST softmax 예제 코드를 보면모델이 https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py# Create the modelx = tf.placeholder(tf.float32, [None, 784])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10]))y = tf.matmul(x, W) + b인데, y = tf.nn.softmax(tf.matmul(x, W) + b)이게 맞지 않나요?	0	cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))여기서 소프트맥스를 해줍니다	0	저도 이것때문에 한참 헷갈렸었는데 softmax_cross_entropy_with_logits를 적용하는 여부에 따라 결정되더군요. 구버전의 MNIST 예제를 보시면 차이가 보이실겁니다. 깃헙보다는 tensorflow.blog에서 공개하신 First Contact With Tensorflow 책의 4장 예제가 구버전의 예제이니 차이를 보시면 좋을 것 같습니다.
37	파이썬 모듈들을 공부하고 있어 많이 사용하는 2개를 간략히 정리했어요
4	혹시 tf.train.batch()와 tf.train.shuffle_batch() 차이를 잘 알고 계시는 고수님계신가요?전 단지 shuffling된 결과를 넘겨주냐 아니냐인 줄 알았는데, tf.train.batch()하더라도 shuffling된 결과가 넘어오네요.batch만큼 데이터 읽어올 때 정해진 데이터가 아니라 매 번 다른 데이터가 넘어옵니다.저는 cifar10 DB에서 test용 영상과 레이블을 batch_size = 10으로 하여 읽어드리고 프로그램 실행 시 첫 batch에 대해서 레이블을 찍어보니, 프로그램 실행할 때마다 다르네요.혹시 아시는 분들 답변 부탁드립니다~	1	다른쪽에shuffling된거 같은데요 코드를 안봐서 확실히는 모르겠지만 input_producer는 default로 shuffle하게되어있어서 이거 때문일 수도있고요	2	http://stackoverflow.com/questions/35001027/does-batching-queue-tf-train-batch-not-preserve-order
0	1x1 Convolution, NIN, Inception model의 설명에서 등장하는 'local receptive field'를 어떤 식으로 이해하면 좋을까요? 한글로 표현한다면 어떤 단어 가 될까요? 조언 해주시면 많은 도움이 될 것 같습니다. 감사합니다 !^^	2	의미는우리의 신경이 특정 부분에서만 영향을 받는다는건데요팔뚝을 꼬집어도 그 꼬집은 부분만 통증이 오고 발가락은 안 아프잖아요 신경 자극 수용영역이 지역적이다 이상하긴 하네요 ㅋㅋㅋ
44	많은 분들이 보셨을 동영상인데요 저는 요즘에야 마스터 알고리즘이란 책이랑 이 동영상 보았습니다. 마스터 알고리즘이랑 이 동영상이 저 같은 완초보들이 이 분야에 입문하기 위한 전체적인 그림을 보는데 도움이 될 것 같습니다.  추천하는 의미에서 올립니다.  https://youtu.be/efWSbITntR0https://youtu.be/5zecsT0OlG4	0	감사합니다.
20	텐서플로우 MNIST Softmax 예제를 보면# Create the modelx = tf.placeholder(tf.float32, [None, 784])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10]))y = tf.matmul(x, W) + b부분이 있는데,x가 55000개의 데이타이면55000 x 784 행렬이 되고, W를 곱하면, 55000 * 10 사이즈 행렬이 되지 않나요?그러면 어떻게 55000 x 10 행렬에, b (1x10) 행렬을 더할 수 있지요? 돌기는 도는데.. 몬가 잘못이해하고 있는것 같아서 질문 드립니다.	0	차원이 다른데도 더해지네요. 다른 테스트를 해봤습니다.import tensorflow as tfinput_data = [     [1,1,1],[2,2,2]    ]x = tf.placeholder(dtype=tf.float32,shape=[None,3])w  =tf.Variable([[2],[2],[2]],dtype=tf.float32)b  =tf.Variable([4],dtype=tf.float32)y = tf.matmul(x,w)+bprint x.get_shape()sess = tf.Session()init = tf.global_variables_initializer()sess.run(init)result = sess.run(y,feed_dict={x:input_data})print result	0	https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html	0	아, 저번에 예제 볼때는 무심코 넘어갔는데 덕분에 다시 한번 보게되네요 :)	0	https://images.google.co.kr/imgres?imgurl=http%3A%2F%2Fwww.scipy-lectures.org%2F_images%2Fnumpy_broadcasting.png&imgrefurl=http%3A%2F%2Fwww.scipy-lectures.org%2Fintro%2Fnumpy%2Foperations.html&docid=ASBmt001TjplmM&tbnid=OpQNZXhOQREPrM%3A&vet=1&w=1238&h=898&source=sh%2Fx%2Fim	0	아무래도 브로드 캐스트 같은데..	0	저도 저 예제 처음 봤을때 딱 막혔던게 b더할 때 차원문제와 (broadcasting 때문 가능) Wx가 아닌 xW일까였네요.(batch를 다루기 위함)아. 참고로 bais 더할 때 tf.nn.bias_add()를 사용하기도 합니다.
7	어제 과학기술회관의 발표 잘 들었습니다. 짧은 세션들의 세미나보다 넉넉한 시간을 가지고 충분히 이야기를 풀어주시는 시간이라 많은 공부가 되었습니다.어제 인상깊었던 부분을 한 단어로 표현하면 Interpretability 였습니다. 블랙박스인 머신러닝의 학습부분을 인간이 이해할 수 있게 풀어내기.김현준님께도 여쭤보긴 했지만 머리속이 명쾌하게 정리되지는 않더군요.1. 머신이 학습한 가중치, 알고리즘을 인간이 이해할 수 없는 수준이 오지 않을까? 마치 인간이 원숭이에게 자동차의 구조와 원리를 이해시키는것이 불가능 하듯이2. 윤리, 법리, 인간중심의 사고의 측면에서는 필요하겠으나 순수하게 기술발전의 측면에서도 머신의 학습을 인간이 이해하는것이 필요한가? 기술의 개발에 유의미한 기여를 하는가? - 다시 한 번 세 발표자분께 감사의 말씀 드립니다.
8	안녕하세요 이제 막 텐서플로우 시작한 대학생입니다.제가 윈도우7에서 아나콘다프롬프트창을 활용해서 텐서플로우를 공부하고 있는데 프롬프트 창에서 텐서플로우를 사용하기에 많이 불편해서 그러는데..... 혹시 윈도우7 아나콘다 환경에서 파이참 활용하시는 분들 계신가요?ㅠㅠ	1	아나콘다를 설치하면 스파이더가있을텐데 그거 쓰시면 편할거에요	1	인터프리터만설정하시면 파이참 이클립스다가능합니다	1	스파이더도괜찮습니다	1	아나콘다 프롬프트 창이나 cmd창에서 jupyter notebook 쳐 보세요. 파이참은 아니지만 좋아요 😁	1	윈도우 10을 설치해서 윈도우버전 텐서플로우 사용하세요.	1	파이참 쓰고있습니다.	0	Visual Studio와 Visual Studio Code도 사용 가능합니다.
113	안녕하세요! 저희 회사 (ab180) 스터디의 일환으로, 딥러닝이 이미지 프로세싱 분야에 적용된 예시와, 이미지를 다룰때 가장 많이 쓰는 네트워크인 ConvNet에 대해 정리해봤습니다.아직 많이 부족하지만, 더 많은 분께 조금이라도 도움이 되고자 스터디 자료를 공유해봅니다!	1	좋은 자료 감사합니다.	0	자료 감사합니다	0	자료 감사합니다.
49	강남 과학기술회관에서 개최된 공개강좌 "인공지능 시대 어떻게 준비할까 ?"인공지능에 대한 지대한 관심을 보여주듯고등학생부터 노교수 분들까지 700여 좌석이 꽉찼을 정도첫번째 발표는 Vuno의 김현준 CSO의 "인공지능 기반의 의료영상분석"- 전세계 의료영상 SW 시장규모는 약 2조원- 폐질환 분석의 경우 인간보다 월등한 97%의 정확도- 골연령 자동측정등 다양한 의료분야의 기술개발 중- 풀어야할 과제 :  결과만 좋게 나온다고 끝나는 것이 아니라 user를 충분히 설득할 수 있는 근거를 제시하여 함오작동을 실제로 사용자가 인식할 수 없는 경우가 존재인간의 숙련도 및 환경 변화 대처능력 저하시킴오진 발생 시 책임소재등의 문제로 전문의의 보조적인 역활로만 제한두번째 발표는 서울대 이진원 연구원의 "인공지능의 작동원리와 활용분야"인공지능을 처음 접하시는 분들을 대상으로 이해가 쉽도록 설명자료를 만들기 위해 무척 고심한 흔적이 역력하고 설명도 잘 하시고.기본개념의 이해에 많은 도움을 줄  입문자를 위한 최고의 자료  Wonderful !마지막 세번째 발표는 세트렉아이의 전태균 박사가 발표한 "항공우주분야의 적용사례와 인공지능 관련 능력개발 방법"- 우선 항공우주분야에 있어서 SW기술의 중요성에 대한 강조가 인상적- Super resolution, Object detection, Trend analysis등과 같은 실제 활용기술에 대한 소개- 미래 인공지능의 발전방향은 하나의 플랫폼에서 다양한 분야에 대해 적용이 가능한  범용 인공지능(Artificial "General" Intelligence)- 인공지능 관련 역량을 효율적으로 개발하는 방법- 인공지능 시대에 생존하는 방법등전박사님 발표자료 참조하셔요.	1	행사자료에 직함 오기가 있었는데, CTO 아니고 CSO입니다 :)
9	안녕하세요 저는 개인적으로 혼자 deep learning을 공부하고 있는 학생입니다. 다름이 아니라, 질문이 몇가지 있어서 고수님들께 조언을 구하려고 올립니다.현재 CNN + Auto encoder를 조합하는 모델을 만들고 싶습니다.레이블이 없는 이미지 데이터들의 feature들로 표현을 하고, 그 feature들의 유사성으로 유사성 판단을 할 목적입니다.CNN, AE는 각각을 공부해서 개념을 이해하겠지만, 조합을 생각하려니 몇가지 문제점이 있었습니다.예를 들어 convolution layer 2개짜리라 가정했을때CNN :   Input(X) -> conv1 -> maxpooling -> conv2 -> maxpooing -> fcCost : Y - Y’가 최소 (Y : 레이블,  Y’ : fc*w + b)AE : input(X) —> encoding —> Y —> decoding —> ZCost : Z - X 가 최소 (Z: 노이즈를 준 X 를 인코딩하고 디코딩, X: input)그래서 조합된 모델을 생각했을때는처음 Input에 노이즈를 준 후 convolution과 풀링과정을 여러번 거친후 fc 가 나왔을때 Y를 fc *w + b 로 정의합니다. // 인코딩 + convolution이제 디코딩하려면 convolution과정은 썻던 w 의 역함수를 곱하면 되지만, 풀링과정에서는 데이터 손실이 있어서 복구가 불가능합니다.그렇다고 풀링과정 없이 학습을 하자니 계산량이 어마어마할것 같습니다. 만약 풀링과정(2X2)이라면, 리버스는 1개의 셀을 제외한 3개의 셀에 아무값이나 넣어도 될런지, 혹은 1이나 0으로 넣는게 좋은지,혹 3개의 셀에 아무 값이나 넣어도 된다면 굳이 Input에 노이즈를 줄 필요는 없다고 생각이 듭니다.여기서 cost는 처음 input과 모든 과정을 다 거친 Z의 차이로 계산하려 합니다.(nosed_X -> encoding -> convolution -> pooing -> Y -> reverse pooling -> reverse convolution -> Z, 최종적 cost = Z-X)그리고 혹시 tensorflow에서 이런 과정을 해주는 함수들이 있을까요?? convolution, 풀링의 리버스 에 관한…어떤 답변이든 저에게 큰 도움이 될 것 같습니다. 대부분의 강의들은 일반적이거나, 예제없이 추상적인 개념위주의 설명이라관련된 자료를 찾기가 쉽지 않아 글을 올립니다….혹, 댓글로 쓰기 어려우시면 메일로 답변을 주셔도 됩니다.감사합니다.hyundae313@gmail.com	1	키워드는 transpose입니다. 흔히들 deconv라고도 하는데 좋은 표현은 아닙니다. 그리고 풀링의 리버스는 fractional stride라고 해서 stride를 0.5를 주는 것으로 이해하면 됩니다.위 모든 것을 tensorflow에서는 conv2d_transpose 함수를 사용하면 됩니다.	1	음 convolution의 역함수를 곱하는 것으로 손실없이 복구가 되는지 모르겠네요. activation이 없다고 가정할 때 convolution의 역변환은 dense하지 않나요?	0	Sedong Nam 조언 감사합니다 !!	0	봉희종 (Heejong Bong) 제가 아직 초보라서 혹 질문이 잘못됬을수도 있습니다,, 제가 이해한 바로는 convolution에 쓰이는 w들의 역함수를 곱하면 되리라 생각합니다. data 손실이 없는 연산이므로 리버스 역시 가능하다고 생각이되서.......	0	data 손실이 없을 수는 있는데 convolution의 역변환을 convolution으로 볼 수는 없을 것 같습니다. sparse linear transform이 꼭 sparse하지는 않아서요.
38	저희 TF-KR 1차 모임에서 좋은 발표를 해주셨던 Taegyun Jeon님과 저희그룹의 핵심 멤버이신 Jinwon Lee 님의 강의입니다. 무료 강좌라고 합니다.	1	내용이 궁금합니다...	1	아 참가 신청한 그 교육이군요! 감사합니다.	3	이미지는 교회 기도회 포스터 느낌이 ㅎ	0	저도 참가합니다.	1	오늘 발표했던 내용 슬라이드 올려드립니다. 출판본이랑 차이가 많아서 이걸 보시는게 도움이 될거같습니다. http://www.slideshare.net/TaegyunJeon1/ss-70432543
204	[Numpy Array 정복!]Numpy Array는 TensorFlow 를 잘 다루기 위한 기본기 같은 것인데요, 최근 무료로 공개된 ‘Python Data Science Handbook‘의 2장에 코드와 멋진 설명! 코드들을 쓱 보기만해도 감이 팍팍 옵니다.http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb	2	ㅎㅎㅎ.	1	감사합니다	0	이 정도는 아는데 다른 것과 연계된 부분 책은 없나요	1	감사합니다. :)	1	잘 보겠습니다. 제에게는 numpy 진입장벽 있습니다.
186	공부하다가 우연히 찾은 블로그인데, 김성훈교수님의 머신러닝 강좌를 매우 잘 정리해놨습니다. 다른 분들께도 도움이 될 것 같아서 공유합니다.	4	저도 읽어봤는데 참 잘 정리해주셔서 감사합니다.	1	와딩	1	차근차근 보기에 정말 정리가 잘 되어있군요.	2	저의 파이썬 선생님의 티스토리가 드디어 오픈이 되네요! :)	1	잘 보겠습니다. 요점 정리 같은 게 필요했습니다.	0	감사합니다.
43	https://github.com/proin/saturnjupyter를 사용해보다가 불편해서 유사한 기능을하는 웹 어플리케이션을 만들어봤습니다.원래 nodejs 기반으로 크롤러 등을 돌릴때 사용하려고 만든거였긴한데..파이썬 기능을 추가해서 tensorflow 등 라이브러리를 쓸수있으면 편리할거같아서 확장을 해보았습니다.링크에 docker install 참고하시면 python3 기반으로 tensorflow 포함하여 설치해보실수있습니다	1	대박이네요.. 감사합니다!	1	와
19	[TF KR 2차 오프라인 모임 포스터 세션 신청 안내] #4안녕하세요. TF KR 운영진 이지민입니다. 지금부터 TF KR 2차 오프라인모임 포스터 세션 신청을 시작하도록 하겠습니다.포스터 세션은 그동안 딥러닝 및 TensorFlow에 관해 공부한 내용을 다양하게 공유하고자 준비한 세션입니다.주제는 자유이며 그동안 공부했던 내용, 연구 주제 관련 내용, 연구 성과, 회사 소개 등 본인이 원하는 주제를 선택하여 준비해주시면 됩니다.모집이 완료되는대로 포스터 크기 및 제출과 관련하여 재공지 드리도록 하겠습니다.포스터 세션 신청은 선착순 60명이며, 신청 후 포스터를 1/4(수)까지 주최측에 제출해주시면 출력하여 행사 당일 배포해드립니다.----------------------------------------------------------------------------- 신청방법: https://goo.gl/forms/jaDQpqjTUT3JG7202 (이 링크를 통해 양식에 맞게 신청해주시면 됩니다.)- 참가비: 무료- 포스터 제출 기한: 1/4 (수)* 포스터세션 발표자 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.* 포스터세션은 포스터 발표자만 참여 가능합니다. 많은 분들을 모시고 싶으나 공간상 예산상 제약이 있는 점 이해를 부탁드립니다. ^^ ----------------------------------------------------------------------------참가 신청과 관련하여 문의 사항이 있으시면 본 글에 댓글로 달아주시면 안내해드리도록 하겠습니다. 감사합니다. :-)	0	이전 공지:[TF KR 2차 오프라인 모임 안내 및 강연자 공개 모집] #1https://www.facebook.com/groups/TensorFlowKR/permalink/390292334645164/[TF KR 2차 오프라인 모임 참가신청 안내] #2https://www.facebook.com/groups/TensorFlowKR/permalink/394323050908759/[TF KR 2차 오프라인 모임 참가신청 안내] #3https://www.facebook.com/groups/TensorFlowKR/permalink/395808854093512/	0	포스터 세션 샘플 : https://www.dropbox.com/s/nvtt94jacaf6vzc/TensorFlow%20%ED%8F%AC%EC%8A%A4%ED%84%B0%EC%96%91%EC%8B%9D.pptx?dl=0포스터는 일괄 인쇄를 위해 첨부한 양식을 바탕으로 작성해주시기 바랍니다!	2	기대되네요. ^^
3	신경망 질문 하나만 드리겠습니다. 매우 케이스가 많은 분류 문제를 해결하려고 하는데, 적당한 방법이 뭔지 잘 모르겠습니다. 샘플은 천만 단위가 있고, 각 샘플은 결과값을 갖는데 이 결과가 대략 수천개 정도의 결과를 갖습니다. 즉 어떤 한 케이스에 해당하는 샘플이 대략 만개가 있는 실정입니다. 이 천만개를 전부 학습시키고 싶은데,문제는 이 수천개의 결과를 어떻게 해야 할지 모르겠습니다. 결과가 어떤 연속 혹은 이산형 값으로 주어지는 경우는 아니구요.. 그냥 A,B,C ... 이런 패턴 인식 문제입니다. 제가 생각한 방법은1) 단순히 출력 레이어의 수를 결과와 똑같이 : 이러면 수천개의 원소를 갖는 벡터가 되는데 제 생각에 이렇게 많은 것까지 분류를 할 수 있을지 모르겠습니다.2) 이진수 형태로 표현3) 비슷한 분류를 묶어서 표현 실질적인 데이터가 A01,A02...B01,B02.. 이런식으로 연관된 데이터가 있기 때문에(A,B로 묶이는) 이점을 이용하여 묶어서 만들기이정도를 생각해봤는데좋은 방법을 알고 계신 고수분들이 있다면알려주세요 ㅠ 감사합니다.	0	군집화를 이용하면 어떨까요?	0	전체 케이스가 정해져있는게 아니라면 윗분 말대로 클러스터링을 하셔야 할듯 합니다
148	혹시 저처럼 삽질하시는 분들이 계실까봐 정보 공유해드립니다.저만 몰랐을수도...유명한 이미지 데이터셋인 mnist, imagenet, cifar 등이 아닌본인의 이미지 데이터셋을 직접 가공해서 학습시키고 싶은분들은텐서플로우 모델쪽 slim 소스를 활용하세요.기존 소스를 조금만 변경하면 본인의 이미지 데이터셋을 tfrecord 으로 쉽게 변경할 수 있으며유명한 conv 모델들과 fine-tuning 도 제공하고 multiple gpu, multiple cpu등 다양한 deploy 세팅도 파라미터로 모두 조정 가능합니다.많은 세부 기능들을 FLAGS로 빼놔서 사용하기 엄청 편하네요.새로운 모델을 만들때도 slim으로 작성하면 훨씬 간단합니다.이런 좋은 오픈소스가 있는줄도 모르고 데이터 가공하느라 한땀한땀 삽질하고 기존 모델 구현하느라 레이어, shape 하나하나 신경썼던게 눈물이 나네요.(물론 이해하는데 도움은 됐지만요..)아무튼 모르셨던 분들께는 많은 도움이 될 듯 합니다.	2	오..	1	오 감사합니다!	1	Inception 모델로 삽질 중이었는데. 감사합니다~	1	오... 저도 몇달간 삽질했는데 반가운 자료네요 ㅜㅜ	0	tensorflow를 해보는중인데, 아직 마니 미숙합니다.. 혹시 이를 어떤식으로 이용해야하나요? ㅠㅠ제가 8만개의 이미지파일을 이용해서, 이미지 input이 들어오면, 이와 유사한 이미지 or 같은 카테고리를 output으로 내놓는코드를 짜고있습니다..
4	오라클, 세계최대 글로벌 클라우드 로드쇼 'Oracle CloudWorld Seoul' 개최- 클라우드와 함께 어떻게 비즈니스 혁신을 가속화 하고, 변화를 주도할 수 있는지? 등
88	Park Ricky 님께서 올려주신 포스트를 보고 1장 무료 다운로드부분 (https://manning-content.s3.amazonaws.com/download/9/a3272eb-d214-4710-a4ee-226c92b9b615/Shukla_MLwTensorFlow_MEAP_V05_ch1.pdf) 을 읽어 보았는데요, 아주 재미있게 쓰여져있습니다. 1장은 supervised, unsupervised, reinforcement 등의 일반적인 ML의 개념을 재미있는 그림과 함께 다룹니다. 아래 그림과 같이 책의 구성을 보니 사고 싶은 마음이 들어 구매했습니다. (구매시 ctwpscfastw 쿠폰 사용하면 39% 할인 됩니다.)https://tensorflow.blog/2016/12/23/python-ds-handbook-ml-with-tf-repo/	0	책이 덜 지루해보이는군요..ㅎㅎ 뒷 챕터들이 궁금해집니다. :)  저도 살포시 구매를..	0	음?! 목차부터 재밌네요! ㅎㅎ	0	오 재밌어보여요 정말	0	Sung Kim 코드 잘썼습니다. ~
0	Bazel로 설치했다가 bazel 설치 버전 지우고 pip으로 넘어가신 분 계신가요..? bazel로 설치한 tensorflow가 안지워지고 pip list하면 pip으로 설치한것과 bazel로 설치한 것이 둘 다 뜨고, pip으로 설치한 tensorflow를 import하면 bazel을 사용하면 못쓴다는 내용의 에러가 뜨네요;;혹은, bazel로 설치했던 tensorflow 버전을 높이려면 어딜 참조해야할까요..? 그냥 다 지우고 pip으로 설치하고싶은데 혹시 해보신분 계신가요?	0	전 pip이용해서 소스로 깔았던 거 지우고 바이너리로 다시 설치하니까 그냥 되더라구요.	0	지우는 법은 인해봐서 확실히 모르지만 bazel로 깐놈 본체는 .bazelcache에 있습니다.
1	집에 있는 데탑으로 깔짝 깔짝 집러닝하다가 피시 노후화로  맥북하나 장만해서 본격적으로 해보려합니다.맥은 첨이라 잘모르는데 혹시 추천사양 있을까요	0	NVidia GPU 달린 노트북을 사시는걸 추천드립니다. 맥북은 요새 라데온이 달려나오지 않나요?	0	저도 nvida gpu 달린 노트북 추천합니다. 집러닝 재밌네요 ㅋㅋ	0	한성 보스몬스터! 집러닝 좋습니다.	0	저 얼마전에 보몬장만했어요 gtx1060에 145만원.. 가성비꿀	0	조언 참고해서 asus로 주문했어요 ㅎ
1	궁금한 것이 있습니다. 2개의 DNN을 따로 만들어서 학습을 시켜 모델을 저장하였습니다. 1.ckpt, 2.ckpt 그리고 다른 함수 내에서 두 tensorflow 모델을 각 각 함수로 저장하고 각 함수에서는 1.ckpt, 2.ckpt를 불러 실행을 시키려는데, 1은 잘 돌아가나 두번째부터 variable scope가 관련된문제들이 발생합니다. variable scope을 각 각 따로 설정하고 training하고 실행해도 checkpoit file에서 tensor name을 찾을수없다는 에러가 뜨네요..ㅠ	1	training시각각 모델 스코프지정하여 저장하고아래와같이 모델을 생성하고 restore하면 됩니다with tf.name_scope("model"+str(1))as scope:    _out_ = residual_network(xin,xinD,n_class,IsTrain, scope="model"+str(1))_out=tf.nn.softmax(_out_)pred  = tf.argmax(_out,1) with tf.name_scope("model"+str(2))as scope:    _out2_ = residual_network(xin,xinD,n_class,IsTrain, scope="model"+str(2))_out2=tf.nn.softmax(_out2_)pred2  = tf.argmax(_out2,1) ##################all_vars = tf.global_variables()    model_vars1 = [k for k in all_vars if k.name.startswith("model"+str(1))]    strRestore="models/"+strTaget1+".ckpt-" + str(restore_epoch[0])    tf.train.Saver(model_vars1).restore(sess,strRestore)    print ("load(" +strRestore+")  Restore ok!")     model_vars2 = [k for k in all_vars if k.name.startswith("model"+str(2))]    strRestore="models/"+strTaget2+".ckpt-" + str(restore_epoch[1])    tf.train.Saver(model_vars2).restore(sess,strRestore)    print ("load(" +strRestore+")  Restore ok!")
16	Maluuba.com 에서 두 개의 QA 데이터셋을 새로 공개했습니다.발표자료에 의하면 역대 최고 크기의 QA 데이터셋이라고 하네요.발표자료: http://www.marketwired.com/press-release/maluuba-releases-worlds-largest-human-created-question-answering-dataset-advance-artificial-2184930.htm그래서 각각 어떤 데이터셋인지 간단히 요약해 보았습니다.
0	spyder나 터니널에서도 출력결과시b '출력결과'b가 붙어서 나오는데 원래그런가요 우분투에서는 안그랬는데....먼가 잘못된건가요??혹시 수정방법이있으면 공유줌 부탁드립니다	2	http://stackoverflow.com/questions/6269765/what-does-the-b-character-do-in-front-of-a-string-literal
4	http://goodtogreate.tistory.com/m/entry/GPU-TensorFlow-on-Window-10-TensorFlow-GPU%EB%B2%84%EC%A0%84-%EC%9C%88%EB%8F%84%EC%9A%B010-%EC%84%A4%EC%B9%98이 사이트 보고하던중윈도우 10에서아나콘다 python 2.7 버전으로 설치cuda 8.0 _ win10 설치 했습니다그리고 난후 이미지를 보면 아나콘다 root계정 터미널을 실행하고pip install tensorflow-gpu 명령어를 입력 했으나저런 빨간글씨가.... 해결법 혹시 알수있을까요.....	0	아마 윈도우에서는 python 3.5만 지원하는 걸로 알고있습니다.	0	2.7이 되나요??
6	[python // tensorflow // recruit]안녕하세요 매번 눈팅만 하다가 쓰는 글이 구인글이라니 좀 부끄럽습니다만...(혹 문제가 된다면 알려주세요 바로 수정/삭제하도록 하겠습니다.)현재 저희 회사에서는 Tensorflow를 이용한 RL모델로 트레이딩 봇을 만들고 있는데, 이 여정을 함께하실 개발자분을 구하고 있습니다.* 주요 업무1. 데이터 수집 및 분석/정제2. RL 모델을 이용한 트레이딩 봇 개발*자격조건1. 파이썬(3.x) 숙련자2. 딥러닝에 대한 이해와 응용능력*우대조건1. 수학, 물리학, 컴퓨터공학 전공자2. 석사 이상의 학력 보유자3. 데이터 시각화 기술 보유자4. Tensorflow, Torch 등 오픈소스 머신러닝 라이브러리 사용 경험자회사 홈페이지: http://move.is 기업 정보는 http://www.saramin.co.kr/zf_user/recruit/company-info-view/idx/6273250 에서 추가로 확인하실 수 있습니다.관심있으신 분들은 dev+recruit@move.is 로 메일 보내주시면 감사하겠습니다.	1	이쪽에 관심이 많습니다. 혹시 공개가능한 범위 내에서 진행상황이나 진행방향을 알려주실 수 있으신가요? 관련 논문이라든가 ...?
18	실무에서 텐서플로우로 한국어 관련 작업을 하다 보니 재미난게1. 형태소 분석은 하나 안하나 비슷하고 안하는게 더 잘 나오는 경우가 많네요?!2. 컨텐츠의 내용을 파악하는데 단어순서는 그닥 별 영향이 없군요?! 3. RNN은 정확도 향상 정도 대비 부하가 커서 쓸 업두가 안나네요.4. 대부분의 경우 word2vec 따위 하등 도움이 안되네요..... 5. 당연하지만 NN 튜닝보다 받은 데이터의 정확도가 영향이 제일 크네요경험에 의한 결론이고 원인은 결과에 맞춰 고민 중 입니다만 해볼수록 참 난해하네요 ㅠㅜ관련 자료 좋은거 있음 추천 바랍니다.+ 갑님들께 "너네 자료가 썩었어요" 라고 설득 잘하는 노하우 좀 부탁드립니다 ㅠㅜ	0	형태소분석은 필수인거같은데.... 분석기 성능도 중요하겠죠? 네트워크가 데이터의 시퀀스를 고려하지 않는다면 단어순서는 상관없죠. w2v도 pre-training으로 사용해서 성능 향상을 보는 경우가 있구요 당연히 데이터가 정갈해야죠! 저는 rnn이 가장 좋던데요 ㅎ한국어는 어순도 중요해서요	0	목적과 방법론에 따라 다르지 않을까요	2	조사를 처리하지 않고 tokenize 해서 word2vec을 하면 망할거에요..ㅋㅋ	4	데이터가 어떤 종류인지는 잘 모르겠지만 문법이 맞지 않은 데이터를 사용하는 중이시라면 트위터 형태소 분석기를 추천드립니다
3	혹시 제가 출력한 문구 외에 텐서플로우에서 콘솔에 뿌려주는 문구들 출력 안 하게 하는 방법이 있나요? (그림에서 빨간색 문구들)사용하는 gpu가 늘어나니 문구들이 너무 많아져서 신경쓰이네요..	1	Donghyeon Lee 답변 주신대로 해봐도 여전히 출력이 되네요.. 좀 더 찾아보니, https://github.com/tensorflow/tensorflow/issues/1258 에서 다룬 이슈이고, 제가 이해한 바로는  tensorflow/core/platform/default/logging.cc 을 수정해서 다시 빌드해야 되는 것 같습니다. 전 포기 -_-;;;	0	꼼수일 수도 있지만, 내가 출력하는 문구에 [w2oifs] 이런 unique tag를 달고 grep으로 걸러내면 대충되지 않을까(요)? ㅎㅎ	1	제 기억에 텐서플로우가 출력하는 문구들은 stdout이 아니라 stderr로 가던걸로 기억하는데요.... err부분을 리다이렉트 하거나 출력을 파일에 저장 후 꺼내면 텐서플로우 관련 문구가 빠지는걸로 기억합니다....
14	[TF KR 2차 오프라인 모임 STAFF 신청 안내] #6 (마감되었습니다.)안녕하세요. TF KR 운영진 이지민입니다. 지금부터 TF KR 2차 오프라인모임 STAFF 신청을 시작하도록 하겠습니다.행사 당일 진행(리셉션, 행사 물품 관리, 포스터 세션 준비 등)을 도와줄 STAFF를 모집합니다. :-)신청이 완료되면 지원 동기와 신청해주신 순서에 기반하여 10분을 선정한 후, 개별적으로 결과를 안내해드리도록 하겠습니다.--------------------------------------- 신청방법: 마감되었습니다!- 참가비: 무료* 참고: 1/14 (토) 오전(대략 오전 9시 경)에 행사 준비부터 함께 해주실 수 있는 분들만 신청을 부탁드리겠습니다.* STAFF 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.--------------------------------------* 이전 공지[TF KR 2차 오프라인 모임 안내 및 강연자 공개 모집] #1https://www.facebook.com/groups/TensorFlowKR/permalink/390292334645164/[TF KR 2차 오프라인 모임 참가신청 안내] #2https://www.facebook.com/groups/TensorFlowKR/permalink/394323050908759/[TF KR 2차 오프라인 모임 포스터 세션 신청 안내] #4https://www.facebook.com/groups/TensorFlowKR/permalink/395845197423211/[TF KR 2차 오프라인 모임 Lightening Talk 신청 안내] #5https://www.facebook.com/groups/TensorFlowKR/permalink/396314110709653/	3	많은 분들의 빠른(!) 신청에 감사드리며, STAFF 신청이 마감되었음을 알려드립니다!! 감사합니다. :-)	3	벌써마감입니다.	3	오오. 저와 함께 몸으로 때우실 분들 모두 격하게 환영합니다. :-)	1	저는 영 선착순에 약해서 다음번엔 스탭으로 신청해야 겠네요 ㅠㅜ 선착순 안되는 저는 몸으로 때우는게 최고인듯요 ㅠㅜ
112	Sung Kim 교수님의 머신러닝 강의(https://hunkim.github.io/ml/) 실습 코드를 다음 깃허브에 업로드 해 두었습니다. 텐서플로 0.12 버전으로 테스트 한 것 입니다. 교수님이 TF-KR 그룹에 올려달라고 하셔서 올립니다. 가입하자마자 이런 글을 쓰게 되어 죄송합니다. (_ _); https://github.com/golbin/TensorFlow-ML-Exercises	4	다음에 강의할 기회가 있으면 이 코드들 사용할게요. 감사	1	그동안 본 실습 코드중에서 제게는 가장 깔끔한 코드네요. 감사합니다.	0	"가입하자마자 이런 글을 쓰게 되어" 너무 감사. 그리고 앞으로도 이런글 많이 부탁드립니다!	0	감사합니다.	1	오... 트윗에서 뵙던분이 여기에 ㅋㅋㅋ
42	미 백악관, 인공지능(AI) 대응 보고서 발표- 인공지능은 수백만 명의 미국인의 현재 생계를 혼란시킬 것이다. 이에 대한 대안으로
47	[TF KR 2차 오프라인 모임 일반신청 안내] #7안녕하세요. TF KR 운영진 이지민입니다.드디어 내일이 일반신청이네요! 한번 더 안내드리며, 업데이트된 프로그램도 공유하고자 합니다! :-)일반신청은 선착순으로 170명을 모집하게 되며, 온오프믹스 페이지를 통해 신청해주시면 됩니다. (1차 오프라인모임과 동일)다만 신청 시 추가 정보에 주어진 간단한 딥러닝 관련 문제(3문제, 필수입력)를 풀어주셔야 합니다. 딥러닝 및 Tensorflow에 조금이라도 더 관심이 있는 분들을 모시기 위한 것이니 즐거운 마음으로 문제를 풀어주시기 바라겠습니다!이와 더불어 No-Show 방지를 위해 지난 오프라인 모임 때와 마찬가지로 신청비 1만원을 받습니다. 신청해주신 분들이 꼭 오시기를 바라는 마음으로 받는 것이니 이해 부탁드립니다. :-) 마지막으로 참여해주시는 모든 분들에게 구글 코리아에서 준비한 소정의 선물을 드릴 예정이며, (맛있는) 저녁 식사도 제공됩니다.--------------------------------------- 신청일시: 12/23(금) 10:00 AM- 신청방법: 온오프믹스를 통한 신청 (http://onoffmix.com/event/86620)- 참가비: 10,000 원** 온오프믹스 등록시 가급적이면 신용카드 결제를 하시는 것을 추천드립니다. 무통장입금으로 하실 경우, 빨리 신청하더라도 입금확인이 늦어서 순번이 밀리는 경우가 종종 발생합니다.--------------------------------------	4	오오. 내일 온오프믹스가 엄청난 트래픽을 받을 것 같습니다!	0	아직 포스터 세션은 신청 진행 중에 있습니다! 관심 있으신 분들은 다음을 참고해주세요!![TF KR 2차 오프라인 모임 포스터 세션 신청 안내] #4https://www.facebook.com/groups/TensorFlowKR/permalink/395845197423211/	1	내일 10시에 참여할수 있을지 걱정이네요 ㅎㅎ	0	조재민 (J-min Cho) 요 재민~ 내일 신청해야겠네ㅋㅋ	0	기대되네요. 답안 제출시 오답여부는 알수 있나요?? ㅎㅎㅎ	4	생각해보니 답안의 경우 일단 막쓰고 나중에 수정하셔도 됩니다.. 허둥지둥하느라 생각도안하고 휘갈겼네요 :)
33	롯데,  IBM 왓슨 도입, 인공지능시대 연다.- 왓슨을 통해 고객 이해를 기반으로 하는 맞춤형 고객 서비스 역량 향상 기대	0	일본어로 물어봐야하나...	0	하필이면 롯데...	0	직원들 쪼는 방법을 왓슨이 어케 해석할지
20	아래 CentOS 7 기반 Multi GPU에 Tensorflow 설치 가이드 요청이 있어 간단히 정리해 드립니다.CentOS에서는 Source 설치를 권장해드리며 Tensorflow가 cmake가 아닌 Bazel로 컴파일해야 하기때문에 인스톨 과정이 다소 복잡합니다만 순서대로 따라가시면 큰 문제 없이 설치하실 수 있을 것입니다.1. Install Dev Pakageyum updateyum groupinstall 'Development Tools'yum install -y gcc g++ freeglut freeglut-devel gcc-c++ (확인차)yum install kernel-develyum install kernel2. Install NVIDIA Driver##NVIDIA에서 해당 GPU Driver 다운로드./NVIDIA-Linux-x86_64-352.79.run##nouveau는 Default Graphic driver인데 freeglut가 인스톨되면서 같이 인스톨되며 초기 GNOME, KDE를 사용할 수 있게 합니다. 문제는 이게 활성화되어 있으면 nvidia driver를 인식하지 못하는 문제가 생깁니다.따라서 아래와 같이 비활성화 시켜야 합니다./etc/modprobe.d/blacklist-nouveau.confblacklist nouveauoptions nouveau modset=0lsmod | grep -i nouv3.Install CUDA Toolkit##Toolkit download https://developer.nvidia.com/cuda-downloadsdownloadcuda_7.5.18_linux.run##Path 설정 (~/.bashrc)  CUDA_HOME=/usr/local/cuda-7.5  PATH=$CUDA_HOME/bin:$PATH  LD_LIBRARY_PATH= $CUDA_HOME/lib64:$LD_LIBRARY_PATH:/root/cuda/nccl-master/build/lib  export CUDA_HOME PATH LD_LIBRARY_PATH4. Install Python Libraryyum install epel-releaseyum updateyum install -y python-devel.x86_64yum install -y python-pipyum install -y numpy scipy5. Install cuDNN## cuDNN은 NIVIDA site에서 회원 가입 후 다운로드tar xvzf cudnn-7.0-linux-x64-v4.0-prod.solitairetheme8cp ./cuda/include/cudnn.h /usr/local/cuda/includecp ./cuda/lib64/libcudnn* /usr/local/cuda/lib64schmod a+r /usr/local/cuda/lib64/libcudnn*6. Install JDK## JDK는 Oracle site에서 다운로드sudo rpm -ivh jdk-8u77-linux-x64.rpmls /usr/java/jdk1.8.0_77/ ## 인스톨 확인export JAVA_HOME=/usr/java/jdk1.8.0_776. Install library archive 3.1.2wget http://libarchive.org/downloads/libarchive-3.1.2.tar.gztar xvzf libarchive-3.1.2.tar.gz./libarchive-3.1.2/configure./libarchive-3.1.2/make./libarchive-3.1.2/make install7. Install Bazelyum -y install zlib-develgit clone https://github.com/google/bazel/tar -xvfz bazel.tar.gz./bazel/compile.sh8. Install Tesnorflow Sourceexport PATH="$PATH:~/bazel/output" (Bazel 설치된 디렉토리)#git clone --recurse-submodules https://github.com/tensorflow/tensorflow#git 1.6.5 이상 버전에서는 git clone --recursive https://github.com/tensorflow/tensorflow./tensorflow/configure# 아래와 같이 자신의 환경에 맞게 옵션 설정을 합니다. ./configurePlease specify the location of python. [Default is /usr/bin/python]:Do you wish to build TensorFlow with GPU support? [y/N] yGPU support will be enabled for TensorFlowPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify the Cudnn version you want to use. [Leave empty to use system default]:Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: "3.5,5.2"]: 3.5Setting up Cuda includeSetting up Cuda lib64Setting up Cuda binSetting up Cuda nvvmConfiguration finished9. Tensorflow Compilecd ~/tensorflowbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer (시간이 좀 걸림)bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu (구동되는지 확인)10. Install PIP Packagebazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_packagebazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg# error: invalid command 'bdist_wheel' 에러 나면 pip install wheelpip install /tmp/tensorflow_pkg/tensorflow-0.7.1-py2-none-any.whl11. Single GPU CNN 학습 구동python ./tensorflow/tensorflow/models/image/mnist/convolutional.py12. Multi GPU CNN 학습 구동cd ./tensorflow/tensorflow/models/image/cifar10python cifar10_multi_gpu_train.py --num_gpus=8 --max_steps=10000	1	유익한 정보 감사드립니다.	0	한눈에 정리 되있어서 어려움없이 설치했습니다. 감사합니다 !!
89	한글 자연어처리 정보를 정리한 Awesome-Korean-NLP Github Repo 를 다시 공개합니다! 많은 피드백 부탁드립니다ㅎㅎ	0	오픈한글은 현재 API 가 중단된걸로 알고 있습니다. ~~
11	혹시 tensorboard에서 histogram_summary를 잘 해석하여 유용한 정보를 뽑아내는 노하우들 갖고 계신가요?예를들어 DISTRIBUTIONS/HISTOGRAMS 결과가 다음과 같으면 어떤 해석이 가능하며 그에 따른 학습에 필요한 조치는 뭘까요?1. step에 따라 gradient가 줄어드니 수렴이 되간다? 정도?2. b3의 gradient가 상대적으로 b1/b2보다 크니 뭘 어떻게 조치해본다? (layer 3의 노드를 늘려봐라는 등)고수님들의 조언 부탁드립니다~	1	이게 상당히 어려운 문제인 것 같습니다. Hidden layer 가 없고 shallow (direct) network 이 logistic regression 만 하고있다면 weight (coefficient) 가 0에서 많이 벗어날 수록 결과에 더 큰 영향을 주고있다고 할 수 있습니다만... hidden layer 가 하나만 생겨도 weight 들의 분포가 어떤 의미일지 유추해내기가 쉽지않습니다. 게다가 텐서보드의 시각화는 weight 들 의 distribution 입니다. 노드의 위치정보는 재거하고 어떤 값의 weight 들이 얼마나 많은지를 시간축으로 보여주죠. 그래서 배우고있나 아닌가 정도밖에 볼 수 없는 것 같습니다.	1	이거때문에 클라이언트를 설득해야 하는데 설득할 근거를 만들지 못한다고 하더라구요분명 결과는 잘 나오는데, 통계모델처럼 이 값이 이렇고 저 값이 저러니 이건 좋은 모델이고 이정도 신뢰할 수 있다를 못하니까..."W, B를 모두 히트맵으로 뽑아서 세번째 히든 레이어에 보시면 왼쪽 윗부분이 전체적으로 핫하죠? 그건 이런걸 뜻하고 따라서 이 모델은 이런 방향을 잘 잡아내는 겁니다" ... 라고 할 수가 없는게 답답하다고 하네요.요즘 저 네트워크 안에 담긴 파라미터들이 무슨 역할을 하는지를 분석하는 연구도 많이 진행되고 있다고 하니, 조만간 그런 근거를 댈 수 있지 않을까 기대해봅니다.
0	안녕하세요! 질문이 하나 있습니다.tensorflow models 예제에 있는 word2vec을 보고 있는데요  emb_dim을 키우면 랜덤값을 더 작게 줘서 초기화 하는 이유가 궁금합니다!이것 말고도 rnn 예제에도 값을 점점 더 작게 줘서 초기화를 하던데 왜 그런건가요??	0	보통 random_normal의 stddev이 너무 크거나 random_uniform의 범위가 너무 넓으면 여러 레이어를 거치면서 값이 크게 튀는 경우가 있습니다. 이런 경우 초기 weight들이 optimum에 너무 멀리 있어 training이 안정적이지 않습니다. 따라서 레이어 수가 많은 경우 weight 초기값의 크기를 줄여 그런 문제가 생기는 것을 방지해줍니다.
29	http://yeramee.tistory.com/1이 포스트를 따라해보니(저는 cpu only이고 다 똑같이 따라했습니다.)1. pycharm 에서 import tensorflow as tf 할 때 tensorflow에 빨간줄이 뜹니다.2. 콘솔에서 tensorboard를 실행시키니 사진과 같이 나옵니다... 아무것도 나타나지 않아요. (이전에 잘 나왔던 event log파일로했는데도요)- 포스트를 따라하면서 anaconda로 tensorflow를 다시 깔게되었고 실행할 때 source activate tensorflow 명령하고 실행시켰습니다.	0	선 좋아요 후 감상	1	CPU 버전으로 설치하셨나요? GPU 버전으로 설치 하셨나요? CPU 버전이면 올바르게 설치가 되지 않은 것 같네요. 올려 주신 질문으로는 정확히 답하기 어려울 것 같아요.	1	pycharm project interpreter 경로가 anaconda2/env/tensorflow/bin으로 되어 있나요? 위에 글을 보면 tensorflow를 가상환경에서 설치하신것 같은데 패키지 읽어오는 경로가 달라서 못 읽어오는 것 같기도 하네요.	1	요즘 텐서플로우 관련하여 테스트할 자료들이 넘쳐나는데 개발환경 구축이 어려웠는데 감사합니다.	0	빨간줄 뜨는거, 저도 그러는데 어떻게 해결하셨나요 ?
6	구인구직여기에 올려도 될지 모르겠지만,서울아산병원/울산의대 의료영상/음성/정보 인공지능 교수/포닥 초빙교수 : 서울아산병원 병원장발령/울산의대 총장발령 겸직 연구교수 (서울대 기금교수급)포닥 : 의료영상로봇연구실 포닥 (http://home2.ulsan.ac.kr/user/mirl/index.action)namkugkim@gmail.com에게 연락주십시요. 특이사항: 향후 대형국책과제로 병원에서 의료영상/음성/병리/내시경 동영상/수술장동영상 등의 인공지능 학습 및 적용을 이끌어나갈 분을 찾습니다. *문제가 되면 삭제하겠습니다.
109	[2016 년 딥러닝의 주요 발전]2016년 딥러닝분야 가장 중요한 발전은 무엇일까요? Unsupervised learning 중 Generative Adversarial Networks (GANs) 에 특히 많은 발전이 있었는데요. 특히 GAN을 설명하는 부분이 정말 재미있습니다. 피카소의 그림짝퉁을 그리는 G가 있고, 주어진 그림이 진품인지를 확인하는 D가 있을때 G는 D를 속이기 위해 자신을 발전 시키고, D는 진품/가품을 확인하는 기술이 점점 발전하게 되는 방식으로 GAN을 설명합니다.그 외에도 NLP 분야의 Text understanding, Question Answering, Machine Translation 등에서도 많은 발전이 있었네요.
5	파이썬도 초보고 텐서플로우는 더더욱 초보, 인사드립니다. 머신러닝에 관심이 있는 이유는, 3D 애니메이션 제작에 있어서 작업분량을 줄여보고자 함에 있습니다. 가령, 블렌드쉐입(얼굴표정)을 만든다던가 혹은 리깅에 절차적으로 쓰인다던가, 3D스캔한 데이타를 리토폴로지(선정리를 통해 애니메이션이 가능한 모델을 만드는 것) 하는것, 초기 설정 이미지를 기반으로 3D 라이팅을 구성하는 것 등의 과정에 머신러닝이 쓰일 수 있을듯하여 관심을 가지고 있습니다. 인터넷을 통해 기초강의를 듣다보니 이런 일을 해결하기란 아직 힘들겠구나란 생각도 들지만, 차근차근하다보면 방법이 생기겠지요. 간혹 질문을 드릴수도 있습니다. 엉뚱한 질문이더라도 너그러히 응해주시기를 부탁드립니다. 혹시 텐서플로우를 3D에 적용시키려는 모임(마야를 사용합니다.)이 있다면 소개를 부탁드립니다. 감사합니다.
52	Magenta로 개발된 AI가 사람과 잼(먹는 잼 아님)을 하는 영상입니다! Magenta는 Google Brain 팀이 TensorFlow를 이용하여 만든 딥러닝으로 음악 작곡하기 위한(?) 라이브러리입니다. 피아노, 드럼, 베이스가 각각 실시간으로 사용자의 입력(연주)을 받은 LSTM 모델들로부터 연주된다고 하네요. 너무 신기해서 공유합니다 ㅎㅎㅎ영상의 데모를 직접 돌려볼 수 있게 소스 코드도 공개한듯 합니다.(아래 링크 첨부했습니다) 예전에 일렉트로닉 음악 만들어 보겠다고 사고 묵혀둔 키보드를 꺼낼때가 됬군요..저는 취미로 기타를 치는 사람인데 기타프로 악보들을 학습해봐도 재밌을것 같네요 ㅎㅎ영상: https://youtu.be/QlVoR1jQrPkblog: https://magenta.tensorflow.org/2016/12/16/nips-demo/Magenta: https://github.com/tensorflow/magentaDemo repository: https://github.com/tensorflow/magenta/tree/master/magenta/demos/NIPS_2016	3	AI적용 여부까진 모르지만 가수 신혜철씨가 마지막으로 하던 작업이 프로그래머와 함께 일반인들이 작곡을 쉽게 할 수 있는 프로그램을 만드는 작업이었다고 하더군요.
373	[구글브레인팀에서 만든 TensorFlow Tutorial]1. TensorFlow를 어떻게 사용하는지 예를 보여줘서 동기 부여2. 이미 만들어 놓은 Deep Learning 모델을 보여주고 (대부분은 그대로 사용가능, Inception, Show and Tell, Text summary, etc.)3. 간단한 lab을 통한 TensorFlow 실습슬라이드/lab등도 너무 잘만들어져 있어서 기본적인 TF강의에서 그대로 사용해도 좋을것 같습니다. 슬라이드: https://github.com/sherrym/tf-tutorial/blob/master/DeepLearningSchool2016.pdf비디오: https://www.youtube.com/watch?v=Ejec3ID_h0w (코드 설명은 잘 못합니다. 슬라이드만 보셔도 될듯.)코드: https://github.com/sherrym/tf-tutorial	0	감사합니다 ^^	0	감사합니다	0	좋은 자료 감사합니다!	6	Bayarea DL school에서 발표된 내용이군요. 다른 내용을 참고하실분들을 위해 링크를 걸어두겠습니다. http://www.bayareadlschool.org/schedule	0	좋은 자료 감사합니다 ^^	0	Jisung Yoo
6	안녕하세요, caffe를 이용하다 tensorflow로 넘어온 사용자 입니다.tf.cintrib.layers.batch_norm 을 사용하려는데 몇 가지 변수들을 어떻게 지정해야 될 지 모르겠습니다.github의 간단한 설명만으로는 이해가 되지 않습니다.입력 변수 중,is_training  reuse  variables_collections outputs_collections  update_collections trainable  batch_weights  fused  scope을 어떻게 쓰는지 정확히 알고 싶습니다.지금은 is_training을 training시 true, test시 false로 두고 학습 시키는데 test시 성능 저하가 일어납니다.updates_collection을 None으로 해야 된다거나reuse를 사용해야 된다는 것이 정확히 어떤 의미인지 이해가 되지 않습니다.혹시 batchnorm 예제 코드를 가지고 계시거나, 위의 내용을 잘 아시는 분 있으시면 댓글 바랍니다.감사합니다!	4	updates_collection 이 None 이면 BN에서 feed-forward 할때 moving average의 업데이트가 항상 실행되게끔 구현이 되어 있습니다. training 하는 경우는 상관없지만 test 할 때에도 update되고요, 그래서 이 방식보다는 documentation에 나와있는 대로 (그리고 기존에 하신 대로) is_training 에 True/False를 feed하면서 update_op 을 쓰는 게 정석적인 방법입니다. 나머지 입력 변수에 대한 설명은 documentation 에 나와있는 설명 그대로일테니 doc을 자세히 다시 읽어보시면 좋을것 같습니다. test 시 성능이 잘 안되는 문제는 moving average의 decay를 0.9 정도로 조정하면 잘 될 수도 있으니 한번 시도해 보세요. (https://github.com/tensorflow/tensorflow/issues/1122)	1	reuse와 update_op이 문제될 때는 multigpu를 사용하실 때입니다. gpu들이 같은 variable을 공유해야하기 때문에 두 번째 gpu부터 reuse를 True로 주어야합니다.  또한, multigpu상에서는 variable이 첫 gpu에서 생성되면 두 번째 이후부터 생성된 update_op은 첫 gpu에서 생성된 variable을 update할 수 없기 때문에 해당 부분에서 variable과 update_op을 동시에 cpu에 생성하도록 코드를 다시 짜거나 update_op=None으로 둡니다. update_op이 없으면 속도는 느려지지만 성능 저하는 발생하지 않습니다. test시 성능 저하는 test시 update_op이 variable을 제대로 update하지 못하기 때문일 가능성이 높습니다. update_op=None으로 놓고 test 한 번 해보시는 걸 추천합니다.
46	전세계 1억명 사용자가 넘는, 실시간 화상 채팅앱 아자르에서 구글 스피치와 번역 API를 사용한 사례입니다. 화상채팅에서 자국어로 말하면 상대방의 언어로 실시간 번역해서 텍스트로 출력해주는 시나리오인데... 이게 이제 현실로 가능하고 서비스로도 있네요. 머신러닝의 완성도와, 사례를 찾으시는 분들께 강추 드립니다.
10	텐서플로우 집러닝 입문하려고합니다입문하기에 어떤것이 좋을지 궁금합니다책이나 강의 등 추천해주시면 감사드리겠습니다!아울러 리눅스라던가 어떤 기반지식이있으면 되는지도 알려주심 감사드리겠습니다 !	11	홍콩과기대의 김성훈 교수님 강의를 2~3번 반복해서 들으시면 좋을 것 같습니다. 설명 친절하게 잘해주십니다. https://m.youtube.com/playlist?list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm	1	파이썬 numpy, tensorflow 라이브러리 기본지식이 필요하다고 생각됩니다.	0	벤지오 교수님 책, 앤드류응 교수님 쿄세라 강의 추천합니다.	1	저는 딥러닝 자체는 www.neuralnetworksanddeeplearning.com으로 공부했고 텐서플로우는 구글에서 제공하는 tensorflow 튜토리얼로 공부했습니다.
162	합성곱 신경망(CNN) 딥러닝을 이용한 한국어 문장 분류를 진행한 과정을 정리하여 소개해 봅니다. 문서 내용 대부분은 http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ 를 참조했고 가능한 한국어로 쉽게 풀이해서 쓰려고 했는데 일부 용어들은 한국어가 오히려 더 어렵게 느껴져서 아쉬움이 있네요. 한글로 된 학습/평가 셋도 일부 추가했으니 실제로 활용하는데 도움이 되었으면 합니다. 추후 반응이 좋으면 한글 학습셋은 좀 더 정리해서 추가해보도록 하겠습니다. 잘못되었거나 보안해야할 부분이 있으면 많은 지적 부탁드립니다.	3	좋은자료 정말 감사합니다.	2	"추후에 반응이 좋으면" 추후 반응이 좋은것 같습니다.	5	좋은 자료 감사드립니다!!p.s 언어처리는 형태소 분석기와 corpus가 핵심인데...국내에서는 자기네것을 꼭꼭 숨겨서 끌어안고 있다가 "대박기회"만 노리지만, 정작 현실은 남이 다 만든거 또만들고 또만드는 형국으로^^ , 그럼에도 불구하고 공개해주신 분들께 다시한번 감사드립니다	0	감사합니다 ㅎㅎ 근데 혹시 문장이 아닌 문단 수준에서도 가능한것이 있나요?ㅎㅎ	0	감사합니다	0	오 좋네요. 찾던건데, 음 질문이 있는데 sentence matrix를 convolution할때 보통 filter size를 다르게 해서 하나요?? 만약 문장의 길이가 filter의 length보다 짧을 경우도 존재할 것 같은데 이런경우에는 어떻게하시나요?? 왜 이게 질문이냐면.. placeholder로 문장을 넣으실텐데 그럼 computational graph내에서는 문장길이를 유추할수없을 것같아서요. 문장 길이별로 batch해서 트레이닝 시키시나요?	0	질문이 있습니다. 아직 초보여서요..eval.py 할 때문재인 박지원 안희정 이유 오늘 초아,politics오늘 초아 태연,entertain반기문 일본 세자,politics러블리즈 지수,entertain기타 환불 카드사 채무,etc안희정 문재인 과거,politics트위터 서울대 수석,etc40 직장 남성 고민 상담,etc오늘 첫끼 떡볶이,etc눈 이유,etc파일이 이렇게 되어 있는데..아래처럼 포맷을 만들어서..accuracy를 확인하는 방법은어떻게 해야할까요?문재인 박지원 안희정 이유 오늘 초아오늘 초아 태연반기문 일본 세자러블리즈 지수기타 환불 카드사 채무안희정 문재인 과거트위터 서울대 수석40 직장 남성 고민 상담오늘 첫끼 떡볶이눈 이유
58	여러분의 100시간은 안녕하신가요 (...)	0	100시간만에라니...	0	100시간이면 한달만에 뚝딱만든건데 천재네요 ㅎㅎ	1	내가 문명 100시간 할 동안 주커버그는 집에서 애도 키우고 자비스도 만들고 ...	0	김지훈 (Jihoon Manolo Kim) 10000000시간 드림.	0	제가 잘 모르나, 100시간이라 함은 일종의 인스턴트라면의 개념으로 표현한것 아닌지요? 이미 잘 만들어진 각각의 기능을 조립한 시간? 개념 말이죠	0	중급개발자 치곤 잘했네요., 라고 한국에선 취급받을지도요.. (먼산..)
16	[TF KR 2차 오프라인 모임 Lightening Talk 신청 안내] #5안녕하세요. TF KR 운영진 이지민입니다. 지금부터 TF KR 2차 오프라인모임 "Lightening Talk" 신청을 시작하도록 하겠습니다.Lightening Talk은 포스터 세션 사이에 진행되며, 회사에 계신 분들을 대상으로 지원을 받을 예정입니다.회사에서 딥러닝을 활용하고 있는 내용이나 구인, 회사 홍보 등 자유롭게 5분간 Talk을 진행해주시면 됩니다.신청이 완료되면 Talk 내용과 신청해주신 순서에 기반하여 10분을 선정한 후, 개별적으로 결과를 안내해드리도록 하겠습니다.--------------------------------------- 신청방법: https://goo.gl/forms/R2xCtRHIlBEtX0IS2 (이 링크를 통해 양식에 맞게 신청해주시면 됩니다.)- 참가비: 무료* Lightening Talk 발표자 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.--------------------------------------참가 신청과 관련하여 문의 사항이 있으시면 본 글에 댓글로 달아주시면 안내해드리도록 하겠습니다. 감사합니다. :-)======================================================* 이전 공지[TF KR 2차 오프라인 모임 안내 및 강연자 공개 모집] #1https://www.facebook.com/groups/TensorFlowKR/permalink/390292334645164/[TF KR 2차 오프라인 모임 참가신청 안내] #2https://www.facebook.com/groups/TensorFlowKR/permalink/394323050908759/[TF KR 2차 오프라인 모임 참가신청 안내] #3https://www.facebook.com/groups/TensorFlowKR/permalink/395808854093512/[TF KR 2차 오프라인 모임 포스터 세션 신청 안내] #4https://www.facebook.com/groups/TensorFlowKR/permalink/395845197423211/
27	[TF KR 2차 오프라인 모임 참가신청 안내] #3안녕하세요. 잠시 뒤 오후 3시부터 TF KR 2차 오프라인 모집이 본격적으로 시작됩니다.앞서 안내해드린 것처럼 이번 오프라인 모임에는 참가신청 트랙이 총 4개입니다. (포스터 세션 신청/Lightening Talk 신청/STAFF 신청/일반신청)참가를 원하시는 분들께서는 원하는 트랙 중 "하나에만" 신청을 해주시면 됩니다.그럼 참가 신청 일정을 다시 한번 안내해드리겠습니다.(자세한 사항은 링크를 참고해주세요. https://www.facebook.com/groups/TensorFlowKR/permalink/394323050908759/)-------------------------------------------------------------------------(1) 포스터 세션 신청 (선착순 60명) : 12/20(화) 3:00 PM (2) Lightening Talk 신청 (10명) : 12/21(수) 3:00 PM(3) STAFF 신청 (10명) : 12/22(목) 3:00 PM위 세 트랙의 경우, 신청일시에 맞춰 본 페이스북 페이지에 신청링크(구글 설문조사)가 담긴 글을 올릴 예정입니다. 글에 있는 링크를 통해 양식에 맞게 신청해주시면 됩니다.(4) 일반신청 (선착순 170명) : 12/23(금) 10:00AM (온오프믹스를 통한 신청, http://onoffmix.com/event/86620)-------------------------------------------------------------------------그럼 많은 분들이 참가해주시길 바라면서 잠시 후 3시에 포스터 세션 신청 공지를 올리도록 하겠습니다.감사합니다. :-)	1	정말 재미있을듯 합니다.	0	이전 공지:[TF KR 2차 오프라인 모임 안내 및 강연자 공개 모집] #1https://www.facebook.com/groups/TensorFlowKR/permalink/390292334645164/	0	이전 공지:[TF KR 2차 오프라인 모임 참가신청 안내] #2https://www.facebook.com/groups/TensorFlowKR/permalink/394323050908759/	2	기대됩니다!!	2	저기 들어가니까 2일 후에 신청이 시작된다고 나오네요	1	기대되네요 ^^
91	안녕하세요. '한국에도 머신러닝 관련 팟캐스트가 있었으면 좋겠다...' 생각하다가 제가 그냥 유투브 채널을 하나 만들어버렸습니다ㅎㅎ 제목은 "테리의 딥러닝 토크" 입니다! 지금까지 3개의 동영상이 올라와 있는데요, 1. 딥러닝 토크를 시작합니다! 2. 머신러닝, 그 느낌적인 느낌3. 머신러닝 / 딥러닝 강의 7가지 추천[YouTube] https://www.youtube.com/channel/UCDku86cssbM288VJtl-GQKg모든 영상들은 유투브 채널에서 확인하실 수 있고, 앞으로도 5~7분씩 짧게짧게 머신러닝의 기본개념들부터 최신 논문소개까지 다양하게 다뤄볼 생각입니다. 나중에 잘되면 뛰어난 연구자분들 모셔놓고 팟캐스트도 한번 해볼게요 ㅎㅎ. 감사합니다!	0	감사합니다!!!!!	0	오 요즘 딥러닝 관심 엄청 많은데 ㅎㅎ 선배님 구독 꾹 누르겠습니다. 제가 하는 플립이라는 서비스에서도 5분정도 음성으로 하고싶은 얘기하고 공유할수있어요~ 유투브 시간 오래걸리시면 플립도 괜찮을것같아서 깨알홍보합니당ㅋㅋ
107	크롤링에 필요한 부분을 정리해봤어요링크가 깨져서 아래로 접속하시면 볼 수 있네요.http://www.slideshare.net/dahlmoon/ss-70166576	1	ppt가 300페이지나 되다니	1	만드시느라 정말 수고많으셨어요.감사합니다^^	2	안병호
15	안녕하세요. 저는 교토대학교 김선민이라고 합니다.저는 수문학 및 수자원공학을 전문으로 하고 있고, 최근에 딥러닝에 매료되어 관련 공부를 하던 중에 김훈 교수님의 유투브 강의를 보게 되었습니다. 내용을 너무도 쉽게 잘 설명해주셔서, 더불어 모든 슬라이드에 관련 출처가 자세히 소개되어 있어서, 너무도 많은 도움이 되었습니다. 그 와중에 한가지 조언을 구하고자 이렇게 메일을 드립니다.(김훈 교수님께 메일을 드렸더니 여기에 올려보라 하시네요 :)가장 기초적인 질문으로 "딥러닝으로 공학적 문제를 해결할 수 있을까요?"좀 더 구체적으로 "딥러닝으로 학습된 뉴럴넷은 패턴분류 등의 정성적 답이 아닌, 출력단자의 수치가 의미를 갖는 정량적 문제에도 응용 가능할까요?"더욱 심오하게 "딥러닝으로 학습된 뉴럴넷은 기존의 물리모델 (인간의 지식에 근거한 물리식으로 구성된)을 대체할 수 있을까요?바른 답을 얻고자 첨언하자면,뉴럴넷은 1990년대에 수자원분야에서도 범용성 비선형 회귀모델로 많이 활용되었습니다. 다만, 잘 아시는 바와 같이, 여러 기술적 문제로 관심이 시들해 졌다가 최근에 딥러닝 기법을 활용하는 연구가 서서히 나타나고 있습니다. 하지만 아직까지는 딥러닝의 안정적 학습기법 이상의 진정한 활용을 보지 못했습니다.제가 이해하고 있는 딥러닝의 진정한 가치는, 주어진 많은 데이타에서, 인간이 분류하고 선택해주지 않은 빅데이터에서, 딥러닝 과정을 통해 뉴럴넷 스스로 데이타의 대표적인 특징과 관련성을 찾아내 준다는 것입니다. 그 과정의 결과로 의미있는 "정량적" 값을 출력으로 나타내 줄 수 있다면, 어쩌면 기존의 물리모델을 대체할 수 도 있겠다는 가능성을 보게 되었습니다. 혹시 여러분중에 제 의문에 대해 간략하게나마 조언을 주신다면 많은 도움이 되겠습니다. 또는 참고가 될만한 자료나 논문을 소개해 주셔도 감사하겠습니다.	1	뉴럴넷 패턴 분류가 정성적 답인가요?	1	잘 아는건 아니지만 저도 비슷한 의문을 가지고 있어서 조언이라기보다는 제 생각을 공유합니다ㅎㅎ제 생각으로는 뉴럴넷이 'scalable' 한 회귀로써 큰 가치가 있다고 생각되는데, 이에 관해서 수학자들이 특정 조건하에서 뉴럴넷 구조로 거의 모든 함수를 근사할수 있다는 결과를 내놓은 것으로 알고있습니다. 그렇기 때문에 공학적 관점에서 입출력간의 관계를 모사하는데에는 큰 문제가 없지 않을것 같습니다. 가령 pipeline 에서 수두와 유속 관계처럼 보통 경험적인 식으로 실생활에 적용하는 문제에는 크게 효용이 있을것 같습니다. 하지만 물리적 모델이라고 하면 그 식 안에서 어떠한 현상이 일어나는 원리가 보여야 하고, 식의 간결함도 어느 정도 중요한데 뉴럴넷 구조로 나타낸 모델은 직관적인 원리나 간결함이 떨어지지 않을까요?	1	인공신경망 모형은 classification 뿐만 아니라 regression에도 적용이 가능하다고 들었습니다. 다만, classification문제에 특화된 activation function에 차이가 있다고 들었습니다. 저도 한번 테스트를 해보니 training에 들어가는시간에 비해 정확도가 다른 regression model에 비해 월등하진 않았습니다. 다만 regression 문제를 어떻게 define하느냐에 따라 다양한 전처리 또는 basis function 정의에 따라 풀 수 있는 성능이 달라지더라구요- 이를 잘 고민해보시길 바랄게요-	1	그리고 이에 더해 말씀을 드리면 classification과 regression은 첫째 목적이 다르고, 둘째 target variable이 유한set인가 무한set인가에 따라 다르거든요. Regression은 classification과 다르게 모든 영역에서 주어진 데이터 셋과 유사해야하기 때문입니다.	2	미분방정식을 수치해석이 아니라 딥러닝으로 풀 수 있으면 공학적으로 이용가치가 올라가겠네요	4	분명 처음 뉴럴넷 구조는 일종의 nonlinear function approximator로 등장하였지만, 최근 트렌드는 조금 다른 것 같아요. 예를 들어서 LSTM등을 통한 langual modelling (variable length coding)이나 Fully Convolutional Net (FCN)을 활용한 semantic segmentation도 있고, region proposal network (RPM)을 응용한 Faster RCNN이나 SSD 같은 알고리즘들을 보면 우리가 원하는 '동작'을 할 수 있는 '구조'를 잘 설계하려는 연구가 많이 진행되고 있습니다. 단순히 '구조'를 떠나서 최근 핫한 generative adversarial net (간)에 대한 연구는 정말 훨씬 더 다양합니다. 문장을 주고, 이에 해당하는 이미지를 만든다던가, 최근에 나온 plug and play GN은 분류기만 바꿔끼어서 새로운, 그것도 꽤나 고화질의, 이미지를 만들어낼 수 있습니다.	5	다음과 같이 질문을 나눠서 생각해 볼 수 있을 것 같습니다.1) 현재의 딥 러닝 구조가 기존 물리모델을 대체할 가능성이 있느냐. No인간이 물리 모델을 만드는 과정을 보면 많은 입력속에서 공통점을 발견하여 효율적으로 세상을 인지하는 상태에서 특정 영감을 받은 사람에 의해  더 많은 것을 설명해주는 모델이 깔끔하게 정리됩니다. 현재 딥러닝은 많은 데이터를 압축해서 효율적으로 인지하게 도와주지만, 두번째 부분, 어떤 특정 수준에 도달했을 때 간단한 형태로 수렴하여 더 많은 것을 설명하는 부분은 없습니다. 예를들어 뉴턴은 사과가 떨어지는 것을 보고 태양계의 궤도를 예측하지만, 현재 딥러닝은 사과가 떨어지는 것을 계속 보여주면 다른 떨어지지 않은 사과도 떨어진다는 사실을 높은 확률로 맞추는 것에 불과합니다. 한가지 가능성을 남겨보자면, 인간은 제한된 입력만이 가능한 것에 반해, 뉴럴넷은 많은 데이터를 짧은 시간안에 학습한다는 점입니다. 그래서 세상에 일어나는 관찰할 수 있는 수많은 사건들을 뉴럴넷에 압축했을 때, 그 뉴럴넷이 인간이 만든 모델보다 물리적 사건들을 더 잘 예측할 것이냐는 그럴 수도 있지만, 그것은 여전히 발견된 입력값들을 효율적으로 압축해서 새로운 입력값을 근사하는 구조일 뿐, 완전히 동떨어진 사실이나 먼 미래에 대해 영감을 제공하는 규칙을 발견할 가능성은 없다고 봅니다.2) 미래의 딥 러닝 연구가 인간의 물리모델을 대체할 가능성이 있느냐. Yes뇌과학에서 설명하는 인간의 뇌 구조는 시뮬레이션이 충분히 가능해 보이기 때문에, 인간이 생각하는 물리 모델과 비슷하거나 더 나은 수준의 모델을 만들어 내는 개선된 뉴럴넷은 얼마든지 가능해 보입니다.3) 미래의 딥 러닝은 세계를 설명하는 궁극적인 물리모델을 무한한 시간이 주어진다면 찾을 수 있는 구조인가. (모름, 아마도 No) 아마도 튜링머신에 기반을 둔 컴퓨터 구조에서는 안될 것 같은 근거없는 느낌적 느낌입니다.	6	딥러닝이 성공적으로 적용되는 여러 다양한 task가 있지만, 공통적으로는 복잡한 input-output relation을 학습데이터만으로 deep net이 가장 유연하게 approximation할 수 있다는 것이 핵심인 것 같습니다.. 근데 ML관점에서는 universal approximator라는 것만으로는 설명이 안되는게 딥러닝의 아주 좋은 generalization performance죠.. 뭔가 deep net이 가지고 있는 inductive bias가 데이터와 맞아 떨어진다고 할 수 있는데요.. 말하자면 억지로 만든 artificial data에서는 deep net이 train error는 아주 낮지만 test error는 아주 높을수도 있다는 거죠.. 해당 데이터가 이에 맞는가가 관건인데.. 왠만하면 잘 먹히는게 신기하긴 하죠 ㅎㅎ딥러닝이 물리모델을 대체할 수 있는가? 이에 대한 연구를 페북에서 하고 있습니다.. https://arxiv.org/abs/1603.01312 제 의견은.. 딥러닝이 물리적 시스템의 작동을 예측해줄순 있겠지만, 그 방식은 전혀 다를 것입니다.. 물리 미분방정식이 논리와 이성적인 사고에 의존한다면, 딥러닝은 사람의 직관적인 방식을 모사한다고 생각합니다.. 그래서 서로 쓰임새가 전혀 다르므로 대체한다기보다는 상호보완된다고 하는 것이 맞을 것 같습니다..
82	[TF KR 2차 오프라인 모임 참가신청 안내] #2안녕하세요. 이전에 안내드렸던 TF KR 2차 오프라인 모임의 참가신청 방법을 안내해드리고자 합니다.이번 오프라인 모임에는 참가신청 트랙이 총 4개입니다. (포스터 세션 신청/Lightening Talk 신청/STAFF 신청/일반신청)각 신청 별로 자세한 내용을 안내해드리도록 하겠습니다. :-)--------------------------------------------------------------------(1) 포스터 세션 신청 (선착순 60명)포스터 세션은 그동안 딥러닝 및 TensorFlow에 관해 공부한 내용을 다양하게 공유하고자 준비한 세션입니다.주제는 자유이며 그동안 공부했던 내용, 연구 주제 관련 내용, 연구 성과, 회사 소개 등 본인이 원하는 주제를 선택하여 준비해주시면 됩니다.모집이 완료되는대로 포스터 크기 및 제출과 관련하여 재공지 드리도록 하겠습니다.(제출된 포스터는 주최 측에서 일괄적으로 인쇄하여 행사 당일 배포해드립니다.)- 신청일시: 12/20(화) 3:00 PM- 신청방법: 신청일시에 맞춰 본 페이스북 페이지에 신청링크(구글 설문조사)가 담긴 글을 올릴 예정입니다. 글에 있는 링크를 통해 양식에 맞게 신청해주시면 됩니다.- 참가비: 무료- 포스터 제출 기한: 1/4 (수)* 포스터세션 발표자 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.--------------------------------------------------------------------(2) Lightening Talk 신청 (10명)Lightening Talk은 포스터 세션 사이에 진행되며, 회사에 계신 분들을 대상으로 지원을 받을 예정입니다.회사에서 딥러닝을 활용하고 있는 내용이나 구인, 회사 홍보 등 자유롭게 5분간 Talk을 진행해주시면 됩니다.신청이 완료되면 Talk 내용과 신청해주신 순서에 기반하여 10분을 선정한 후, 개별적으로 결과를 안내해드리도록 하겠습니다.- 신청일시: 12/21(수) 3:00 PM- 신청방법: 신청일시에 맞춰 본 페이스북 페이지에 신청링크(구글 설문조사)가 담긴 글을 올릴 예정입니다. 글에 있는 링크를 통해 양식에 맞게 신청해주시면 됩니다.- 참가비: 무료- Talk 시간: 5분씩 총 10명 (50분)* Lightening Talk 발표자 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.--------------------------------------------------------------------(3) STAFF 신청 (10명)행사 당일 진행(리셉션, 행사 물품 관리, 포스터 세션 준비 등)을 도와줄 STAFF를 모집합니다. :-)신청이 완료되면 지원 동기와 신청해주신 순서에 기반하여 10분을 선정한 후, 개별적으로 결과를 안내해드리도록 하겠습니다.- 신청일시: 12/22(목) 3:00 PM- 신청방법: 신청일시에 맞춰 본 페이스북 페이지에 신청링크(구글 설문조사)가 담긴 글을 올릴 예정입니다. 글에 있는 링크를 통해 양식에 맞게 신청해주시면 됩니다.- 참가비: 무료- 참고: 1/14 (토) 오전에 행사 준비부터 함께 해주실 수 있는 분들만 신청을 부탁드리겠습니다.* STAFF 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.--------------------------------------------------------------------(4) 일반신청 (선착순 170명)일반신청은 선착순으로 170명을 모집하게 되며, 온오프믹스 페이지를 통해 신청해주시면 됩니다. (1차 오프라인모임과 동일)다만 신청 시 추가 정보에 주어진 간단한 딥러닝 관련 문제(3문제, 필수입력)를 풀어주셔야 합니다. 딥러닝 및 Tensorflow에 조금이라도 더 관심이 있는 분들을 모시기 위한 것이니 즐거운 마음으로 문제를 풀어주시기 바라겠습니다!이와 더불어 No-Show 방지를 위해 지난 오프라인 모임 때와 마찬가지로 신청비 1만원을 받습니다. 신청해주신 분들이 꼭 오시기를 바라는 마음으로 받는 것이니 이해 부탁드립니다. :-) - 신청일시: 12/23(금) 10:00AM- 신청방법: 온오프믹스를 통한 신청 (http://onoffmix.com/event/86620)- 참가비: 10,000 원* 일반신청 참가자 전원에게는 구글 코리아에서 준비한 소정의 선물을 드립니다.--------------------------------------------------------------------참가 신청과 관련하여 문의 사항이 있으시면 본 글에 댓글로 달아주시면 안내해드리도록 하겠습니다.많은 분들을 뵐 수 있는 2차 오프라인 모임이 되었으면 좋겠습니다. 감사합니다. :-)	2	이전 공지:[TF KR 2차 오프라인 모임 안내 및 강연자 공개 모집] #1https://www.facebook.com/groups/TensorFlowKR/permalink/390292334645164/	1	와우 드디어 시작이네요~ :-)	1	다양한 프로그램 기대됩니다!	0	안녕하세요, TensorFlow KR 오프라인 2차 모임에 포스터를 게재하려합니다.포스터 관련 초록 제출 마감일이,수요일 (12월 21일) 까지인가요?아니면 1월 4일까지 인가요?확인 부탁드립니다.
5	Saver 관련 질문 드립니다.현재 TensorFlow v 12.0에서 Saver로 checkpoint 파일을 저장하게 되면,(예를들어, tf.Saver.save("model"))model.data-00000-of-00001, model.index, model.meta와 같이 3개 파일이 만들어집니다. 이전 버전에서는 model과 model.meta와 같이 2개 파일이 만들어졌었는데요.문제는 v 12.0의 checkpoint 파일을 이전 버전에서 불러오고 싶은데 혹시 방법을 아시는 분 있으신지요?+바뀐 이유를 아시는 분도 있으신가요?	3	https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/python/training/saver.py#L902 saver 포맷 버전이 바뀌었습니다. write_version=tf.train.SaverDef.V1 을 써보세요	0	체크포인트 파일 사용할 때 보통 ckpt파일을 읽어와서 사용하던데 meta파일은 용도가 무엇인가요?
5	NEC, 인공지능으로 암치료용 펩티드 백신 개발·실용화 한다.- 헬스케어 사업 강화, NEC자체 AI기술 'NEC the WISE' 활용 신약개발사업 시작
1	RNN many to one 모델로 Logistic Classfication을 구현할 수 있나요?구현할 수 있다면 git hub에 참고할 만한 소스코드가 있을까요?
0	안녕하세요, TensorFlow KR 오프라인 2차 모임에 포스터를 게재하려합니다. 포스터 관련 초록 제출 마감일이, 수요일 (12월 21일) 까지인가요? 아니면 1월 4일까지 인가요? 확인 부탁드립니다.
8	[스터디 공지] #싸이그래머 #ReMind 강화학습 + 머신러닝 기초 (Re:Mind)  : 파트 1 * 2주에 한번 수요일, 저녁 7시 - 10시 30분. 강남근처, 회비 없음, 2017년 1월 4일 시작.* 이벤트 링크 - https://www.facebook.com/events/268658876884293/* 스터디 자료는 정리가 되면 모두 공유 & 공개 됩니다.* 주로 딥러닝 강화학습을, 실습은 텐서플로우로 할 생각입니다. 안녕하세요, 정통..심리학 그룹 싸이그래머(https://www.facebook.com/groups/psygrammer/) 2017년 스터디 첫 공지입니다. 이제부터 무조건 스터디는 파트 1으로 포매팅하는 전략으로 파트1이 되었습니다만. 사실은 그전에 DGM(Deep Graphical Models)에서 하던 것을 이어서 합니다. 벤지오의 딥러닝북 - 후반부와, 베이지안 머신러닝(머피)의 중반부, 셔튼의 강화학습 기초 초중반부, 딥마인드의 발표논문 리뷰를 이어서 합니다. 하지만! 새로 기초부터 시작하는게 있습니다.Re:Mind 스터디에서는 강화학습 실험 프레임워크를 셋팅하고 작동법 기초를 알아보는 시간을 가집니다. 먼저 딥마인드의 DeepMind Lab - https://github.com/deepmind/lab 으로 해보겠습니다.이 스터디는 전공/실무자 모임이 아닌, 관심있는 누구나 함께 하실 수 있는 취미 모임입니다. 참여를 원하시는 분들은 댓글을 달아주시거나, 이벤트에 참석을 누르시거나 해당 스터디 장소로 바로 찾아오시면 됩니다.키워드#베이지안 #딥러닝 #강화학습 #딥마인드
3	안녕하세요? 이제 막 텐서플로우를 공부 하고 있는 학생인데요! 텐서플로우에서 tf.contrib.layers.embedding_column의 하는 역할과 매개변수로 dimension 값을 무엇을 근거로 주는것인지 알고 싶습니다.  마지막으로 embedding이라는 것을 여기 저기 예제 파일에서 보이는데 텐서플로우에서 말하는 embedding이란 무엇인지 궁금합니다!	1	svd은 하나의 matrix를 3개로 나눕니다. embedding은 하나의 matrix를 다차원으로 확장시킵니다. (제가 이해하기로는.....)   input ---> output 이 있다고 가정하면  중간,--->, 에 무엇이 있든지 output이 input과 같은 형태로 나오면 중간, -->, 에 들어가는 연산 부분은 svd이든지 embedding이든지 알려고 하는 내용에 따라  바꾸어서 생각할 수 있습니다.  ( input이 a이고 2*1 matrix라고 표현하면 여기에 128 embedding을 시키면 예가 중간에서 1*128 matrix로 바뀌어도 output이 1*1 matrix라고 하면 중간의 1*128 matrix는 결국은 추가적인 연산을 위해서 data type을 converting 한거라고 보셔도 될 것 같습니다.	1	https://www.tensorflow.org/tutorials/wide_and_deep/ 을 보시면,1000-dimensional one-hot(sparse) vector 를 8-dimension dense vector 로 바꿉니다.data 가 놀(?)수있는 공간을 압축 시킨다고 보시면 되요. 수증기를 압축시켜서 물로 만드는것 처럼.그러면, 비슷한 output 을 만들어내는 data 는 비슷한 direction 을 가르키는 vector 가 됩니다.설명이 좀 hand-wavy 한데, https://en.wikipedia.org/wiki/Word_embeddinghttps://en.wikipedia.org/wiki/Word2vec 읽으셔서 나머진.. ㅎ	2	'데이터를 몇 개의 파라미터로, 어떤 방식으로 표현하겠느냐' 라는 말과 같습니다. data encoding 과 같은 말입니다. 통계학에서의 '충분통계량'을 결정하는 문제와도 비슷합니다가장 간단하고 널리 쓰이는 embedding 에는 one-hot encoding 이 있습니다.ex. (해가 쨍쨍하다), (비가 조금 온다), (비가 많이 온다) 의 3가지 날씨 표현1) one-hot encoding(1,0,0), (0,1,0), (0,0,1) 으로 표현2) 다른 방법: "'날씨' 축 직선에서 현재 날씨가 어디에 위치하느냐"(0.0), (0.5), (1.0) 으로 표현embedding에 정답은 없고 각각 여러 가지 특성이 있는데 메모리 크기 (위의 1) one-hot encoding은 숫자를 하나만 사용하는 2) 방법에 비해 한 가지를 기록하는 데 더 많은 3개의 숫자가 필요하죠) 등 필요에 따라서, 문제에 따라서 여러가지를 사용해 볼 수 있습니다.
2	안녕하세요. 클러스터 시스템을 구성하여서 Tensorflow를 클러스터 구성하려는데 스케줄러를 이용해서 하려고 합니다. PBS스케줄러를 이용하려는데, Tensorflow에서 배치커맨드라는걸 지원하면 사용가능하다는데, Tensorflow에서 배치커맨드를 지원하나요?
9	안녕하세요 텐서플로우 관련 질문 있어서 올립니다.제가 텐서플로우로 네트워크 만들어 놓고, LBFGS로 트레이닝시키려 하는데, 텐서플로우에서 제공하는 Optimizer에서는 LBFGS가 구현이 안되어 있네요.혹시 이렇게 외부 Optimizer 직접 만들어서 트레이닝시키면 어떻게 해야하나요?? 구글링 해보니 line search 값 넣어주는 방법이 있다고는 하는데 잘 안 나오네요ㅎㅎ	1	LBFGS가 필요있나요.. 그냥 SGD도 잘되는데.. ;;	4	직접 계산해 넣을 수 있습니다. tf.compute_gradient랑 tf.apply_gradient 찾아보세요~	2	제가 써본 적은 없지만 텐서플로우의 ScipyOptimizerInterface 를 사용할 수 있지 않을까 합니다. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/opt/python/training/external_optimizer.py)또 OpenAI 의 Yaroslav 가 작성한 슬라이드 중 끝부분에 보면 텐서플로우와 lbfgs 를 사용한 퍼포먼스 향상 부분이 있습니다.(https://github.com/yaroslavvb/imperative/blob/master/imperative_slides.pdf)그리고 Yaroslav 의 깃허브도 보시면 먼가 힌트를 얻으실 수 있을 거 같아요.(https://github.com/yaroslavvb/lbfgs) :-)
10	이런 기사가 있었네욤. :-)	0	정부는 언제나 뒷북 ㅋㅋ	1	저대로 될까요?	0	결국 인재육성이 아니라 장비에 수백억 들이고 나 일했어 그러겠죠 ㅡㅡ;;
0	도움을 받아 텐서플로우를 설치하고 파이참으로 프로그래밍을 하고있습니다.그런데 튜토리얼을 진행중 input_data 다운과 설치 위치 사용 방법을 잘 모르겠습니다	0	어떤 튜토리얼을 보고 계신가요? 기본 예제 input data는 텐서플로우에서 클래스로 제공해서 쉽게 쓸수있습니다. 설치 위치 사용 방법은 어떤 의미인가요?	0	from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/", one_hot=True)여기서 넘어 가질 않습니다...
109	저희 그룹의 이진원 (Jinwon Lee)님과 전태균 (Taegyun Jeon)님이 출격하시네요. 와우!~	4	우와! 기대 됩니다.	8	앗... 이런게 벌써 떴군요!  지금 열심히 준비중이긴 한데 대상이 주로 학생과 선생님들이라고 들어서 굉장히 기초적인 내용을 다루게 될 것 같아요...ㅠㅠ 저보다는 전박사님 강의를 기대하고 있습니다	0	이태우	1	전태균 박사는 직장이 자뀌었네 ㅋㅋ	2	기대되네요! 전화 신청은 통화가 어려워 메일로 신청 했습니다. 멋진 강연 부탁드립니다 :)	2	감사합니다 신청 메일 보냈습니다.	3	저도 가 볼까요... 휴가를 써..서...
1	이런 질문을 해도 될지 모르겠습니다..조금 급해서 물어볼 곳이 없어 남깁니다. 텐서플로 환경설정을 위해 titanX pascal과 데스크탑 조립부품을 구매했습니다. 우분투를 설치할 예정입니다만..만약 랙서버를 이용할 경우에는 방법이 있는건지요..1. 썬더볼트 외장그래픽카드 독을 우분투 PC에 연결?2. 랙서버를 구매?리눅스에서도 썬더볼트를 사용가능하다고는 들었습니다만...혹시 아시는분 있으시면 답글 부탁드립니다.	0	꼭 1U여야 합니까? 1U는 쉽지 않을것이고 그렇지 않다면 취향대로 골라 쓰시죠https://www.supermicro.com/products/nfo/gpu.cfm
7	Spark랑 Tensorflow를 같이하면 더 좋은 효과가있다는데해보신분 계신가요??아님 둘을 따로 봐야하나요??	1	Databricks에서 tensorframe이란 패키지를 만들고 깃허브에 올렸는데 구글에서 찾아서 직접해보시는게 더 빠를겁니다.	3	학습 Workload가 어떤 유형인가에 따라 다를 것 같습니다. 같은 네트워크를 분산학습 시키는 Workload에는 별 효과가 없다는 것이 Google Brain 분산버전 vs GPU 버전으로 입증된 듯 하고, Alphago의  MCTS같은 Workload에는 효율적일 것 같습니다. 요약하면, Spark에서 partition 단위 데이터별로 독자적인 Network를 학습하게 되는 경우라면 좋은 효과가 있겠고, partition 단위 데이터들이 같은 Network을 학습해야 되는 경우라면 비효율적이 될 것 같습니다.	1	오 저도 궁금하던 주제였는데 좋은 의견들 보고 갑니다. 학습단계 이외에도 데이터 수집/관리 단계에 적용해도 괜찮치 않을까 생각이 듭니다.	0	ㅡㅡ 매뉴얼 자체가 부족하다고 해서 노가대 작업  많이 했다고 하네요	5	https://www.quora.com/Is-Apache-Spark-a-good-framework-for-implementing-Deep-Learning어제 비슷한 고민으로 찾아봤던 건데요 참고요
13	50 things I learned at NIPS 2016 - Andreas Stuhlmüller
14	텐서플로우 사이트가 소소하게 업데이트 되었군요.r0.12와 모바일도 좀 구체화 된것 같네요.아래 링크는 모바일 페이지입니다.
0	안녕하세요 제가 딥러닝 문외한이라 얼토당토한 질문들이 많은데 많은 양해 부탁드려요 ^^;;fine_tuning이라는 것에 대해 궁금해서 그러는데요. 제가 간략하게 찾아본 바로는 작은 양의 데이터로 모델을 만들려면 과적합이 일어날 소지가 많기 때문에 이미 충분히 많은 데이터로 학습한 모델을 미세조정해서 작은 양의 데이터도 충분히 추론할 수 있는 모델을 만드는 것이라고 이해했는데 맞나요?제가 궁금한 점은 기존 inception-v3 모델을 fine_tuning 해서 flower 데이터를 추가했을 경우, 기존 inception-v3 모델이 학습했던 imagenet 데이터도 함께 추론이 가능할까 입니다.
6	NNPACK을 raspberry pi 3 에서 빌드할수 있도록 수정했습니다. tiny-dnn에 있는 benchmarks_all을 NNPACK을 이용해 돌려보니 7초에서 1초로 줄어드네요.빌드하려면 다음 작업이 추가로 필요합니다.1. raspberry pi에 clang을 설치하세요. (sudo apt-get install clang)2. configure할때 --enable-rpi 옵션을 사용하세요. tiny-dnn에서 사용하려면 --enable-shared 옵션도 넣어줘야 합니다.3. 최신 버전의 ninja를 받아서 빌드해야 합니다. raspberry pi에 있는 패키지는 버전이 낮아 빌드가 안됩니다.
20	마이크로소프트, ‘모두를 위한 AI’ 향한 대화형 컴퓨팅의 새로운 비전 공유- AI 기반 챗봇 ‘조’ 정식 공개, 코타나 디바이스 SDK, 코타나 스킬 킷 등 제조사 및 개발자를 위한 새로운 툴킷도 공개
16	런칭 2개월 만에 2016년 애플이 선정한 베스트 앱에 선정된 글로벌 육아앱 BabyTime에서 데이터 엔지니어를 모십니다!현재 글로벌 50만 이상의 유저 다운로드가 발생하였으며, 육아 액티비티 정보를 분석해서 유저들에게 가치있고 편리한 육아 정보를 제공 할수 있는 서비스를 만들어 나가는데 함께 하실 분을 모십니다. 텐서플로우와 같은 머신러닝과 관련한 최고의 페이스북 모임이라고 알고 있습니다.많은 관심과 추천 부탁 드리겠습니다.
5	혹시 여기에 데이터 엔지니어 관련 구인 포스팅을 올릴수 있나요? 안된다면 이글도 삭제 하겠습니다 ^^;	2	텐서플로우와 관계있으면 ok. 아니면 삭제 부탁 드립니다.
2	안녕하세요 최근 inception v3를 통해 이미지 인식을 해보고 있는데요. 기존에 학습한 imagenet 데이터에 제가 추가로 data를 추가해서 학습하고 추론할 수 있나요?? 결과적으로 imagenet data + 추가 데이터가 학습되어서 추론 모델로 만들어 질 수 있는지 문의 드립니다.	2	이게 참고가 될지 모르겠네요 https://github.com/tensorflow/models/tree/master/slim#fine-tuning-a-model-from-an-existing-checkpoint
37	텐서플로우 0.12.0 RC0 윈도우 버전에서 웹 리소스(HTML, JS) 파일이 없어 텐서보드가 빈화면으로 출력되는 문제가 발생하여 (PIP 설치 시에, Python 3.5, Anaconda) 소스를 받아서 필요한 웹리소스를 묶어 봤습니다. 첫 페이지에 모두 로딩 되는 것은 확인 했는데, 이게 필요한 모든 리소스를 묶었는지는 검증을 못 했습니다. 필요하신분께 도움이 되면 좋겠네요.압축 파일 주소는 https://www.dropbox.com/s/hxekoifmbyvrl33/tensorboard.zip?dl=0이고, 압축풀 경로는 아나콘다 기준으로 Anaconda3\Lib\site-packages\tensorflow\tensorboard폴더입니다. 감사합니다.	1	감사합니다😀😀	3	드디어 되네요.... ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ정말 감사드립니다!	1	정말 감사합니다.	1	오우~ 꿀팁이네요! 윈도우 텐서플로 배포본에는 이 말고도 model 이 포함 되어있지 않아서 테스트 모델이 하나도 없더군요 ㅋ	1	힌트 주신대로 model도 github tensorflow 에서 받아서 넣었더니 바로 되네요~ 다른 분들도 참고하시면 좋겠습니다 ㅎㅎ	1	감사합니다
3	안녕하세요tensorflow 로 딥러닝을 공부중인 박시영입니다tensorflow 가 윈도우에서 gpu 로 가능하다고 해서설치중입니다. 그래서http://goodtogreate.tistory.com/m/entry/GPU-TensorFlow-on-Window-10-TensorFlow-GPU%EB%B2%84%EC%A0%84-%EC%9C%88%EB%8F%84%EC%9A%B010-%EC%84%A4%EC%B9%98이 사이트를 바탕으로 설치중인데요이중 cmd  창에  업그레이드 관련 명령어를 입력할경우다음 과 같이cannot remove entries from nonexitent file 이라고 뜨는데 상관이 없는건가요?	0	전 pip upgrade 하고 다시 설치 했어요	0	프롬프트에 있는 노란색 글씨들을 잘 읽어보심 됩니다.	0	윈도우 10 에서 설치방법 좀 부탁드립니다
115	저희는 챗봇을 개발합니다. 에이다는 매일 학습해서 뿌듯하게 잘자라고(?) 있습니다. 8퍼센트 페북 페이지에서 open beta 직접사용해보시고, 챗봇활용하고 싶으신 스타트업 있으시면 연락주세요.AI 개발자님도 모십니다. 오셔서 텐서플로우 전문가가 되세요. aws 서버 마음것 돌리실수 있습니다.	1	"aws 서버 마음것 돌리실수 있습니다." 부럽습니다.	2	아... 한글/언어 도 많이 배우시게 됩니다.	1	여러 질문을 한번에 하는 것 같은 (단답식 질문이아닌 장문으로 된 질문?)에 대한 답변 성능이 궁금합니다!	0	😄 부러워요~~	0	조재민 (J-min Cho) 재민아 너가 일하는곳 아니야?	0	우와멋나네요 말로만듣던 챗봇!!
52	엔비디아, 뉴욕대 얀 레쿤 교수와 공동 개발 '딥러닝 교육 키트' 발표- 바르셀로나에서 개최된 신경정보처리시스템 국제학회 머신러닝 컨퍼런스에서 공개	0	김건우 말씀하신게 이거군요!	1	우선 17학번은 영어를....ㅠㅠ	0	Hwang Jinha
41	Toshinori Hanya씨가 정리한 Object localization & detection 과 Instance Segmentation에 대한 설명자료를 번역해봤습니다.  최근에 발표된 가장 성능이 좋은 Single Shot MultiBox Detector와 Recurrent Instance Segmentation에 대하여 기존 다른 기술과의 차이점을 설명.Single Shot MultiBox Detector와 Recurrent Instance Segmentation의 architecture를 알기 쉽도록 설명하고, loss function 계산시 true와 estimated value 사이의 cross correlation와 cross entropy등의 의미를 이해하기 쉽도록 Xavier Giro의 별도의 설명자료도 첨부http://www.slideshare.net/ssuser06e0c5/single-shot-multibox-detector-recurrent-instance-segmentationSingle Shot MultiBox Detectorhttp://www.slideshare.net/xavigiro/ssd-single-shot-multibox-detectorRecurrent Instance Segmentationhttp://www.slideshare.net/xavigiro/recurrent-instance-segmentation-upc-reading-group	1	좋은 자료 감사합니다!	1	유택근 (Tack-geun You)
7	안녕하세요. TF에 궁금한 점이 있어 글 올립니다.Prisma앱 출시 후 Style Transfer가 핫한데요.Style Transfer 방식이 스타일 이미지/컨텐츠 이미지가 있을 경우 랜덤한 이미지를 파라미터로 놓고, 그 랜덤한 이미지의 스타일과 컨텐츠의 Loss 를 Optimize하는 형태로 처리하게됩니다. Ltotal(~p,~a, ~x) = αLcontent(~p, ~x) + βLstyle(~a, ~x) training하는 경우 랜덤 이미지를 파라미터로하여 iteration을 돌면서 Optimize하면 되는데, Inference같은 경우 어떤 방식으로 동작하는지 궁금합니다.training후 텐서플로우 학습 모델 데이터에는 어떤 것들이 포함되어 있는 것인지?실제 동작은 어떻게 되는것인지?관련하여 고수분들의 소중한 답변 부탁 드립니다.^^;감사합니다.	0	랜덤노이즈에 저 loss에대 한 gradient를 계속 업데이트해주어서 나온것이 결과물입니다. Cnn의 weight를 학습하는 training이 아니라 input image를 loss에 따라 optimize한다고 생각하심 될것같습니다.
11	Tensorflow공부 삼아 Genetic Algorithm을 구현 중에 의견을 여쭙고자 질문을 올립니다. 구현은 현재 Fitness Function으로 평가하고 Parent가 될 Conformation까지는 계산해놓은 상태입니다. 또한 Mutation연산자의 경우는 Matrix를 이용하여 연산할 수 있도록 구현 중에 있습니다.(아이디어는 Identity Matrix를 구현하고 각 대각원소에 값들을 일정한 distribution에 따라서 다시 계산하고, Trace를 이용하여 Normalization하여 Determinant가 1이 되게 한 것을 이용하려고 합니다.)그런데 Crossover연산자를 만드는 중간에 Matrix을 이용하여 하려고 하니 두 Conformation(Vector)를 Matrix를 이용하여 어떻게 섞어야 할지 감이 안와서 질문을 드립니다.Matrix가 아니라면, Slice와 몇가지 Control 연산자를 사용하면 Crossover연산자를 구현할 수 있을 것 같은데... 일단은 Matrix폼으로 표현하여 만드는 것부터 테스트해보려고 합니다.Matrix형태로 Crossover 연산자를 구현할 수 있을까요? 못 구현한다면 다른 좋은 방법은 어떤게 있을까요??	2	crossover 연산을 하려는 두 vector를 concatenation하여 하나의 matrix로 만든 뒤에 (2xn), 한 행에 0과 1이 random하게 들어있는 nx2 matrix를 만들어 곱하면 crossover 연산이 되지 않을까요? 0, 1이 random 하게 들어있는 nx2 matrix 만드는 방법은 우선 random_uniform을 통해 nx1의 행렬을 만들고, crossover rate (ex. 0.9) 이상이면 1, 이하이면 0이 되도록 condition연산을 취해줍니다. 그 뒤에 1로 차 있는 같은 크기 nx1 행렬을 만들어 이전에 만든 행렬로 빼준 뒤 둘을 axis=1로 concatenation하면 nx2 행렬이 만들어질 것 같습니다.
7	텐사플로우를 배워가고 있습니다. 기존에는 matconvnet등으로 쉽게 썼는데 tf로 넘어오면서 사용법에 어려움이 있네요. 도움부탁드립니다. 1. tensorflow 그래프 구조를 tensorboard로 연결해서 시각화 나는것 말고 간단히 프린트로 출력해서 볼 수 있는 방법이나 함수가 있을까요? 뭔가 구조만 잘 만들어졌는지 차원은 맞게 정의했는지만 확인하려는데 tensorboard를 사용하는게 좀 헤비해서요.2. 구글 inception 네트워크를 받아서 일부만  사용하려고 하는데, protobuf를 통해 graphDef를 가져와서 하는 예제를 봤습니다. 기본 튜토리얼 예제랑 사용법도 다르고 c++api 랑 섞여있는것 같아서 사용을 잘 못하고 있습니다.  tf.graph 라는 클래스를 가지고 직접 그래프 구조를 다루는 방법을 알아야 좀 써볼 수 있을 것 같은데 기본 mnist예제에서 variable ,constant 자료형을 엮어서 그래프 만드는거랑 사용법이 달라서 혼란스럽습니다. 개념적으로 설명해주실 수 있는분 계신가요.	0	간단하게 체크만 해보실거면 keras로 모델만들고 model.summary() 해보시면 shape이랑 input, output은 금방확인할수 있습니다. 이후 model을 tensor로 받아서 tf에서 그대로 쓰시면 되구요.	1	안녕하세요, 민준홍 박사님. UNIST 이규현 입니다. 지나가다 답변을 드릴수 있을까해서 남깁니다. 1번은 tflearn.utils.get_incoming_shape()를 통해 각각 네트워크의 차원을 리턴 받아 출력해보실 수 있을 것 같고 위에 분이 말씀하신대로 전체적인 네트워크를 출력해 보시고 싶으시면 keras의 summary를 이용해도 좋을 것 같습니다. 2번은 VGG와 같은 네트워크가 npy와 같은 numpy binary로 저장 되었을 시에 그냥 로드해서 사용하였는데, protobuf를 사용하더라고 비슷하게 사용될 것 같은데, 이 부분은 도움을 못드려 죄송합니다.	1	에폭 안에 df을 만들어 accuracy와 error를 기록하게 하고 이것을 바로 그래프로 확인하는 방법을 주로 사용합니다. 이렇게하면 jupyter notebook(만약 사용하신다면) 에 그래프로 로그를 남겨놓을 수 있어서 나중에 하이퍼 파라이터 조정에 매우 유용합니다.
106	안녕하세요. 회사에서 스터디로 머신러닝 강의들을 보면서 정리해보았습니다.비전공자이기에 한줄 한줄이 읽기 어려웠고 또 입력과 출력이 어떤 형태로 되어있는지 많이 생각해야하는 고민이 있어서한글 주석을 왕창(?) 달고 결과를 이쁜 형태로 보이도록 바꾸어보았습니다.https://github.com/proauto/ML_Practice고수님들에게는 필요하지 않겠지만 저처럼 머신러닝을 처음 접하는 분들을 위해 공유해봅니다.(틀린 부분이 있으면 피드백 감사합니다~!)(TensorFlow-Tutorials와 SungKim 교수님의 자료 + MNIST를 여러가지 방법으로 돌려보기)	1	좋은정보 감사합니다.	1	감사합니다!	1	감사합니다!!!	1	공부하는 데 저한테도 큰 도움이 될 것 같아요! 공유 감사합니다 ㅋㅋ	0	오.. 많은 분들이 공유해주셨네요 더 많이 공부해서  추가해볼게요~	1	이 자료로 애매했던 개념들이 더욱 명확하게  머릿속에 잡혔습니다!! 감사합니다^^
10	안녕하세요. 음악 인식을 하고 있는데 의문점이 있어 문의 드립니다. 제가 보유한 음악 데이터셋에서 music genre(pop, rock, R&B, jazz, classic…)를 인식해보려고 하는데, music genre classification에서 유명한 소스코드나 라이브러리를 아시는분 추천 부탁드려요.computer vision에서는 몇몇의 이정표같은 유명한 딥러닝 네트워크 (e.g.,VGG, Resnet)들이 많이 공개되어 있는데, music genre classification에서는 어떤 것이 유명한지 잘 모르겠네요. 꼭 music genre classification이 아니더라도 음악쪽에서 유명한 딥러닝 코드나 라이브러리 아시면 추천 부탁드려요.한가지 더 여쭤볼게 있는데, music information retrieval (MIR) 분야를 제대로 해보고싶은데, 혹시 top conference나 top journal 리스트도 알 수 있을까요?	0	저도궁금합니다.	0	전 ISMIR말곤 잘모르겠네요	2	https://github.com/mlachmish/MusicGenreClassification
92	http://bcho.tistory.com/1150 텐서플로우 자료형과 그래프, 세션에 대한 기본적인 소개 입니다. 이 그룹에 올리기가 제일 무섭습니다만, 그래도 고수님들이 한번 보시고 틀린걸 지적해주시는 경우가 있어서 꿋꿋하게 올려봅니다.	0	상수형과 플레이스홀더의 차이는 뭘까요? 플레이스홀더가 입력치를 나중에 바꿀 수 있다고 할 수도 있는데 그건 상수형일때도 가능한게 아닌지 궁금합니다	1	상수형도 값을 못 바꾸는 것은 아닙니다 바꿀 수는 있지만 여기서 상수라 함은 "사용자 정의 값"이라고 생각하는게 더 맞을 것 같습니다.사용자가 알 수 있고 직접 넣을 수 있는 데이터형은 constant입니다.영상에서 조금 제가 실수한 부분이기도 합니다 사실...ㅠ 관례적으로 이 값은 건들지 마시오 하는 값을 정의할때도 상수형으로 정의합니다	1	플레이스 홀더의 경우 Converting의 성격이 강합니다. 보통 데이터셋을 받을 때는 분명 데이터 포멧이 제각각일 것이고 어떤 데이터형도 플레이스홀더가 인식할 수만 있으면 텐서로 처리 할 수 있습니다.또한 feeding기능을 지원하기 때문에 많은 데이터를 로드된 데이터 그대로 당겨올 수 있는 것입니다. 상수형이나 변수형은 임의의 데이터셋을 바로 텐서로 받아들이지 못합니다.
2	첫 글을 질문으로 올리게 되어 송구스럽네요..첫 입문을 하다 보니.. 모르는게 너무 많네요..;; ㅠinceptionV3 Model에 example의 retrain.py를 통해서 학습 데이터를 학습 시킨 후 텐서보드로 확인을 해봤는데요..질문입니다.1. 학습에 대한 검증은 어떻게 하면 될까요.??2. 학습 시 라벨 별 최소 학습 이미지 개수는 꼭 라벨 사이즈와 동일해야 하나요?3. CNN은 무감독 학습으로 알고 있는데, 만약 인식 결과가 잘못 되었고 이게 아니다.. 라고 알려 주어야 하는지, 그렇다면 어떻게 알려 주어야 하는지..??모르는게 너무 많아 질문이 보시기에 무식할 수도 있음을 양해 바라며 미리 감사 드립니다~!!	1	CNN은 감독학습입니다.. 물론 라벨(정답)이 없다면 무감독 학습이 되긴하죠	2	1. 학습데이터와 별개인 테스트 데이터셋을 구성해 검증합니다2. 질문이 잘 이해가 안되네요3. CNN은 지도(감독)학습입니다	1	k fold cross validation이라는 방법이 있는데 1번 질문에 대한 답이 될거 같습니다
12	안녕하십니까저는 딥러닝에 관심있는 청년입니다텐서플로우를 공부하기위해 환경을 만들다가 어려워 자문을 구하고자 질문 드립니다.윈도우7에서 도커를 설치후 텐서플로우를 설치후 파이톤설치 후파이참 설치순이 맞는건지 질문드립니다.그리고 인공지능 오픈소스가 오픈되었다고 하여 공유 드립니다.	3	이번에 0.12버전이 나오면서 윈도우 Tensorflow 설치가 쉽게 됩니다.python 3.5, cuda, cudnn 설치후 anaconda3버전으로 pip install tensorflow-gpu만하면 설치 완료됩니다.	0	설치 완료후 구동은 어떤 소프트웨어를 사용하나요?
9	안녕하세요. 얼마전 질문을 올렸던 이도엽이라고 합니다.저번 답변이 도움이 많이 되어,한번 더 도움을 얻을 수 있을까 하여 질문 올립니다.Time Series Data분석을 위해 기존에 LSTM,GRU 등과 같은 순환신경망과Full Connected Neural Network를 그다음 Layer에 얹어 분석하는것과 같이순환 신경망을 이용한 사례들을 몇몇 본적이 있습니다.(위에서 언급한 사례는 정확히 Gist 전박사님의 전력가격예측 모델이었습니다.)지나가는 말로,이제는 단순히 RNN 모델만 사용하지 않고Conv Net의 특성을 활용하여 Feature를 뽑아낸 후,이를 기반으로 분석하면 훨씬 시계열 데이터 처리에 도움이 될 수 있다는 말을 들었는데,마땅한 Reference를 찾기가 쉽지가 않군요..(고민을 좀 해보았는데 Conv net의 결과를 순환신경망으로 넘기는 과정이 생각보다 직관적으로 다가오지 않더라고요.좀 더 자세히 말하면, Conv Net이 처리된 이후의 결과들이 시간 순서로 정렬되어 있어야한다는 점. Conv Net을 거치면서 여러개의 Feature Map이 생성되어 이를 동시에 처리해야한다는 점 등에서 Break가 걸리네요.지금 쓰다보니 문제가 정리되어 좀 더 생각해보면 아이디어를 얻을 수 있을 듯 한데,그래도 일단 고수님들의 조언 구해봅니다.)이 그룹에 뛰어난 실력가분들이 많아 위와 관련된 사례나 알고 게신 것들이 있으면 조언을 구합니다..	2	1. PIXEL CONV과 RNN의 이점을 살린 모델으로는 최근에 WAVENET 이라고 음성 합성 분야에서 DEEP MIND 측이 제안한 모델이 있구요, 2. CONV의 이점을 살리기 위해서 CONVOLUTIVE LSTM 컨셉도 최근에 나온 것으로 알 고 있습니다. 기존 컨셉데로 컨브로 FEATURE EXTRACTION 후에 기존 FULLY -> RNN 형식을 취하시려면 FULLY와 마찬가지로 피쳐맵들을 RNN 입력에 맞게 RESHAPE 해야되는데요, 이 때, 최상층 피쳐맵 차원이 충분히 줄지 않았을 경우 차원이 엄청나게 커질 가능 성이 있습니다. 차원이 커지게 될 경우, 학습이 상당히 어려워 지기 때문에, CONV 마지막 단에서는 RECEPTIVE FIELD를 피쳐맵 전체로 하여 (1*1*FEAUTRE MAP_NUMBER) 로 만드신 후 RNN 을 써주시면 될 것 같습니다.	1	요새는 conv net에서 피쳐 추출후 rnn으로 넘겨주는 모델들이 대다수입니다. 관련 논문들도 쉽게 찾아볼 수 있구요. 피쳐맵의 평균을 넘겨주는 경우도 있고, end to end 방식으로 순차적으로 넘겨줄 수도 있고 방법은 여러가지에요~ 또한 alex net과 같이 기존에 성능이좋았던 cnn모델에서 fc7번이라던가 이런식으로 정보를 넘겨주는 경우가 많습니다
11	안녕하세요. Tensorflow에서 cnn을 활용하여서 연구를 하고 있는데요,1. cnn에서 각 layer들의 학습결과를 보고 싶으면 어떻게 하면되나요 ?저번에 질문하였을 때, print(w)이런식으로... 하면된다고 하여서 하였는데 수치데이터로 나오고, 이것을 다시 visualization해주어야 하더라구요. 한번에 가는 방법이 혹시 있을까요 ?2. cnn에서 multiclass-classificaiton을 하고있는데, 여기서 multiclass confusion matrix를 보여주고 싶은데, sklearn을 사용하면되나요? (검색해보니 결과가 너무 다양해서.. 맞는지 확신이 안들어서...)	1	layer visualization하는거는 yosinski.com/deepvis를 참고하시는게좋을거같네요
17	안녕하세요? RNN을 이용하여 회사 이름 작명을 해본결과, 중간에 이상한 이름들이 좀 나오는데 이런것들을 줄일수 있는 방법이 없을까요?	1	재미있는 아이디어네요. 학습데이타가 더 많으면 좋고, 또 어떤 규칙을 정해 post-filter를 만들어 보는 것은 어떨까요?	1	또 회사 이름을 작명할때 본인이 원하는 단어 몇개를 입력하면 이를 잘 조합해주는 것도 좋을듯 합니다.	1	MULTI TASK LEARNING 형식으로, 이상한 것과 이상하지 않은 형태의 CLASSIFICATION을 추가해주면 어느정도 해결되지 않을까요?
4	입문을 시도하고픈 학생인데 혹시 텐서플로우를 이용하여 소리와 관련된 딥러닝분야를 구현할 수 있을까요?	3	https://tensorflow.blog/2016/11/06/urban-sound-classification/
3	안녕하세요. 저는 현재 운동 종류를 인식하는 TensorFlow를 CNN 으로 만들어보고 있는 이상욱이라고 합니다.저는 이를 위해 CNN 모델을 2개 만들었는데요. 하나는 운동 하는 지 안하는 지를 결정하고, 하나는 운동의 종류를 찾게 되어 있습니다. 근데 제가 문제가 생겼습니다. checkpoint restore에서 계속 오류가 납니다. Tensor name "fully_connected_3/weights" not found in checkpoint files CNN1_Models/Model_Ex.ckpt라는 오류가 나오고요. 대충 짐작했을 때, 이 문제는 tensorflow가 모델 두 개를 동시에 사용하면서, 자동 네이밍 할 때 생기는 Restore 함수의 오류 같은데요. 이 문제를 해결할 수 있는 방법이 없을까요?제 코드는 https://github.com/leesang627/ExerciseRecog 에 있습니다.	1	save시  model에서 scope 지정하여  각각 저장하고 restore는 아래와 같이 하면됩니다all_vars = tf.all_variables()model_one_vars = [k for k in all_vars if k.name.startswith(FLAGS.model_one_scope)]model_two_vars = [k for k in all_vars if k.name.startswith(FLAGS.model_two_scope)]tf.train.Saver(model_one_vars).restore(sess, model_one_checkpoint)tf.train.Saver(model_two_vars).restore(sess, model_two_checkpoint)
152	요즈음 Deep Learning과 Reinforcement Learning을 같이 사용하면 더 많은 문제를 풀수 있습니다. Reinforcement Learning을 깊게 이해할수 있는 1998년 나왔던 첫번째판 책이 거의 20년만에 새로운 버전이 나왔습니다.Q-learning 과 Policy Gradient등 다양한 내용을 담고 있습니다.https://webdocs.cs.ualberta.ca/~sutton/book/the-book-2nd.html현재 draft를 PDF를 다운받아 읽어 보실수 있습니다.https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf	0	감사합니다. 잘 볼께요.	0	대단히 감사합니다.만, 읽어보는데 시간이 한참 걸리겠네요. ㅠㅠ
141	안녕하세요.<(가제)밑바닥부터 시작하는 딥 러닝>을 번역 중인 이복연입니다.출간이 얼마 남지 않았는데, 아마존 재팬에서 워낙 인기라 좀 부담이... ㅎ그래서 짧게 베타리딩을 해주실 분을 모십니다.https://goo.gl/Ct6dl2책은.. 딥 러닝 이론을 파이썬으로 직접 구현해보며 익히는 입문서입니다. 가장 개발자 친화적인 학습법이죠. ^^기간은 거의 바로 시작해서 2주 정도 여유가 있을 것 같습니다.도와주실 분은 제게 연락 부탁드립니다~ 꾸벅	0	기대되는 책이네요	0	베타리더 조건 같은것도 있나여?	0	관심이 가네요	0	지원합니다.	0	김성원 베타리더 조건이라 하시면.. 아무래도 정식 출간 전에 오류를 최소화하려는 목적이라, 기술이나 논리적 오류(주로 잘못 번역한 부분이겠죠)를 캐치해주실 수 있는 분이면 좋겠습니다. ^^ 프레임워크 활용서가 아니라 이론 입문서이니 수학 공식도 좀 나오고 그렇습니다.	0	저자가 일본인가요	0	메세지 드렸습니다.	0	현재 이책으로 공부중입니다. 연락주세요. 좋은 한글 번역본이 나오도록 협력하고 싶습니다.	0	메세지 드렸습니당 ㅎㅎ	0	우오아아아앙	0	응원합니다!!!	0	저도 지원할 수 있을까요? 인공지능 개발자입니다 ^^;; 제품 개발도 해봤습니다.	0	저도 지원 할 수 있을까요? ^^	0	저도 ... 손들어봅니다	0	저 신청해 봅니다^^	0	정식출간 기대하겠습니다 ^^	0	저도 신청해봅니다. 쪽지 드렸습니다. 감사합니다. ^^	1	우앗! 이번엔 지원을 너무 많이 해주셔서 고민을... ㅋㅋ	0	베타 리딩 신청합니다~	1	과한 관심을 받고 있어서.. 점심 먹고 한 분씩 연락드리겠습니다. 모두들 식사 맛있게 드세요~	0	저도 손들어 봅니다. ㅋ	0	저도 신청합니다	0	신청하고 싶은데;; 도움 드릴 수 있을까 싶어 망설이게 되네요. ㅎㅎ 출간 기대합니다~	0	저도 신청합니다. 감사합니다	0	신청은 할 수 없을 것 같지만, 출간 기대합니다.	0	좋은 책 진행하시네요~저도 신청합니다~	0	신청하기엔 도움이 별로 안 될 것 같고ㅠ 출간 기대합니다~	0	저도 신청하겠습니다. 딥러닝과 강화학습 매우 관심분야에요 ~	0	베타리딩을 희망합니다.	0	저도 베타리딩 신청해봅니다!	1	생각보다 너무 많이들 신청해주셔서 행복한 고민을.. ㅠㅠ 모든 분들이 한 가지씩만 지적해주셔도 정리하기도 벅차게 생겼습니다. 감당이 안 될 것 같아 추가 신청 그만 받고.. 지금까지 신청해주신 분 중에서도 죄송하지만 몇 분께만 부탁드려야 할 것 같습니다. 가능한 한 다양한 배경 + 무작위를 조합해볼게요. 제가 도움받는 입장인데, 상황이 이리 되어 양해 부탁드립니다. 책 잘 만들어서 보답할게요~	0	저도 신청합니다~	0	신청합니다	0	Wegra Lee 책나오면 읽어보겟습다 :)	0	왠지 좋은 책일 것 같은데 한국어 차례라도 먼저 보고싶습니다.	0	혹시 기회가된다면 즐겁게 베타리딩 하겠습니다 !	0	출간되고 알려주시면 사볼생각이 있습니다	0	저도 베타 리뷰나 책을 보고싶습니다~	0	신청합니다
0	딥러닝, a.i가 몇년안에 booming 되면 H/W 관점에서는 어떻게 달라질까요? 메모리 시장 관점에서는 어떤식으로 영향을 끼칠지 궁금합니다. 아울러 HPC, accelerator도 어떤식으로 변모 될 지도 궁금합니다.
62	LeCun 교수님의 NIPS 키노트 소개와 슬라이드 입니다.아직 영상은 올라오지 않았지만 슬라이드를 보니 전반부에는 CNN을 이미지 인식등의 많은 연구들을 소개하고, 기계에게 어떻게 *상식*을 가르쳐 주는지에 대해 이야기 하면서 Entity RNN을 소개합니다. 재미있는것들이 많아지고 있습니다."Entity RNN is a new model that maintains an estimate of the state of the world from textual descriptions of events."	0	기계나 사람이나 상식이 필요한건 마찬가지네요
33	https://research.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html?m=1Embedding을 통해 보여주고 분석하는 일은 이제 이 분야에서 아주 흔한 일이 되었지만 저같은 초심자입장에서 더 편한 툴이 있었으면 하는 것은 사실이였습니다. 구글이 또 편하고 다양한 환경을 지원하는 툴을 오픈소스로 공개했습니다. 비록 PCA tSNE과 제한적인 사용자 projection을 지원하지만 좋은 UI를 제공하는 툴이라 생각되네요. 텐서플로우를 서야할 이유가 하나 더 는거 같습니다. 관련논문: https://arxiv.org/pdf/1611.05469v1.pdf
2	3차원 모션 인식 이미지 데이터를 학습시키려고 하는데, 이미지 각각의 크기가 다른 경우에는 보통 어떻게 처리하나요?	0	개인적생각이지만 사이즈를 통일화 하는건어떨까요?깨지는부분도있지만 전체적인 부분은 인식될꺼같은데
6	AI는 보조 역활에서 매니저로, 가상현실은 현실과 구분하기 어려울 것- 에릭슨 컨슈머랩, 2017 ‘핫 소비자 트렌드 10’ 발표
6	구걸글 죄송합니당...커스텀 이미지 직접 불러와서 CNN구현한 소스 구할 수 있을까요?포맷된 데이터로 구현한 소스밖에없네요..ㅠ_ㅠ	2	Python 에서 opencv로 이미지를 읽은 다음 CNN모델에 맞게 전처리 및 리사이즈를 해주고 feed_dict으로 이미지를 모델에 전달해주시면 됩니다	1	Kadenze 깃허브 소스 쳐 보시면 강의랑 커스텀 까지 보유하고 있으니 참고하세욥	0	커스텀 이미지로 트레이닝 시키면 IO 속도 때문에 자체 포맷으로 변환하는게 정신건강에 편하더라고요.	0	사진 보고 한번 가봤습니다. ㅋㅋ
4	[Conv. Net 관련 질문]안녕하세요.현재 Time Series Data를 모델링/예측하는 프로젝트를 진행하고 있는대학원생입니다.한가지 궁금한 질문이 생겼는데, Tensorflow에서 기본적으로 제공하는 Conv2d 등은 Kernal크기가 반드시 정방형(2*2, 3*3, 4*4...) 을 사용해야 하나요~~?Conv Net을 보면 대부분 Convolution Layer의 Input을 정방향으로 사용하는 것만 보아 궁금사항이 올려 업로드합니다!!	5	Time Series라면 아마도 1*n의 kernel을 사용하시기 희망하시는 것 아닌가 싶습니다. 그렇게 사용하는 것은 (제가 해봤는데) 전혀 문제 없고, 정방향이 아닌 n*m 형태도 (제가 안 해 봤지만 ^^) 문제 없습니다. 추가로 그런 상황(정방형이 아닌 상황)에서 input_depth, output_depth (또는 number of filters)도 제가 여러가지로 해 봤는데 문제 없습니다. 다음 수식도 참고가 되실듯 하네요.out_height = ceil(float(in_height) / float(strides[1]))out_width  = ceil(float(in_width) / float(strides[2]))https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#convolution	1	여기 http://cs231n.stanford.edu/slides/winter1516_lecture11.pdf 11페이지에 보시면 3x3 필터를 1x3과 3x1로 나눠서 계산량을 줄이는 시도를 보실 수 있어요.	0	답변감사합니다! 우선 단변량 시계열 데이터로 해보려고 Conv1d을 쓰려했는데, tf.nn.maxpool 의 input 이 4차원으로 되어있어 conv2d로 진행하며 윈도우 사이즈를 조절하는 식으로 진행하고 있습니다!!	0	업로드 링크들도 참조하니 많은 도움이 되네요😀
42	https://aws.amazon.com/rekognition/이번엔 아마존이군요...	0	아예 서비스로 내놔버리는군요 ㅎㅎ 멋지네요	0	크...
1	질문있습니다 리눅스 환경에서 실제로 GPU를 쓰려고하면export CUDA_VISIBLE_DEVICES=0라는 명령어가 필요했습니다.윈도우환경에서는 불필요한것인가요??	1	전에 다른 언어에서 CUDA를 사용할 때도(윈도우였습니다) 저 명령어가 필요했던 걸로 기억합니다.Tensorflow도 마찬가지로 필요하지 않을까 조심스레 추측합니다.	1	윈도우 에서도 복수개의 CUDA 장치중에 선택적 사용을 위하여(http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars) CUDA_VISIBLE_DEVICES 라는 환경 변수가 사용될 수 있는 것 같은데, 윈도우이니 export 라는 명령어로 지정하는 것은 아니고 EXPORT 대신 SET 명령어를 사용하거나(http://stackoverflow.com/questions/18701783/windows-equivalent-of-export) 내 컴퓨터 등록정보-고급 시스템 설정 창에  환경변수 입력창이 있으니 그 곳에 설정하면 될 것 같습니다.
3	neural network 초보자가 질문드립니다. tensorflow로 deeplearning(hidden layer 4~5)을 수행하고 있는데 잘되긴합니다만, 최종적으로 얻어진 ANN의 식(equation?)을 얻어내고 보고를 해야 논문으로 인정해주나요? computational science에는 경험이 일천한지라... 그저 잘된다는 비교결과들과 코드 정도만 공개하면 안될까요? 반드시 그 식이 필요한건지요? 저는 현재 10번정도 반복 실험? 한데이터로 평균을내어 test set에 대한 결과를 유추하고 있습니다만.... 이정도로는 부족할지요?	0	아, 그리고 혹시 최종 식을 어떻게 유추해? 낼수있는지 방법을 아신다면 알려주시거나 정보를 주시면 더할나위 없겠습니다. 감사합니다	1	논문을 보면 주로 테스트셋으로 넣으신 데이터와 실데이터간의 cross validation 결과를 올리지 않나요? 딥러닝으로 나온 결과값에 대한 검증이 핵심일것 같습니다	1	주로 ROC Curve와 AUC값을 제시하시고. 비교하고자 하시는 다른 모델이 있으시다면 커브를 함께 보여주시면서 성능이 더 좋아졌다고 주장하시면 됩니다.Result 에서 sensitivity specificity ppv npv 수치 제시하시면 됩니다.ex) The diagnostic power of the Fuchu-Kids algorithm had a sensitivity of 91.7%, a specificity of 92.3%, a positive predictive value (PPV) of 88%, and a negative predictive value (NPV) of 94.7%.
3	질문 있습니다. CNN 결과 아래 영상에서 예를 들어 사람을 인식했을 때의 좌표값이나 ROI정보를 받아오는 방법이 있나요?	0	대표적인건 faster-rcnn에서쓰는 selective search나 yolo가 있습니다 여러방식이있지만 간단하게말하면 object를 찾는 layer와 classification하는 layer를 쌓아서 트레이닝하는거에요
8	KT경제연구소-KISA, '2017년 ICT 10대 주목 이슈 선정' 특집보고서 발간- AI, 5G, MR(혼합현실), 자율주행차, IoT/IIoT, 생체인증, 핀테크2.0, O2O, 데이터커머스, 플랫폼경제
34	텐서플로우 윈도우 설치관련 입니다. 따로  ppt를 만들려고 했으나 .. 그럴 필요가 없이 너무 간단해서 올립니다.노트북 1대데스크탑 2대에 설치 했습니다.총 3대입니다. 전부다 윈도우 8.1pro 버전을 사용합니다.(gpu   버전입니다. 저같은 경우는 gtx 960을 쓰고 있고, 그래픽 드라이버는 윈도우8.1 처음 설치할때 자동으로 잡아주는 드라이버 사용했습니다. )설치순서입니다.1 . https://www.continuum.io/downloads#windows 에서 아나콘다 3.5  버전을 다운로드 받으세요. - 그냥 쭈욱 설치하시면 됩니다. 64bit!!2. https://developer.nvidia.com/ 에서  cuda를 받으세요. cudnn도 윈도우 7이나 윈도우10 버전을 받으세요.cuda - 8.0cudnn 5.0  - 회원가입하시면 됩니다.으로 홈페이지에서 추천하는 버전들로 받았습니다.3. 이제 3개다 설치합니다.  cudnn  은 압축을 풀면 3개의 bin,lib, include 가 나오는데,  이걸 cuda설치 경로에 가서 같은 이름을 가진 폴더에 각각 넣어주세요.4.  anaconda 명령창을 관리자모드로 열어서 이렇게 한줄 칩니다.pip install tensorflow-gpu  끝입니다. -  이 명령어만 치면 알아서 whl파일 받아서 설치해줍니다.  (제가 기존에 윈도우에서는 winpython+theano를 사용했었는데, winpython에서는 안되네요.)  -------------------------------------------------------------------------------------------------------------------------------------------winpython 됩니다. winpython-64bit 3.5.2 3qt5 버전을 받고 설치한후winpython 커맨창을 관리자 모드로 연후 설치하면 아나콘다와 같이 되네요 ㅎㅎ제가  winpython을 사용하려는 이유는 portable 이기 때문입니다.!!!5.추가(pip 업그레이드 하라고 나올건데. python -m pip upgrade ~~~ (커맨드 창에 나옵니다.)) 그대로 하셔도 되고 안하셔도 됩니다. 파이프 버전이 업데이트 되서 하라는 건데. 뭐 하시는게 좋겠죠.---------------------------------------------------------------------------------------6. 실행화면 입니다잘 설치됬나 확인하는 방법입니다. 저는 import tensorflow as tftf.Session() 이렇게 두줄 만 적습니다. 아래와 같이 나오면 성공입니다.----------------추가--------------------------------------winpython 문제 해결했습니다.버전이 업데이트 되면서 qt관련된것이 사라졌는데winpython 3.5.1.2 버전을 다운받게 되면 qt관련 파일들이 있기 떄문에qt 관련 오류가 안뜨네요. ㅎㅎ anaconda도 qt관련 오류가 뜨는데. 전윈파이썬을 써야겠어요 . ㅎㅎ-----------winpython 안에 qt파일 이 있는것들을 받으시길 바랍니다.전 개인적으로  anaconda 보단 winpython 추천 드립니다.전!!!윈도우에선 winpython - 이클립스 리눅스에선 anaconda -  이클립스 사용하겠습니다. 이상입니다.------------진짜 마지막입니다.---아나콘다 완전 지우고 재설치 하고 재부팅 하고 하니깐밑에 오류 없습니다... 무슨 ???? 컴퓨터의 세계는 알면 알수록 신기하네요.. 수고하세요... ---------------------- 한글경로 문제였습니다.. 무조건 영어 경로로하세요......	0	cudnn은 nvidia에 가입이 되어있어야 되구요,  anaconda에 내장되어있는 spyder를 사용하려면 아래와 같은 오류가 뜨네요. 저는 파이참을 사용중이라서 상관이 없으나.  혹시 다른분들도 이런 오류가 발생하는지??	0		0	추가.  제가 주로 윈도우에서는 이클립스- 자바 를 사용하기 때문에 이클립스에서도 잘 되는지 확인했습니다.	0	pip install tensorflow-gpu 하면 저는 아래처럼 에러뜨는데 이건 왜 그런거죠?Collecting tensorflow-gpu  Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )No matching distribution found for tensorflow-gpu	0	아나콘다에서하시는건가요?	0	제가 초보라서 그러는데, 아나콘다와 winpython의 관계가 어떻게 되는 것인가요? 둘 중 하나만 까는 것인지, 둘다 깔아야 되는 것인지요? 전 jupyter notebook을 사용하고 싶습니다. 이 환경에서도 되는 것인지요?	0	아나콘다를 3.5 버젼으로 설치하라는 말씀은 파이썬3.5버젼이 설치되어있어야한다는 말인가요? 2.7버젼을 사용 중이고 아나콘다도 2.7버젼으로 사용하면 안되나요??	0	질문있습니다. 저도 윈도우 10에서 환경 구축하려는데, 너무 간단하다는 말이 이해가 안가서요... 그냥 아나콘다건, 쿠다건 모두 다 셋업파일 받아서 바로바로 설치만 하면 되는건가요?? 아니면 리눅스 처럼 cmd창에서 명령어로 설치해야하나요??	0	감사합니다 gtx1070두개짜리 데스크탑에 설치완료했습니다. 이제 불현듯 나타나는 우분투 무한로그인과 작별할시간이 다가오는거 같아 기쁘기가 서울역에 그지없습니다.
3	써모케어 AI, 인공지능으로 영유아 발열 관리 한다.- 엠트리케어는 현재 유럽 CE 인증 및 미국 FDA 인증을 추진하고 있다.
46	저는 국립암센터 병리과에서 근무하는 병리의사입니다.  우리나라에서 의료영상중 현미경 영상을 이용한 병리 진단에 관련된 머신러닝에 대해 연구하시거나 관심 있으신분 있으신가요? 같이 연구할수 있으면 좋을것 같아서요.	0	쪽지 확인부탁드립니다	0	이석훈 (Sukhoon Lee)	0	메시지 확인 부탁드립니다	0	일반인도 접근가능한 충분한 데이터가 있는곳이 있을까요 ㅠㅠ	1	영상처리로 현미경 Auto Focusing(완료), 딥러닝으로 혈구 분류하려합니다.	0	최지윤	0	멋진 아이디어이네요! 기대합니다	4	안녕하세요. 2012년부터 KAIST 물리학과 의광학연구실에서 label-free holographic microscopy와 머신러닝을 결합하여 질병 원인균 식별, 혈구 분류 등 다양한 연구를 수행하고 있습니다. 전반적인 내용은 http://www.osa.org/en-us/about_osa/newsroom/news_releases/2015/new_microscope_technique/ 의 미국광학회 뉴스와 논문 링크를 참고하시면 될 것 같습니다. 위 연구 이후 deep learning을 도입하여 기술의 정확도를 향상시켰고, 여러 외부기관과의 공동연구를 통해 다양한 대상으로 연구를 확장하고 있습니다. Label-free tissue imaging을 이용한 AI-assisted pathology 등에도 관심이 있습니다. 혹시 research interest가 맞으신다면, 교수님께 연락해주시면 감사하겠습니다 (연구실 홈페이지: bmol.kaist.ac.kr).	0	관심이 있습니다. 저는 코호트 DB를 이용한 질병예측을 해본적이 있습니다.	0	안녕하세요? 컴공과 학생입니다. genomic data에 관심 있어서 분석을 틈틈히 해보려고 합니다. file format이 여러개 있는데 어떤 걸 받아야 하는지요? (다는 받기 어려울 것 같습니다.) TFT, VCF , BAM
0	tensorflow kr에게 질문합니다.제가  이미지에서  객체를 인식하고(특히 자동차)  아래? 있는 글처럼 박스를 치려고 하는데..RCNN등등저도 찾아보고 있는데..구글에 수많은 정보가 있지만, 퀄리티 있는 좋은!! 관련논문 있으면 추천해주시면 감사하겠습니다.
10	-----------텐서플로우 윈도우 버전을 살펴보다가 알게된점 공유합니다.당황하시는 분들이 있을것같아서. mnist가 안돌아가니..--틀린거 있으면 말씀해주세요!!!! 윈도우 Tensorflow 버전에서는 mnist로 예제를 돌려볼때from tensorflow.examples.tutorials.mnist import input_data 가 안되네요examples가 내장이 안된듯 하네요.아직 텐서플로우 코드베이스에 통합이 안된듯 하네요.. 추후 버전에서 지원해줄것 같습니다.---------------------------------해결책은 기존 처럼 input_data.py 라는 파일을  신경망 코드와 같은 위치에 놓고http://yann.lecun.com/exdb/mnist/ 가셔서 4개의 gz 파일을 다 받아서 지정한 디렉토리에 넣어놓으셔야 동작 되는것 같습니다.- 타고타고 쭈욱 읽어봤는데. 왜 안되는지는 정확히 모르겠는데.tensorflow.examples 가 없는건 맞고maybe_download라는 함수가 있긴한데 여기서 딱 되야할것 같은데.쨌든 직접 넣으셔야 합니다.	0	저는 잘됐었던걸로 기억합니다	0	지난주 수요일 윈도우즈에서 텐서플로우 깔고 실험했을때는 잘 되던데요..	0	원본 깃헙 소스에서 복사해서 넣으시면 됩니다. examples, models 둘 다 그렇더군요. 저도	0	아직 RC0 버전이니 정버전 나올때까지 조금 기다리시면^^;;;
15	텐서플로우 생초보인데 Hello Tensorflow 출력해보려고 했습니다.근데 제대로 나오긴하는데 저 'hello tensorflow' 전에 b는 왜출력되는걸까요	0	http://stackoverflow.com/questions/6269765/what-does-the-b-character-do-in-front-of-a-string-literal 참고하셔용~!	1	http://pythonkim.tistory.com/8 여기가 설명이 보다 더 잘 되어 있네요	0	질문있습니다. pycharm 환경은 어떻게 만드셨나요??
9	안녕하세요. 미국 비자 전문업체인 (주)하우파트너즈에서는 안내문과 같이 12월 한정 NIW 고학력 독립이민  이벤트를 진행합니다. 딥러닝이나 인공지능을 전공하신 고학력자는 매우 유리합니다.저에게 이력서를 미리 이메일로 (howpartners@gmail.com)  보내주시면, "예비" 판단하여 드립니다. 궁금하신 점이 있으시면, 메시지나 전화로 언제든지 연락주세요 (010-3201-8593). 감사합니다. 정일형 미국변호사 드림 홈페이지: www.howpartners.com	1	Kyu Ye Rachel Song	0	페북 홈페이지 (https://www.facebook.com/HOWPartners) 입니다. 공유 & 좋아요도 많이 눌러주세요.^^ 감사합니다.	0	안녕하세요. NIW 비자 신청 관련 설문서를 첨부합니다. 관심있으신 분은 작성하여 보내주세요. 감사합니다. https://goo.gl/forms/JfJVlz1r779EG10K2
3	총4대의 데스크탑+노트북에 window tensorflow 를 설치했습니다. 노트북-gpu  gt630m 에는 아무이상이없이 잘 설치가됬고한대는amd cpu라서 cpu버전 - i7 4790k를쓰는데회귀코드는 gpu속도못지않게돌아가네요문제는 gtx960 인데 numa node? 이게맞는지모르겠는데  support 어쩌고문제가뜨네요 스택overflow를 찾아보면 여러개의 gpu를 사용할시.. 필요한어쩌고저쩌고라고하는것같은데무시해도된다는의견도있구‥근데문제는 cpu보다 느리다는겁니다 회귀코드가‥이게 그럴수도있는건가요?병렬처리에대해서는 몰라서‥‥------------------------------------------------------------------------------------------------------이게 해결인지 모르겠으나.회귀코드에서는 cpu가 더 빠른 성능을 보이나MNIST_ CNN, 이미지 관련 코드에서는 역시 GPU가 압도적으로 빠르네요.텐서플로 내부적으로 어떻게 처리하는지는 잘은 모르겠지만,궁금한점이 많기도 하고, 이런거를 좀 알아야.. 될것 같아서.제가 앞으로 해야할 주제가 이미지랑 연관이 되어있어 실험해봤습니다.ㅎㅎ 그리고 MNIST CNN을 LOW CODING으로 코딩을 해봤었는데(당연히 CPU만 사용했고, 직접 매트릭스로 BACKPROPAGATION, DROPOUT, DATA 확장 등등 구현), 텐서플로우 CPU가 압도적으로 빠르네요. 내부적으로 무슨 짓을 한것 같네요.  역시 전문가가 작성한 코드는 뭔가 다른가 봅니당.제가 작성했던 코드로는 MNIST_CNN ..이...98퍼 되는데에 3일동안 켜놨었는데..텐서플로우는 CPU만으로도 98퍼에 수렴하는데 몇분조차 안걸리네요..프레임 워크 씁시다. ㅎㅎ	0	정상적으로설치되어있는 리눅스에서는 numa node문제가 없음에도 cpu만썼을때보다 약간은 느린감이있네용	0	원래 GPU가 빠른 연산이 있고 CPU가 빠른 연산이 있습니다. 기본적으로 모델이 작을수록 CPU가 유리해요.
8	혹시 아래 그림과 같이 이미지의 Convolution - Deconvolution 모델 예제 코드를 구할 수 있을까요??	1	https://github.com/ronghanghu/text_objseg
33	Python 생초보들을 위한 파이썬 환경 소개. 1. python은 언어의 이름입니다. python 2와 python3가 현재 python이라는 이름을 가진 두가지 매우 유사한 언어 정의입니다. 2. 두 언어 정의 모두에 여러 종류의 인터프리터가 존재합니다. 표준인터프리터가 CPython입니다. CPython은 이름과 같이 C로 구현되었습니다. Python 재단에서 직접 관리합니다. 이 외에도 java virtual machine위에서 돌아가는 jython, Mono위에서 돌아가는 ironpython, 최적화 기술들을 이용하여 python으로 만든 인터프리터인 pypy등이 존재합니다. 기본적으로 인터프리터가 바뀌더라도 언어 정의상 바뀌는 부분이 없기 때문에 코드는 상호간에 재사용할 수 있어야 합니다. 그러나 패키지는 인터프리터에 따라서 구현되어 있을 수도 있고 그렇지 않을 수도 있습니다.  CPython을 위해서 구현된 패키지가 다른 인터프리터에서 돌아간다는 보장은 없습니다. 대부분의 경우 CPython을 중심으로 패키지가 구현되고, 다른 인터프리터에 구현되거나 되지 않거나 합니다. 3. 디스트리뷰션은 파이썬 인터프리터를 여러 종류의 중요한,연관된 패키지, 그리고 중요한, 연관된 툴들과 묶어서 배포하는 것입니다.  중요한 디스트리뷰션들로는 Anaconda, Canopy, Python(x,y), winpython등이 있습니다. 패키지를 묶어서 배포하기 때문에  일일이 의존성을 맞춰서 설치하는 수고를 줄일 수 있습니다.  디스트리뷰션에 따라서 서로 다른 도구들을 가지고 있고, 환경의 파라미터들도 서로 조금씩 다를 수 있습니다. 대부분의 디스트리뷰션은 CPython을 인터프리터로 사용하지요. 4. pip는 패키지를 설치, 업데이트, 제거하기 위한 도구입니다. PyPI python package index라는 DB를 이용하여 패키지간의 의존성 문제를 해소하며 패키지를 설치해 줍니다. https://pypi.python.org/pypi/tensorflow/0.12.0rc0윈도우 버젼의 텐서플로우가 pip에 등록되었기 때문에 pip로 설치할 수 있게 된 겁니다. ..제가 잘못 알고 있던 부분은 고수분들이 수정해 주실 겁니다.	0	중간에 있는 pypi는 pypy겠죠? :>
2	제가 windows 환경에서 tensorflow를 사용하고 있는데요, tensorboard를 실행시켜도 아무것도 없는 빈 화면이 뜹니다...혹시 해결 방법이나 원인 아시는 분 있나요??아직 매우 초보자여서 많은 도움 바랍니다...<정보>windows 10tensorflow 0.12, gpu-basedGTX-950CUDA 8.0, Cudnn 5.0PyCharm 사용 중	1	Tensorboard 포함된 버전은 릴리즈 될 예정입니다. 현 rc0에는 빠져있습니다.
2	TPU (Tensorflow Processing Unit) 관련 무식한 질문 입니다.1. 기업, 개인이 현재 구매 가능한가요? 가능하다면 가격은, 구매 루트는?2. 딥러닝 시장에 대한 needs가 늘어나 accelerator를 사용할 시, 서버의 장착하는 메모리 탑재량도 늘어날까요?3. TPU 의 spec 도 궁금합니다. 이놈이 붙으면 기존 서버 보드 구성품과 중복 되는게 머가 있을지? 4. TPU 사용시 최소사양 메모리가 있나요(TPU내부 메모리 말구요)4. 이걸쓰면 딥렁닝 연산의 머가 좋아지는지는 알겠는데, 어떻게해서 좋아지는지가 잘 모르겠습니다.	1	GPU 보다 더 딥러닝에 최적화된 하드웨어입니다. 구입을 할 수는 없고 구글 클라우드에서 빌려서 사용할 수는 있습니다. 하드웨어 구입해서 쓰시려면 GPU를 알아보세요. 타이탄X나 K80같은걸 알아보시는게 좋을것 같습니다.	0	4. 딥러닝 연산의 뭐가 좋아지시는지자세히 아시면 공유좀 부탁드립니다^^제가알기로는 Float32로 된 tensor를  INT8로 quantize 시키고, 이를  GPU대비해서 더 넓은 메모리 대역폭을 가지고 연산할수 있는 ASIC 칩셋이 들어있는것으로 압니다	6	제가 아는것도 비슷합니다.  GPU에는 주로 64비트, 32비트 부동소숫점 연산자가 많은데요, TPU에는 거기에 할당된 트랜지스터들을 16비트, 8비트 연산자에 할당했을겁니다.  그러면 지금 최신 GPU보다 이론상 4배~8배 이상 가속이 가능하거든요.  구글 블로그에서 언급한 "기존 방식보다 7년은 앞서는 컴퓨팅 속도를 달성했다" 랑도 맞는 수치이고요.  한마디로 남들 일주일 돌려서 학습시키는 모델을 하루 안걸리고 학습되는거죠.
3	안녕하세요~질문좀 드리겠습니다~아래 결과 영상은하나의 이미지를 넣고 그 안에 객체들을 인식하는건데..CNN은 트레이닝/테스팅 데이터의 이미지크기가 같아야 되는거아닌가요?전체 배경에서 사람객체를 찾아서 인식할 때 전체이미지에 비해 사람이미지는 크기는 그에 반해 아주 작은데...어떻게 처리한걸까요??	0	Faster rcnn paper 보시면 설명 잘되어 있습니다. selective search등 여러방법이 있습니다.	1	selective search 하고 CNN에서 사용한 이미지 크기로 wrap 한 다음 입력하는거 아닌가요??	1	윗분들 말씀대로, 영상 혹은 feature map에서 영상신호처리 방법등을 써서 물체가 있을법한 위치(ROI)를 만들고 분류한다는 개념으로 보시면 됩니다 ㅎOverfeat / r cnn / fast rcnn / faster rcnn  순으로 논문 봐보시면 되요 ㅎ	1	네모와 네모 클래스를 학습하는것입니다.	0	네모 영역(region) 하나하나를 classification 한다고 보시면 돼요
20	안녕하세요, 열혈눈팅회원입니다. 가끔 딥러닝이나 텐서플로우 스터디 관련 공지글을 올렸었는데요, 이번에 그 스터디들이 다 모이는 연말모임에서 특강들이 몇개 있는데, 마침 이 그룹에 어울릴만한 자료가 있어서 공유합니다. 이번에는 구글의 딥러닝기반 기계번역 시스템에 대한 것입니다.이 글은 목적이 자료공유입니다(꼭 스터디뽀개기 모임에 참여하지 않으셔도 됩니다)공유된 글 링크들을 참조하시면 다른 자료들도 다운로드 가능합니다	1	어제 강의 정말 잘 들었습니다! :) 내공이 팍팍 느껴지더군요!
4	얼마 전 회사에서 구글 페북등 많은기업들이 딥러닝 관련한 API를 오픈소스화하여 인프라 확충에 열을 올리고 있는 이유는 많은 developer들이 시중의 나와있는 알고리즘들을 소스로 구현해내고, 공개된 오픈소스를  추가 보완해 나가면 기업 입장에서는 API의 정확도 및 functionality가  좋아집니다 라고 얘기했는데 맞는 얘기인지요. 추가 설명두 부탁합니다.	3	구글 페북 등이 서비스에서 돈을 버는 회사라서 주도권을 쥐기 위해 가능한 것입니다. 소프트웨어를 판매하는 MS가 MS 오피스 프로그램을 오픈소스화하여 품질을 올릴 생각은 절대로 일어날 일이 없죠.	0	Forbes에 답이 될만한 글이 있더군요."Here's Why Google Is Open-Sourcing Some Of Its Most Important Technology" http://bit.ly/2h0A0kO
111	이미 많은 분이 올려주셨는데 AI, 머신러닝, 딥러닝 등의 개념을 쉽게 설명해서 많은 학생을 이 분야로 초대하는 것 같습니다.한글로 더빙되면 좋을 것 같은데 우리 그룹 더빙의 대가이신 김홍배님 곧 만들어주실듯합니다. 생각해보니 목소리도 LeCun과 비슷하신듯 합니다. :-) 이 분야가 쉽지는 않지만 재미있는 분야 인 것은 확실합니다. 많은 학생분들이 뛰어들면 좋을 것 같습니다.  	0	좋은 정보 감사합니다 :)	0	유투브에서도 강의 잘보고있습니다!	0	좋은 자료 감사합니다. 맛있게 먹고 소화시켜 제 피와 살로 만들겠습니다.
73	TensorFlow v0.12.0 RC0 에서 윈도우 지원이 추가되어,윈도우10에서 Tensorflow-0.12.0 GPU 버전을 설치하는 방법을 공유합니다. (Anaconda 환경)(윈도우 10 1주년 업데이트 버전, GTX1080, CUDA 8.0, CUDNN 5.1, python 3.5.2)0. 그래픽카드 드라이버 설치(369.30 사용중)1. Anaconda 4.2.0 for windows 64-bit 설치2. CUDA 8.0.44 - win10 다운로드3. CuDNN 5.1 - cuda 8.0, win10용 다운로드4. 아나콘다 설치 (기본값으로 설치함)5. CUDA 설치 (기본값으로 설치함)6. CuDNN 압축 해제 후, CUDA 설치 경로에 각각 붙여넣기CUDA 설치 경로 : C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.07. Anaconda 활성화 및 텐서플로우 GPU 버전 설치(관리자 모드로 cmd실행)8. 파이썬 실행 후 테스트----.리눅스에서 설치하는것보다 훨씬 쉬운 것 같습니다. CUDA 설치시 환경변수에 자동으로 쿠다 경로가 추가되므로, 6에서 CuDNN 파일을 붙여넣기만 해주면 됩니다.	0	7은 없나여	0	드디어 윈도우10에서 ㅎㅎ	0	무조건 아나콘다인가요...	0	텐서플로우 GPU 버전 설치는 어떻게 해야하나요...?	0	우어......ㄷㄷ	0	제가 초보라서 잘 모르는게 많습니다.궁금한게 있어서 질문드리겠습니다.저 7번의 아나콘다 활성화란 말은 어떤 작업인가요?그리고 갑자기 cmd에서 conda(pip도)가 작동을 안하는데 관리자모드 cmd모드란게 따로 있나요? 엊그제까지는 그냥 cmd에서도 실행이 되었었는데 말이죠...따로 아나콘다 프롬프트를 실행시키면 콘다랑 pip가 실행은 됩니다.	0	윈8.1 작동 확인했습니다.	0	오 드디어!!! 감사합니다 ㅎㅎ	0	0, 1번 시행할때 디렉토리 위치는 임의로 정해도 되나요??
113	텐서플로우가 윈도우를 지원하게되면서 별다른 메뉴얼을 찾아보기 힘들더라구요 제가 윈도우 개발환경 구축하면서 만들어본 메뉴얼을 공유합니다.	1	감사합니다!	1	감사합니다! 깔끔하네요 :)	1	감사합니다!	1	요런걸 기다렸습니다! 감사합니다	1	감사합니다!! 그런데 환경변수 설정할때 Path에 한글 경로가 들어가있으면 안되는 것인가요??	1	회사에서 Deep learning & tensorflow 관련 해서 교육해야 되는데 대부분의 청중의 노트북은 윈도우라 실습환경 구축에서 고민 많이 하고 있는데 답을 주시네요. 감사합니다.	1	감사합니다 cmd에서는 아주 잘됩니다. pycharm 에서 사용하려면 어떻게 할 수 있을까요?
6	Google Neural Machine Translation & Google Book Scan Project
1	End-To-End Memory Networks 를 구현해보려고하는데요context:  Sam walks into the kitchen.  Sam picks up an apple.   Sam walks into the bedroom.  Sam drops the apple.Q :  Where is the apple?A : Bedroom이런 결과를 이끌어 내기 위해서 파이썬 어디에 내용을 입력하고 질문을 입력해야하는 것인지 모르겠습니다..내용과 질문을 코딩에 넣고 학습을 하는게 맞는거죠? 어디에 Context와 Question을 넣어야하는지 알려주시면 감사하겠습니다ㅠ+ 학습할때 epoch가 37~39까지하고 멈추던데 이상없는것이죠?	0	https://github.com/carpedm20/MemN2N-tensorflow여기가 논문링크입니다.
6	윈도우 8.1pro버전에서gpu버전 되네요 ㅎ	0	첫번째 데스크탑에서 막 해보다가 된거라서.. 우선 간략하게  아나콘다3.5버전을 설치하시구, 다음으로 cuda 8.0 윈8버전을 다운받아서 설치하시구, cudnn은 윈10 버전 받아서 넣었습니다.  그리고 아나콘다 cmd창관리자 모드로 여셔서 pip install tensorflow-gpu  치시면 너무 쉽게 설치가 ...되네용	0	pip install https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl 제 데스크탑에 이 명령어로는 tensorflow가 설치는 되는데 아나콘다에서 못읽어서 삭제한후 tensorflow -gpu로 설치했더니 되네요 cudnn도 윈도우10 꺼 잘 인식하네요. 리눅스에서와  같은 화면이 나옵니다.	0	아 그래픽 드라이버는 376.09 를 쓰고 gtx 960 을 쓰고있습니다.	0	8.1인데 10버전호환이되나보네요ㅎㅎ960 GPU테스트속도괜찮은가요?고생하셨습니다ㅎㅎ	0	cudnn은 윈7버전도 되더라구용..ㅋㅋ	0	파이썬3.5가 윈도우 7 64비트지원해주는걸로알아서 cudnn이 윈7을지원하면 구동이가능할거같네요ㅎㅎ!?문제는 gpu를구해야겠네요	0	대학원생이기때문에 제가진행 하고있는 데이터 의 10메가가넘지않다보니 960도 전 괜찮아요ㅎ좀기다리면되니깐ㅎㅎ 그렇게느리지도않구요ㅎ	1	Cuda는 8.0  홈페이지에서 cudnn은5.0 을 권장해서  5.0으로 설치했습니다  리눅스에서보다 설치시간이‥‥체감상 100분의1로준거같아요 너무간편하네요그래픽드라이버문제도생각할필요없구 편합니다	0	정말 리눅스보다 훨씬 쉽습니다.... 리눅스에서 설치했던 고생 생각하면......	0	혹시라도 모르시는분들을위해서 윈도우8.1 에서 gpu버전 설치하는방법을 시간이되면  파워포인트로공유하겠습니다	0	윈도우 7에서도 동작하는 거 확인했습니다. ^^
5	안녕하세요. 가입하고 첫글이 질문이라서 죄송합니다.windows 10에 windows 용 tensorflow를 설치 했습니다.anaconda를 이용해서 설치 했으며, GPU 버전을 설치했습니다.테스트로 아래 코드를 실행 했을때 아래와 같이 cuda library를 호출 합니다.다른 분들께서 설치 하신거 보니깐 cuda library를 저런 식으로 호출하는 것을 본적이 없습니다.시스템 환경은OS : Windows 10GPU : Nvidia NVS 4200MCuda : 8.0Python: 3.5.2IDE: Pycharm community입니다.혹시 저와 같은 문제 겪으신분 있으신가요???아니면 저렇게 나오는 것이 정상인가요???참고로 windows cmd에서 실행해도 동일하게 나옵니다.감사합니다.	0	저는 우분투에서도, 윈도우에서도 GPU버전에서는 항상 호출하던데요...	0	정상입니다 리눅스에서도같습니다	0	ㅠㅠ윈도우에서구동되는걸보니 반갑네요	0	저건 그래픽카드의 computational capacity가 최소 권장 사양보다 낮기 때문에, 나오는 경고 메시지입니다. 저도 같은 경우를 겪었는데, 저의 경우, 그래픽 카드의 capa는 3.0인데, cuda 8.0의 최소 사양은 3.5더라고요. 이 경우, gpu를 무시하고, cpu로만 작동하더군요.	0	Nvidia에 물어봤더니, 텐서플로우를 binary 설치했기 때문이라고 합니다. 소스 코드를 받아서 빌드하면 빌드 과정에 computational capacity를 설정하는 과정을 거치는데, 이 때 자신의 그래픽 카드 capa에 맞는 사양으로 설정해 주면 된다더군요.	0	저도 아직 해 보진 못 해서 실제 잘 작동되는지는 아직 확실치는 않습니다.
3	안녕하세요. jupyter notebook으로 tensorflow tutorial 따라하고 있는데, word2vec 쪽에 질문이 있습니다.소스:https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/examples/tutorials/word2vec/word2vec_basic.py환경은 0.11 버전이고 docker입니다.노트북에서 visualize하기 위해서는 뭔가 별도로 설정이 필요한가요?	1	%pylab inline 같은걸로 plot같은거 띄울수 있지만.. 실질적으로 개발하시면서 tensorboard를 더 많이 이용하실겁니다...
84	최근에 연구실에서 GPU 달린 PC 하나와 도커를 세팅하면서 가이드를 만들었으니 참고하실 분들 참고하세요~ 여기서 얻은 정보를 많이 참고했습니다. 도커 부분은 Seung Gyu Chang (aka 장도커)가 큰 도움을 줬습니다. 하드웨어: http://enginius.tistory.com/653도커: http://enginius.tistory.com/654도커를 사용할 경우 가장 큰 장점은 혹시나 apt-get 등으로 설치하다가 뻑나도 복구가 용이하다는 것과 nvidia-docker를 쓰게되면서 CUDA8.0만 설치하고, cudnn은 설치할 필요가 없어진다는 점이죠. nvidia developer 계정이 없어도 됩니다.	0	docker로 설치하면 GPU 메모리 사용하고 하는데는 문제가 없나요? 전에 nvidia-docker만 써봐서 test를 안해봤는데...그냥 메모리도 문제 없으니 상관없겠죠? ㅎㅎ	0	저도 nvidia docker를 씁니당	0	세팅을 하는데 정말 힘들었는데 메뉴얼 참고해서 다시 시도를	0	Cpu gpu에비해서 저럼한것 사용하셨군요ㅎ
7	https://www.youtube.com/watch?v=ls8jHqRnEQk이 영상처럼 원래 단일 layer에서 여러 layer로 코드를 바꿔주면서 ReLu를 사용했는데 Cost가 전혀 줄어들 생각을 안하네요...어디가 잘못된걸까요.... 제 코드는 https://github.com/jcwleo/MachineLearning_win/blob/master/tflow/10-NeuarlNetwork_Relu/mnist_DeepNN.py 입니다	1	자답입니다..... 가장 기본적인 개념을 까먹고 있었네요. 여러 레이어를 사용할때는 절대로 weight값의 초기값을 0으로 두면 안됐는데 초기값을 zero로 넣고 해버렸네요. 랜덤한 값을 넣어주고 돌리니 제대로 학습이 됩니다.
57	http://www.cirrascale.com/blog/index.php/exploring-the-pcie-bus-routes/가끔 멀티 gpu시스템을 구성하시려는 분들의 글이 올라오는데잘못된 PC셋팅으로 시간과 돈을 날리시는 분들이 계셔 관련내용을 올려봅니다첨부링크는 pciE버스의 구조와 데이터 흐름에 관한 좋은 내용인데귀찮거나 결론만 알고 싶은 준들을 위해 요약해 드리면...1. GPU는 무조건 최신 좋은것으로.. 멍청한 놈 여럿보다 똘똘한놈 하나가    밥도 덜먹고 좋습니다. 엔비디아로 사시는것은 센스...    12GB 이상 단일모델을 돌리려면 TESLA  k80 24GB가 필요하실지도...2. 여러놈을 붙이려면 동일칩셋 끼리 묶어야 데이터 송수신경로가 최단화됩니다     지금 붙어있는 구형카드는 중고나라에 파시고 1080이나 타이탄 한종류로 미세요.....3. 여러개를 붙일때 제일 좋은것은 NV-link로 테슬라 P100을 묶어놓은 DGX-1같은 완제품임다    (Supermicro나 Tyan에서 베어본도 나오기는 함)    하지만 저런걸  사실분은 제글을 볼 필요가 없을것이고요 실질적으로 봤을때      권장사양은 아래와 같습니다    CPU: 인텔 Xeon E5 혹은 i7 익스트림(HEDT제품군) - CPU 지원 pciE lane 40개인것    MB. : 2011v3소켓 지원되는 c612 혹은 x99보드 - pciE switch 칩셋 붙은놈으로    SSD: NVME 타입 ssd(m.2소켓 아니면 pciE 3.0 x4)    중요한것은 GPU 4개 까지는 데이터 이동경로나 트래픽으로 볼때 싱글 CPU로도 충분하니 CPU파워가 많이 필요하면 듀얼가지 마시고싱글 중에 코어 많은놈으로 하세요....물론 GPU 5개 가려면 듀얼cpu써야 합니다(xeon e5-26xx)4. GPU 8개 이상을 엮으려면 코코링크의 칩셋을 쓴 서버를 쓰시던가     Mellanox Connect-X3 이상 인피니밴드 FDR급 라인으로 으로 노드를 엮어야 합니디만(GPUdirect RDMA)    딥러닝 프레임워크에서 지원하기도 어렵고 가격이 어마무시하니 이런것이 있다는 정도만.....	0	개인적으로는 개인 수준에서 하는것이라면 지금은 1070정도로 간보시다가 1080ti 출시 기다리시거나, 아니면 시원하게 파스칼 타이탄X 두장꼽고 끝내시는것이 좋지 않을까 합니다	1	안녕하세요. pciE버스를 잘 몰라서 게시글을 읽게되었습니다. 작성자분께서 "GPU 4개까지는 싱글 CPU가 유리하다"고 적어주셨는데, 이 말을 'GPU 4개보다 CPU가 더 빠르다'로 해석해도 되는건지요?	0	PCIE 레인이 충분하다고 가정하면 멀티GPU를 구성할 때 산술적인 GFLOPS값을 기준으로 성능을 가늠할 수 있을까요?	1	방금 회원분 한분이(죄송합니다만 성함을 기억하지 못했습니다) 지적을 주셨는데, Tesla 제품군이 아닌 일반 지포스 탑재 GPU는 GPU direct RDMA가 지원되지 않아 인피니밴드를 통한 클러스터 구성이 불가능한것이 맞습니다. 다만, 동일 컴퓨터에 설치된 카드간에 직접 메모리카피(GPU direct P2P)는 가능한것이 맞는것 같고요, 2개 이상의 카드간의 메모리 카피가 가능한지는 의견이 좀 갈리는것 같습니다. 두번째로 테슬라는 DMA엔진이 두개가 데이터가 양방향으로 흐를수 있습니다만, 일반 지포스는  입력/출력이 동시에 불가능합니다. 다만 파스칼 타이탄은 테슬라와 같이 양방향 동시입출력이 가능하다고 합니다. https://www.microway.com/knowledge-center-articles/comparison-of-nvidia-geforce-gpus-and-nvidia-tesla-gpus/	1	좀 찾아본 결과 GPUdirect에서 Peer to Peer  효과를 제대로 보려면 모든 카드들은 동일한 Pcie root complex - 쉽게 말해 같은 CPU 아래에에 있는 같은 PLX 스위치 아래 있어야 한다고 합니다. GPU 서버용으로 PCIE single root complex 구조를 강조하는 보드들이 있는데...여유가 허락하시면 이런 보드를 구매하시는것이 좋을것 같습니다.
75	[TensorFlow 구현]안녕하세요. 매번 좋은 정보들을 얻으면서 도움만 받다가 이번에 처음으로 글 올립니다.저는 고려대학교에서 Jaegul Choo교수님과 함께 딥러닝 연구를 하고 있는 학생입니다.이번에 "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" (https://arxiv.org/abs/1502.03044)을 TensorFlow로 구현하여 공유합니다. 본 논문은 attention mechanism을 image captioning task에 적용시킨 논문입니다. 기존에 김택수님이 구현해 놓은 것을 참고하여 좀 더 업그레이드해봤습니다. 코드를 돌려 볼수 있게 정리해 놓은 깃허브 링크 첨부합니다.(https://github.com/yunjey/show-attend-and-tell-tensorflow)	2	우와 감사합니다~!
20	인공지능 동영상으로 쉽게 배워 본다!- 페이스북 인공지능 연구 총괄 얀 레쿤이 들려주는 인공지능 이야기
9	머신러닝에서, Ensemble 이라는 방법이, 동일한 모델을 각각 학습 시킨후, 예측시, 각 모델로 예측을 한 결과를 평균등을 통해서 값을 구하는 방법으로 알고 있는데요.(전문가 한명보다, 일반인 여러명의 판단이 더 정확하다는 원리.)근데, 이때, 각 모델을 학습시킬때 같은 데이타 가지고 하나요? 다른 데이타 가지고 하나요? 학습 데이타를 어떻게 넣는지가 궁금합니다.	0	저는 k-fold 분할을 주로 씁니다. k=gpu 갯수로 ㅎㅎ	0	Bootstraping 을 사용 할 수 있습니다.	1	Bagging과 Boosting 참고하세요 http://jangjy.tistory.com/166	1	앙상블은 큰 개념의 단어라..동일하지 않은 모델을 여러개 사용하는 경우도 있는걸로 압니다..
1	질문있습니다....처음으로 Neural Network를 실행해보는데    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])    layer_1 = tf.nn.relu(layer_1)    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])    layer_2 = tf.nn.relu(layer_2)    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']weights = {    'h1': tf.Variable(tf.random_normal([3, 3])),    'h2': tf.Variable(tf.random_normal([3, 3])),    'out': tf.Variable(tf.random_normal([3, 1]))}biases = {    'b1': tf.Variable(tf.random_normal([3])),    'b2': tf.Variable(tf.random_normal([3])),    'out': tf.Variable(tf.random_normal([1]))}github에 있는 예시코드 가져다가 쓰고 있는데입력 데이터는 3개입니다.out_layer의 값이 1개가 되도록 하는것이 목표입니다.출력해보니 3개가 나오는데 그 이유를 잘 모르겠습니다.[[0.142674] [0.932842] [0.687921]] 이런식으로 출력 됩니다...	1	행렬 A와 B의 곱은 A의 행 벡터와 B의 열 벡터의 내적입니다 이 연산의 결과 행렬의 모양은 B행렬과 같을 것 입니다  그렇기에 out행렬의 모양인 [3, 1]이 나오게 됩니다 ㅎㅎ	1	출력쪽의 코드를 봐야 정확히 알수 있을거같네요...	0	입력데이터마다 하나의 값이 나온 게 맞지 않나요?
93	이 그룹에 올릴때 가장 긴장됩니다. CNN에 대한 내용을 정리해 봤습니다. 혹시 틀린 부분이나 제가 빼먹은 부분이 있으면 지적해주시면 감사하겠습니다	0	그렇지 않아도 필요한 내용이었는데. 감사합니다~	0	깔끔하게 정리해주셨네요감사합니다	0	고맙습니다.	0	정말 잘 정리되어 있는것 같습니다. 많은 도움 되었습니다.	0	저같은 비전공자도 이해하기 쉽게 잘 정리해주셔서 너무 감사드립니다.	0	오군영	0	정리가 잘 되어있네요. 잘 봤습니다. 그런데 본문 CNN구현 코드 부분에 작성자 이름에 살짝 오타가 있는것 같네요 ;)	0	수포자들에게 희망의 메시지네요정말 깔끔하게 정리해주셔서 감사합니다	0	잘정리해주셔서 감사합니다. http://bcho.tistory.com/1148 여기 글 마지막에 10-fold cross-validation도 추가 하면 좋을거 같아요.	0	다시 한번 감사드립니다. 저 같은 딥러닝 초보자들한테 많은 도움이 됩니다.	0	되게 깔끔하게 정리하신것같아요. 많이 배우고 가겠습니다 ㅎㅎ!	0	항상 올리신글 잘 보고있습니다 감사합니다
202	윈도우 플랫폼 지원이 공식적으로 추가되었습니다~	0	wow	4	열심히 Docker 깔아서 환경 만들어서 이미지 꾸어놨더니 그날 저녁에 Window용 출시되는 이 타이밍을 어쩔까요 ㅠㅠ	0	윈10 bash 에서 이것저것 하고 있었는데😂😂😂😂	0	윈도우 8에서 keras , tensorflow import  확인했습니다.	1	덕분에 우분투 지우네요 ㅜㅜ 감격	0	장영재 ㅠㅠ	0	YEAH!	0	리눅스 까는거 귀찮아서...(리눅스 못하는거 절대 아님...)뒹굴거리고 있었는데...ㅋㅋㅋ계속뒹굴거려야 겠다...한 일년있으면 음성인식 인터페이스가 나올지도.. ㅋㅋㅋ	0	김동민	0	헠...	0	amd 지원 여부 아시나요??	0	김건	0	방금 설치했습니다~~~	0	감겨억ㅠㅠ	0	리눅스에서 계속사용중이었는데ㅎ  텐서플로우 와  우분투가 먼가 좋긴하지만ㅎㅎ 윈도우가 파워포인트엑셀 한글때문에좋습니다 듀얼부팅 으로사용하느라 짜증났는데 이제야ㅎㅎ 드디어ㅎ	0	오 텐서플로우 윈도우!!	0	윈도우 7에서도 가능한가요?? 본문 보면 윈도우7, 10 둘다 되는것 같은데 다른분들은 윈도우10에서만 환경 만드셔서 실제로 윈도우7에서 가능한지 헷갈립니다....
4	텐서플로우용 서버 GPU로 괜찮은 모델이 모가 있을까요? 조언좀 부탁드립니다.	1	뭐니뭐니해도 titanX가 그래도 가장 잘 나오지 않나 싶습니다 ㅎㅎㅎ 1080도 설치하기가 좀 까다롭긴 하지만 그만한 성능을 내주고요 ㅎㅎㅎ	0	비싼게 역시 좋겠죠.....	1	titanX의 single-precision 성능이 단일GPU기준으로 딥러닝용으로는 거의 최곱니다	0	예상 가격과 용도를 알려주셔야...NV-link 인터페이스를  사용하는 테슬라 P100이 성능은 제일 좋습니다만....	0	타이탄이 이름값해요!	0	Google cloud에선 어떤 insatance를…
1	안녕하세요 auc값을 구하는 것 때문에 질문드릴 게 있습니다.Binary classification 문제에서 딥러닝 모델을 생성할때 비교를 위해 h2o와 tensorflow 둘다에서 같은 모델을 생성했습니다. 그런데 h2o에서 test auc값은 0.63인 반면에 tensorflow 에서 test auc값이 0.49가 나왔습니다. 하이퍼 파라미터를 거의 똑같이 줬는데도 불구하고 이렇게 상이한 값이 나오는건 제가 tensorflow에서 auc를 잘못 구한건가요?auc값은 tensorflow의 경우 sklearn.metrics의 roc_auc_score 함수를 사용했습니다. h2o는 auc가 자체적으로 잘나오더라구요.	0	auc가 0.49면 전혀 학습이 되지 않은거네요. 학습 과정을 다시 살펴보셔야 할듯합니다.
28	안녕하세요, 열혈눈팅회원입니다. 가끔 딥러닝이나 텐서플로우 스터디 관련 공지글을 올렸었는데요, 이번에 그 스터디들이 다 모이는 연말모임에서 특강들이 몇개 있는데, 마침 이 그룹에 어울릴만한 자료가 있어서 공유합니다. 정확히 텐서플로우는 아니지만, 딥러닝강화학습/강화학습으로 어떻게 대화형 시스템을 만들 것인지와 관련된 간단한 리뷰 자료입니다.이 글은 목적이 자료공유입니다(꼭 스터디뽀개기 모임에 참여하지 않으셔도 됩니다)공유된 글 링크들을 참조하시면 다른 자료들도 다운로드 가능합니다.
0	며칠 삽질하다가 도저히 안되서 고수님들께 질문 올립니다. 혹시 tensorflow slim으로 학습한 모델을 c++에서 로드하여 사용해 보신분 있나요? 저의 경우 다음과 같이 했습니다.1. slim inception v3를 이용해 flower dataset을 학습2. pbtxt, ckpt를 freezed graph로 변경3. label_image/main.cc에서 graph와 label 파일 이름 변경4. input_layer를 fifo_queue_Dequeue, output_layer를 InceptionV3/Predictions/Softmax로 변경빌드하고 실행해보면 에러없이 실행은 되는데 결과같이 이상하게 나오네요 ㅠㅠ
3	'Probabilistic Graphical Model' 스터디 관심있는분?~ (1월 말~ / 월요일 / 판교)2017년 1월 말부터(조금 당겨질수도 있음) 매주 월요일 저녁(7:30~9:30) 판교에서 진행할 예정이고요, 전체 일정은 Coursera의 관련 강의(Probabilistic Graphical Model)를 따라 15주로 잡고 있습니다.Certi에도 관심있는분은 Coursera PGM course에 미리 등록해 두시기 바랍니다. (이번 세션은 12월 10일까지 등록이라서, 2달전에 미리 공지 올립니다. Specialization이 아니라 1, 2, 3 각 코스로 들어가면 무료 등록 가능)강의링크https://www.coursera.org/learn/probabilistic-graphical-models참고도서https://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193/ref=sr_1_1?ie=UTF8&qid=1480503543&sr=8-1&keywords=probabilistic+graphical+models스터디 이벤트 페이지https://www.facebook.com/events/1740731876253026/
13	Chanwoo Lee 님 대략 머신 러닝 개념만 이해하고 이제 실제 코딩을 해보려고 하는데요. 이 때 바로 텐서 플로우로 넘어가는게 좋을까요? 아니면 numpy,pandas를 미리 보고 넘어가는게 좋을까요?예제들을 보니 많은 예제들이 데이타를 전처리하고 정재하는데 numpy와 pandas를 많이 쓰는거 같더라구요.	5	csv 형태의 데이터를 쓰신다면 판다스를 쓰게됨이 불가피 할 것입니다 이미지의 경우 load하고 resize 정도만 잘 처리하면 그다음부터는 거의 머신러닝 모델이기 때문에 머신러닝을 연습하기에 이미지 데이터가 가장 좋은 재료입니다 :)텐서플로 공홈에 올라와있는 mnist 예제를 백지부터 짜는 연습을 해보시면 다른 데이터도 건드려볼 수 있지 않을까요!	0	잘 날려진 공학자들의 친구 매스랩처럼 텐서를 쓰시면 되지 않을까 싶어요.^^	0	프로필 사진상으로는 두분 닮으신거 같아요 처음엔 헷갈렸어요 ㅎㅎ
195	이웅원 님께서 올려주신 "강화학습 깃북"을 읽어보았는데요. 강화학습이 요즈음 핫한 연구분야라 새로운 개념도 많고 또 이와 뉴럴넷트웍이 연결되면서 상당히 복잡한 면이 있는데 이 책에서 이런 부분들을 거의 다 다루고 있습니다.David Silver의 강의와 Sutton 교수님의 책에 나오는 거의 모든  갬념을 한글로 풀어 설명해줍니다. (아직) 설명이 조금 부족한 부분은 원문이나 슬라이드를 붙여두어 이해에 도움이 됩니다. RL에 관심있으신분들 일독 하시면 도움이 될듯 합니다. https://www.gitbook.com/download/pdf/book/dnddnjs/rl책에 대한 의견도 보내주시면 최종편에는 반영이 될것으로 생각합니다.	6	공유해주셔서 감사합니다!	2	이웅원 이의령 이영무 @양혁렬	1	감사요!	1	공유 감사드립니다.항상 교수님께 도움받고 있습니다.^^	1	감사합니다.	1	좋은 자료 감사합니다.	2	내용이 좋네요. 정말 열심히 정리하신 느낌을 받았습니다. 감사합니다.	3	감사합니다. 오늘 아무일도 못하고 이것만 보고 있네요!	3	멋진 Won Woong Lee 님!!! 진짜 열심히 정리한 글이죠. 항상 응원하는 연구원입니다! ^^	1	인간은 trial and error로 강화 학습을 하는 게 두뇌의 구조라는게 와닿네요.	1	감사합니다!	0	잘 읽어 보도록 하겠습니다. 감사합니다.~^^
0	안녕하세요, 텐서플로우를 공부중인 미천한 학생입니다. 다름이 아니라 이론적인 부분과 기초는 모두를 위한 딥러닝으로 쌓고 있는데, 실제적인 예제도 있으면 좀 더 도전적이 될 것 같달까요... ㅎㅎ 대강 깃허브 등에 있는 예제도 찾아봤는데, 것보다는 좀더 시각적으로 도전적인 video recognition 이나 classification, video stream recognition 등의 예제를 텐서플로우로 구현한 부분을 찾아보고 있는데 잘 없네요! ㅠㅠ 혹시 비슷한 예제가 있다면 알려주시면 정말 감사합니다 (_ _)
4	혹시 Tensorflow에서 반복적으로 training 실행할때 성능이 줄어드는 현상이 보고된게 있나요? 모델은 일반적인 NN(Hidden Layer 2개)입니다.GTX1080 x 2, i7-6700K 시스템에서 process 8개로 training중인데, 첫번째 training일때는 GPU 2개 합쳐서 160%가까이 사용율이 나오는데, 그 이후 부터는 사용율이 줄어들면서 몇시간 후엔 100%정도까지 사용율이 떨어집니다.아래 그림에서 빨간원이 첫번째 training에 해당하구요. notch 가 발생한 부분이 8개 process가 training 완료하고 결과 export 하느라 잠시 GPU가 idle 합니다. 이 첫번째 training 에선 best 성능이 나오는데, 그 다음부터 성능이 점점 줄어듭니다.두번째 training 이후는 weight, bias 값만 random하게 초기화될뿐, 첫번째 training과 하는 동작은 동일합니다.참고로 CPU frequency, load 는 시종일관 거의 변화 없구요.	0	같은 이슈일지는 모르겠으나 저도 비슷한 경우를 겪었는데 저같은 경우는 입력 큐사용 시 학습이 진행됨에 따라 시스템 캐시메모리가 꽉차서 입력 데이터 수급이 느려져서 gpu 사용률이 급감했습니다. 이 경우 주기적으로 캐시 메모리를 삭제해줌으로써 해결했구요.
2	딥러닝을 하면서 안드로이드를 사용하는 경우가 있나요?	0	컴퓨터에서 학습 시킨 것을 안드로이드에 이식해서 어플에 사용하는 용도로 씁니다 안드로이드 위에서 개발은 현실적으로 힘들죠
2	혹시 torch사용했던분들이나 사용중이신분 계신가요?더자유롭다기에‥	1	그건 루아 베이스인데요 좀 편하긴 한데 루아를 배우셔야합니다 파이선으로 계속 하시려면 Keras 추천 드립니다이것도 모듈러 방식이라 편합니다
46	최근까지 Mxnet으로 딥러닝 모델링을 하다가 Tensorflow로 넘어온 사람입니다. Tensorflow의 세밀한 모형 설정 가능성을 보면서 감동을 받고 있습니다. 혹시  Tensorflow for R을 사용하시는 분이 계시면 도움을 받거나 도움드릴 수 있는 기회가 있으면 좋겠네요. 개인적으로 생각한 Tensorflow For R의 장점은 wrapper 패키지 구현체 중에서 제가 봤던 가장 이상적인 R wrapper 패키지여서 텐서플로의 기본 구현 API를 가장 잘 인터페이싱 하고 있는 점이였습니다. 심지어 help 메시지도 Python help를 동적으로 가져와서 R에서 보여주네요.  무엇보다 R의 기본 데이터 객체를 바로 tensor 구조체로 넣을 수 있다는 장점은 데이터 핸들링 및 시각화가 편리한 R의 장점을 최대한 활용할 수 있는 포인트라 생각합니다. Mxnet에서 Tensorflow로 넘어온 가장 중요한 계기가 된건 Mxnet이 아직 GPU 메모리를 효율적으로 사용하지 못해서 였습니다. 최근 몇일 사이에 0.7에서 0.9 버전으로 버전업을 하고 조만간 정식 릴리즈를 한다고 하니 이것도 어찌 발전이 될지 기다려볼 부분이라 생각되네요.	1	관심있습니다.  소개차원에서 포스팅 했던 글입니다. http://icanibe.blogspot.kr/2016/10/r-tensorflow.html?m=1http://icanibe.blogspot.kr/2016/10/python-tensorflow-r.html?m=1	0	Mxnet은처음들어보네요ㅎㅎ	0	정말수많은 프레임워크가 있네요‥	0	어라? tensorflow for r 은 gpu위에서 돌아가나요?
1	안녕하세요 가입하고 처음으로 글을 남기네요 여러분의 도움이 필요해 이렇게 질문을 올립니다.RNN lab에서 hell입력으로 ello를 출력하는 예제를 봤는데요, 다른 단어를 학습 시키려면 또 다른 RNN 모델이 필요한건가요? 하나의 RNN으로 모두 학습이 가능할것 같고 그런게 맞는것 같은데 방법을 모르겠네요...혹시 참고 할만한 문서나 깃헙 주소를 알려주실수 있으신가요..? 부탁 드립니다 미리 감사 드립니다.	1	강의에서 나온 방법을 언어모델(language model)이라고 합니다.강의에서는 캐릭터단위의 언어모델을 구현한 것인데 학습 데이터를 hello 1개만 넣었을 뿐입니다.이와 같은 방법으로 다양한 단어들을 학습데이터로 구축하셔서 학습하면 알파벳 하나가 나왔을 때 다음 알파벳을 예측하는 언어모델이 구현되게 됩니다.
24	안녕하세요. 요즘 취미로 Andrew NG 교수의 Machine Learning 강좌를 수강중인 직장인입니다. 다름이 아니라 선지자 분들께 Support Vector Machine의 Decision Function에 대해 질문드리고 싶은 것이 있습니다.사진속 Decision Rule에 있는 'alpha'와 'b'는 어떻게 유도되는 걸까요? (b를 w0, alpha를 lambda로도 많이 표현하는 것 같습니다.)MIT open course 등의 유튭 비디오들과 구글 검색을 통해 이런저런 문서들을 따로 챙겨봤는데, 제가 본 자료들에서는 이에 대한 유도과정은 생략하고 있거나 추상적으로만 짚고 넘어가는게 전부였습니다. 혹시 레퍼런스를 알고 계시거나 설명 가능하신 분께 지식공유 부탁드리고 싶습니다. 이것때문에 요즘 밤잠이 통 개운치가 않습니다 ㅠㅜ읽어주셔서 감사합니다.	1	사진 첨부한 강의 영상입니다.https://www.youtube.com/watch?v=_PwhiWxHK8o	7	Yaser님의 Learning from data 수업에서 (질문주신 내용 포함해서) SVM에 대해서 상세히 다루고 있습니다. https://www.youtube.com/watch?v=eHsErlPJWUU&hd=1	1	오늘도 좋은거 하나 건저 가네요	1	유도과정은 convex optimization 문제로 원래 form을 dual form으로 바꿔서 저게 나오는 걸로 알아요	7	SVM은 공간 사이의 점을 2분할 하면서 분할선이 점들과 최대의 마진을 갖도록 하는 방법입니다. 이 최대마진선은  argmax(|w^2|) 과 조건식 y( wx +b ) -1 >= 0 을 만족해야하고 이를 이용하면 라그랑지안 식을 정의할수있는데, 이때 나오는 lambda 상수가 위에 있는 alpha입니다. 유도된 라그랑지안 식을 미분하여 풀면 w = Sigma( alpha *  y * x) 가 나와서 위에 동영상 캡처의 식으로 정리될수있는 것이구요. alpha구하기는 쿼드라틱 문제라 여러가지방법으로 푸는데 시간이 오래 걸려서 smo같은 단계적 방법을 주로 씁니다.자세한 전체 과정은 아래 자료를 보시면 될듯합니다.http://web.cs.iastate.edu/~honavar/smo-svm.pdf	1	이런곳에서 뵙는구만. ^^
1	[포토]도요타, 인공지능차 '모빌리티 팀메이트 컨셉트' 카 'Concept- i' 공개- 인공지능(AI)에 의해 사람을 이해하고 함께 성장하는 파트너를 목표로
27	파이썬 내부 로컬과 클로벌 변수관리 기준도 알아두면 좋습니다
21	모두 반갑습니다. 가입하고서는 거의 눈팅만 하며 살다가 속이터져서(?) 글 올립니다.알고있다고 느끼는 것과, 이론을 알고 있는 것, 구현하는 것이 세가지는 서로 조금씩 다른 영역임을 느낍니다.툭툭 건들고 스쳐지나갔던 mnist 튜토리얼에서 정말 가볍게 지나간 batch를...다른 데이터를 구하여 csv로 만들어 놨더니...어라. batch 어떻게 하지? 하고 막막해집니다.어쩌면, 사실 나는 아는 것이 하나도 없는게 아닌가....하고 batch의 이론 부분을 다시 훑어봤는데..이거 아는건데....하고 막막합니다......아.. 나는 사실 python과 tensorflow를 너무 대강한거구나.....하는 결론까지 왔습니다.종이에는 수식을 끄적여두곤, 파이참엔 코딩을 못하며 울먹이는 밤입니다.	1	저 또한 같은 느낌을 받으며 삽질합니다	1	공감ㅠ	2	자신의 데이터로 처음부터 끝까지 해결할수 있을때 제대로 아는게 아닐까 합니다.	1	가볍게 지나간 모든 것이 새롭습니다. learning rate는 어째야 좋을지, 루프는 몇번돌려야 과적합까진 안갈지, 배치사이즈는 어째야 할것이며, 드롭아웃 레이트는 어떻게 좋을지...
9	안녕하세요!드디어 기다리시던 머신러닝스터디 4차 스터디가 시작됩니다!!cafe.naver.com/mlstudy주제는 Deep Learning for NLP (stanford cs224d 강의) 입니다.장소는 토즈 강남점입니다.  http://map.naver.com/local/siteview.nhn?code=11840366&_ts=1483713442969시간은 1월 7일 토요일 11시~13시입니다.첫번째 모임이니만큼 간단한 모임 소개와 lecture 1 리뷰, 스터디 진행 방향에 대한 논의가 있을 예정입니다.강의계획서는 http://cs224d.stanford.edu/syllabus 에서 확인하실 수 있습니다.장소지원은 예산연도가 마감되어 3월부터 가능할 것이라고 합니다.모임 장소 이용비는 6천원씩입니다.대형 부스를 빌려 자리가 많이 남을 것 같습니다.스터디에 참여하고 싶으신 분은 아래 연락처로 연락 주시고 참여하시면 됩니다.카카오톡 protocolstack9메일 protocolstack9@gmail.com그럼 내일 뵙겠습니다.
37	안녕하세요.Tensorflow 튜토리얼들에 대한 공부가 거의 마무리되었는데, 문득 지금까지 배운 방법들로 MNIST 최대 성능을 뽑아보자는 생각에 구현해봤습니다. #모두를위한딥러닝 의 lab11에서와 거의 동일한 4-layers CNN구조에, data augmentation (학습 데이터 5배로 뻥튀기), batch normalization, ensemble까지 더해봤더니 99.72%까지는 나오네요.Ensemble빼고, 단일 모델은 99.61%까지 정확도가 나왔습니다.(30여번 모의실험 결과 중 최고 성능치입니다.)제 깃허브에 학습된 모델까지 같이 업로드하였으니, 혹시 필요하신 분들은 참조하시기 바랍니다.혹시, 네트워크 구조 바꾸지 않고 더 추가할 만한 방법론들이 있을까요?xavier initializer, dropout, exponentially decayed learning rate까지는 적용되어 있고, l2-normalizaton은 넣어봤는데 성능이 잘 안 나와서 제외시켰습니다.아. 그리고 처음으로 slim을 써봤는데 코드가 간결해져서 좋네요.	0	앙상블은 어떤가요?	1	언제 괜찮으시면 공부하신 순서나 내용, 감상도 이야기주시면 도움이 될듯 합니다. :)
12	강화학습에서 궁금한 게 있습니다.강화학습은 문제를 MDP로 정의하고 푸는데 이 때 state는 markov하다는 가정을 합니다. 1. State가 markov하지 않을 때는 어떨 때인가요?2. 이럴 때 문제를 푸는 방법이 POMDP로 정의하는 것일까요?3. 그리고 제어에서의 state는 markov한걸까요? 강화학습 자료들을 찾아봐도 state가 markov하다는 가정만 소개하비 어떨 때가 markov이고 어떨 때가 markov하지 않은건지는 찾지 못했네요	2	1. 다음 시간의 상태가 현재 상태에 뿐만 아니라 이전 상태에도 의존하면 Markov가 아닐 것입니다.e.g.1. 벽돌깨기의 한 frame만 보면 공이 왼쪽으로 갈지 오른쪽으로 갈지 모르니 Markov가 아닙니다.e.g.2. 바둑은 이전에 어떤 수를 두었든 현재 흑백 돌 위치가 다음을 결정하므로 Markov입니다. (알파고 논문에서는 그래서 ``Markov Game''이라는 말을 쓰더군요.)2. POMDP를 활용하여 푸는 방법도 있지만, 최근 deep reinforcement learning에서는 MDP 세팅으로 가정하고 세팅한 뒤 동작시킵니다.3. 제어를 어떻게 설계하냐에 따라 다릅니다.	1	예전에 김성필 연구원님과도 말씀을 나눴었습니다만, markov 하다는 것은 이전의 히스토리가 현재 상태에 영향을 안미쳐야 하겠죠. 주가 같은 시계열 데이터들은 전날의 주가만으로 오늘의 주가를 예측할 수 없을테니 아마도 markov하지 않을 것 같습니다. POMDP도 MDP이므로 markov하지 않을때 푸는 것은 아닐거 같구요. 제어에서는 위치, 속도, 가속도 정보를 이용해서 state를 만들고, 그 히스토리를 이용하지 않는다면 markov하다고 볼 수 있지 않을까 하네요.	4	다음 action을 결정하는데 필요한 모든 정보를 (파악만 가능하다면) 현재 state에 넣으면 되기 때문에 사실상 대부분의  RL 문제를 MDP 문제로 만들 수 있습니다.
60	안녕하세요. Tensorflow slim(TF-Slim)에 대한 자료가 잘 없는거 같아 제가 한 경험을 강의식으로 작성해 봤습니다. Slim을 사용하면서 느낀 점은 현재 여러 툴에서 신경망,SVM,DecisionTree 같은 알고리즘을 배경 지식없이 가져다 쓰는거 처럼... 딥러닝도 최소 이미지 분류 분야에 관해서는 그냥 가져다 쓰면 되는구나 입니다.저 처럼 이론보다는 현업에 그냥 적용해 결과만 뽑고 싶은 분들에게는 이 slim을 추천드립니다.*현재 2.3절 까지만 작성되어 있습니다. 다음주 3 올리겠습니다.	0	3. 내 이미지로 학습 하기 ( caltech 이미지 사용 )이 글은 아직 없는건가요 ?	1	slim 저도 잘 쓰고 있는데 learning 모듈은 따로 적용하기가 귀찮아서 그냥 argscope랑 pre-trained model 정도 적용하기 편한것에 만족하고 사용하는 중입니다 ㅎㅎ	0	저는 inception fine-tune 하고 있는데 slim과 차이가 따로 있나요??
11	#ReMind (강화학습 기초 실습+딥러닝) Re:Mind 파트 1 - 1회차 후기* 1회차 후기만 공유하겠습니다. 스터디 자료는 정리가 되면 모두 공개&공유합니다.- 자료 & 커리큘럼 링크 - https://github.com/psygrammer/remind* 정통..심리학 그룹 싸이그래머에서 진행하는 스터디입니다.- https://www.facebook.com/groups/psygrammer/* 네이버D2의 지원을 받고 있습니다.  2017년 첫 싸이그래머 스터디는 Re:Mind 였습니다. 강화학습(Re)과 딥러닝으로 유명한 딥마인드(Mind) 논문 리뷰를 하는 스터디입니다. 스터디는 총 4개의 부분으로 구성되어 있습니다. 강화학습 기초 이론 / 강화학습 기초 실습 / 베이지안 기반 머신러닝 이론 / 딥러닝 이론 / 딥마인드 논문 읽기 - 머신러닝 기초와 중급이 섞여있는 스터디입니다.     * (강화학습 실습) DeepMind Lab (1)먼저 김정주​님이 첫번째 발표를 하셨습니다. 강화학습 이론만 하는게 힘들어서 실습을 하자는 취지에서 새롭게 시작하는 부분입니다. 얼마전 딥마인드가 발표한 '딥마인드 랩'이라는 강화학습 시뮬레이션 도구의 설치와 소개를 준비해오셨습니다. 막상 보니까 어려운 부분이 있어서, OpenAI의 Gym을 이용한 텐서플로우 위주로 실습을 준비하고 중간중간 딥마인드 랩을 리뷰하는 식으로 진행하기로 했습니다.- https://gist.github.com/haje01/8a854fc0ccfa6f742c3021345a1cf528 * (머피ML) 15 Gaussian processes (1) 두번째는 제가 발표했습니다. 머피ML은 (주로 베이지안)확률모델링 기반으로 머신러닝을 통합하여 설명하고 있는 Murphy의 책으로 공부해서 붙은 이름입니다. 이번에 랜덤 프로세스의 일종인 가우시안 프로세스에 대한 부분을 살짝 소개만 했습니다. 책의 중반쯤이고, 다음 시간에는 이전에 못다한 커널 방식의 모형들을 살펴봅니다. 이후부터는 그래피컬 모델링 쪽으로 책이 집중되더군요.* (딥마인드) Learning to Learn by Gradient Descent by Gradient Descent세번째도 제가 발표했습니다. 딥마인드의 논문리뷰였습니다. 메타학습에 대한 딥마인드의 이 논문은 정말 생각할 거리를 많이 던져주더군요. 특징추출을 딥러닝이 알아서 하자는 식에서 한걸음 더 나가, 어떤 알고리즘이 좋은지도 딥러닝이 알아서 하자 라는 '학습에 대한 학습'이라는 테마 아래, 이 논문은 튜닝하고자 하는 뉴랄넷을 학습시키는 뉴랄넷을 만들었습니다. 그리고 당연히 Gradient Descent 방식으로 이를 풀어나가고 있습니다. 하이퍼파라미터 중에서 learning rate에 대해 메타학습하는 내용이었습니다. 데이터로부터 적정값을 가지도록 LSTM 구조로 뉴랄넷에 대한 뉴랄넷을 구성한 형태였습니다.* (딥마인드) Safe and Efficient Off-Policy Reinforcement Learning 마지막으로 김영삼​님이 발표하셨습니다. 딥마인드의 논문리뷰였습니다. 이번에 살펴본 논문은 강화학습 알고리즘에 대한 것이었습니다. 강화학습의 핵심 테마는 '탐색'과 '활용' 사이에 어떻게 균형을 잡는가 하는 것입니다. Off-Policy 알고리즘은 Behavior Policy와 Target Policy로 나눠서 이를 해결합니다. 그런데 이 과정에서 불안정성과 비효율성이 발생한다고 하는군요. 이를 해결하기 위해 Retrace(lambda)라는 지표를 만들었고, 매우 효과가 좋았다고 합니다.   * (딥러닝북) 18 Confronting the Partition Function (1) - 이재영마지막으로 이재영​님이 발표하셨습니다. 이안 굿펠로우와 벤지오가 쓴 딥러닝북의 후반부쯤의 진도입니다. 머신러닝 모형들이 확률 예측을 하기 위해서는  Partition Function이 필요합니다. 이를 구하기가 실제로는 매우 어려운데요, 이번 장에서는 이를 구할 수 있는 다양한 방법들을 에너지-베이스드 모형에서 어떤 식으로 할수 있는지 설명하고 있습니다.
2	여기에 문의드리는게 제일 좋을것 같아서 올려봅니다.혹시 GPU 써서 딥러닝 돌리시는 분들 어떤 구성으로 쓰시나요?? 노트북으로 쓰시는지 아니면 대데스크탑으로 쓰시는지요?? 한대 장만 하려 하는데 조립으로 구성해야 할지 그냥 게이밍 노트북을 사야할지 고민이네요;;  가격은 본체만 한 100정도로 생각 합니다.	2	데스크탑이 좋지요 노트북은 휴대하기좋다는거 빼고는 전부 데스크탑보다안좋아서요 컴퓨팅파워로 보나 메모리로보나	1	데스크탑이요.우분투를 설치하기에도 노트북보다는 데스크탑이 편해요.	0	혹시 GPU는 어느정도 급으로 쓰세요?? 모델을 알 수 있을까요??	1	1060 사용하고있습니다.Tensorflow 에서 CIFAR-10 예제코드 train시 23시간정도 걸려요	0	사실 100만원으로 구성하시는 거면 연습용으로정도밖에쓰기힘드실거에요ㅜㅜ	1	그렇군요... 그정도면 어느정도 감당 할 줄 알았는데 ;;  좀 더 써야 하나	3	제가하고있는프로젝트에서는 타이탄x두개로 하는중인데 트레이닝예상시간이 이틀정도걸립니다....
26	파이썬 기초도 제대로 이해할 필요가 있을 것 같아요추상화 클래스를 상속받지 않아도 goose typing으로 확인이 가능한 구조이니 이런 점도 명확히 이해하셔야 합니다	1	와 읽어봤는데 정말 몰랐던것들도 많고 ㅋㅋ 이런게 있다니 하고 충격받는것도 많네요. 좋은 정보 감사합니다.	1	ØSUN ?	1	ㅇㄷ
385	멋지십니다!	0	멋지십니다!	0	옷! 제 지도에 추가해야겠네요.	0	어제 첨 보기 시작했는데 저같은 완전 초보가 보기에도 너무 쉽게 설명해 주시더군요	0	저도 이분 강의로 기초를 잡았습니다.	4	#모두를위한딥러닝 링크 추가합니다. ㅋㅋ	5	대체 이런 기사에는 왜 해당 코스의 URL 을 기재하지 않는걸까요? 최소한 바로 검색할 수 있게 잘 정제된 검색어라도 표기하든가. 국내 언론 특유의 모습인데 바뀔 때도 되었건만...	0	Awesome !!	4	저도 링크 찾다 유투브에서 모두를 위한 딥러닝 검색하니 나오네요 ㅎㅎ 플레이리스트는 여기로 가시면 됩니다 https://www.youtube.com/playlist?list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm	0	VI SI ON 空慈
41	IBM, 5년이내 인간의 삶을 변화시킬 5대 혁신 발표- 인공지능, 하이퍼이미징, 매크로스코프, 랩온어칩(lab-on-a-chip), 스마트센서
26	Ian Goodfellow 트윗에 친구가 만들었다면서 소개가되었길래 들어가봤는데...정말 멋진 서비스인거 같습니다 ㅎㅎ	1	https://byor.xyz/ resume review system인것 같네요.
25	요새 핫하다는 책 한 권 구입완료했습니다.	1	오오~ 저는 외국이라 구입에 어려움이. 읽고 후기 부탁드려도 될까요?	1	구입해놓고 매주 발표 준비한다고 못보고 있네요..^^
2	Stochastic neural network와 관련된 TensorFlow 예제코드를 추천해주실 분 있나요?	1	tensorflow.org 에도 많이 있고 https://github.com/nlintz/TensorFlow-Tutorials/ 등에도 참고할만한 예제가 많을것 같습니다.	1	Sung Kim 답변 감사드립니다. 제가 질문을 잘못 올렸다는 생각이 듭니다.stochatic output을 생성하는 neuron이면서 동시에 backpropagation을 할 수 있는지가 질문이었는데요. 찾다 보니 관련 연구를 찾을 수 있었습니다.https://arxiv.org/pdf/1611.00712v2.pdfreparameterization trick이 특징점인 것 같습니다. 감사합니다.
33	지난번 포스팅한 MNIST softmax를 이용한 숫자 인식 예제에 잘못된 점이 있어서 재 포스팅하였습니다http://bcho.tistory.com/1154지난번에 그룹에서도 논의했던건데, 텐서플로우 튜토리얼을 보면y =  tf.matmul(x, W) + b로 구현하고코스트 함수를 Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))이 구현이 학습에는 맞습니다.tf.nn.softmax_cross_entropy_with_logits 함수 자체가 softmax를 포함하고 있습니다. ttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard7/tf.nn.softmax_cross_entropy_with_logits.md 레퍼런스에 따르면WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.그런데 예제 처럼하면 y 는 softmax를 포함하고 있지 않기 때문에 학습은 가능하겠지만 맞는 모델은 아니기 때문에k = tf.matmul(x, W) + by = softmax(k)Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(k, y_))로 고치는게 맞겠습니다.	0	softmax가 비용이 큰 함수인데 두번이나 해주는 이유가 따로 있나요?
54	애플에서 공개한 "Simulated+Unsupervised (S+U) learning" https://arxiv.org/abs/1612.07828 를 TensorFlow로 구현했습니다.https://github.com/carpedm20/simulated-unsupervised-tensorflow논문은 유한한 진짜 데이터(ex. 진짜 눈 사진)를 보충하기 위해, 인위적으로 만든 데이터(ex. 게임 엔진으로 만든 눈 사진)를 진짜 데이터처럼 보이게 만들어주는 모델을 제안했습니다.모델은 adversarial learning을 통해 학습되며 일반적인 Generative Adversarial Network(GAN)의 학습과 다른 점은 3가지라고 말합니다.1. input의 특징들을 잃어버리지 않게 만들어 주는 regularization term2. 특수한 패턴으로 discriminator를 속이는 꼼수를 배우지 않게 하기 위한 local adversarial loss3. 가장 최근에 본 학습 데이터에 너무 편향되게 학습하는 것을 막기 위해 사용한 history buffer논문에서는 눈 사진과 손 사진으로 학습한 결과를 보여줬지만, 자동차 주행 시 찍은 사진과 GTA와 같은 게임에서 찍은 사진 데이터를 활용한다면 자율 주행 자동차의 강화 학습을 돕는 등 다양한 방법으로 활용할 수 있을 것 같습니다.	1	정말 대단한 구현입니다.	1	머쪄용
70	Solaris라는 블로거가 구현한 텐서플로우 기반의 Deep Q Learning 예제 코드입니다. OpenAI Gym이 제공해주는 Environment를 사용하지 않고 직접 구현하고 있습니다. 260라인이 조금 넘는데, 논리가 복잡하지는 않습니다. 이번 주말에는 이 코드를 수정하여 재미있는 시험을 해보면서 김교수님 강화학습 수업 예습을 할까 합니다.	1	Solaris 이분블로그재밌습니다ㅎ	1	트래픽이 몰려서 솔라리스님 블로그 접속이 안되는 것 같습니다. 해당 포스트에 사용된 코드는 다음 깃헙 주소에 있습니다. https://github.com/solaris33/CatchGame-QLearningExample-TensorFlow	3	솔리리스님 대단하시네요. 그리고 여기 DQN이해하시면 제 강의 안들으셔도 될듯. 전 정말 비전공자들의 입문을 위한 기본적인 내용을 다룰 예정입니다. :-)	1	혹 솔라리스님 저희 그룹 멤버신가요?
7	엔비디아 젠슨 황, 자율주행차·인공지능·딥 러닝·게이밍·스마트홈 비전 제시- 차량용 인공지능 기반 코파일럿(Co-Pilot), 게이밍을 위한 지포스 나우(GeForce NOW) 및 스마트홈 구현을 위한 첨단 기술
9	http://www.pcworld.com/article/3153726/components-graphics/radeon-vega-revealed-5-things-you-need-to-know-about-amds-cutting-edge-graphics-cards.htmlAMD에서 차세대 GPU 아키텍쳐 Vega라는게 나왔네요역시나 머신러닝을 고려한 설계가 들어 있는거 같습니다.인용Finally, AMD teased Vega’s “Next-gen compute engine,” which is capable of 512 8-bit operations per clock, 256 16-bit operations per clock, or 128 32-bit operations per clock. The 8- and 16-bit ops mostly matter for machine learning, computer vision, and other GPU compute tasks, though Koduri says the 16-bit ops can come in handy for certain gaming tasks that require less stringent accuracy as well. (The AMD-powered PlayStation 4 Pro also supports 256 16-bit operations per clock.)	1	얼마전 엔비디아의 테슬라 제품군에 대응하기 위해, vega기반의 instinct시리즈가 발표되었습니다. 머신러닝에서는 텐서플로우도 지원예정인데 각각 장단점이 있는 엔비디아와 AMD카드를 한 컴퓨터에 넣고 돌릴생각만 해도 기대가 되는군요^^http://instinct.radeon.com/en-us/about/http://instinct.radeon.com/en-us/about/
6	인텔-BMW-모빌아이, 자율주행차 40대 실제 주행 실증한다.- 자율주행에 강력한 머신러닝 및 딥러닝 시뮬레이션 인프라를 기반으로 한 인공지능 기능 탑재
2	Tensorflow 사용법이나 개요가 나와있는 책 하나 추천해주세요!	1	텐서플로우 첫걸음 추천합니다.	0	네형
0	맥 환경에서 텐서플로우 gpu 옵션으로 테스트 성공하신 분 있나요?? 그간 맥cpu 버전은 잘 사용해왔었는데 gpu 옵션 설치 가이드라인이 생겨서 따라 해보는데도 설치 및 테스트 에러와 관련된 글이 전혀 없네요..;	0	요즘에는 tensorflow-gpu pip 패키지로 쉽게 설치됩니다. 잘 돌아가고요.	0	CUDA 최신 버전 설치, cuDNN 최신 버전 설치, .bash_profile 건드려주고 tensorflow-gpu pip으로 설치하고 딱 실행하면! 에러가 하나 그건 심볼릭 링크 하나 걸어주면 해결됩니다. 에러 내용 구글링 하면 나오고요.	1	문제는 제 경우 GPU가 GT750M인데 실제로 돌려보면 CPU보다 살~~~짝 빠르고요. 메모리를 많이 쓰는 경우 오히려 CPU보다 느려져서 다시 CPU 버전으로 돌아왔습니다.
1	rnn(contrib)는 api의 tf.nn.rnn_cell과 다른 점이 무엇인가요?설명으로는 Unlike rnn_cell.LSTMCell, this is a monolithic op and should be much faster. The weight and bias matrixes should be compatible as long as the variable scope matches, and you use use_compatible_names=True.이렇게  나오는데 설명해주실분 ? 있으신가요.타고 들어가보니 rnn_cell.RNN을 상속받던데.. 왜 더 빠르다고 하는건지??? 잘 모르겠습니다.-------------------------------------------------------------------------------------------------------In general, tf.contrib contains contributed code. It is meant to contain features and contributions that eventually should get merged into core TensorFlow, but whose interfaces may still change, or which require some testing to see whether they can find broader acceptance.Code in tf.contrib isn't supported by the Tensorflow team. It is included in the hope that it is helpful, but it might change or be removed at any time; there are no guarantees.-위의 글을 찾았는데, 그대로 이해해도 될까요? contrib 에 대해서?아직 완벽하지는 않지만, 사람들에 의해서 계속 작성되고 있는.. 사용자들이 기여한 코드란 뜻이겠죠?
24	Ian Goodfellow가 얼마전 공개한 NIPS에서의 GAN tutorial은 정말 generative model을 공부하기에 꿀자료인데요, 그 중 chapter 2에 나오는 generative model 분류에 대해 정리해봤습니다. 내용에 대해 자세한 부연설명 댓글이나 토론 환영합니다!
24	도움을 부탁드립니다!! 함께 강화학습을 공부하는 친구들끼리 실용적인 강화학습 책을 써보려고 하는데 여러가지 의견을 듣고 싶어서 설문조사를 만들어보았습니다! 첫번째는 제가 작성한 강화학습 깃북에 대한 리뷰이고 두번째는 강화학습책에 대한 수요에 대한 내용입니다! 강화학습에 관심있으신 분들이 어떤 것때문에 관심있는지 등등이 궁금하네요! https://www.facebook.com/groups/modulabs/permalink/1195948890470292/	1	읽고 많이 도움이 되었습니다~ 감사합니다 ㅎㅎ	1	너무나 정리 잘해 주셔서 너무 감사합니다.RL 스터디를 해볼까 했는데 이렇게 좋은 글을 따 내어주시니... ^^	1	Dynamic Programming 부분을 읽는 중입니다. 감사합니다
94	처음 시작하는 분을 위해 주피터노트북 사용법	1	이건 정말 중요한거같아요.	1	정말정리 잘 되어 있네요
7	안녕하십니까딥러닝을 접한지 얼마 안되는 대학원생입니다. ㅎㅎ현재 CNN을 통해서 Classification을 해보려고 하고있습니다.인터넷에 있는 대부분의 예제들은 Mnist 데이터셋을 사용하고 있는 것 같아서, Mnist와 같이 데이터셋을 만들려고 시도 중에 있는데요..혹시 전문가님들은 데이터셋을 어떻게 만들고 계신지요?	0	이미지는 그냥 cifar10 pascal 데이터셋 같은거 그냥 쓰시는게 나을 것 같고 그런게 아니라면 꽃의 종류별로 특징 데이터를 이용해서 분류하는 예제가 있었는데 뭐 그런느낌으러 하면 될것 같은데요	0	이미지는 mnist와 비슷하게 한글 자음 수화이미지를 구글에서 가져와서 30x30 픽셀로 모두 변환해서 트레이닝 시켜본 적은 있습니다. mnist와 큰 차이점은 없었고 라벨종류가 더 많고 데이터가 적어서 정확도도 떨어졌습니다.
1	안녕하세요.Tensorflow 예제를 공부하다가 CIFAR-10에서 train과 test를 나누어서 파일을 정리한 것이 흥미롭더군요.Python을 원래 알고 있지 않았고, Tensorflow와 함께 공부하다보니 Python에도 공부하면 좋을 것이 많다는 것을 뒤늦게야 알게 되었어요.서론은 이쯤하고, cifat10_input.py 내부를 보는 중에, CIFAR10의 원본 Image size는 32 by 32인데 내부 Input size는 24 by 24더군요. 부분때문에 코드를 보아도 뭔가 이렇다 할 답은 못찾고 있습니다만.32 by 32 image를 불러온 후 정중앙에서의 24 by 24를 취하고 외곽data는 버린다고 이해했는데 이게 맞는걸까요?	0	코드에 이 부분때문에 그렇게 이해했습니다.  # Image processing for evaluation.  # Crop the central [height, width] of the image.  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,                                                         width, height)	0	# Process images of this size. Note that this differs from the original CIFAR# image size of 32 x 32. If one alters this number, then the entire model# architecture will change and any model would need to be retrained.IMAGE_SIZE = 24 보신코드가 그냥 24로 트레인되있어서 그렇습니다.	1	cifar10_input.py의 distorted_inputs함수에서 tf.random_crop()이 호출됩니다. 중앙이 아니라 랜덤 위치에서 24x24로 crop되요~
42	최근 한 온라인 바둑 게임에 나타난 정체불명의 도장깨기 고수가 알파고 였다는군요 ㅋ 어쩐지~	2	http://m.news.naver.com/read.nhn?mode=LSD&sid1=105&oid=025&aid=0002673334	0	소오름....
36	http://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198이 책 보신분 계신가요?배송이 늦어지고 있어서 취소할까말까 망설이고 있는데혹시 보신분들 어떤지 소감이 궁금합니다.	1	베타리딩을 했었는데 개인적으로 좋아하는 스타일의 책입니다. 용어는 일부 (어쩔수없이) 어색한 부분은 있는데 라이브러리를 안쓰고 직접 코딩하는 것을 좋아해서요	0	음.  이 책이 출간되는지 몰랐네요.목차를 보니 '6. 학습 관련 기술' 이라는 부분이 있는데 다른 책과 달리 별도로 이 부분을 명시적으로 기술할려고 한 점이 인상적이네요.	0	어제 출시된줄 알았는데 아직 예약판매네요. 궁금한듸...	14	역자입니다. ^^ 오늘 서점에 입고되었다는 소식 들었습니다.	3	저도 피드백은 개인사가 생겨서 드리지못했지만 미리 읽어봤는데 굉장히 좋은 책입니다강추드립니다	0	엇그제 서점에 없던데 아직 출간 안했었군요. 나오면 한번 가봐야 겠습니다	0	저는 몇주전에 사서 원서로 읽고 있는 중인데 역서가 나온줄 몰랐네요;; 저는 초보입장에서 꽤 좋은 책이라고 생각하고 있습니다. 서점에 일본에서 많이 팔린 책이라고 써 있어서 골랐습니다. ^^;;	0	덕분에 주문했습니다. ㅎㅎ	0	목차를 보니 굉장히 기대되더라고요. 전자책으로도 출간되면 좋겠습니다...	0	신재현	0	상당히 좋은 책입니다.	0	어제 서점에서 쓱 봤는데 바로 카드 꺼낼뻔 했습니다 ㅎㅎ
212	2017년 TensorFlow 와 함께 딥러닝에 빠져들자![2017년 1월  #모두를위한딥러닝 시즌 1 수업을 들으시는 100분에게 선물을 드립니다.]딥러닝은 이미 우리 생활 깊숙히 들어와 있고 딥러닝에 대한 이해가 반드시 필요한 시대로 나가고 있습니다. 더우기 TensorFlow등의 오픈소스 라이브러리를 사용하면 매우 쉽게 딥러닝을 사용할 수 있습니다. 앞으로의 프로그래밍은 단순한 알고리즘 기반이 아니라 딥러닝과 인공지능 기반이 될것입니다. 딥러닝은 꼭 알아 두어야 합니다. 2017년 1월   #모두를위한딥러닝 시즌 1  수업을 들으시고 2월 1일 준비된 퀴즈를 맞추시는 100분을 추첨하여 선물을 드립니다. 이벤트에 대한 자세한 안내: https://docs.google.com/document/d/1mArk2XvKcFf7XvwAqxb8VhdRmMZwl7uYRiIsdzCMQvo/pub저희 그룹 분들은 다 아시는 내용이지만 다른 분들이 2017년 딥러닝 시작할수 있도록 많은 홍보 부탁드립니다.#모두를위한딥러닝	2	공유 !	1	신아영 이효정 열공하자구 😁😊	3	저도 공유합니다!	1	공유합니다.^^	1	딥러닝 처음 시작시 정말 많은 도움이 되었습니다 ㅎ 주변에 적극 추천 중입니다~^^	1	딥러닝에 빠져 볼랍니다.ㅎ 감사합니다	1	좋은 일 하시네요! 감사합니다 ><	1	필요한 몇 개만 듣고 아직 다 듣지 못해서, 이번 기회에 참가해봐야겠네요! 연구실 후배들도 소개해주어야겠습니다, 감사합니다!!	1	이번 기회에 다 들어 봐야겠네요..	1	이벤트가 좋은 동기가 되겠네요! 일단 붙습니다! ㅋㅋ	0	감사합니다 교수님 😿	1	저도 복습모드!	1	저도 도전해보겠습니다!^^	1	몇권 책을 읽어본 것 보다 교수님 동영삼 본 것이 더 도움 됬습니다.	0	회사에서 스터디를 만들어 어제부터 시작했습니다 :) 하루에 2~3강 수준으로 스케줄을 잡으니 1월 설날 전에 다 볼 수 있겠더라고요. 그리고 지난 연말에 홍콩 가족여행을 갔었는데, 한번도 뵌 적이 없지만 교수님 생각이 났습니다. 2016년에도 교수님이 공유해주신 자료로 많은 공부가 되어서. 감사드리고, 새해에도 좋은 일 많으시길 바랍니다.
6	Geoffrey Hinton 교수님의 Neural Network for Machine Learning강의 자료를 보면서 질문이 드는 점이 있는데 아시는 분이 있나요?!?Data가 적은 경우 , 혹은 많지만 redundancy가 없는 경우에는 Full-batchData가 많지만 redundancy가 높은 경우에는 mini-batch방식을 사용하여 학습을 한다는 것에 대한 이해는 다 하였는데,실제 데이터 분석을 할 때, 내가 가지고 있는 dataset이 redundancy가 높은지 적은지 등을 판단하는 척도 등이 존재하나요?!?! 아니면 사람이 주관적으로 판단을 하나요?? (판단을 하더라도 어떤 기준을 두어야할지 궁금하네요...)	5	아주 여러 기준이 있을 수 있는데 분포를 그려보아 균등한 그림이 그려지면 redundancy가 적고 반대로 좁은 위치에 몰려있으면 높다고 말합니다. 기준은, 예를 들자면 r,g,b 각각에 대해 분포를 그려보는 것도 하나가 될 수 있습니다. 척도는 예를 들어 Kurtosis(첨도)를 쓸 수 있습니다. Gaussian을 기준 대상으로 삼는데 3보다 작으면 high redundancy, 반대로 크면 low라고 할 수 있습니다. 다변량적으로 보고싶으면 주성분분석을 한 뒤 몇개의 주성분축에 대해 위와 같은 분석을 하면 되겠습니다.https://ko.wikipedia.org/wiki/%EC%B2%A8%EB%8F%84
4	안녕하세요. 텐서플로우를 이용해서 영상 처리를 공부하고 있는 학생입니다.다름이 아니라 텐서플로우로 학습을 시키던 중 이해할 수 없는 현상이 일어나서 질문을 올립니다.제가 사용하고 있는 input의 형태는 mat 파일 형태로 scipy library를 이용해서 입력으로 주고 있습니다.그런데 이 input으로 학습을 하였을 때는 학습이 되었으나, input에서 mean을 뺀 데이터로 학습을 하니 학습이 안 되었습니다. 그래서 다시 원래의 input으로 학습을 하였는데 학습이 안 되었습니다!?혹시 제가 모르는 텐서플로우 프로그램 내부의 기록 또는 설정 때문에 이런 현상이 일어나는 것이 아닌가 질문 드립니다.코드는 아래에 첨부하였습니다.
3	[질문] 맥북프로 최신형에 Intel HD Graphics 530, Radeon Pro 455가 있는데 GPU를 tensorflow에서 사용할수 있는 방법이 있을까요? 없을것 같지만 질문드려 봅니다.	1	Nvidia가아니면안되는것같네요	1	Cpu로돌리는수밖에없을것같아요	0	감사합니다^^	1	안되요. 저도 비슷한고민하다 맥북포기했어요	3	텐서플로우 gpu 버전 중 cuda가 아닌 opencl이 있는걸로알고있습니다. Cuda는 nvidia에서 지원하는 병렬언어라고하면 opencl은 라데온과 nvidia 둘다 가능한걸로만 알고있는데 깊숙히는 몰라서 알려드리긴힘든데 한번 확인해보시는것도 나쁘지않을 것 같네요	2	텐서플로우가 아직 정식으로 opencl 자체를 지원하지 않는걸로 알고 있습니다. 검색해보니 이런건 있네요. https://github.com/benoitsteiner/tensorflow-opencl	0	모든 분들꼐 감사합니다. 저도 좋은 정보 공유하도록 하겠습니다.
185	https://goo.gl/47DJv1안녕하세요. <밑바닥부터 시작하는 딥러닝> 역자입니다.번역하면서 정리한 번역 용어표 공유합니다.우리말 자료가 별로 없는 상황에서 외국 정보를 바로 찾아 익히시는 분들 입장에서는 번역어가 낯설 수 있어서, 시중의 다른 책들도 참고해 정리했습니다.쭉~ 보시면 우리말 책들이 사용하는 용어에 어느 정도는 익숙해지실 겁니다. ^^	0	감사합니다.	0	대박 감사합니다😄👍	0	텐서플로우 문서 번역 내용도 일관성 있도록 수정하면 좋겠네요 :-)	0	감사합니다! :)	0	안녕하세요 책 주문 했습니다 ^^	0	감사합니다	0	지금까지 나온 딥러닝 책중 가장 좋은책같네요..	1	여기서 말하긴 그렇지만.. 딥러닝 첫걸음, 텐서플로 첫걸음 외 몇권을 봤는데 이책만큼 개념에 대해서 제대로 설명하고 있는 책이 없습니다 ㅎㅎ 아하 그리고 제이펌 딥러닝 제대로 시작하기 라는 책도 굉장히 좋네요.. 일본분들의 실력이 ㅎㄷㄷ 하신듯 하네요.
48	MS와 아산병원이 협업으로 의료 빅데이터 분석대회를 엽니다. 아마 의료정보 보호문제로 Azure 환경 안에서만 데이터 확인 및 분석을 마쳐야 하는 제약이 있습니다만, 그래도 국내에서는 가장 큰 규모로 열리는 대회이니 관심있으신분들은 참여해보시면 좋을것 같습니다. Azure에서도 텐서플로우와 K80 GPU를 쓸수 있는것으로 알고 있습니다. p.s 개인1등 부상이 "취업추천서"라니 씁쓸하네요. 몇몇 과제는 국내 기업과 상당한 비용을 들여 추진중으로 아는데, 거기에도 "도입 추천서" 써주시려나요 ㅎhttp://amc-conetest.azurewebsites.net/ASAN-MS/apply.html글이 제대로 안보인다고 해서 재작성했습니다^^;;	1	좋은 정보 감사합니다	1	참가자에게 추천서를 작성해주고 부상은 별도로 (5백만원) 있는것 아닌가요?
95	Kevin Hughes라는 분이 구현한 Tensorflow 기반의 마리오카트64 오토파일럿(?) 입니다.	0	아주 재미있네요. 어떤 알고리즘을 사용한것인가요?
33	안녕하세요.개인적으로 늘 궁금하였던 batch normalization과 여러 weight/bias 초기화 방법들을 비교해 보는 코드를 구현해봤습니다.간단한 네트워크로 구현된 예제를 찾아볼려고 했는데 그렇게 딱히 마음에 드는 코드가 없어서 제 입맛에 맞게 구현해 봤습니다.hidden layer 2개짜리 MLP로 MNIST를 풀어봤습니다.tensorflow에서 batch normalization 구현은 정말 여러가지 버전이 돌아다녔는데, 결국 제일 쓰기 편한 tensorflow.contrib.layers.python.layers의 batch_norm으로 구현했네요.weight초기화 방법도 xaiver/he 방법 다 tf.contrib.layers의 api를 활용했습니다.혹시나 필요하신 분들을 위해 코드 공유합니다.
78	그까이꺼인공지능쉽고쉽게Dohyoung Rim 어려운걸 쉽게 설명해주셔서 ~ 감사드려요 ^^	0	그까이거...  이렇게 쉬운데 왜 제대로 하는 곳이 없을까요?	2	ㅎㅎ 저랑 배경이 비슷한 분이시네요~ AI 중에서도 기계학습 (ML) 만을 다루지만 확실히 '그까이거' 수준으로 쉽게 잘 쓰셔서 재미있게 읽었습니다. 그시절엔 ANN(NN) 관련 이야기는 그냥 몇시간 강의로 끝나고 현업에서도 MLP 정도 구현해서 데이터마이닝 솔루션에 구색맞추기로 만들었던 기억이 있습니다. 그에 반해 요즘 Deep Learning은 정말 대단합니다! 저도 틈틈히 텐서플로나 그 외 Caffe, DL4J 등 살펴보는 재미가 쏠쏠하네요. ^^	1	감사합니다 ㅎㅎ 감사히 잘 보겠습니다	1	인공지능이랑 머신러닝이 요즘 자주 혼용되는 경우를 보는 것 같습니다. AI를 설명한 부분이 아쉽네요.	0	쉽게 표현하시느라 대단히 수고 하셨습니다..
246	아침에 GAN에 대한 중요한 feed가 2개나 올라 왔습니다. 1. (2017년) GAN이 세상을 바꿀것이다. https://medium.com/@Moscow25/gans-will-change-the-world-7ed6ae8515ca2. Andrew Ng 교수님의 제자자랑과 함께 @Ian Goodfellow 의 NIPS 2016 GAN tutorial 문서 (56 page): https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Fandrew.ng.96%2Fposts%2F1233107080078530GAN은 기존 딥러닝의 학습방법을 획기적으로 (마치 우리가 무엇을 배우듯) 바꾸어서 아마 머신러닝 전반의 혁신을 가져오지 않을까 기대하고 있습니다.(어디선가 읽은 예로) 다음의 두명의 등장인물이 있다고 가정합니다.G: 피카소의 그림 가작을 그리는 것이 직업A: 주어진 그림이 피카소의 그림인지 아닌지를 판별하는 것이 직업 최소한의 학습데이타로 G가 그림을 만들어 내고 A는 이를 판별합니다. 이 판별 결과가 학습데이타가 되어 G는 그림 솜씨를 발전 시키고, A는 G가 만들어낸 더 장교한 그림을 판별하면서 판별력을 발전 시키고, 이렇게 수억번 왔다갔다 하다보면 G와 A가 전문가가 되게 된다는 아이디어인데요. 사실 우리가 글쓰기, 운동, 그림그리기등 많은 것을 이렇게 배우게 됩니다.그 결과의 예로 주어진 문장으로 만든 새 그림을 보면 정말 엄청납니다. 2016년이 RL의 딥마인드가 알파고 등으로 사람들을 놀라게 했다면 2017년은 GAN이 세상을 바꾸게 될까요?	1	조금은 무섭기까지 하네요 ^^;;	0	잘모르지만... 강화학습도 짬뽕된거라 볼 수 있는건가요? GAN지 나네요~	5	하하 저 새 그림이 미시간에 이홍락 교수님 연구실에서 나온 성과인데, 작년 닙스에 저 새 그림 + 새의 part 위치까지 같이 학습을 시키는 모델이 나왔어요. 이제 빨간 부리를 갖는 새를 그리면서 새의 부리, 다리, 머리 등의 위치까지 같이 고려할 수 있습니다. http://www.scottreed.info/files/nips2016.pdf	1	16년 unsupervised learning 부활, 17년말 쯤 됬을때는 Unsupervised의  승리	1	오 이미지 이외에서도 쓰일수 있을까요	2	와... 정말 엄청나군요. 이건 또 어떤 큰 변화를 만들어낼지 기대됩니다. 요즘 이쪽 분야은 꼭 프로스포츠를 보는 것 같은 기분이에요. 엄청난 속도와 변화.
84	좋은 코드가 하나 있어서 공유합니다. GAN을 활용해서 super-resolution을 하는 텐서플로우 코드입니다. pythton3에서 돌아간다고 하는데, python2에서도 잘 돌아가는 것을 확인했습니다. 	4		0	오~ 감사합니다. 오늘 집에서 돌려봐야겠네요.	1	감사합니다.. 이미지 처리 관련 기술이 제가 주로 일하는 금융, 통신 도메인에서도 효과적으로 사용할 수 있습니다.가깝게는 비대면 거래 인증부터 각종 심사 작업 등에 이르기까지 활용 범위가 넓습니다..  감사합니다..  꾸벅..	0	정말 대단하십니다..!	0	오오 이것 멋지군요. 직접 소개해주셔서 저도 한번 해봤습니다. loss curve 가 특이하군요~
15	안녕하세요. 현재 학부를 졸업하고 머신러닝/딥러닝 매력에 빠져 머신러닝으로 박사과정을 준비하는 정원석이라고 합니다. 다름이 아니라, 캐글에서 이미지 분석을 딥러닝으로 돌려보려고 하는데 사양이 너무 낮아 불편함을 느끼고 있습니다. 가격이 문제 없다면 어떠한 환경을 구축하는 것이 가장 좋을까요?1.  데스크탑 (GPU) + 낮은사양의 노트북 (원격으로 돌린다) 2. 높은 사양의 노트북 ( 윈도우)3.맥북프로의견 부탁드립니다 감사합니다 !!	1	1번 한표!	1	가격에 문제가 없다면 엔디비아로 1번 저도 한표입니다	1	1이 젤좋아요 3을 실행할 가격과 1을 실행할 가격이 거의 같아서 그리고 지피유는 있는게 훨씬 좋은 것 같아요	1	뽀대나게 3번으로 가려 했으나, 현실적인 GPU달린 노트북 사서 비디오강의 들으며 잘 돌리고 있습니다. 2번에 한표	1	1번이요!	1	1번으로 한표 드리고 싶은데 , 멀티 nvidia gpu 이슈가 있는걸로 알고있습니다. 멀티gpu 하신다면 텐서플로 부분에서 확인하고 써보세요.	1	1번이죠.	4	https://github.com/jcjohnson/cnn-benchmarks 참고하시기 바랍니다. 이미지 분석쪽은 갈수록 모델들이 깊어지면서 무거워지고 있는 추세라서, ResNet-200 같은 모델은 batchsize를 16으로 매우적게 잡아줘도 GTX1080(8GB)에선 안돌아 갑니다. GTX1080 탑재된 노트북은 가격이 300만원 이상이고, 17인치에 4KG 전후라 휴대성은 포기하셔야 됩니다. 즉, 연구용도면 1번, 학습용도면 2번 일 것 같습니다.	1	1번이 경험상 제일 좋습니다만 2번처럼 노트북으로 돌리시려면 최소한 파스칼 gpu 들어간 모델 사셔야하는데 그럼 노트북이 많이 무거워지죠.. 너무 큰 데이터셋이나 스펙이 자주 필요한게 아니면 구글 클라우드 서비스나 AWS에서 돌리는 것도 괜찮아요	1	당연 1번이죠. 단일 노트북이면 오래돌릴때 백그라운드에 계속 켜놓기도 은근 신경 쓰입니다.	1	1 번이 좋아요. 저도 놋북으로 다 하고 싶어서 견적을 받아봤는데 워크스테이션 노트북 최고 사양으로 사신다해도 같은 비용을 들인 데스크탑의 사양에 못따라갑니다.	1	저도 1번 추천입니다. ㅎ	0	저도 1번 추천합니다. 지금도 그렇게 사용하고 있구요...
104	업데이트: 많은 분들이 관심을 가져주시고 의견 주셔서 매우 감사합니다. DongPil Seo 님의 소개로 영국분을 소개받아 멋진 영국발음으로 우선 같이 진행해보겠습니다.대략: 영어선생님께서 글을 읽고, 이에 대한 설명과 영어의 표현들에 대해 재미있게 이야기 해보려고 합니다. 대략 한번 녹음해보고 여러분들에게 더많은 커멘트 부탁드리겠습니다.감사합니다.---[영어 선생님 계신가요?]혹시 저희 그룹에 또는 컴퓨터나 딥러닝에 관심이 있는 전/현직 영어 선생님이 계신지요? 일주일에 한번 정도 영어로된 문서를 원어민같은 발음으로 읽고 간략 해석과 문법적 설명 (영어 선생님) + 기술적인 설명 (Sung) 을 하는 코너를 만들어 보려고 합니다.개발자에게는 영어도 익히고 기술적 지식도 익히는 일거양득이 될것입니다.계시면 이글의 댓글이나 메시지 부탁드립니다. (혹시 주위에 아시는 영어 선생님 계시면 추천해주셔도 좋습니다.)	1	딥러닝에 관심있으신지는 모르겠지만 황지환 선생님.	2	저는 현직은 아닙니다만 학원에서 영어를 7년 정도 가르쳤습니다.	3	저도 영어를 가르친 적은 없지만 번역 프로젝트엔 참여해봤습니다!!	2	한국어를 매우 잘하는 외국인을 아는데 .. 꼭 선생님이어야 하나요? ~	3	Sumi Han 수미님 소환..ㅎㅎ	1	염화음 오클리?	2	Sung-il Kim 혹시 관심 있으세요?	2	제가 하고 싶습니다. 유학 시 방학때만 귀국해서 학원 강사했던 경험이 전부지만 현재 회사에서 제 분야에 딥러닝을 도입하려 노력중인만큼 제게도 좋은 기회가 될것 같습니다.	0	와우~~ 기대됩니다.^^
7	안녕하십니까.딥러닝 공부한지 얼마 안된 대학원생입니다.혹시 왜 Activation Function을 쓰는지 알 수 있을까요?왜 Activation Function을 써야 하는지 수학적 지식이 부족해서 잘 모르겠습니다.	6	예를 들어, 모든 hidden node, output node에서 activation function이 y = x (identity function) 이라면 output node에서 출력되는 값이 input들의 weighted sum이 되므로 비선형의 복잡한 관계를 모델링하는 것이 불가능합니다. 반대로 말하면, 비선형인 activation function을 썼을 때 복잡한 의사결정경계를 모델링하길 기대할 수 있겠죠. 직관적으로 설명드리면  이 정도로 말씀드릴 수 있겠네요.	1	모든 모델을 선형으로만 표현할수 없으니 비선형을 추가하는거죠	0	https://ko.m.wikipedia.org/wiki/%EA%B4%91%EC%A0%84_%ED%9A%A8%EA%B3%BC 가 쿨해서...	1	선형 함수만 쓰면 아무리 layer를 많이 써도 1 layer짜리로 동일하게 구현 가능합니다...XOR같은 건 아예 못풀죠^^	0	https://en.m.wikipedia.org/wiki/Universal_approximation_theorem
2	가입 승인 감사드립니다.Tensorflow를 처음 시작하려고 합니다.인공지능이라는 것의 여러 기법들에 대해서 수박 겉 핥기 식으로만 알고 있는 상태고 python은 기초정도는 할수 있습니다.참고할수있는 서적이나 싸이트가  있을까요?참고로 python은 버전 3.5를 사용하고 있습니다.	4	https://hunkim.github.io/ml/
74	안녕하세요, 버클리에서 자율주행차 연구를 하고 있는 학생입니다. TORCS와 GAN을 활용하여 트레이닝 하던중 Ian Goodfellow가 OpenAI에서 발표한 GAN 대해 구체적으로 설명한 tutorial형식의 white paper가 있어서 공유합니다. 	0	오 나이스 감사합니다 :)
7	2017년 R&D 사업에 19조 5천억 지원 한다.- IoT, 인공지능, 스마트 헬스케어, 정보보안, 청정에너지 및 기후변화 핵심기술 연구개발 등에	0	돈퍼주지말고 그돈으로 환경을 조성해주셨으면 합니다.
1	Rnn쪽은 쓸일이없어 이론공부및 backpropagation이런코드만짜보다가 텐서플로우를통해 Mnist분류  rnn 코드를 tf.transpose(x,[1.0.2])이 코드 정확히# transpose뒤의 [1,0,2]가 이해가안가네요# api읽어보고예시를봐도 정확한의미를모르겠다는‥‥알려주실분계신가요?	0	원래 매트릭스의 디멘션을 012순에서 102로 바꾼다는 겁니다 예를 들면 2x3x4 는 3x2x4가 되겠지요
2	가입신청 받아주셔서 감사합니다 ^-^제가 이번에 텐서플로우를 배우려고 하는데, 파이썬 2와 파이썬 3 버전이 있더라고요. 어떤 버전을 선택하는 게 좋을까요?	1	http://bfy.tw/9FIm	0	파이썬2는 수명이 2020까지 인걸로 압니다! 저는 파이썬3을 추천합니다	0	앞을보고 Python3로 가시면 될 것 같습니다. 기존 Python2 코드가 많지만, 유사하여 어느정도 변환이 가능합니다. 저 같은경우는 기본 python3로 하고 python2 환경 따로 만들어서 활용하고 있습니다.	0	다들 조언 감사합니닷!	0	윈도우를쓰시면 선택의 여지가 없이 python 3죠 아직은 ^^
4	혹시 우분투에 caffe 와 tensorflow 둘다 설치해서 사용하고 계시는분이 있는지 궁금하네요. 현재 우분투에서 caffe를 사용하고 있고 windows10에서 tensorflow를 사용하고 있는데 우분투로 옮겨가려고 하고 있습니다. 혹 충돌이 나진 않을까 괜한 걱정에 질문 드려요! ^^;;;	2	원래도별문제는없는데 걱정되시면 가상환경으로하시면돼요	1	Docker 사용해서 쓰고 이습니다	1	우분투 16.04 네이티브로 설치한 후 python의 virtualenv를 이용하여 각각 다른 가상환경에 TF_0.11과 caffe 설치했습니다. 충돌은 나지 않습니다.
7	2017년 새해 복 많이 받으세요![경력 채용공고 - 딥러닝 석.박사 과정 및 이수자 or 경력자]안녕하세요.저는 현재 학업에 전념하고 있는 대학원생이고요. 아래 기업에는 속해 있지 않음을 알려드리고, 같은 대학원생 분들 및 경력자 분들께 전달하고자 합니다.현재 머신러닝, 딥러닝-인공지능 관련 대학원 석.박사 과정 또는 이수자 분들께 도움이 되시지 않을까 하여 글을 남겨봅니다.(주)Wins 상무님의 채용공고 부탁(지인의 부탁)으로 글을 작성하게 되었습니다. Wins는 AnLab과 마찬가지로 국내 보안업계에서 TOP5 안에 들어가있는 보안회사입니다.현재 Wins에서 "머신러닝, 딥러닝 경력자 모집(관련 전공자 석.박사 우대 및 경력 인정)"을 하고 있습니다.부서는 개발부서이고, 직급과 연봉은 면접시 경력에 준하여 책정되겠습니다.세부 경력 및 업무내용은"해킹에 대한 미래예측위협 알고리즘 및 가치적 빅데이터 분석을 해본 경력자[딥러닝]", "분석가가 미들웨어시스템 안에 머리 분석 두뇌에 대한 알고리즘을 개발할 학자" 입니다.해당 직종으로 진로를 희망하시는 분들께, 도움이 되셨으면 합니다.관심 있으신 분들은 저에게 메일을 보내주시면 감사하겠습니다.sdy0621@gmail.com감사합니다.	1	윈스도 머신러닝에 대응하고 있군요, 멀리서 응원합니다 :-)
8	COURSERA에서 앤드류 응 교수님의 머신 러닝 강의를 듣고 있는 학생입니다. 다름이 아니라 아래 사진(강의 슬라이드)에서 u^t v = p * \\u\\ 부분이 이해가 가지 않아 질문 글을 올립니다.Inner product(projection)을 하면 그냥 p 값이어야 하는데 왜 u의 length를 곱하는 건가요?	0	고등학교 내적 에서 성분끼리곱한값도 내적으로 배웁니다	1	그냥 P는 내적된값이 아니라 v가 u위로 정사영된 값입니다. 식으로 나타내면 P=|v|cos(theta) 입니다	3	벡터를 좋아해서..끄적여봤어용...	5		2	수식 과정, 감사합니다.!! 좌표계 변환할때 내적을 projection으로 이용해서 했던게 기억속에 남아있어서 착각을 했네요. 이번 기회를 참고 삼아 벡터를 다시 한번 봐야겠네요.
36	유니코드도 알아두면 좋을 것 같아 간단히 정리	2	감사합니다. 근래에 .xlsx 파일을 python에서 처리하려니 유니코드 처리를 해야했습니다. 마침 호기심을 품고 있는데 감사합니다~	2	ㅎㅎ 늘 감사드립니다 Python에 대해 많이 알아가고 있습니다!
20	라스베이거스, 호텔 윈 라스 베이거스 전 객실에 '인공지능 아마존 에코' 설치- 모든 투숙객은 실내 조명과 온도 조정에서, TV 그리고 커튼 제어도 음성으로	0	이제 음성인식은 정말 우리생활로 성큼 다가왔군요. 에코음성인식도 아마 딥러닝 사용하겠지요?
6	SK-SM, 인공지능 서비스 나만의 비서 '에이브릴(SM-Aibril)' 공개- 왓슨 기반 인공지능 ‘Aibril(에이브릴)’과 SM엔터테인먼트의 셀러브리티 콘텐츠를 결합
2	안녕하세요, 신텍스넷을 한번 실행 시켜보려고 하는데, 전 과정은 모두 완료 했고 bazel도 0.43으로 최신버전 업그레이드 했고요.Tensorflow 공홈 가이드 대로 따라 하는데, 관련 과정에서 에러가 나네요.    git clone --recursive https://github.com/tensorflow/models.git  cd models/syntaxnet/tensorflow  ./configure  cd ..  bazel test syntaxnet/... util/utf8/...  # On Mac, run the following:  bazel test --linkopt=-headerpad_max_install_names \    syntaxnet/... util/utf8/..../configure 과정에서 관련 오류가 지속적으로 발생합니다. 혹시 유사한 경우를 경험 해 보았던 분이나, 어떻게 해결하시는지 아시는 분이 있을까요..?우분투는 16.04 모델입니다.아래는 오류에 대한 log파일입니다.Please specify the location of python. [Default is /home/ryan/anaconda2/bin/python]: Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] nNo Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N] nNo Hadoop File System support will be enabled for TensorFlowFound possible Python library paths:  /home/ryan  /home/ryan/pynaoqi-python2.7  /home/ryan/anaconda2/lib/python2.7/site-packagesPlease input the desired Python library path to use.  Default is [/home/ryan]/home/ryan/anaconda2/lib/python2.7/site-packagesDo you wish to build TensorFlow with GPU support? [y/N] yGPU support will be enabled for TensorFlowPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5.0Please specify the location where cuDNN 5.0 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: Invalid path to cuDNN  toolkit. Neither of the following two files can be found:/usr/local/cuda-8.0/lib64/libcudnn.so.5.0/usr/local/cuda-8.0/libcudnn.so.5.0.5.0Please specify the Cudnn version you want to use. [Leave empty to use system default]: Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: libcudnn.so resolves to libcudnn.5Please specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: "3.5,5.2"]: INFO: Options provided by the client:  Inherited 'common' options: --isatty=1 --terminal_columns=120INFO: Reading options for 'clean' from /home/ryan/git_ryan/models/syntaxnet/tensorflow/tools/bazel.rc:  Inherited 'build' options: --force_python=py2 --host_force_python=py2 --python2_path=/home/ryan/anaconda2/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --define PYTHON_BIN_PATH=/home/ryan/anaconda2/bin/python --spawn_strategy=standalone --genrule_strategy=standaloneINFO: Reading options for 'clean' from /etc/bazel.bazelrc:  Inherited 'build' options: --action_env=PATH --action_env=LD_LIBRARY_PATH --action_env=TMPDIR --test_env=PATH --test_env=LD_LIBRARY_PATHUnrecognized option: --action_env=PATHERROR: /home/ryan/git_ryan/models/syntaxnet/tensorflow/tensorflow/tensorflow.bzl:568:26: Traceback (most recent call last): File "/home/ryan/git_ryan/models/syntaxnet/tensorflow/tensorflow/tensorflow.bzl", line 562 rule(attrs = {"srcs": attr.label_list..."), <3 more arguments>)}, <2 more arguments>) File "/home/ryan/git_ryan/models/syntaxnet/tensorflow/tensorflow/tensorflow.bzl", line 568, in rule attr.label_list(cfg = "data", allow_files = True)expected ConfigurationTransition or NoneType for 'cfg' while calling label_list but got string instead: data.ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension file 'tensorflow/tensorflow.bzl' has errors.Configuration finished
85	Sung Kim  교수님 강의를 다 듣고, 이제 구현으로 넘어가려고 참고 서적을 몇권 사서 읽어봤는데, 거기에 대한 주관적인 서평입니다 참고하세요	0	'딥러닝 제대로 시작하기'를 출판한 제이펍에서 '알고리즘 중심의 머신러닝 가이드(제2판)'을 번역하였는데 이 책은 코드위주의 자세한 설명이 많습니다 ^^	1	좋은 길잡이 감사드립니다. 곧 나오는 큰거또한 리뷰해 주시고 계속적으로 리뷰에 주셔서 저같은 초보들에게 많은 가르침을 해주세요 ^^	0	MLP가 무슨약자인가요?	8	저 또한 전공이 이쪽 분야는 아니면서(저는 빅데이타 및 분산 컴퓨팅 쪽 전공입니다.) 실무를 하면서 공부해가는 1인으로서 주관적인 의견을 추가하자면(대협님 말고 처음 시작하시는 분들을 위한 컴멘트 입니다. ^^), 우선 머신러닝부터 다 보고 딥러닝을 시작하시는게 숲을 보는데 훨씬 도움이 된다! 입니다. Sung Kim  교수님 모두의 머신러닝 강의에 나오는 여러 기법 들 중 머신러닝분야에서 오래전부터 사용하던 기법들도 많이 나옵니다.(예를 들어 앙상블 모델 같은...k-fold 틱한 내용에 대한 언급도 강의에서 살짝 있었던것 같구요.) 그런 부분들이 딥러닝 책들에는 거의 언급이 안되거나 매우 짧게 언급되기 때문에, 그런 내용들에 대한 기본 지식을 머신러닝 분야에서 익히고 오는게 실 활용이나 응용, 그리고 기본적인 이해에도 많은 도움이 되는 것 같습니다. 대협님께서 딥러닝 책 관련 리뷰해주신것 처럼 머신러닝 분야도 4~5권의 책을 보는 것 보다, Coursera 의 제대로된 강의 2~3개 듣는 것이 훨씬 많은 도움이 되었습니다. 저는 존스홉킨스 대학의 머신러닝(7개월짜리..다소 길어요 TT)와 앤드류 웅 교수님의 머신러닝 강의를 들었었는데요. 딥러닝 넘어오기 전단계로 많은 도움이 되었습니다. 요즘 실무에 딥러닝을 조금씩 접목해가는 걸 해가고 있는데요. 실무에서는 딥러닝 까기 가기 전에 머신러닝 알고리즘에서 완결이 되거나, 기존 머신러닝과 딥러닝을 함께 (예를 들어 딥러닝의 전단계로 머신러닝으로 데이타의 전처리를 해주는 등의..) 쓰는 경우가 훨씬 현실세계에 맞는 듯한 느낌을 강하게 받고 있습니다.요즘 자연어 검색 및 Bot 등에 대한 프로젝트를 진행하고 있는데, 무작정 CNN 이나 RNN 을 쓰기 전에, Word2Vec( 심층 신경망은 아님.) , TF-IDF, linear-SVC 등으로 여러가지 전처리 모델을 만들어 주고 해당 전처리 모델들이 뱉어 주는 해당 문장에 대한 1차 Output 을 다양하게 활용하며 딥러닝 접근을 하는것이 여러가지로 훨씬 유리한 결과를 얻어 낼 수 있었습니다. (특히 한글은 아직 NLU가 완벽하지 않아서, 문장을 획일화 시키고 입력으로 넣어줌에 있어 저 알고리즘들이 큰 기여를 했었습니다.)
8	CNN 모델을 학습시킨후, 모델을 restore하는데 에러가 발생해서 도움을 구해 봅니다.리스토어 할때, 변수를 못 찾는거 같은데요.NotFoundError (see above for traceback): Tensor name "Variable_1/Adam" not found in checkpoint files /Users/terrycho/anaconda/work/cnn_session-1000.index  [[Node: save_4/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_recv_save_4/Const_0, save_4/RestoreV2_4/tensor_names, save_4/RestoreV2_4/shape_and_slices)]]이런 에러가 뜹니다.아래 노트북 링크인데, (에러 포함) 혹시 조언 주실 수 있으실까요?	1	노트북을 잘 몰라서 이렇게 되면 두개의 파일처럼 되는것인요? 그래프가 중복되는듯한.  첫번째 부분(파일)에서 (학습시작하기전에) restore한번 해보세요.	0	노트북이라 조금 애매하지만Build predication model and restore session 에서 tf.reset_default_graph() 부터 먼저 해주시고, saver.restore에서 파일이름에 있는 .index를 없애보시면 어떨까요?	0	모델저장이 안 되어 있거나 로딩 위치가 안 맞아도 저런 에러뜨기도 합니다	0	다른 라이브였긴했는데, 저장할때 로드할때 사용한 라이브러리 버전이 다를때 비슷한 에러가 발생했습니다.	0	모바일이라 제대로 보지는 못했지만 Adam 관련 변수인걸 보아... 혹시 optimizer를 adam 아닌거에서 adam으로 바꾸신건 아닌지요?	0	아. 원인을 찾았는데요 두가지 원인입니다.	0	첫번째는 텐서플로우 버전이 올라가면서 파일명 규칙이 바뀌었습니다. .index 를 아래와 같이 빼니 되네요.# prepare sessionsess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())saver = tf.train.Saver()saver.restore(sess, '/Users/terrycho/anaconda/work/cnn_session')	0	그래도 다시 실행하면 같은 에러가 나는데요. 앞의 Sung Kim 교수님이 말씀하신데로 그래프 중복 문제 같습니다. 파이썬 노트북 특성상 한번 코드를 실행 시키면 그 컨택스가 계속 남아 있어서 생기는 문제인데요. (그래프가 이미 메모리에 올라가 있어서 다시 실행하면 그래프가 중복됨).	1	파이썬 노트북(주피터) 커널을 리스타트 시키고 다시 실행하니 되네요.	0	조언들 감사드립니다. 지금 해결했습니다.	0	
11	안녕하세요! 새해 힘차게 시작하셨나요? ^^ 한빛미디어 도서 리뷰 이벤트 소개 드립니다. 따끈따근한 #밑바닥부터시작하는딥러닝 과 #딥러닝첫걸음 도 있습니다.관심과 참여 부탁 드립니다. 감사합니다!
2	안녕하세요! TF설치시 이렇게 뜨면서 설치가 안되는데 어떻게 하면 설치 가능해 질까요?	0	새로운 버진은 "$ pip install tensorflow" 하시면 됩니다. https://www.tensorflow.org/get_started/os_setup 참고하세요.	1	아마 우분투 버전이 낮아서 생기는 문제일 것 같네요. pip 버전을 올리는 방법을 찾아보시거나, 우분투 버전을 올리시는게 좋을 것 같아요
0	번역 리파지토리(https://github.com/tensorflowkorea/tensorflow-kr)에서 0.12.0에 해당하는 번역을 위한 브랜치는 따로 없을까요?
26	가끔 필요할것 같아서 정리했어요	1	감사합니다	1	저에게 아주 유용한 자료가 될것 같습니다. ^^ 감사합니다.
16	[TF KR 2차 오프라인 모임 포스터 세션 신청 안내] #10안녕하세요. TF KR 운영진 이지민입니다. TF KR 2차 오프라인모임의 포스터 세션을 한번 더 홍보드리고자 합니다!포스터 세션은 그동안 딥러닝 및 TensorFlow에 관해 공부한 내용을 다양하게 공유하고자 준비한 세션입니다.주제는 자유이며 그동안 공부했던 내용, 연구 주제 관련 내용, 연구 성과, 회사 소개 등 본인이 원하는 주제를 자유롭게 선택하여 준비해주시면 됩니다.포스터 세션 신청은 선착순 60명이며, 신청 후 포스터를 1/8(일)까지 주최측에 제출해주시면 출력하여 행사 당일 배포해드릴 예정입니다.아직 자리가 남아있으니, 혹시나 일반신청에 늦으신 분들의 많은 참여 부탁드리겠습니다! :)----------------------------------------------------------------------------- 신청방법: https://goo.gl/forms/jaDQpqjTUT3JG7202 (이 링크를 통해 양식에 맞게 신청해주시면 됩니다.)- 참가비: 무료- 포스터 제출 기한: 1/8 (일)* 포스터세션 발표자 전원에게는 구글 코리아에서 준비한 소정의 선물과 특별한 기념품을 드립니다.* 포스터세션은 포스터 발표자만 참여 가능합니다. 많은 분들을 모시고 싶으나 공간상 예산상 제약이 있는 점 이해를 부탁드립니다. ^^ ----------------------------------------------------------------------------참가 신청과 관련하여 문의 사항이 있으시면 본 글에 댓글로 달아주시면 안내해드리도록 하겠습니다. 감사합니다. :-)	0	금융 이상거래 탐지 관련해서 내년에 제출해 보겠습니나.. 금번은 준비가 부족해서..
35	CUDA 8.0 + caffe 프레임워크를 이용한 nvidia geforce 계열 그래픽카드 벤치마크 입니다. 실제 게임성능에서는 대역폭이나, 드라이버 최적화에 따라서 구세대 상위기종과 신세대 하위기종의 성능이 엎치락 뒤치락합니다만,딥러닝을 위한 연산능력 비교에서는 정말 자비없을정도로 무조건 최신 칩셋이 유리하군요, 연결된 링크에 있는 전력당 성능비까지 감안하면 무조건 새것을 사라고 밖에 권할수 없겠습니다	2	저는 어제 980ti 2개를 1080 2개로 업그레이드 했는데, 성능 향상이 5%미만이라서 실망이에요. NN의 구조나, 연산 종류등에 따라 성능 향상이 거의 안되는 경우도 있는거 같습니다. 어떤게 bottleneck이 된건지 감이 안잡히네요. CPU 사용율 50%, GPU 사용율 각 80% 정도 수준이고, GPU PCIE 사용율 50%미만 상황인데.. GPU 메모리 사용율도 50%수준이구요.
6	텐서플로우 관련 책을 한권 사서 볼려구 하느데요어떤 책이 적당할까요?	5	저희 운영진중 한분이 번역하고 추가 하신 텐서플로우 첫걸음이라는 책이 매우 인기 서적인것으로 알고 있습니다.
162	이미 보신 분들도 계시겠지만 NIPS2016 에 발표된 논문들의 구현이라고 합니다. 그런데 보니 TensorFlow 를 사용한 구현들이 매우 많습니다.(10개만 봤는데 그중 4개가 TF구현입니다.)- https://github.com/ajarai/fast-weights- https://github.com/deepmind/learning-to-learn (유명한 딥마인드의 런투런 구현)- https://github.com/tensorflow/models/tree/master/video_prediction- https://github.com/openai/weightnorm이 재미난 소스코드를 읽다보면 2017년이 금방 지나가게 될것 같습니다. :-)https://cdn.ampproject.org/c/s/amp.reddit.com/r/MachineLearning/comments/5hwqeb/project_all_code_implementations_for_nips_2016/	0	
5	[What Chatbots Can Learn from Pickup Artists]픽업아티스트들은 '매력적인/효과적인 대화 기술' 들을 끝없이 연구한 사람들이니, Dialogue Management를 설계하실 때 가장 기본적으로 이들의 전략을 참고해보면 좋을 것 같습니다.
6	머신러닝 초짜인데요 ㅎ.ㅎ.. 여러분들은 Learning rate의 값을 어떻게 잡으시나요?저는 요 Learning rate라는 계수를 여지껏 적당히 잡고 사용하였습니다. 그냥 너무 커서 Overshooting이 일어나지 않게 적당히 이 정도면 될거라 생각했었거든요..근데 방금전 Sigmoid 함수로 XOR 연산을 학습시키는데 놀라운 결과를 얻게 되었습니다. Learning rate의 값을 0.01로 잡으면 10000번 돌려도 cost가 0.6에서 멈춰 분류가 제대로 되지 않았고 0.1로 잡으면 0.01까지 내려가서 분류를 제대로 할 수 있게 되었습니다.아마 Learning rate의 값을 바꿔보지 않았다면 밤새 삽질을 했겠죠..어떻게 하면 적당한 Learning rate의 값을 한번에 알 수 있을까요?그리고 GradientDescent가 이렇게 Local minimum에 머무르는건 Sigmoid 함수의 모양과 연관이있나요? 제가 수학을 잘 못해서 ㅎㅎ.. 이렇게 여쭤봅니다.. 감사합니다	3	COURSERA에서 앤드류 응 교수님의 머신러닝 week6주차 강의를 보시는 것을 추천합니다!!	2	레이트가 너무 작으면 로컬 옵티멈에 빠질 수 있습니다. 너무 크면 옵티멈을 찾지 못하고 발산할 수 있구요. 값을 단계적으로 변화시키면서 학습결과를 지켜봐야합니다.	2	Learning rate를 너무 작게 잡아 학습이 끝나기 전에 수렴해서 그렇습니다. 크게 잡아도 발산해버리지요... 시그모이드 함수는 인터넷 찾아보시면 바로 확인할수 있습니다! 학습률은 수정해가면서 찾아가는 것으로 알고 있습니다. 그리고 Local optima에 빠지는건 시그모이드와 연관이 있다기보단 기울기따라 내려가는 Gradient Descent 방법의 문제와 연관있다고 생각합니다..	3	한번에 알아내는 방법은 아직 없고 cross validation을 써서 노가다로 확인해야 합니다. 만약 최적의 learning rate를 수학적으로 찾을 수 있는 방법을 만든다면 머신러닝계의 스타가 될겁니다.	2	Learning rate은 일반적으로 학습 반복 횟수에 따라 감소시켜주는 decay 기법을 사용합니다.
6	여기에 이런 질문을 올리는게 맞을지 모르겠습니다.GPU 서버를 구매하려고 하는데 예산은 부가세 빼고 2,500만원이 되고 주로 텍스트 데이터에 대한 단어벡터 및 분류모델 학습에 사용할 것 입니다.이미 여러곳에서 견적을 받아봤는데, GPU 서버에 대한 지식이 부족해서 비교를 하기가 어렵더라고요. 1. 비싸고 좋은 GPU를 쓰는게 좋은지 아니면 여러개의 GPU를 붙여서 쓰는게 좋은지가 궁금하고요.2. 메모리 대역폭에 대한 이슈가 높던데, 적어도 어느정도 이상은 되어야 한다 이런 기준점이 있는지 궁금합니다.3. 마지막으로 추천해주실만한 서버가 있다면 말씀해주시면 좋을것 같습니다.감사합니다.	1	일단은...  2500 정도  예산이면 조립 서버  급이겠네요..  gtx 1080 정도(gpu 메모리 8GB)가 시작으로는 괜찮으나...   추가적인 작업이나 테스트 를 위해서는 좀 더 고민을 해보셔야 합니다.   또한 4장 이상으로 연결 시  발생하는 열로 인한 성능 저하도 고려를 하셔야 합니다.최대 사용 전력량 또한 반드시 고려해 보셔야 하구요..  고민 만 많이 올려 드렸네요..	0	gpu의 메모리도 중요합니다. 트레이닝 시킬 모델에 따라 메모리 적은 gpu 여러장보다는 메모리 큰 그퓨 한 장이 더 유용할 경우도 있습니다.
13	의료용 빅데이터, 인공지능(AI) 기술이 적용된 의료기기 허가‧심사 절차 마련- 이번 가이드라인을 통해 빅데이터 및 인공지능 의료기기 개발 및 허가에 도움이
116	SangKil Park 님이 올려주신 포스트, Top 10 Python libraries of 2016 를 보니 TensorFlow가 무려 5위에 자리하고 있습니다.딥러닝/TensorFlow 는 이제 일반적인 프로그래밍의 기본 요소가 될것 같습니다. 즉 프로그래머라면 반드시 알아야 하는 상식이죠!이 블로그가 뽑은 10가지 리스트는 다음과 같습니다.1. Zappa2. Sanic + uvloop3. asyncpg4. boto35. TensorFlow*6. gym + universe7. Bokeh8. Blaze9. arrow10. hug	1	심지어 6위는 gym... 놀랍네요!
